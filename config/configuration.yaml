default:
  # General settings
  precision: 16                     # Use mixed precision (AMP) for GPU efficiency
  computation_device: "cpu"        # Changed to "cuda" for GPU
  random_seed: 42                   # Seed for reproducibility
  action_repeat: 2                  # Number of times actions are repeated
  total_training_steps: 1000000     # Total training steps
  evaluation_interval_steps: 10000  # Steps between evaluations
  evaluation_number_of_episodes: 5  # Number of episodes for evaluation
  training_episode_dir: ""          # Directory for training episodes
  evaluation_episode_dir: ""        # Directory for evaluation episodes
  batch_size: 32                    # Batch size (GPU can handle this)
  sequence_length: 50               # Length of sequences
  number_of_environments: 1         # Single environment setup
  compile_models: true              # Enable torch.compile for GPU speedup
  debug: true                       # Keep true for verbose logging

  # Logging
  logging_interval: 100             # Frequency of logging metrics
  log_video_predictions: true       # Visualize predictions

  # Optimizer settings
  optimizer_type: "adamw"           # Optimizer type
  model_learning_rate: 1e-4         # Learning rate for world model
  optimizer_epsilon: 1e-8           # Epsilon for stability
  gradient_clip_value: 100.0        # Global gradient clipping norm
  weight_decay_value: 1e-5          # Weight decay

  # Agent components
  actor:
    number_of_layers: 2
    distribution_type: "onehot"
    lr: 8e-5
    eps: 1e-8
    grad_clip: 10.0                 # Strict clipping for actor stability
    entropy: 0.1                    # Encourage exploration
    standard_deviation: 1.0
    minimum_standard_deviation: 0.1
    maximum_standard_deviation: 2.0
    temperature: 1.0
    unimix_ratio: 0.01
    output_scale: 1.0
    exploration_behavior: "random"

  critic:
    number_of_layers: 2
    distribution_type: "symlog_disc"
    lr: 8e-5
    eps: 1e-8
    grad_clip: 100.0
    use_slow_target: true
    slow_target_update_interval: 100
    slow_target_update_fraction: 0.005
    output_scale: 1.0

  # World model (RSSM) settings
  dynamics_stochastic_dimension: 32
  dynamics_deterministic_dimension: 200
  dynamics_hidden_units: 200
  dynamics_recurrent_depth: 1
  dynamics_use_discrete: true
  discrete_latent_num: 32
  discrete_latent_size: 32
  dynamics_mean_activation: "linear"
  dynamics_standard_deviation_activation: "softplus"
  dynamics_minimum_standard_deviation: 0.1
  unimix_ratio: 0.01
  initial_state_type: "zero"

  # Encoder/Decoder
  encoder:
    output_dimension: 1024
  decoder:
    dummy_parameter: null
    loss_scale: 1.0

  # Prediction heads
  reward_head:
    distribution_type: "symlog_disc"
    number_of_layers: 2
    output_scale: 1.0
    loss_scale: 0.5
  continuation_head:
    number_of_layers: 2
    output_scale: 1.0
    loss_scale: 0.1

  # Network settings
  units: 256
  activation_function: "relu"
  normalization_type: "layer"
  use_orthogonal_initialization: true

  # Training hyperparameters
  training_updates_per_forward: 1
  number_of_pretraining_updates: 1000
  exploration_termination_step: 50000
  discount_factor: 0.997
  discount_lambda: 0.95
  kl_free: 1.0
  dynamics_loss_scale: 6.0
  representation_loss_scale: 0.1
  gradient_head_keys: ["decoder"]
  imag_horizon: 15

  # Data augmentation
  augmentation_enabled: true
  augmentation_crop_size: 64

  # Miscellaneous
  use_state_mean_for_evaluation: true
  reward_EMA: false
  number_of_possible_actions: 2
  os_name: "posix"
  max_samples_per_epoch: 10000