--- Starting train_step at 2025-04-01 01:51:07 ---
Full starting_state: {'deter': tensor([[[ 0.0352, -0.1119, -0.0620,  ...,  0.1201, -0.0922, -0.1210],
         [-0.1722, -0.0129, -0.0634,  ..., -0.1149,  0.0056,  0.0726],
         [-0.1163, -0.0850, -0.1389,  ..., -0.0105,  0.0892, -0.1005],
         ...,
         [-0.0983,  0.0282, -0.1527,  ...,  0.1247, -0.1133,  0.0020],
         [ 0.0961, -0.0072, -0.1477,  ...,  0.0472, -0.1142, -0.0511],
         [-0.0707,  0.0724, -0.1346,  ...,  0.1964,  0.0364,  0.0822]],

        [[-0.1690,  0.1060,  0.0277,  ..., -0.0415, -0.0525, -0.0440],
         [-0.1518, -0.0055, -0.0227,  ...,  0.0241, -0.0119,  0.0891],
         [ 0.1351,  0.0044, -0.1024,  ...,  0.0689, -0.0133,  0.0490],
         ...,
         [ 0.1790,  0.0670,  0.0185,  ...,  0.0075, -0.0193,  0.0452],
         [ 0.0315,  0.0664, -0.0916,  ...,  0.0354,  0.0333, -0.1756],
         [-0.2157, -0.0775, -0.0286,  ...,  0.0988,  0.2034, -0.1735]],

        [[-0.0552, -0.0644, -0.0010,  ...,  0.1214, -0.1245,  0.1039],
         [ 0.0087, -0.0181, -0.1173,  ..., -0.0890, -0.0625,  0.1310],
         [ 0.0491, -0.0772, -0.1292,  ..., -0.0804, -0.1254,  0.1164],
         ...,
         [ 0.1692,  0.0989,  0.0015,  ...,  0.0193, -0.1226,  0.0564],
         [ 0.1054,  0.0683, -0.0277,  ...,  0.0694, -0.0988, -0.0757],
         [-0.0560, -0.0950, -0.0237,  ...,  0.0092,  0.0604, -0.0150]],

        [[-0.1263, -0.0572, -0.0573,  ...,  0.0090,  0.0176,  0.0810],
         [-0.0328,  0.0252,  0.0757,  ..., -0.1102, -0.0158, -0.0835],
         [-0.1828,  0.0529, -0.1223,  ...,  0.1514, -0.0538, -0.0209],
         ...,
         [-0.0289, -0.0041, -0.1470,  ...,  0.0249,  0.0466, -0.0854],
         [-0.1953, -0.0539, -0.1646,  ...,  0.0230,  0.0028, -0.0325],
         [-0.0676,  0.1172, -0.0741,  ..., -0.0730, -0.0413,  0.0426]]],
       grad_fn=<StackBackward0>), 'stoch': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 1.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 1., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]])}
train_step: Starting state deter shape: torch.Size([4, 10, 128])
train_step: Starting state stoch shape: torch.Size([4, 10, 1024])
After ensuring logits/stoch: {'deter': tensor([[[ 0.0352, -0.1119, -0.0620,  ...,  0.1201, -0.0922, -0.1210],
         [-0.1722, -0.0129, -0.0634,  ..., -0.1149,  0.0056,  0.0726],
         [-0.1163, -0.0850, -0.1389,  ..., -0.0105,  0.0892, -0.1005],
         ...,
         [-0.0983,  0.0282, -0.1527,  ...,  0.1247, -0.1133,  0.0020],
         [ 0.0961, -0.0072, -0.1477,  ...,  0.0472, -0.1142, -0.0511],
         [-0.0707,  0.0724, -0.1346,  ...,  0.1964,  0.0364,  0.0822]],

        [[-0.1690,  0.1060,  0.0277,  ..., -0.0415, -0.0525, -0.0440],
         [-0.1518, -0.0055, -0.0227,  ...,  0.0241, -0.0119,  0.0891],
         [ 0.1351,  0.0044, -0.1024,  ...,  0.0689, -0.0133,  0.0490],
         ...,
         [ 0.1790,  0.0670,  0.0185,  ...,  0.0075, -0.0193,  0.0452],
         [ 0.0315,  0.0664, -0.0916,  ...,  0.0354,  0.0333, -0.1756],
         [-0.2157, -0.0775, -0.0286,  ...,  0.0988,  0.2034, -0.1735]],

        [[-0.0552, -0.0644, -0.0010,  ...,  0.1214, -0.1245,  0.1039],
         [ 0.0087, -0.0181, -0.1173,  ..., -0.0890, -0.0625,  0.1310],
         [ 0.0491, -0.0772, -0.1292,  ..., -0.0804, -0.1254,  0.1164],
         ...,
         [ 0.1692,  0.0989,  0.0015,  ...,  0.0193, -0.1226,  0.0564],
         [ 0.1054,  0.0683, -0.0277,  ...,  0.0694, -0.0988, -0.0757],
         [-0.0560, -0.0950, -0.0237,  ...,  0.0092,  0.0604, -0.0150]],

        [[-0.1263, -0.0572, -0.0573,  ...,  0.0090,  0.0176,  0.0810],
         [-0.0328,  0.0252,  0.0757,  ..., -0.1102, -0.0158, -0.0835],
         [-0.1828,  0.0529, -0.1223,  ...,  0.1514, -0.0538, -0.0209],
         ...,
         [-0.0289, -0.0041, -0.1470,  ...,  0.0249,  0.0466, -0.0854],
         [-0.1953, -0.0539, -0.1646,  ...,  0.0230,  0.0028, -0.0325],
         [-0.0676,  0.1172, -0.0741,  ..., -0.0730, -0.0413,  0.0426]]],
       grad_fn=<StackBackward0>), 'stoch': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 1.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 1., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]]), 'logits': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]])}
train_step: Normalized hidden_state shape: torch.Size([1, 4, 128])
train_step: Normalized stoch shape: torch.Size([4, 1024])
train_step: Normalized deter shape: torch.Size([4, 128])
train_step: Post-imagine_trajectory: Imagined features shape: torch.Size([4, 15, 1152])
train_step: Post-imagine_trajectory: Imagined actions shape: torch.Size([4, 15, 2])
train_step: Post-imagine_trajectory: Imagined action indices shape: torch.Size([4, 15])
train_step: Post-imagine_trajectory: Imagined state deter shape: torch.Size([4, 15, 128])
train_step: Post-imagine_trajectory: Imagined state stoch shape: torch.Size([4, 15, 1024])
Reward shape: torch.Size([4, 15, 1]), Value shape: torch.Size([4, 15, 1]), Slow Value shape: torch.Size([4, 15, 1]), Discount shape: torch.Size([4, 15, 1, 1])
Return targets length: 15, First target shape: torch.Size([4, 4, 1])
train_step: Actor distribution shape: torch.Size([4, 15, 2])
train_step: Action log probabilities shape: torch.Size([4, 15])
train_step: Action log probabilities sample: tensor([[-0.3722, -0.8765],
        [-0.1756, -0.3148]], grad_fn=<SliceBackward0>)
train_step: Advantages shape: torch.Size([4, 4, 4, 15])
train_step: Advantages sample: tensor([[[[-1.0082, -1.0082, -1.0082, -1.0082, -1.0082, -1.0082, -1.0082,
           -1.0082, -1.0082, -1.0082, -1.0082, -1.0082, -1.0082, -1.0082,
           -1.0082],
          [-1.0082, -1.0082, -1.0082, -1.0082, -1.0082, -1.0082, -1.0082,
           -1.0082, -1.0082, -1.0082, -1.0082, -1.0082, -1.0082, -1.0082,
           -1.0082],
          [-4.4618, -4.4618, -4.4618, -4.4618, -4.4618, -4.4618, -4.4618,
           -4.4618, -4.4618, -4.4618, -4.4618, -4.4618, -4.4618, -4.4618,
           -4.4618],
          [-1.6936, -1.6936, -1.6936, -1.6936, -1.6936, -1.6936, -1.6936,
           -1.6936, -1.6936, -1.6936, -1.6936, -1.6936, -1.6936, -1.6936,
           -1.6936]],

         [[-0.7236, -0.7236, -0.7236, -0.7236, -0.7236, -0.7236, -0.7236,
           -0.7236, -0.7236, -0.7236, -0.7236, -0.7236, -0.7236, -0.7236,
           -0.7236],
          [-5.1817, -5.1817, -5.1817, -5.1817, -5.1817, -5.1817, -5.1817,
           -5.1817, -5.1817, -5.1817, -5.1817, -5.1817, -5.1817, -5.1817,
           -5.1817],
          [-3.6463, -3.6463, -3.6463, -3.6463, -3.6463, -3.6463, -3.6463,
           -3.6463, -3.6463, -3.6463, -3.6463, -3.6463, -3.6463, -3.6463,
           -3.6463],
          [-0.7236, -0.7236, -0.7236, -0.7236, -0.7236, -0.7236, -0.7236,
           -0.7236, -0.7236, -0.7236, -0.7236, -0.7236, -0.7236, -0.7236,
           -0.7236]]],


        [[[-1.3999, -1.3999, -1.3999, -1.3999, -1.3999, -1.3999, -1.3999,
           -1.3999, -1.3999, -1.3999, -1.3999, -1.3999, -1.3999, -1.3999,
           -1.3999],
          [-1.3999, -1.3999, -1.3999, -1.3999, -1.3999, -1.3999, -1.3999,
           -1.3999, -1.3999, -1.3999, -1.3999, -1.3999, -1.3999, -1.3999,
           -1.3999],
          [-3.3510, -3.3510, -3.3510, -3.3510, -3.3510, -3.3510, -3.3510,
           -3.3510, -3.3510, -3.3510, -3.3510, -3.3510, -3.3510, -3.3510,
           -3.3510],
          [-1.5850, -1.5850, -1.5850, -1.5850, -1.5850, -1.5850, -1.5850,
           -1.5850, -1.5850, -1.5850, -1.5850, -1.5850, -1.5850, -1.5850,
           -1.5850]],

         [[-0.1955, -0.1955, -0.1955, -0.1955, -0.1955, -0.1955, -0.1955,
           -0.1955, -0.1955, -0.1955, -0.1955, -0.1955, -0.1955, -0.1955,
           -0.1955],
          [-3.0447, -3.0447, -3.0447, -3.0447, -3.0447, -3.0447, -3.0447,
           -3.0447, -3.0447, -3.0447, -3.0447, -3.0447, -3.0447, -3.0447,
           -3.0447],
          [-2.0600, -2.0600, -2.0600, -2.0600, -2.0600, -2.0600, -2.0600,
           -2.0600, -2.0600, -2.0600, -2.0600, -2.0600, -2.0600, -2.0600,
           -2.0600],
          [-0.1955, -0.1955, -0.1955, -0.1955, -0.1955, -0.1955, -0.1955,
           -0.1955, -0.1955, -0.1955, -0.1955, -0.1955, -0.1955, -0.1955,
           -0.1955]]]], grad_fn=<SliceBackward0>)
train_step: Return scale: 1.0630628003180027
train_step: Scaled advantages shape: torch.Size([4, 4, 4, 15])
train_step: Scaled advantages sample: tensor([[[[-0.9484, -0.9484, -0.9484, -0.9484, -0.9484, -0.9484, -0.9484,
           -0.9484, -0.9484, -0.9484, -0.9484, -0.9484, -0.9484, -0.9484,
           -0.9484],
          [-0.9484, -0.9484, -0.9484, -0.9484, -0.9484, -0.9484, -0.9484,
           -0.9484, -0.9484, -0.9484, -0.9484, -0.9484, -0.9484, -0.9484,
           -0.9484],
          [-4.1971, -4.1971, -4.1971, -4.1971, -4.1971, -4.1971, -4.1971,
           -4.1971, -4.1971, -4.1971, -4.1971, -4.1971, -4.1971, -4.1971,
           -4.1971],
          [-1.5931, -1.5931, -1.5931, -1.5931, -1.5931, -1.5931, -1.5931,
           -1.5931, -1.5931, -1.5931, -1.5931, -1.5931, -1.5931, -1.5931,
           -1.5931]],

         [[-0.7236, -0.7236, -0.7236, -0.7236, -0.7236, -0.7236, -0.7236,
           -0.7236, -0.7236, -0.7236, -0.7236, -0.7236, -0.7236, -0.7236,
           -0.7236],
          [-4.8743, -4.8743, -4.8743, -4.8743, -4.8743, -4.8743, -4.8743,
           -4.8743, -4.8743, -4.8743, -4.8743, -4.8743, -4.8743, -4.8743,
           -4.8743],
          [-3.4300, -3.4300, -3.4300, -3.4300, -3.4300, -3.4300, -3.4300,
           -3.4300, -3.4300, -3.4300, -3.4300, -3.4300, -3.4300, -3.4300,
           -3.4300],
          [-0.7236, -0.7236, -0.7236, -0.7236, -0.7236, -0.7236, -0.7236,
           -0.7236, -0.7236, -0.7236, -0.7236, -0.7236, -0.7236, -0.7236,
           -0.7236]]],


        [[[-1.3168, -1.3168, -1.3168, -1.3168, -1.3168, -1.3168, -1.3168,
           -1.3168, -1.3168, -1.3168, -1.3168, -1.3168, -1.3168, -1.3168,
           -1.3168],
          [-1.3168, -1.3168, -1.3168, -1.3168, -1.3168, -1.3168, -1.3168,
           -1.3168, -1.3168, -1.3168, -1.3168, -1.3168, -1.3168, -1.3168,
           -1.3168],
          [-3.1522, -3.1522, -3.1522, -3.1522, -3.1522, -3.1522, -3.1522,
           -3.1522, -3.1522, -3.1522, -3.1522, -3.1522, -3.1522, -3.1522,
           -3.1522],
          [-1.4910, -1.4910, -1.4910, -1.4910, -1.4910, -1.4910, -1.4910,
           -1.4910, -1.4910, -1.4910, -1.4910, -1.4910, -1.4910, -1.4910,
           -1.4910]],

         [[-0.1955, -0.1955, -0.1955, -0.1955, -0.1955, -0.1955, -0.1955,
           -0.1955, -0.1955, -0.1955, -0.1955, -0.1955, -0.1955, -0.1955,
           -0.1955],
          [-2.8641, -2.8641, -2.8641, -2.8641, -2.8641, -2.8641, -2.8641,
           -2.8641, -2.8641, -2.8641, -2.8641, -2.8641, -2.8641, -2.8641,
           -2.8641],
          [-1.9378, -1.9378, -1.9378, -1.9378, -1.9378, -1.9378, -1.9378,
           -1.9378, -1.9378, -1.9378, -1.9378, -1.9378, -1.9378, -1.9378,
           -1.9378],
          [-0.1955, -0.1955, -0.1955, -0.1955, -0.1955, -0.1955, -0.1955,
           -0.1955, -0.1955, -0.1955, -0.1955, -0.1955, -0.1955, -0.1955,
           -0.1955]]]], grad_fn=<SliceBackward0>)
train_step: Entropy shape: torch.Size([4, 15])
train_step: Entropy sample: tensor([[0.6197, 0.6790],
        [0.4414, 0.5834]], grad_fn=<SliceBackward0>)
train_step: Entropy coefficient: 0.01
train_step: Actor loss: -1.633305311203003
train_step: returns shape after mean: torch.Size([4, 15])
train_step: target_indices shape: torch.Size([4, 15])
train_step: value_logits shape: torch.Size([4, 15, 255])
train_step: target_twohot shape: torch.Size([4, 15, 255])
--- Starting train_step at 2025-04-01 01:51:08 ---
Full starting_state: {'deter': tensor([[[ 1.5102e-01,  3.7750e-02, -5.7378e-02,  ..., -6.9296e-02,
           3.7908e-02, -9.9997e-02],
         [-4.6784e-02,  6.0073e-02, -7.9146e-02,  ..., -1.0525e-01,
          -7.6994e-02, -8.3514e-03],
         [ 1.0553e-01,  1.6321e-01,  2.0626e-02,  ..., -1.2285e-02,
          -1.0520e-01,  2.8885e-02],
         ...,
         [ 6.7621e-02,  1.3142e-05, -1.5396e-01,  ...,  3.4088e-03,
          -2.3851e-02, -4.3127e-02],
         [-2.2765e-01,  2.3713e-01, -1.1570e-01,  ...,  6.0290e-02,
           9.4457e-02, -2.6838e-02],
         [-7.6516e-02, -4.6784e-02,  4.6506e-02,  ..., -5.9397e-02,
          -5.7959e-02, -3.2732e-02]],

        [[-3.3707e-02,  1.4274e-01,  2.0140e-02,  ..., -2.1004e-02,
           7.7764e-02,  9.2445e-03],
         [-6.7594e-03,  1.3527e-02, -7.9089e-02,  ..., -1.5656e-01,
          -1.7513e-02, -6.9388e-02],
         [ 5.9084e-02, -1.1800e-02,  1.6712e-01,  ...,  1.3051e-01,
          -5.8184e-03,  3.2947e-02],
         ...,
         [-2.4399e-01, -1.4285e-02,  2.0806e-02,  ...,  1.7761e-02,
          -1.5699e-02, -3.4760e-02],
         [-5.9961e-02,  1.0174e-02,  1.9903e-01,  ...,  8.4634e-02,
           3.3558e-02,  6.6336e-02],
         [ 6.4929e-02, -2.9489e-02, -6.7362e-02,  ..., -1.1885e-01,
          -4.2316e-02,  3.4482e-02]],

        [[-3.1973e-02,  4.5018e-02, -5.7616e-02,  ...,  7.4471e-02,
           7.3416e-02, -3.7199e-02],
         [-6.4106e-02,  3.4813e-02, -3.2241e-02,  ..., -1.3373e-01,
          -1.6504e-01,  1.3152e-01],
         [ 2.4338e-02,  9.8941e-02,  2.1076e-02,  ...,  2.8119e-02,
          -1.7902e-02, -1.2864e-01],
         ...,
         [-5.2949e-02, -5.2822e-04,  1.7213e-01,  ...,  1.9075e-01,
           5.5172e-03, -1.5422e-02],
         [-2.7562e-02,  6.6297e-02, -6.6368e-02,  ...,  5.6924e-02,
           1.8924e-02, -4.4475e-02],
         [-7.7247e-02, -5.0066e-02,  3.3030e-02,  ..., -5.4495e-03,
           5.4240e-03,  3.8751e-02]],

        [[ 1.5013e-01,  2.8210e-02,  7.8132e-02,  ...,  1.7640e-02,
           6.1502e-02,  4.4420e-02],
         [ 4.5785e-02, -6.8110e-02, -3.8315e-02,  ..., -1.0583e-01,
           2.1102e-02, -1.1778e-01],
         [-3.8492e-01,  1.6928e-02, -1.9448e-02,  ..., -2.0418e-01,
          -1.0101e-01,  6.8681e-02],
         ...,
         [-1.3472e-01, -6.6417e-02,  1.2712e-01,  ..., -6.3980e-03,
           6.2265e-02,  3.6656e-02],
         [ 2.2073e-02,  1.1194e-01, -2.1827e-01,  ..., -6.3245e-02,
           2.5111e-02, -9.5556e-02],
         [-3.7376e-02, -1.0645e-01, -1.0255e-01,  ..., -1.2390e-01,
           1.1825e-01,  1.6901e-01]]], grad_fn=<StackBackward0>), 'stoch': tensor([[[0., 0., 0.,  ..., 0., 0., 1.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 1., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 1., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 1.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]])}
train_step: Starting state deter shape: torch.Size([4, 10, 128])
train_step: Starting state stoch shape: torch.Size([4, 10, 1024])
After ensuring logits/stoch: {'deter': tensor([[[ 1.5102e-01,  3.7750e-02, -5.7378e-02,  ..., -6.9296e-02,
           3.7908e-02, -9.9997e-02],
         [-4.6784e-02,  6.0073e-02, -7.9146e-02,  ..., -1.0525e-01,
          -7.6994e-02, -8.3514e-03],
         [ 1.0553e-01,  1.6321e-01,  2.0626e-02,  ..., -1.2285e-02,
          -1.0520e-01,  2.8885e-02],
         ...,
         [ 6.7621e-02,  1.3142e-05, -1.5396e-01,  ...,  3.4088e-03,
          -2.3851e-02, -4.3127e-02],
         [-2.2765e-01,  2.3713e-01, -1.1570e-01,  ...,  6.0290e-02,
           9.4457e-02, -2.6838e-02],
         [-7.6516e-02, -4.6784e-02,  4.6506e-02,  ..., -5.9397e-02,
          -5.7959e-02, -3.2732e-02]],

        [[-3.3707e-02,  1.4274e-01,  2.0140e-02,  ..., -2.1004e-02,
           7.7764e-02,  9.2445e-03],
         [-6.7594e-03,  1.3527e-02, -7.9089e-02,  ..., -1.5656e-01,
          -1.7513e-02, -6.9388e-02],
         [ 5.9084e-02, -1.1800e-02,  1.6712e-01,  ...,  1.3051e-01,
          -5.8184e-03,  3.2947e-02],
         ...,
         [-2.4399e-01, -1.4285e-02,  2.0806e-02,  ...,  1.7761e-02,
          -1.5699e-02, -3.4760e-02],
         [-5.9961e-02,  1.0174e-02,  1.9903e-01,  ...,  8.4634e-02,
           3.3558e-02,  6.6336e-02],
         [ 6.4929e-02, -2.9489e-02, -6.7362e-02,  ..., -1.1885e-01,
          -4.2316e-02,  3.4482e-02]],

        [[-3.1973e-02,  4.5018e-02, -5.7616e-02,  ...,  7.4471e-02,
           7.3416e-02, -3.7199e-02],
         [-6.4106e-02,  3.4813e-02, -3.2241e-02,  ..., -1.3373e-01,
          -1.6504e-01,  1.3152e-01],
         [ 2.4338e-02,  9.8941e-02,  2.1076e-02,  ...,  2.8119e-02,
          -1.7902e-02, -1.2864e-01],
         ...,
         [-5.2949e-02, -5.2822e-04,  1.7213e-01,  ...,  1.9075e-01,
           5.5172e-03, -1.5422e-02],
         [-2.7562e-02,  6.6297e-02, -6.6368e-02,  ...,  5.6924e-02,
           1.8924e-02, -4.4475e-02],
         [-7.7247e-02, -5.0066e-02,  3.3030e-02,  ..., -5.4495e-03,
           5.4240e-03,  3.8751e-02]],

        [[ 1.5013e-01,  2.8210e-02,  7.8132e-02,  ...,  1.7640e-02,
           6.1502e-02,  4.4420e-02],
         [ 4.5785e-02, -6.8110e-02, -3.8315e-02,  ..., -1.0583e-01,
           2.1102e-02, -1.1778e-01],
         [-3.8492e-01,  1.6928e-02, -1.9448e-02,  ..., -2.0418e-01,
          -1.0101e-01,  6.8681e-02],
         ...,
         [-1.3472e-01, -6.6417e-02,  1.2712e-01,  ..., -6.3980e-03,
           6.2265e-02,  3.6656e-02],
         [ 2.2073e-02,  1.1194e-01, -2.1827e-01,  ..., -6.3245e-02,
           2.5111e-02, -9.5556e-02],
         [-3.7376e-02, -1.0645e-01, -1.0255e-01,  ..., -1.2390e-01,
           1.1825e-01,  1.6901e-01]]], grad_fn=<StackBackward0>), 'stoch': tensor([[[0., 0., 0.,  ..., 0., 0., 1.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 1., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 1., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 1.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]]), 'logits': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]])}
train_step: Normalized hidden_state shape: torch.Size([1, 4, 128])
train_step: Normalized stoch shape: torch.Size([4, 1024])
train_step: Normalized deter shape: torch.Size([4, 128])
train_step: Post-imagine_trajectory: Imagined features shape: torch.Size([4, 15, 1152])
train_step: Post-imagine_trajectory: Imagined actions shape: torch.Size([4, 15, 2])
train_step: Post-imagine_trajectory: Imagined action indices shape: torch.Size([4, 15])
train_step: Post-imagine_trajectory: Imagined state deter shape: torch.Size([4, 15, 128])
train_step: Post-imagine_trajectory: Imagined state stoch shape: torch.Size([4, 15, 1024])
Reward shape: torch.Size([4, 15, 1]), Value shape: torch.Size([4, 15, 1]), Slow Value shape: torch.Size([4, 15, 1]), Discount shape: torch.Size([4, 15, 1, 1])
Return targets length: 15, First target shape: torch.Size([4, 4, 1])
train_step: Actor distribution shape: torch.Size([4, 15, 2])
train_step: Action log probabilities shape: torch.Size([4, 15])
train_step: Action log probabilities sample: tensor([[-0.1330, -0.3684],
        [-0.1210, -0.4242]], grad_fn=<SliceBackward0>)
train_step: Advantages shape: torch.Size([4, 4, 4, 15])
train_step: Advantages sample: tensor([[[[ -3.0615,  -3.0615,  -3.0615,  -3.0615,  -3.0615,  -3.0615,  -3.0615,
            -3.0615,  -3.0615,  -3.0615,  -3.0615,  -3.0615,  -3.0615,  -3.0615,
            -3.0615],
          [ -4.9676,  -4.9676,  -4.9676,  -4.9676,  -4.9676,  -4.9676,  -4.9676,
            -4.9676,  -4.9676,  -4.9676,  -4.9676,  -4.9676,  -4.9676,  -4.9676,
            -4.9676],
          [ -7.9763,  -7.9763,  -7.9763,  -7.9763,  -7.9763,  -7.9763,  -7.9763,
            -7.9763,  -7.9763,  -7.9763,  -7.9763,  -7.9763,  -7.9763,  -7.9763,
            -7.9763],
          [ -2.1032,  -2.1032,  -2.1032,  -2.1032,  -2.1032,  -2.1032,  -2.1032,
            -2.1032,  -2.1032,  -2.1032,  -2.1032,  -2.1032,  -2.1032,  -2.1032,
            -2.1032]],

         [[ -1.9891,  -1.9891,  -1.9891,  -1.9891,  -1.9891,  -1.9891,  -1.9891,
            -1.9891,  -1.9891,  -1.9891,  -1.9891,  -1.9891,  -1.9891,  -1.9891,
            -1.9891],
          [ -4.0015,  -4.0015,  -4.0015,  -4.0015,  -4.0015,  -4.0015,  -4.0015,
            -4.0015,  -4.0015,  -4.0015,  -4.0015,  -4.0015,  -4.0015,  -4.0015,
            -4.0015],
          [ -7.1781,  -7.1781,  -7.1781,  -7.1781,  -7.1781,  -7.1781,  -7.1781,
            -7.1781,  -7.1781,  -7.1781,  -7.1781,  -7.1781,  -7.1781,  -7.1781,
            -7.1781],
          [ -0.9773,  -0.9773,  -0.9773,  -0.9773,  -0.9773,  -0.9773,  -0.9773,
            -0.9773,  -0.9773,  -0.9773,  -0.9773,  -0.9773,  -0.9773,  -0.9773,
            -0.9773]]],


        [[[ -4.7921,  -4.7921,  -4.7921,  -4.7921,  -4.7921,  -4.7921,  -4.7921,
            -4.7921,  -4.7921,  -4.7921,  -4.7921,  -4.7921,  -4.7921,  -4.7921,
            -4.7921],
          [ -7.1674,  -7.1674,  -7.1674,  -7.1674,  -7.1674,  -7.1674,  -7.1674,
            -7.1674,  -7.1674,  -7.1674,  -7.1674,  -7.1674,  -7.1674,  -7.1674,
            -7.1674],
          [-10.2195, -10.2195, -10.2195, -10.2195, -10.2195, -10.2195, -10.2195,
           -10.2195, -10.2195, -10.2195, -10.2195, -10.2195, -10.2195, -10.2195,
           -10.2195],
          [ -1.2939,  -1.2939,  -1.2939,  -1.2939,  -1.2939,  -1.2939,  -1.2939,
            -1.2939,  -1.2939,  -1.2939,  -1.2939,  -1.2939,  -1.2939,  -1.2939,
            -1.2939]],

         [[ -4.4470,  -4.4470,  -4.4470,  -4.4470,  -4.4470,  -4.4470,  -4.4470,
            -4.4470,  -4.4470,  -4.4470,  -4.4470,  -4.4470,  -4.4470,  -4.4470,
            -4.4470],
          [ -6.9549,  -6.9549,  -6.9549,  -6.9549,  -6.9549,  -6.9549,  -6.9549,
            -6.9549,  -6.9549,  -6.9549,  -6.9549,  -6.9549,  -6.9549,  -6.9549,
            -6.9549],
          [-10.1773, -10.1773, -10.1773, -10.1773, -10.1773, -10.1773, -10.1773,
           -10.1773, -10.1773, -10.1773, -10.1773, -10.1773, -10.1773, -10.1773,
           -10.1773],
          [ -0.7536,  -0.7536,  -0.7536,  -0.7536,  -0.7536,  -0.7536,  -0.7536,
            -0.7536,  -0.7536,  -0.7536,  -0.7536,  -0.7536,  -0.7536,  -0.7536,
            -0.7536]]]], grad_fn=<SliceBackward0>)
train_step: Return scale: 1.14384719671458
train_step: Scaled advantages shape: torch.Size([4, 4, 4, 15])
train_step: Scaled advantages sample: tensor([[[[-2.6765, -2.6765, -2.6765, -2.6765, -2.6765, -2.6765, -2.6765,
           -2.6765, -2.6765, -2.6765, -2.6765, -2.6765, -2.6765, -2.6765,
           -2.6765],
          [-4.3429, -4.3429, -4.3429, -4.3429, -4.3429, -4.3429, -4.3429,
           -4.3429, -4.3429, -4.3429, -4.3429, -4.3429, -4.3429, -4.3429,
           -4.3429],
          [-6.9732, -6.9732, -6.9732, -6.9732, -6.9732, -6.9732, -6.9732,
           -6.9732, -6.9732, -6.9732, -6.9732, -6.9732, -6.9732, -6.9732,
           -6.9732],
          [-1.8387, -1.8387, -1.8387, -1.8387, -1.8387, -1.8387, -1.8387,
           -1.8387, -1.8387, -1.8387, -1.8387, -1.8387, -1.8387, -1.8387,
           -1.8387]],

         [[-1.7389, -1.7389, -1.7389, -1.7389, -1.7389, -1.7389, -1.7389,
           -1.7389, -1.7389, -1.7389, -1.7389, -1.7389, -1.7389, -1.7389,
           -1.7389],
          [-3.4983, -3.4983, -3.4983, -3.4983, -3.4983, -3.4983, -3.4983,
           -3.4983, -3.4983, -3.4983, -3.4983, -3.4983, -3.4983, -3.4983,
           -3.4983],
          [-6.2754, -6.2754, -6.2754, -6.2754, -6.2754, -6.2754, -6.2754,
           -6.2754, -6.2754, -6.2754, -6.2754, -6.2754, -6.2754, -6.2754,
           -6.2754],
          [-0.9773, -0.9773, -0.9773, -0.9773, -0.9773, -0.9773, -0.9773,
           -0.9773, -0.9773, -0.9773, -0.9773, -0.9773, -0.9773, -0.9773,
           -0.9773]]],


        [[[-4.1894, -4.1894, -4.1894, -4.1894, -4.1894, -4.1894, -4.1894,
           -4.1894, -4.1894, -4.1894, -4.1894, -4.1894, -4.1894, -4.1894,
           -4.1894],
          [-6.2660, -6.2660, -6.2660, -6.2660, -6.2660, -6.2660, -6.2660,
           -6.2660, -6.2660, -6.2660, -6.2660, -6.2660, -6.2660, -6.2660,
           -6.2660],
          [-8.9343, -8.9343, -8.9343, -8.9343, -8.9343, -8.9343, -8.9343,
           -8.9343, -8.9343, -8.9343, -8.9343, -8.9343, -8.9343, -8.9343,
           -8.9343],
          [-1.1312, -1.1312, -1.1312, -1.1312, -1.1312, -1.1312, -1.1312,
           -1.1312, -1.1312, -1.1312, -1.1312, -1.1312, -1.1312, -1.1312,
           -1.1312]],

         [[-3.8878, -3.8878, -3.8878, -3.8878, -3.8878, -3.8878, -3.8878,
           -3.8878, -3.8878, -3.8878, -3.8878, -3.8878, -3.8878, -3.8878,
           -3.8878],
          [-6.0802, -6.0802, -6.0802, -6.0802, -6.0802, -6.0802, -6.0802,
           -6.0802, -6.0802, -6.0802, -6.0802, -6.0802, -6.0802, -6.0802,
           -6.0802],
          [-8.8974, -8.8974, -8.8974, -8.8974, -8.8974, -8.8974, -8.8974,
           -8.8974, -8.8974, -8.8974, -8.8974, -8.8974, -8.8974, -8.8974,
           -8.8974],
          [-0.7536, -0.7536, -0.7536, -0.7536, -0.7536, -0.7536, -0.7536,
           -0.7536, -0.7536, -0.7536, -0.7536, -0.7536, -0.7536, -0.7536,
           -0.7536]]]], grad_fn=<SliceBackward0>)
train_step: Entropy shape: torch.Size([4, 15])
train_step: Entropy sample: tensor([[0.3759, 0.6176],
        [0.3547, 0.6447]], grad_fn=<SliceBackward0>)
train_step: Entropy coefficient: 0.01
train_step: Actor loss: -2.8740313053131104
train_step: returns shape after mean: torch.Size([4, 15])
train_step: target_indices shape: torch.Size([4, 15])
train_step: value_logits shape: torch.Size([4, 15, 255])
train_step: target_twohot shape: torch.Size([4, 15, 255])
--- Starting train_step at 2025-04-01 01:51:24 ---
Full starting_state: {'deter': tensor([[[ 2.9179e-02,  3.0765e-02, -7.3020e-02,  ...,  1.6128e-01,
          -1.8118e-01, -1.2303e-01],
         [-3.4177e-02, -1.0239e-01, -1.2609e-01,  ...,  1.8484e-01,
           5.7230e-02,  1.0851e-03],
         [-6.7434e-02, -9.3386e-02, -1.3628e-02,  ..., -4.4096e-02,
           6.9609e-02, -8.1116e-02],
         ...,
         [-1.8305e-02, -5.2068e-02,  1.8299e-02,  ...,  9.3804e-02,
          -2.8345e-03,  4.6281e-02],
         [ 4.3113e-02,  4.5468e-02, -2.2221e-01,  ..., -7.5438e-02,
          -1.3471e-02,  2.7222e-02],
         [ 2.6194e-02,  3.6925e-02, -4.5357e-02,  ..., -5.0046e-02,
           6.5378e-02,  4.2164e-02]],

        [[ 7.8822e-02,  1.8035e-02, -1.3825e-01,  ..., -6.4469e-02,
           1.0418e-02,  2.3924e-02],
         [-6.6902e-02, -7.2971e-02, -1.6209e-01,  ..., -1.0856e-01,
           9.0639e-02, -8.2872e-02],
         [-1.0013e-01,  4.1310e-02, -1.4754e-01,  ..., -2.6373e-02,
          -1.4440e-01,  6.2633e-03],
         ...,
         [-7.8759e-02, -5.3650e-02, -1.5882e-02,  ..., -6.7988e-02,
          -1.4545e-01, -1.1995e-02],
         [-1.8921e-02,  1.4263e-01, -1.0833e-01,  ...,  4.2801e-02,
           6.2313e-02,  1.1253e-02],
         [ 3.0858e-02,  7.6516e-02, -5.1415e-02,  ...,  1.2131e-01,
           4.5420e-02,  9.0360e-02]],

        [[ 9.7419e-02, -7.7367e-02, -4.9637e-02,  ...,  5.3537e-02,
           1.2771e-01, -9.0140e-02],
         [ 8.7303e-02, -5.9841e-02, -5.8404e-02,  ...,  1.0167e-01,
           1.0427e-02,  2.8762e-02],
         [-7.6355e-02, -8.3889e-02,  1.7628e-01,  ...,  8.8319e-02,
          -5.9744e-02, -5.9591e-02],
         ...,
         [-6.2019e-02, -3.4977e-03, -4.5505e-02,  ..., -7.1371e-04,
           7.3068e-05, -7.3095e-02],
         [-1.5608e-02, -9.0376e-02, -1.0705e-01,  ...,  8.4352e-02,
          -4.8599e-02, -8.6186e-02],
         [-9.2226e-02,  1.4090e-01, -1.6297e-03,  ...,  1.8432e-02,
          -3.4840e-02,  7.2604e-02]],

        ...,

        [[ 1.3370e-01, -8.5166e-03, -4.3025e-02,  ...,  6.1602e-02,
           1.5629e-01, -4.9820e-04],
         [-1.2033e-01, -5.8935e-02, -6.0950e-02,  ...,  2.3414e-02,
           1.6950e-01,  5.4209e-04],
         [-5.8933e-02, -1.3907e-02, -1.9069e-01,  ...,  8.4235e-02,
           4.1662e-02, -5.9526e-02],
         ...,
         [-1.3248e-01,  3.4866e-02, -3.8538e-02,  ...,  5.6246e-04,
           5.7559e-02, -7.5832e-02],
         [-5.8338e-02,  3.5016e-02,  5.5672e-03,  ..., -1.9975e-02,
           1.3752e-01, -6.1799e-02],
         [-1.3029e-01,  3.6342e-02, -2.9352e-02,  ...,  1.0065e-01,
          -5.4488e-02,  5.7332e-02]],

        [[-1.7635e-01, -2.9220e-02,  4.3112e-02,  ..., -9.5451e-02,
           1.0047e-01,  9.9368e-03],
         [-4.0172e-02,  2.6026e-03, -3.4924e-02,  ...,  1.2345e-01,
          -7.6300e-02, -1.7227e-01],
         [ 2.9415e-02,  4.4078e-02, -9.8091e-02,  ..., -9.7298e-02,
           1.3376e-01, -9.1258e-02],
         ...,
         [-1.2256e-01, -9.5706e-02, -2.4170e-02,  ..., -3.6912e-03,
           1.0005e-01, -5.2283e-02],
         [ 5.0540e-03, -1.1864e-01, -4.6927e-02,  ...,  2.1015e-01,
           8.5276e-03, -1.9820e-02],
         [-8.6832e-02, -1.2900e-01,  1.0748e-01,  ..., -5.4299e-02,
          -3.6257e-02, -1.6497e-02]],

        [[-1.5980e-02,  1.5397e-01, -6.8700e-02,  ...,  4.6499e-02,
          -6.9479e-02, -8.7991e-02],
         [ 6.8962e-02, -7.8890e-02, -1.3004e-03,  ..., -2.8579e-02,
           3.8113e-02,  1.8036e-01],
         [ 4.0412e-02,  1.6419e-01,  3.9638e-02,  ...,  1.3933e-01,
          -5.2749e-02,  6.0719e-02],
         ...,
         [-4.6161e-02,  1.1905e-01, -1.2923e-01,  ...,  8.3134e-02,
           4.1674e-02,  4.3666e-02],
         [ 8.1848e-02,  1.4881e-01, -2.4742e-01,  ..., -7.2398e-02,
          -1.0124e-01, -1.2258e-01],
         [-1.3751e-01,  5.5552e-02, -1.0719e-01,  ..., -4.7142e-02,
           6.5228e-02,  9.6798e-02]]], grad_fn=<StackBackward0>), 'stoch': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 1., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [1., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[1., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 1.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [1., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]])}
train_step: Starting state deter shape: torch.Size([16, 50, 128])
train_step: Starting state stoch shape: torch.Size([16, 50, 1024])
After ensuring logits/stoch: {'deter': tensor([[[ 2.9179e-02,  3.0765e-02, -7.3020e-02,  ...,  1.6128e-01,
          -1.8118e-01, -1.2303e-01],
         [-3.4177e-02, -1.0239e-01, -1.2609e-01,  ...,  1.8484e-01,
           5.7230e-02,  1.0851e-03],
         [-6.7434e-02, -9.3386e-02, -1.3628e-02,  ..., -4.4096e-02,
           6.9609e-02, -8.1116e-02],
         ...,
         [-1.8305e-02, -5.2068e-02,  1.8299e-02,  ...,  9.3804e-02,
          -2.8345e-03,  4.6281e-02],
         [ 4.3113e-02,  4.5468e-02, -2.2221e-01,  ..., -7.5438e-02,
          -1.3471e-02,  2.7222e-02],
         [ 2.6194e-02,  3.6925e-02, -4.5357e-02,  ..., -5.0046e-02,
           6.5378e-02,  4.2164e-02]],

        [[ 7.8822e-02,  1.8035e-02, -1.3825e-01,  ..., -6.4469e-02,
           1.0418e-02,  2.3924e-02],
         [-6.6902e-02, -7.2971e-02, -1.6209e-01,  ..., -1.0856e-01,
           9.0639e-02, -8.2872e-02],
         [-1.0013e-01,  4.1310e-02, -1.4754e-01,  ..., -2.6373e-02,
          -1.4440e-01,  6.2633e-03],
         ...,
         [-7.8759e-02, -5.3650e-02, -1.5882e-02,  ..., -6.7988e-02,
          -1.4545e-01, -1.1995e-02],
         [-1.8921e-02,  1.4263e-01, -1.0833e-01,  ...,  4.2801e-02,
           6.2313e-02,  1.1253e-02],
         [ 3.0858e-02,  7.6516e-02, -5.1415e-02,  ...,  1.2131e-01,
           4.5420e-02,  9.0360e-02]],

        [[ 9.7419e-02, -7.7367e-02, -4.9637e-02,  ...,  5.3537e-02,
           1.2771e-01, -9.0140e-02],
         [ 8.7303e-02, -5.9841e-02, -5.8404e-02,  ...,  1.0167e-01,
           1.0427e-02,  2.8762e-02],
         [-7.6355e-02, -8.3889e-02,  1.7628e-01,  ...,  8.8319e-02,
          -5.9744e-02, -5.9591e-02],
         ...,
         [-6.2019e-02, -3.4977e-03, -4.5505e-02,  ..., -7.1371e-04,
           7.3068e-05, -7.3095e-02],
         [-1.5608e-02, -9.0376e-02, -1.0705e-01,  ...,  8.4352e-02,
          -4.8599e-02, -8.6186e-02],
         [-9.2226e-02,  1.4090e-01, -1.6297e-03,  ...,  1.8432e-02,
          -3.4840e-02,  7.2604e-02]],

        ...,

        [[ 1.3370e-01, -8.5166e-03, -4.3025e-02,  ...,  6.1602e-02,
           1.5629e-01, -4.9820e-04],
         [-1.2033e-01, -5.8935e-02, -6.0950e-02,  ...,  2.3414e-02,
           1.6950e-01,  5.4209e-04],
         [-5.8933e-02, -1.3907e-02, -1.9069e-01,  ...,  8.4235e-02,
           4.1662e-02, -5.9526e-02],
         ...,
         [-1.3248e-01,  3.4866e-02, -3.8538e-02,  ...,  5.6246e-04,
           5.7559e-02, -7.5832e-02],
         [-5.8338e-02,  3.5016e-02,  5.5672e-03,  ..., -1.9975e-02,
           1.3752e-01, -6.1799e-02],
         [-1.3029e-01,  3.6342e-02, -2.9352e-02,  ...,  1.0065e-01,
          -5.4488e-02,  5.7332e-02]],

        [[-1.7635e-01, -2.9220e-02,  4.3112e-02,  ..., -9.5451e-02,
           1.0047e-01,  9.9368e-03],
         [-4.0172e-02,  2.6026e-03, -3.4924e-02,  ...,  1.2345e-01,
          -7.6300e-02, -1.7227e-01],
         [ 2.9415e-02,  4.4078e-02, -9.8091e-02,  ..., -9.7298e-02,
           1.3376e-01, -9.1258e-02],
         ...,
         [-1.2256e-01, -9.5706e-02, -2.4170e-02,  ..., -3.6912e-03,
           1.0005e-01, -5.2283e-02],
         [ 5.0540e-03, -1.1864e-01, -4.6927e-02,  ...,  2.1015e-01,
           8.5276e-03, -1.9820e-02],
         [-8.6832e-02, -1.2900e-01,  1.0748e-01,  ..., -5.4299e-02,
          -3.6257e-02, -1.6497e-02]],

        [[-1.5980e-02,  1.5397e-01, -6.8700e-02,  ...,  4.6499e-02,
          -6.9479e-02, -8.7991e-02],
         [ 6.8962e-02, -7.8890e-02, -1.3004e-03,  ..., -2.8579e-02,
           3.8113e-02,  1.8036e-01],
         [ 4.0412e-02,  1.6419e-01,  3.9638e-02,  ...,  1.3933e-01,
          -5.2749e-02,  6.0719e-02],
         ...,
         [-4.6161e-02,  1.1905e-01, -1.2923e-01,  ...,  8.3134e-02,
           4.1674e-02,  4.3666e-02],
         [ 8.1848e-02,  1.4881e-01, -2.4742e-01,  ..., -7.2398e-02,
          -1.0124e-01, -1.2258e-01],
         [-1.3751e-01,  5.5552e-02, -1.0719e-01,  ..., -4.7142e-02,
           6.5228e-02,  9.6798e-02]]], grad_fn=<StackBackward0>), 'stoch': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 1., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [1., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[1., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 1.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [1., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]]), 'logits': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]])}
train_step: Normalized hidden_state shape: torch.Size([1, 16, 128])
train_step: Normalized stoch shape: torch.Size([16, 1024])
train_step: Normalized deter shape: torch.Size([16, 128])
train_step: Post-imagine_trajectory: Imagined features shape: torch.Size([16, 15, 1152])
train_step: Post-imagine_trajectory: Imagined actions shape: torch.Size([16, 15, 2])
train_step: Post-imagine_trajectory: Imagined action indices shape: torch.Size([16, 15])
train_step: Post-imagine_trajectory: Imagined state deter shape: torch.Size([16, 15, 128])
train_step: Post-imagine_trajectory: Imagined state stoch shape: torch.Size([16, 15, 1024])
Reward shape: torch.Size([16, 15, 1]), Value shape: torch.Size([16, 15, 1]), Slow Value shape: torch.Size([16, 15, 1]), Discount shape: torch.Size([16, 15, 1, 1])
Return targets length: 15, First target shape: torch.Size([16, 16, 1])
train_step: Actor distribution shape: torch.Size([16, 15, 2])
train_step: Action log probabilities shape: torch.Size([16, 15])
train_step: Action log probabilities sample: tensor([[-1.1348, -0.5812],
        [-1.0762, -1.3032]], grad_fn=<SliceBackward0>)
train_step: Advantages shape: torch.Size([16, 15, 16, 15])
train_step: Advantages sample: tensor([[[[-1.3855, -1.3855, -1.3855, -1.3855, -1.3855, -1.3855, -1.3855,
           -1.3855, -1.3855, -1.3855, -1.3855, -1.3855, -1.3855, -1.3855,
           -1.3855],
          [-7.6510, -7.6510, -7.6510, -7.6510, -7.6510, -7.6510, -7.6510,
           -7.6510, -7.6510, -7.6510, -7.6510, -7.6510, -7.6510, -7.6510,
           -7.6510],
          [-5.9718, -5.9718, -5.9718, -5.9718, -5.9718, -5.9718, -5.9718,
           -5.9718, -5.9718, -5.9718, -5.9718, -5.9718, -5.9718, -5.9718,
           -5.9718],
          [-5.2613, -5.2613, -5.2613, -5.2613, -5.2613, -5.2613, -5.2613,
           -5.2613, -5.2613, -5.2613, -5.2613, -5.2613, -5.2613, -5.2613,
           -5.2613],
          [-7.1482, -7.1482, -7.1482, -7.1482, -7.1482, -7.1482, -7.1482,
           -7.1482, -7.1482, -7.1482, -7.1482, -7.1482, -7.1482, -7.1482,
           -7.1482],
          [-7.6510, -7.6510, -7.6510, -7.6510, -7.6510, -7.6510, -7.6510,
           -7.6510, -7.6510, -7.6510, -7.6510, -7.6510, -7.6510, -7.6510,
           -7.6510],
          [-5.3769, -5.3769, -5.3769, -5.3769, -5.3769, -5.3769, -5.3769,
           -5.3769, -5.3769, -5.3769, -5.3769, -5.3769, -5.3769, -5.3769,
           -5.3769],
          [-6.2270, -6.2270, -6.2270, -6.2270, -6.2270, -6.2270, -6.2270,
           -6.2270, -6.2270, -6.2270, -6.2270, -6.2270, -6.2270, -6.2270,
           -6.2270],
          [-2.5748, -2.5748, -2.5748, -2.5748, -2.5748, -2.5748, -2.5748,
           -2.5748, -2.5748, -2.5748, -2.5748, -2.5748, -2.5748, -2.5748,
           -2.5748],
          [-7.6510, -7.6510, -7.6510, -7.6510, -7.6510, -7.6510, -7.6510,
           -7.6510, -7.6510, -7.6510, -7.6510, -7.6510, -7.6510, -7.6510,
           -7.6510],
          [-1.0178, -1.0178, -1.0178, -1.0178, -1.0178, -1.0178, -1.0178,
           -1.0178, -1.0178, -1.0178, -1.0178, -1.0178, -1.0178, -1.0178,
           -1.0178],
          [-7.6510, -7.6510, -7.6510, -7.6510, -7.6510, -7.6510, -7.6510,
           -7.6510, -7.6510, -7.6510, -7.6510, -7.6510, -7.6510, -7.6510,
           -7.6510],
          [-6.2270, -6.2270, -6.2270, -6.2270, -6.2270, -6.2270, -6.2270,
           -6.2270, -6.2270, -6.2270, -6.2270, -6.2270, -6.2270, -6.2270,
           -6.2270],
          [-1.0178, -1.0178, -1.0178, -1.0178, -1.0178, -1.0178, -1.0178,
           -1.0178, -1.0178, -1.0178, -1.0178, -1.0178, -1.0178, -1.0178,
           -1.0178],
          [-1.3855, -1.3855, -1.3855, -1.3855, -1.3855, -1.3855, -1.3855,
           -1.3855, -1.3855, -1.3855, -1.3855, -1.3855, -1.3855, -1.3855,
           -1.3855],
          [-1.0178, -1.0178, -1.0178, -1.0178, -1.0178, -1.0178, -1.0178,
           -1.0178, -1.0178, -1.0178, -1.0178, -1.0178, -1.0178, -1.0178,
           -1.0178]],

         [[-0.3882, -0.3882, -0.3882, -0.3882, -0.3882, -0.3882, -0.3882,
           -0.3882, -0.3882, -0.3882, -0.3882, -0.3882, -0.3882, -0.3882,
           -0.3882],
          [-7.0033, -7.0033, -7.0033, -7.0033, -7.0033, -7.0033, -7.0033,
           -7.0033, -7.0033, -7.0033, -7.0033, -7.0033, -7.0033, -7.0033,
           -7.0033],
          [-5.2304, -5.2304, -5.2304, -5.2304, -5.2304, -5.2304, -5.2304,
           -5.2304, -5.2304, -5.2304, -5.2304, -5.2304, -5.2304, -5.2304,
           -5.2304],
          [-4.4802, -4.4802, -4.4802, -4.4802, -4.4802, -4.4802, -4.4802,
           -4.4802, -4.4802, -4.4802, -4.4802, -4.4802, -4.4802, -4.4802,
           -4.4802],
          [-6.4724, -6.4724, -6.4724, -6.4724, -6.4724, -6.4724, -6.4724,
           -6.4724, -6.4724, -6.4724, -6.4724, -6.4724, -6.4724, -6.4724,
           -6.4724],
          [-7.0033, -7.0033, -7.0033, -7.0033, -7.0033, -7.0033, -7.0033,
           -7.0033, -7.0033, -7.0033, -7.0033, -7.0033, -7.0033, -7.0033,
           -7.0033],
          [-4.6023, -4.6023, -4.6023, -4.6023, -4.6023, -4.6023, -4.6023,
           -4.6023, -4.6023, -4.6023, -4.6023, -4.6023, -4.6023, -4.6023,
           -4.6023],
          [-5.4998, -5.4998, -5.4998, -5.4998, -5.4998, -5.4998, -5.4998,
           -5.4998, -5.4998, -5.4998, -5.4998, -5.4998, -5.4998, -5.4998,
           -5.4998],
          [-1.6438, -1.6438, -1.6438, -1.6438, -1.6438, -1.6438, -1.6438,
           -1.6438, -1.6438, -1.6438, -1.6438, -1.6438, -1.6438, -1.6438,
           -1.6438],
          [-7.0033, -7.0033, -7.0033, -7.0033, -7.0033, -7.0033, -7.0033,
           -7.0033, -7.0033, -7.0033, -7.0033, -7.0033, -7.0033, -7.0033,
           -7.0033],
          [-1.6438, -1.6438, -1.6438, -1.6438, -1.6438, -1.6438, -1.6438,
           -1.6438, -1.6438, -1.6438, -1.6438, -1.6438, -1.6438, -1.6438,
           -1.6438],
          [-7.0033, -7.0033, -7.0033, -7.0033, -7.0033, -7.0033, -7.0033,
           -7.0033, -7.0033, -7.0033, -7.0033, -7.0033, -7.0033, -7.0033,
           -7.0033],
          [-5.4998, -5.4998, -5.4998, -5.4998, -5.4998, -5.4998, -5.4998,
           -5.4998, -5.4998, -5.4998, -5.4998, -5.4998, -5.4998, -5.4998,
           -5.4998],
          [-3.6747, -3.6747, -3.6747, -3.6747, -3.6747, -3.6747, -3.6747,
           -3.6747, -3.6747, -3.6747, -3.6747, -3.6747, -3.6747, -3.6747,
           -3.6747],
          [-0.3882, -0.3882, -0.3882, -0.3882, -0.3882, -0.3882, -0.3882,
           -0.3882, -0.3882, -0.3882, -0.3882, -0.3882, -0.3882, -0.3882,
           -0.3882],
          [-1.6438, -1.6438, -1.6438, -1.6438, -1.6438, -1.6438, -1.6438,
           -1.6438, -1.6438, -1.6438, -1.6438, -1.6438, -1.6438, -1.6438,
           -1.6438]]],


        [[[-1.1125, -1.1125, -1.1125, -1.1125, -1.1125, -1.1125, -1.1125,
           -1.1125, -1.1125, -1.1125, -1.1125, -1.1125, -1.1125, -1.1125,
           -1.1125],
          [-7.5026, -7.5026, -7.5026, -7.5026, -7.5026, -7.5026, -7.5026,
           -7.5026, -7.5026, -7.5026, -7.5026, -7.5026, -7.5026, -7.5026,
           -7.5026],
          [-5.9947, -5.9947, -5.9947, -5.9947, -5.9947, -5.9947, -5.9947,
           -5.9947, -5.9947, -5.9947, -5.9947, -5.9947, -5.9947, -5.9947,
           -5.9947],
          [-4.9048, -4.9048, -4.9048, -4.9048, -4.9048, -4.9048, -4.9048,
           -4.9048, -4.9048, -4.9048, -4.9048, -4.9048, -4.9048, -4.9048,
           -4.9048],
          [-7.0502, -7.0502, -7.0502, -7.0502, -7.0502, -7.0502, -7.0502,
           -7.0502, -7.0502, -7.0502, -7.0502, -7.0502, -7.0502, -7.0502,
           -7.0502],
          [-7.5026, -7.5026, -7.5026, -7.5026, -7.5026, -7.5026, -7.5026,
           -7.5026, -7.5026, -7.5026, -7.5026, -7.5026, -7.5026, -7.5026,
           -7.5026],
          [-5.5838, -5.5838, -5.5838, -5.5838, -5.5838, -5.5838, -5.5838,
           -5.5838, -5.5838, -5.5838, -5.5838, -5.5838, -5.5838, -5.5838,
           -5.5838],
          [-6.4987, -6.4987, -6.4987, -6.4987, -6.4987, -6.4987, -6.4987,
           -6.4987, -6.4987, -6.4987, -6.4987, -6.4987, -6.4987, -6.4987,
           -6.4987],
          [-2.3631, -2.3631, -2.3631, -2.3631, -2.3631, -2.3631, -2.3631,
           -2.3631, -2.3631, -2.3631, -2.3631, -2.3631, -2.3631, -2.3631,
           -2.3631],
          [-7.5026, -7.5026, -7.5026, -7.5026, -7.5026, -7.5026, -7.5026,
           -7.5026, -7.5026, -7.5026, -7.5026, -7.5026, -7.5026, -7.5026,
           -7.5026],
          [-0.6185, -0.6185, -0.6185, -0.6185, -0.6185, -0.6185, -0.6185,
           -0.6185, -0.6185, -0.6185, -0.6185, -0.6185, -0.6185, -0.6185,
           -0.6185],
          [-7.5026, -7.5026, -7.5026, -7.5026, -7.5026, -7.5026, -7.5026,
           -7.5026, -7.5026, -7.5026, -7.5026, -7.5026, -7.5026, -7.5026,
           -7.5026],
          [-6.4987, -6.4987, -6.4987, -6.4987, -6.4987, -6.4987, -6.4987,
           -6.4987, -6.4987, -6.4987, -6.4987, -6.4987, -6.4987, -6.4987,
           -6.4987],
          [-0.6185, -0.6185, -0.6185, -0.6185, -0.6185, -0.6185, -0.6185,
           -0.6185, -0.6185, -0.6185, -0.6185, -0.6185, -0.6185, -0.6185,
           -0.6185],
          [-1.1125, -1.1125, -1.1125, -1.1125, -1.1125, -1.1125, -1.1125,
           -1.1125, -1.1125, -1.1125, -1.1125, -1.1125, -1.1125, -1.1125,
           -1.1125],
          [-0.6185, -0.6185, -0.6185, -0.6185, -0.6185, -0.6185, -0.6185,
           -0.6185, -0.6185, -0.6185, -0.6185, -0.6185, -0.6185, -0.6185,
           -0.6185]],

         [[-0.5215, -0.5215, -0.5215, -0.5215, -0.5215, -0.5215, -0.5215,
           -0.5215, -0.5215, -0.5215, -0.5215, -0.5215, -0.5215, -0.5215,
           -0.5215],
          [-7.2683, -7.2683, -7.2683, -7.2683, -7.2683, -7.2683, -7.2683,
           -7.2683, -7.2683, -7.2683, -7.2683, -7.2683, -7.2683, -7.2683,
           -7.2683],
          [-5.6762, -5.6762, -5.6762, -5.6762, -5.6762, -5.6762, -5.6762,
           -5.6762, -5.6762, -5.6762, -5.6762, -5.6762, -5.6762, -5.6762,
           -5.6762],
          [-4.5255, -4.5255, -4.5255, -4.5255, -4.5255, -4.5255, -4.5255,
           -4.5255, -4.5255, -4.5255, -4.5255, -4.5255, -4.5255, -4.5255,
           -4.5255],
          [-6.7906, -6.7906, -6.7906, -6.7906, -6.7906, -6.7906, -6.7906,
           -6.7906, -6.7906, -6.7906, -6.7906, -6.7906, -6.7906, -6.7906,
           -6.7906],
          [-7.2683, -7.2683, -7.2683, -7.2683, -7.2683, -7.2683, -7.2683,
           -7.2683, -7.2683, -7.2683, -7.2683, -7.2683, -7.2683, -7.2683,
           -7.2683],
          [-5.2423, -5.2423, -5.2423, -5.2423, -5.2423, -5.2423, -5.2423,
           -5.2423, -5.2423, -5.2423, -5.2423, -5.2423, -5.2423, -5.2423,
           -5.2423],
          [-6.2082, -6.2082, -6.2082, -6.2082, -6.2082, -6.2082, -6.2082,
           -6.2082, -6.2082, -6.2082, -6.2082, -6.2082, -6.2082, -6.2082,
           -6.2082],
          [-1.8419, -1.8419, -1.8419, -1.8419, -1.8420, -1.8419, -1.8420,
           -1.8419, -1.8419, -1.8419, -1.8419, -1.8419, -1.8419, -1.8419,
           -1.8419],
          [-7.2683, -7.2683, -7.2683, -7.2683, -7.2683, -7.2683, -7.2683,
           -7.2683, -7.2683, -7.2683, -7.2683, -7.2683, -7.2683, -7.2683,
           -7.2683],
          [-1.8419, -1.8419, -1.8419, -1.8419, -1.8420, -1.8419, -1.8420,
           -1.8419, -1.8419, -1.8419, -1.8419, -1.8419, -1.8419, -1.8419,
           -1.8419],
          [-7.2683, -7.2683, -7.2683, -7.2683, -7.2683, -7.2683, -7.2683,
           -7.2683, -7.2683, -7.2683, -7.2683, -7.2683, -7.2683, -7.2683,
           -7.2683],
          [-6.2082, -6.2082, -6.2082, -6.2082, -6.2082, -6.2082, -6.2082,
           -6.2082, -6.2082, -6.2082, -6.2082, -6.2082, -6.2082, -6.2082,
           -6.2082],
          [-3.9188, -3.9188, -3.9188, -3.9188, -3.9188, -3.9188, -3.9188,
           -3.9188, -3.9188, -3.9188, -3.9188, -3.9188, -3.9188, -3.9188,
           -3.9188],
          [-0.5215, -0.5215, -0.5215, -0.5215, -0.5215, -0.5215, -0.5215,
           -0.5215, -0.5215, -0.5215, -0.5215, -0.5215, -0.5215, -0.5215,
           -0.5215],
          [-1.8419, -1.8419, -1.8419, -1.8419, -1.8420, -1.8419, -1.8420,
           -1.8419, -1.8419, -1.8419, -1.8419, -1.8419, -1.8419, -1.8419,
           -1.8419]]]], grad_fn=<SliceBackward0>)
train_step: Return scale: 1.1960727083904892
train_step: Scaled advantages shape: torch.Size([16, 15, 16, 15])
train_step: Scaled advantages sample: tensor([[[[-1.1584, -1.1584, -1.1584, -1.1584, -1.1584, -1.1584, -1.1584,
           -1.1584, -1.1584, -1.1584, -1.1584, -1.1584, -1.1584, -1.1584,
           -1.1584],
          [-6.3968, -6.3968, -6.3968, -6.3968, -6.3968, -6.3968, -6.3968,
           -6.3968, -6.3968, -6.3968, -6.3968, -6.3968, -6.3968, -6.3968,
           -6.3968],
          [-4.9928, -4.9928, -4.9928, -4.9928, -4.9928, -4.9928, -4.9928,
           -4.9928, -4.9928, -4.9928, -4.9928, -4.9928, -4.9928, -4.9928,
           -4.9928],
          [-4.3988, -4.3988, -4.3988, -4.3988, -4.3988, -4.3988, -4.3988,
           -4.3988, -4.3988, -4.3988, -4.3988, -4.3988, -4.3988, -4.3988,
           -4.3988],
          [-5.9764, -5.9764, -5.9764, -5.9764, -5.9764, -5.9764, -5.9764,
           -5.9764, -5.9764, -5.9764, -5.9764, -5.9764, -5.9764, -5.9764,
           -5.9764],
          [-6.3968, -6.3968, -6.3968, -6.3968, -6.3968, -6.3968, -6.3968,
           -6.3968, -6.3968, -6.3968, -6.3968, -6.3968, -6.3968, -6.3968,
           -6.3968],
          [-4.4955, -4.4955, -4.4955, -4.4955, -4.4955, -4.4955, -4.4955,
           -4.4955, -4.4955, -4.4955, -4.4955, -4.4955, -4.4955, -4.4955,
           -4.4955],
          [-5.2062, -5.2062, -5.2062, -5.2062, -5.2062, -5.2062, -5.2062,
           -5.2062, -5.2062, -5.2062, -5.2062, -5.2062, -5.2062, -5.2062,
           -5.2062],
          [-2.1527, -2.1527, -2.1527, -2.1527, -2.1527, -2.1527, -2.1527,
           -2.1527, -2.1527, -2.1527, -2.1527, -2.1527, -2.1527, -2.1527,
           -2.1527],
          [-6.3968, -6.3968, -6.3968, -6.3968, -6.3968, -6.3968, -6.3968,
           -6.3968, -6.3968, -6.3968, -6.3968, -6.3968, -6.3968, -6.3968,
           -6.3968],
          [-0.8510, -0.8510, -0.8510, -0.8510, -0.8510, -0.8510, -0.8510,
           -0.8510, -0.8510, -0.8510, -0.8510, -0.8510, -0.8510, -0.8510,
           -0.8510],
          [-6.3968, -6.3968, -6.3968, -6.3968, -6.3968, -6.3968, -6.3968,
           -6.3968, -6.3968, -6.3968, -6.3968, -6.3968, -6.3968, -6.3968,
           -6.3968],
          [-5.2062, -5.2062, -5.2062, -5.2062, -5.2062, -5.2062, -5.2062,
           -5.2062, -5.2062, -5.2062, -5.2062, -5.2062, -5.2062, -5.2062,
           -5.2062],
          [-0.8510, -0.8510, -0.8510, -0.8510, -0.8510, -0.8510, -0.8510,
           -0.8510, -0.8510, -0.8510, -0.8510, -0.8510, -0.8510, -0.8510,
           -0.8510],
          [-1.1584, -1.1584, -1.1584, -1.1584, -1.1584, -1.1584, -1.1584,
           -1.1584, -1.1584, -1.1584, -1.1584, -1.1584, -1.1584, -1.1584,
           -1.1584],
          [-0.8510, -0.8510, -0.8510, -0.8510, -0.8510, -0.8510, -0.8510,
           -0.8510, -0.8510, -0.8510, -0.8510, -0.8510, -0.8510, -0.8510,
           -0.8510]],

         [[-0.3882, -0.3882, -0.3882, -0.3882, -0.3882, -0.3882, -0.3882,
           -0.3882, -0.3882, -0.3882, -0.3882, -0.3882, -0.3882, -0.3882,
           -0.3882],
          [-5.8553, -5.8553, -5.8553, -5.8553, -5.8553, -5.8553, -5.8553,
           -5.8553, -5.8553, -5.8553, -5.8553, -5.8553, -5.8553, -5.8553,
           -5.8553],
          [-4.3729, -4.3729, -4.3729, -4.3729, -4.3729, -4.3729, -4.3729,
           -4.3729, -4.3729, -4.3729, -4.3729, -4.3729, -4.3729, -4.3729,
           -4.3729],
          [-3.7458, -3.7458, -3.7458, -3.7458, -3.7458, -3.7458, -3.7458,
           -3.7458, -3.7458, -3.7458, -3.7458, -3.7458, -3.7458, -3.7458,
           -3.7458],
          [-5.4114, -5.4114, -5.4114, -5.4114, -5.4114, -5.4114, -5.4114,
           -5.4114, -5.4114, -5.4114, -5.4114, -5.4114, -5.4114, -5.4114,
           -5.4114],
          [-5.8553, -5.8553, -5.8553, -5.8553, -5.8553, -5.8553, -5.8553,
           -5.8553, -5.8553, -5.8553, -5.8553, -5.8553, -5.8553, -5.8553,
           -5.8553],
          [-3.8479, -3.8479, -3.8479, -3.8479, -3.8479, -3.8479, -3.8479,
           -3.8479, -3.8479, -3.8479, -3.8479, -3.8479, -3.8479, -3.8479,
           -3.8479],
          [-4.5982, -4.5982, -4.5982, -4.5982, -4.5982, -4.5982, -4.5982,
           -4.5982, -4.5982, -4.5982, -4.5982, -4.5982, -4.5982, -4.5982,
           -4.5982],
          [-1.3744, -1.3744, -1.3744, -1.3744, -1.3744, -1.3744, -1.3744,
           -1.3744, -1.3744, -1.3744, -1.3744, -1.3744, -1.3744, -1.3744,
           -1.3744],
          [-5.8553, -5.8553, -5.8553, -5.8553, -5.8553, -5.8553, -5.8553,
           -5.8553, -5.8553, -5.8553, -5.8553, -5.8553, -5.8553, -5.8553,
           -5.8553],
          [-1.3744, -1.3744, -1.3744, -1.3744, -1.3744, -1.3744, -1.3744,
           -1.3744, -1.3744, -1.3744, -1.3744, -1.3744, -1.3744, -1.3744,
           -1.3744],
          [-5.8553, -5.8553, -5.8553, -5.8553, -5.8553, -5.8553, -5.8553,
           -5.8553, -5.8553, -5.8553, -5.8553, -5.8553, -5.8553, -5.8553,
           -5.8553],
          [-4.5982, -4.5982, -4.5982, -4.5982, -4.5982, -4.5982, -4.5982,
           -4.5982, -4.5982, -4.5982, -4.5982, -4.5982, -4.5982, -4.5982,
           -4.5982],
          [-3.0723, -3.0723, -3.0723, -3.0723, -3.0723, -3.0723, -3.0723,
           -3.0723, -3.0723, -3.0723, -3.0723, -3.0723, -3.0723, -3.0723,
           -3.0723],
          [-0.3882, -0.3882, -0.3882, -0.3882, -0.3882, -0.3882, -0.3882,
           -0.3882, -0.3882, -0.3882, -0.3882, -0.3882, -0.3882, -0.3882,
           -0.3882],
          [-1.3744, -1.3744, -1.3744, -1.3744, -1.3744, -1.3744, -1.3744,
           -1.3744, -1.3744, -1.3744, -1.3744, -1.3744, -1.3744, -1.3744,
           -1.3744]]],


        [[[-0.9301, -0.9301, -0.9301, -0.9301, -0.9301, -0.9301, -0.9301,
           -0.9301, -0.9301, -0.9301, -0.9301, -0.9301, -0.9301, -0.9301,
           -0.9301],
          [-6.2727, -6.2727, -6.2727, -6.2727, -6.2727, -6.2727, -6.2727,
           -6.2727, -6.2727, -6.2727, -6.2727, -6.2727, -6.2727, -6.2727,
           -6.2727],
          [-5.0120, -5.0120, -5.0120, -5.0120, -5.0120, -5.0120, -5.0120,
           -5.0120, -5.0120, -5.0120, -5.0120, -5.0120, -5.0120, -5.0120,
           -5.0120],
          [-4.1008, -4.1008, -4.1008, -4.1008, -4.1008, -4.1008, -4.1008,
           -4.1008, -4.1008, -4.1008, -4.1008, -4.1008, -4.1008, -4.1008,
           -4.1008],
          [-5.8945, -5.8945, -5.8945, -5.8945, -5.8945, -5.8945, -5.8945,
           -5.8945, -5.8945, -5.8945, -5.8945, -5.8945, -5.8945, -5.8945,
           -5.8945],
          [-6.2727, -6.2727, -6.2727, -6.2727, -6.2727, -6.2727, -6.2727,
           -6.2727, -6.2727, -6.2727, -6.2727, -6.2727, -6.2727, -6.2727,
           -6.2727],
          [-4.6684, -4.6684, -4.6684, -4.6684, -4.6684, -4.6684, -4.6684,
           -4.6684, -4.6684, -4.6684, -4.6684, -4.6684, -4.6684, -4.6684,
           -4.6684],
          [-5.4333, -5.4333, -5.4333, -5.4333, -5.4333, -5.4333, -5.4333,
           -5.4333, -5.4333, -5.4333, -5.4333, -5.4333, -5.4333, -5.4333,
           -5.4333],
          [-1.9757, -1.9757, -1.9757, -1.9757, -1.9757, -1.9757, -1.9757,
           -1.9757, -1.9757, -1.9757, -1.9757, -1.9757, -1.9757, -1.9757,
           -1.9757],
          [-6.2727, -6.2727, -6.2727, -6.2727, -6.2727, -6.2727, -6.2727,
           -6.2727, -6.2727, -6.2727, -6.2727, -6.2727, -6.2727, -6.2727,
           -6.2727],
          [-0.6185, -0.6185, -0.6185, -0.6185, -0.6185, -0.6185, -0.6185,
           -0.6185, -0.6185, -0.6185, -0.6185, -0.6185, -0.6185, -0.6185,
           -0.6185],
          [-6.2727, -6.2727, -6.2727, -6.2727, -6.2727, -6.2727, -6.2727,
           -6.2727, -6.2727, -6.2727, -6.2727, -6.2727, -6.2727, -6.2727,
           -6.2727],
          [-5.4333, -5.4333, -5.4333, -5.4333, -5.4333, -5.4333, -5.4333,
           -5.4333, -5.4333, -5.4333, -5.4333, -5.4333, -5.4333, -5.4333,
           -5.4333],
          [-0.6185, -0.6185, -0.6185, -0.6185, -0.6185, -0.6185, -0.6185,
           -0.6185, -0.6185, -0.6185, -0.6185, -0.6185, -0.6185, -0.6185,
           -0.6185],
          [-0.9301, -0.9301, -0.9301, -0.9301, -0.9301, -0.9301, -0.9301,
           -0.9301, -0.9301, -0.9301, -0.9301, -0.9301, -0.9301, -0.9301,
           -0.9301],
          [-0.6185, -0.6185, -0.6185, -0.6185, -0.6185, -0.6185, -0.6185,
           -0.6185, -0.6185, -0.6185, -0.6185, -0.6185, -0.6185, -0.6185,
           -0.6185]],

         [[-0.5215, -0.5215, -0.5215, -0.5215, -0.5215, -0.5215, -0.5215,
           -0.5215, -0.5215, -0.5215, -0.5215, -0.5215, -0.5215, -0.5215,
           -0.5215],
          [-6.0768, -6.0768, -6.0768, -6.0768, -6.0768, -6.0768, -6.0768,
           -6.0768, -6.0768, -6.0768, -6.0768, -6.0768, -6.0768, -6.0768,
           -6.0768],
          [-4.7457, -4.7457, -4.7457, -4.7457, -4.7457, -4.7457, -4.7457,
           -4.7457, -4.7457, -4.7457, -4.7457, -4.7457, -4.7457, -4.7457,
           -4.7457],
          [-3.7836, -3.7836, -3.7836, -3.7836, -3.7836, -3.7836, -3.7836,
           -3.7836, -3.7836, -3.7836, -3.7836, -3.7836, -3.7836, -3.7836,
           -3.7836],
          [-5.6774, -5.6774, -5.6774, -5.6774, -5.6774, -5.6774, -5.6774,
           -5.6774, -5.6774, -5.6774, -5.6774, -5.6774, -5.6774, -5.6774,
           -5.6774],
          [-6.0768, -6.0768, -6.0768, -6.0768, -6.0768, -6.0768, -6.0768,
           -6.0768, -6.0768, -6.0768, -6.0768, -6.0768, -6.0768, -6.0768,
           -6.0768],
          [-4.3829, -4.3829, -4.3829, -4.3829, -4.3829, -4.3829, -4.3829,
           -4.3829, -4.3829, -4.3829, -4.3829, -4.3829, -4.3829, -4.3829,
           -4.3829],
          [-5.1905, -5.1905, -5.1905, -5.1905, -5.1905, -5.1905, -5.1905,
           -5.1905, -5.1905, -5.1905, -5.1905, -5.1905, -5.1905, -5.1905,
           -5.1905],
          [-1.5400, -1.5400, -1.5400, -1.5400, -1.5400, -1.5400, -1.5400,
           -1.5400, -1.5400, -1.5400, -1.5400, -1.5400, -1.5400, -1.5400,
           -1.5400],
          [-6.0768, -6.0768, -6.0768, -6.0768, -6.0768, -6.0768, -6.0768,
           -6.0768, -6.0768, -6.0768, -6.0768, -6.0768, -6.0768, -6.0768,
           -6.0768],
          [-1.5400, -1.5400, -1.5400, -1.5400, -1.5400, -1.5400, -1.5400,
           -1.5400, -1.5400, -1.5400, -1.5400, -1.5400, -1.5400, -1.5400,
           -1.5400],
          [-6.0768, -6.0768, -6.0768, -6.0768, -6.0768, -6.0768, -6.0768,
           -6.0768, -6.0768, -6.0768, -6.0768, -6.0768, -6.0768, -6.0768,
           -6.0768],
          [-5.1905, -5.1905, -5.1905, -5.1905, -5.1905, -5.1905, -5.1905,
           -5.1905, -5.1905, -5.1905, -5.1905, -5.1905, -5.1905, -5.1905,
           -5.1905],
          [-3.2764, -3.2764, -3.2764, -3.2764, -3.2764, -3.2764, -3.2764,
           -3.2764, -3.2764, -3.2764, -3.2764, -3.2764, -3.2764, -3.2764,
           -3.2764],
          [-0.5215, -0.5215, -0.5215, -0.5215, -0.5215, -0.5215, -0.5215,
           -0.5215, -0.5215, -0.5215, -0.5215, -0.5215, -0.5215, -0.5215,
           -0.5215],
          [-1.5400, -1.5400, -1.5400, -1.5400, -1.5400, -1.5400, -1.5400,
           -1.5400, -1.5400, -1.5400, -1.5400, -1.5400, -1.5400, -1.5400,
           -1.5400]]]], grad_fn=<SliceBackward0>)
train_step: Entropy shape: torch.Size([16, 15])
train_step: Entropy sample: tensor([[0.6280, 0.6861],
        [0.6416, 0.5849]], grad_fn=<SliceBackward0>)
train_step: Entropy coefficient: 0.01
train_step: Actor loss: -1.5334413051605225
train_step: returns shape after mean: torch.Size([16, 15])
train_step: target_indices shape: torch.Size([16, 15])
train_step: value_logits shape: torch.Size([16, 15, 255])
train_step: target_twohot shape: torch.Size([16, 15, 255])
--- Starting train_step at 2025-04-01 01:51:39 ---
Full starting_state: {'deter': tensor([[[-1.6953e-01, -1.3183e-03,  4.0775e-02,  ..., -2.8033e-01,
           3.2547e-02,  4.2586e-03],
         [-7.1481e-02,  1.9737e-01, -7.9740e-02,  ...,  2.1586e-02,
          -1.4883e-02, -1.6578e-01],
         [ 7.6293e-02,  8.5050e-02, -1.6431e-01,  ...,  5.0757e-02,
          -5.4908e-03, -1.0760e-01],
         ...,
         [ 1.8584e-02,  1.5722e-01,  1.2323e-01,  ..., -8.7406e-02,
           7.8197e-02,  4.8189e-03],
         [-6.6945e-02, -3.8416e-02,  7.8789e-02,  ..., -8.0898e-02,
          -9.5595e-02,  6.6409e-02],
         [ 7.5904e-02, -6.7324e-03, -1.2550e-01,  ...,  2.1694e-02,
          -1.3141e-01, -7.1745e-02]],

        [[ 4.4008e-02, -1.4011e-01, -3.5897e-02,  ..., -1.3161e-01,
           2.4824e-03, -1.0955e-01],
         [-1.3299e-01,  1.7076e-01, -3.4661e-03,  ..., -7.6564e-02,
           1.9827e-02,  6.6461e-02],
         [-9.2934e-02,  8.5474e-02, -1.0183e-01,  ..., -4.0893e-02,
          -3.8526e-02,  3.7228e-02],
         ...,
         [-3.6003e-02, -9.9289e-02,  7.8706e-02,  ..., -8.0093e-02,
           4.5759e-02, -1.4060e-01],
         [ 7.0409e-02, -5.5923e-02,  1.1175e-01,  ..., -3.3088e-02,
          -8.8451e-02,  5.3155e-02],
         [-1.6218e-01, -4.6923e-02, -4.2373e-02,  ...,  1.8408e-01,
          -2.1780e-02,  9.2241e-02]],

        [[ 1.7174e-02, -1.0830e-01, -3.1063e-02,  ...,  3.1455e-03,
           6.3113e-02, -1.8632e-02],
         [-1.9569e-01,  6.1360e-03,  1.1844e-01,  ..., -4.4964e-02,
           4.9677e-02, -9.3054e-02],
         [-1.3880e-02, -3.3305e-02, -2.4887e-01,  ..., -4.8031e-02,
          -2.0443e-02, -1.8708e-02],
         ...,
         [-4.9700e-05,  1.0360e-02, -1.4028e-02,  ..., -7.0612e-02,
           4.3328e-02,  1.7626e-01],
         [-2.5143e-02,  5.8786e-02,  1.2870e-01,  ...,  1.6963e-02,
           1.3870e-01,  1.4026e-01],
         [-6.3010e-03,  8.0777e-03, -1.0431e-01,  ...,  5.2215e-02,
           4.5606e-02, -6.3230e-02]],

        ...,

        [[ 5.4665e-02,  9.0454e-02, -1.0415e-01,  ..., -1.2490e-01,
          -1.3630e-02,  1.4272e-01],
         [-1.1080e-01,  1.8453e-03, -5.6611e-02,  ..., -3.0113e-02,
           7.3677e-02,  9.0184e-02],
         [-2.0092e-02,  1.2481e-01, -4.1852e-02,  ...,  8.2231e-02,
          -5.3076e-02,  7.0147e-02],
         ...,
         [-2.5079e-02,  3.7904e-02, -2.1144e-01,  ..., -1.6596e-01,
          -9.8816e-03,  1.3211e-02],
         [ 7.5722e-02,  4.0350e-02, -2.5371e-02,  ...,  6.2158e-02,
           4.2015e-02, -1.0534e-01],
         [ 3.4282e-02, -3.7135e-03, -1.4433e-02,  ..., -8.3724e-02,
           3.3342e-02,  1.0030e-01]],

        [[-1.3878e-01, -2.7792e-02, -1.3539e-01,  ..., -3.1617e-02,
           7.7113e-02, -1.9959e-01],
         [ 2.6043e-02,  1.1335e-02, -1.0963e-01,  ..., -9.3781e-02,
           7.9761e-02,  1.5662e-02],
         [-1.7443e-01, -6.0169e-02, -8.6154e-02,  ...,  2.6673e-02,
           3.6328e-03,  1.6835e-01],
         ...,
         [-1.3428e-01,  3.2352e-02,  4.3119e-03,  ..., -1.5681e-01,
          -1.3277e-02, -7.0897e-02],
         [-6.7806e-02, -4.5908e-02,  5.4519e-02,  ..., -4.3950e-04,
           2.5736e-02, -1.9390e-04],
         [-7.6722e-02,  8.6497e-02, -4.7729e-02,  ...,  4.1982e-02,
          -2.7707e-02,  5.0819e-02]],

        [[-9.8454e-02, -2.9438e-02,  4.8803e-02,  ..., -6.2794e-02,
           9.1866e-02,  1.3471e-01],
         [ 1.0190e-01,  5.8182e-03, -9.6102e-04,  ...,  6.7104e-02,
           2.3341e-01,  5.0533e-02],
         [-1.2260e-01, -4.6134e-03,  1.3474e-02,  ..., -4.9505e-02,
          -2.3892e-02, -1.4169e-01],
         ...,
         [-1.9668e-01,  7.6403e-02,  4.4677e-02,  ..., -2.0219e-02,
          -6.8005e-02,  7.2158e-02],
         [-3.3409e-02, -8.1139e-02, -1.2570e-03,  ...,  8.3978e-02,
          -4.7405e-03, -3.8693e-02],
         [-8.9331e-02, -2.1908e-01, -4.3880e-02,  ..., -5.7325e-02,
          -9.7659e-02, -8.7260e-02]]], grad_fn=<StackBackward0>), 'stoch': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [1., 0., 0.,  ..., 0., 0., 0.],
         [1., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 1.],
         [0., 0., 1.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 1., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 1., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]])}
train_step: Starting state deter shape: torch.Size([16, 50, 128])
train_step: Starting state stoch shape: torch.Size([16, 50, 1024])
After ensuring logits/stoch: {'deter': tensor([[[-1.6953e-01, -1.3183e-03,  4.0775e-02,  ..., -2.8033e-01,
           3.2547e-02,  4.2586e-03],
         [-7.1481e-02,  1.9737e-01, -7.9740e-02,  ...,  2.1586e-02,
          -1.4883e-02, -1.6578e-01],
         [ 7.6293e-02,  8.5050e-02, -1.6431e-01,  ...,  5.0757e-02,
          -5.4908e-03, -1.0760e-01],
         ...,
         [ 1.8584e-02,  1.5722e-01,  1.2323e-01,  ..., -8.7406e-02,
           7.8197e-02,  4.8189e-03],
         [-6.6945e-02, -3.8416e-02,  7.8789e-02,  ..., -8.0898e-02,
          -9.5595e-02,  6.6409e-02],
         [ 7.5904e-02, -6.7324e-03, -1.2550e-01,  ...,  2.1694e-02,
          -1.3141e-01, -7.1745e-02]],

        [[ 4.4008e-02, -1.4011e-01, -3.5897e-02,  ..., -1.3161e-01,
           2.4824e-03, -1.0955e-01],
         [-1.3299e-01,  1.7076e-01, -3.4661e-03,  ..., -7.6564e-02,
           1.9827e-02,  6.6461e-02],
         [-9.2934e-02,  8.5474e-02, -1.0183e-01,  ..., -4.0893e-02,
          -3.8526e-02,  3.7228e-02],
         ...,
         [-3.6003e-02, -9.9289e-02,  7.8706e-02,  ..., -8.0093e-02,
           4.5759e-02, -1.4060e-01],
         [ 7.0409e-02, -5.5923e-02,  1.1175e-01,  ..., -3.3088e-02,
          -8.8451e-02,  5.3155e-02],
         [-1.6218e-01, -4.6923e-02, -4.2373e-02,  ...,  1.8408e-01,
          -2.1780e-02,  9.2241e-02]],

        [[ 1.7174e-02, -1.0830e-01, -3.1063e-02,  ...,  3.1455e-03,
           6.3113e-02, -1.8632e-02],
         [-1.9569e-01,  6.1360e-03,  1.1844e-01,  ..., -4.4964e-02,
           4.9677e-02, -9.3054e-02],
         [-1.3880e-02, -3.3305e-02, -2.4887e-01,  ..., -4.8031e-02,
          -2.0443e-02, -1.8708e-02],
         ...,
         [-4.9700e-05,  1.0360e-02, -1.4028e-02,  ..., -7.0612e-02,
           4.3328e-02,  1.7626e-01],
         [-2.5143e-02,  5.8786e-02,  1.2870e-01,  ...,  1.6963e-02,
           1.3870e-01,  1.4026e-01],
         [-6.3010e-03,  8.0777e-03, -1.0431e-01,  ...,  5.2215e-02,
           4.5606e-02, -6.3230e-02]],

        ...,

        [[ 5.4665e-02,  9.0454e-02, -1.0415e-01,  ..., -1.2490e-01,
          -1.3630e-02,  1.4272e-01],
         [-1.1080e-01,  1.8453e-03, -5.6611e-02,  ..., -3.0113e-02,
           7.3677e-02,  9.0184e-02],
         [-2.0092e-02,  1.2481e-01, -4.1852e-02,  ...,  8.2231e-02,
          -5.3076e-02,  7.0147e-02],
         ...,
         [-2.5079e-02,  3.7904e-02, -2.1144e-01,  ..., -1.6596e-01,
          -9.8816e-03,  1.3211e-02],
         [ 7.5722e-02,  4.0350e-02, -2.5371e-02,  ...,  6.2158e-02,
           4.2015e-02, -1.0534e-01],
         [ 3.4282e-02, -3.7135e-03, -1.4433e-02,  ..., -8.3724e-02,
           3.3342e-02,  1.0030e-01]],

        [[-1.3878e-01, -2.7792e-02, -1.3539e-01,  ..., -3.1617e-02,
           7.7113e-02, -1.9959e-01],
         [ 2.6043e-02,  1.1335e-02, -1.0963e-01,  ..., -9.3781e-02,
           7.9761e-02,  1.5662e-02],
         [-1.7443e-01, -6.0169e-02, -8.6154e-02,  ...,  2.6673e-02,
           3.6328e-03,  1.6835e-01],
         ...,
         [-1.3428e-01,  3.2352e-02,  4.3119e-03,  ..., -1.5681e-01,
          -1.3277e-02, -7.0897e-02],
         [-6.7806e-02, -4.5908e-02,  5.4519e-02,  ..., -4.3950e-04,
           2.5736e-02, -1.9390e-04],
         [-7.6722e-02,  8.6497e-02, -4.7729e-02,  ...,  4.1982e-02,
          -2.7707e-02,  5.0819e-02]],

        [[-9.8454e-02, -2.9438e-02,  4.8803e-02,  ..., -6.2794e-02,
           9.1866e-02,  1.3471e-01],
         [ 1.0190e-01,  5.8182e-03, -9.6102e-04,  ...,  6.7104e-02,
           2.3341e-01,  5.0533e-02],
         [-1.2260e-01, -4.6134e-03,  1.3474e-02,  ..., -4.9505e-02,
          -2.3892e-02, -1.4169e-01],
         ...,
         [-1.9668e-01,  7.6403e-02,  4.4677e-02,  ..., -2.0219e-02,
          -6.8005e-02,  7.2158e-02],
         [-3.3409e-02, -8.1139e-02, -1.2570e-03,  ...,  8.3978e-02,
          -4.7405e-03, -3.8693e-02],
         [-8.9331e-02, -2.1908e-01, -4.3880e-02,  ..., -5.7325e-02,
          -9.7659e-02, -8.7260e-02]]], grad_fn=<StackBackward0>), 'stoch': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [1., 0., 0.,  ..., 0., 0., 0.],
         [1., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 1.],
         [0., 0., 1.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 1., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 1., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]]), 'logits': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]])}
train_step: Normalized hidden_state shape: torch.Size([1, 16, 128])
train_step: Normalized stoch shape: torch.Size([16, 1024])
train_step: Normalized deter shape: torch.Size([16, 128])
train_step: Post-imagine_trajectory: Imagined features shape: torch.Size([16, 15, 1152])
train_step: Post-imagine_trajectory: Imagined actions shape: torch.Size([16, 15, 2])
train_step: Post-imagine_trajectory: Imagined action indices shape: torch.Size([16, 15])
train_step: Post-imagine_trajectory: Imagined state deter shape: torch.Size([16, 15, 128])
train_step: Post-imagine_trajectory: Imagined state stoch shape: torch.Size([16, 15, 1024])
Reward shape: torch.Size([16, 15, 1]), Value shape: torch.Size([16, 15, 1]), Slow Value shape: torch.Size([16, 15, 1]), Discount shape: torch.Size([16, 15, 1, 1])
Return targets length: 15, First target shape: torch.Size([16, 16, 1])
train_step: Actor distribution shape: torch.Size([16, 15, 2])
train_step: Action log probabilities shape: torch.Size([16, 15])
train_step: Action log probabilities sample: tensor([[-0.1867, -0.2067],
        [-0.9003, -0.1601]], grad_fn=<SliceBackward0>)
train_step: Advantages shape: torch.Size([16, 15, 16, 15])
train_step: Advantages sample: tensor([[[[ -5.5332,  -5.5332,  -5.5332,  -5.5332,  -5.5332,  -5.5332,  -5.5332,
            -5.5332,  -5.5332,  -5.5332,  -5.5332,  -5.5332,  -5.5332,  -5.5332,
            -5.5332],
          [ -1.2590,  -1.2590,  -1.2590,  -1.2590,  -1.2590,  -1.2590,  -1.2590,
            -1.2590,  -1.2590,  -1.2590,  -1.2590,  -1.2590,  -1.2590,  -1.2590,
            -1.2590],
          [ -6.1939,  -6.1939,  -6.1939,  -6.1939,  -6.1939,  -6.1939,  -6.1939,
            -6.1939,  -6.1939,  -6.1939,  -6.1939,  -6.1939,  -6.1939,  -6.1939,
            -6.1939],
          [ -6.1939,  -6.1939,  -6.1939,  -6.1939,  -6.1939,  -6.1939,  -6.1939,
            -6.1939,  -6.1939,  -6.1939,  -6.1939,  -6.1939,  -6.1939,  -6.1939,
            -6.1939],
          [ -0.8530,  -0.8530,  -0.8530,  -0.8530,  -0.8530,  -0.8530,  -0.8530,
            -0.8530,  -0.8530,  -0.8530,  -0.8530,  -0.8530,  -0.8530,  -0.8530,
            -0.8530],
          [ -3.1097,  -3.1097,  -3.1097,  -3.1097,  -3.1097,  -3.1097,  -3.1097,
            -3.1097,  -3.1097,  -3.1097,  -3.1097,  -3.1097,  -3.1097,  -3.1097,
            -3.1097],
          [ -5.6592,  -5.6592,  -5.6592,  -5.6592,  -5.6592,  -5.6592,  -5.6592,
            -5.6592,  -5.6592,  -5.6592,  -5.6592,  -5.6592,  -5.6592,  -5.6592,
            -5.6592],
          [ -0.5933,  -0.5933,  -0.5933,  -0.5933,  -0.5933,  -0.5933,  -0.5933,
            -0.5933,  -0.5933,  -0.5933,  -0.5933,  -0.5933,  -0.5933,  -0.5933,
            -0.5933],
          [ -6.1939,  -6.1939,  -6.1939,  -6.1939,  -6.1939,  -6.1939,  -6.1939,
            -6.1939,  -6.1939,  -6.1939,  -6.1939,  -6.1939,  -6.1939,  -6.1939,
            -6.1939],
          [ -1.8827,  -1.8827,  -1.8827,  -1.8827,  -1.8827,  -1.8827,  -1.8827,
            -1.8827,  -1.8827,  -1.8827,  -1.8827,  -1.8827,  -1.8827,  -1.8827,
            -1.8827],
          [ -6.1939,  -6.1939,  -6.1939,  -6.1939,  -6.1939,  -6.1939,  -6.1939,
            -6.1939,  -6.1939,  -6.1939,  -6.1939,  -6.1939,  -6.1939,  -6.1939,
            -6.1939],
          [ -6.1939,  -6.1939,  -6.1939,  -6.1939,  -6.1939,  -6.1939,  -6.1939,
            -6.1939,  -6.1939,  -6.1939,  -6.1939,  -6.1939,  -6.1939,  -6.1939,
            -6.1939],
          [ -1.2590,  -1.2590,  -1.2590,  -1.2590,  -1.2590,  -1.2590,  -1.2590,
            -1.2590,  -1.2590,  -1.2590,  -1.2590,  -1.2590,  -1.2590,  -1.2590,
            -1.2590],
          [ -4.5798,  -4.5798,  -4.5798,  -4.5798,  -4.5798,  -4.5798,  -4.5798,
            -4.5798,  -4.5798,  -4.5798,  -4.5798,  -4.5798,  -4.5798,  -4.5798,
            -4.5798],
          [ -6.1939,  -6.1939,  -6.1939,  -6.1939,  -6.1939,  -6.1939,  -6.1939,
            -6.1939,  -6.1939,  -6.1939,  -6.1939,  -6.1939,  -6.1939,  -6.1939,
            -6.1939],
          [ -1.8827,  -1.8827,  -1.8827,  -1.8827,  -1.8827,  -1.8827,  -1.8827,
            -1.8827,  -1.8827,  -1.8827,  -1.8827,  -1.8827,  -1.8827,  -1.8827,
            -1.8827]],

         [[ -5.2155,  -5.2155,  -5.2155,  -5.2155,  -5.2155,  -5.2155,  -5.2155,
            -5.2155,  -5.2155,  -5.2155,  -5.2155,  -5.2155,  -5.2155,  -5.2155,
            -5.2155],
          [ -0.7028,  -0.7028,  -0.7028,  -0.7028,  -0.7028,  -0.7028,  -0.7028,
            -0.7028,  -0.7028,  -0.7028,  -0.7028,  -0.7028,  -0.7028,  -0.7028,
            -0.7028],
          [ -5.9131,  -5.9131,  -5.9131,  -5.9131,  -5.9131,  -5.9131,  -5.9131,
            -5.9131,  -5.9131,  -5.9131,  -5.9131,  -5.9131,  -5.9131,  -5.9131,
            -5.9131],
          [ -5.9131,  -5.9131,  -5.9131,  -5.9131,  -5.9131,  -5.9131,  -5.9131,
            -5.9131,  -5.9131,  -5.9131,  -5.9131,  -5.9131,  -5.9131,  -5.9131,
            -5.9131],
          [ -0.2742,  -0.2742,  -0.2742,  -0.2742,  -0.2742,  -0.2742,  -0.2742,
            -0.2742,  -0.2742,  -0.2742,  -0.2742,  -0.2742,  -0.2742,  -0.2742,
            -0.2742],
          [ -2.6568,  -2.6568,  -2.6568,  -2.6568,  -2.6568,  -2.6568,  -2.6568,
            -2.6568,  -2.6568,  -2.6568,  -2.6568,  -2.6568,  -2.6568,  -2.6568,
            -2.6568],
          [ -5.3485,  -5.3485,  -5.3485,  -5.3485,  -5.3485,  -5.3485,  -5.3485,
            -5.3485,  -5.3485,  -5.3485,  -5.3485,  -5.3485,  -5.3485,  -5.3485,
            -5.3485],
          [ -0.2742,  -0.2742,  -0.2742,  -0.2742,  -0.2742,  -0.2742,  -0.2742,
            -0.2742,  -0.2742,  -0.2742,  -0.2742,  -0.2742,  -0.2742,  -0.2742,
            -0.2742],
          [ -5.9131,  -5.9131,  -5.9131,  -5.9131,  -5.9131,  -5.9131,  -5.9131,
            -5.9131,  -5.9131,  -5.9131,  -5.9131,  -5.9131,  -5.9131,  -5.9131,
            -5.9131],
          [ -1.3613,  -1.3613,  -1.3613,  -1.3613,  -1.3613,  -1.3613,  -1.3613,
            -1.3613,  -1.3613,  -1.3613,  -1.3613,  -1.3613,  -1.3613,  -1.3613,
            -1.3613],
          [ -5.9131,  -5.9131,  -5.9131,  -5.9131,  -5.9131,  -5.9131,  -5.9131,
            -5.9131,  -5.9131,  -5.9131,  -5.9131,  -5.9131,  -5.9131,  -5.9131,
            -5.9131],
          [ -5.9131,  -5.9131,  -5.9131,  -5.9131,  -5.9131,  -5.9131,  -5.9131,
            -5.9131,  -5.9131,  -5.9131,  -5.9131,  -5.9131,  -5.9131,  -5.9131,
            -5.9131],
          [ -0.7028,  -0.7028,  -0.7028,  -0.7028,  -0.7028,  -0.7028,  -0.7028,
            -0.7028,  -0.7028,  -0.7028,  -0.7028,  -0.7028,  -0.7028,  -0.7028,
            -0.7028],
          [ -4.2089,  -4.2089,  -4.2089,  -4.2089,  -4.2089,  -4.2089,  -4.2089,
            -4.2089,  -4.2089,  -4.2089,  -4.2089,  -4.2089,  -4.2089,  -4.2089,
            -4.2089],
          [ -5.9131,  -5.9131,  -5.9131,  -5.9131,  -5.9131,  -5.9131,  -5.9131,
            -5.9131,  -5.9131,  -5.9131,  -5.9131,  -5.9131,  -5.9131,  -5.9131,
            -5.9131],
          [ -1.3613,  -1.3613,  -1.3613,  -1.3613,  -1.3613,  -1.3613,  -1.3613,
            -1.3613,  -1.3613,  -1.3613,  -1.3613,  -1.3613,  -1.3613,  -1.3613,
            -1.3613]]],


        [[[ -8.5557,  -8.5557,  -8.5557,  -8.5557,  -8.5557,  -8.5557,  -8.5557,
            -8.5557,  -8.5557,  -8.5557,  -8.5557,  -8.5557,  -8.5557,  -8.5557,
            -8.5557],
          [ -2.3009,  -2.3009,  -2.3009,  -2.3009,  -2.3009,  -2.3009,  -2.3009,
            -2.3009,  -2.3009,  -2.3009,  -2.3009,  -2.3009,  -2.3009,  -2.3009,
            -2.3009],
          [-10.0043, -10.0043, -10.0043, -10.0043, -10.0043, -10.0043, -10.0043,
           -10.0043, -10.0043, -10.0043, -10.0043, -10.0043, -10.0043, -10.0043,
           -10.0043],
          [-10.0043, -10.0043, -10.0043, -10.0043, -10.0043, -10.0043, -10.0043,
           -10.0043, -10.0043, -10.0043, -10.0043, -10.0043, -10.0043, -10.0043,
           -10.0043],
          [ -1.8521,  -1.8521,  -1.8521,  -1.8521,  -1.8521,  -1.8521,  -1.8521,
            -1.8521,  -1.8521,  -1.8521,  -1.8521,  -1.8521,  -1.8521,  -1.8521,
            -1.8521],
          [ -7.2008,  -7.2008,  -7.2008,  -7.2008,  -7.2008,  -7.2008,  -7.2008,
            -7.2008,  -7.2008,  -7.2008,  -7.2008,  -7.2008,  -7.2008,  -7.2008,
            -7.2008],
          [ -9.0073,  -9.0073,  -9.0073,  -9.0073,  -9.0073,  -9.0073,  -9.0073,
            -9.0073,  -9.0073,  -9.0073,  -9.0073,  -9.0073,  -9.0073,  -9.0073,
            -9.0073],
          [ -0.4513,  -0.4513,  -0.4513,  -0.4513,  -0.4513,  -0.4513,  -0.4513,
            -0.4513,  -0.4513,  -0.4513,  -0.4513,  -0.4513,  -0.4513,  -0.4513,
            -0.4513],
          [-10.0043, -10.0043, -10.0043, -10.0043, -10.0043, -10.0043, -10.0043,
           -10.0043, -10.0043, -10.0043, -10.0043, -10.0043, -10.0043, -10.0043,
           -10.0043],
          [ -3.2209,  -3.2209,  -3.2209,  -3.2209,  -3.2209,  -3.2209,  -3.2209,
            -3.2209,  -3.2209,  -3.2209,  -3.2209,  -3.2209,  -3.2209,  -3.2209,
            -3.2209],
          [-10.0043, -10.0043, -10.0043, -10.0043, -10.0043, -10.0043, -10.0043,
           -10.0043, -10.0043, -10.0043, -10.0043, -10.0043, -10.0043, -10.0043,
           -10.0043],
          [-10.0043, -10.0043, -10.0043, -10.0043, -10.0043, -10.0043, -10.0043,
           -10.0043, -10.0043, -10.0043, -10.0043, -10.0043, -10.0043, -10.0043,
           -10.0043],
          [ -2.3009,  -2.3009,  -2.3009,  -2.3009,  -2.3009,  -2.3009,  -2.3009,
            -2.3009,  -2.3009,  -2.3009,  -2.3009,  -2.3009,  -2.3009,  -2.3009,
            -2.3009],
          [ -7.5487,  -7.5487,  -7.5487,  -7.5487,  -7.5487,  -7.5487,  -7.5487,
            -7.5487,  -7.5487,  -7.5487,  -7.5487,  -7.5487,  -7.5487,  -7.5487,
            -7.5487],
          [-10.0043, -10.0043, -10.0043, -10.0043, -10.0043, -10.0043, -10.0043,
           -10.0043, -10.0043, -10.0043, -10.0043, -10.0043, -10.0043, -10.0043,
           -10.0043],
          [ -3.2209,  -3.2209,  -3.2209,  -3.2209,  -3.2209,  -3.2209,  -3.2209,
            -3.2209,  -3.2209,  -3.2209,  -3.2209,  -3.2209,  -3.2209,  -3.2209,
            -3.2209]],

         [[ -8.5566,  -8.5566,  -8.5566,  -8.5566,  -8.5566,  -8.5566,  -8.5566,
            -8.5566,  -8.5566,  -8.5566,  -8.5566,  -8.5566,  -8.5566,  -8.5566,
            -8.5566],
          [ -1.9529,  -1.9529,  -1.9529,  -1.9529,  -1.9529,  -1.9529,  -1.9529,
            -1.9529,  -1.9529,  -1.9529,  -1.9529,  -1.9529,  -1.9529,  -1.9529,
            -1.9529],
          [-10.0861, -10.0861, -10.0861, -10.0861, -10.0861, -10.0861, -10.0861,
           -10.0861, -10.0861, -10.0861, -10.0861, -10.0861, -10.0861, -10.0861,
           -10.0861],
          [-10.0861, -10.0861, -10.0861, -10.0861, -10.0861, -10.0861, -10.0861,
           -10.0861, -10.0861, -10.0861, -10.0861, -10.0861, -10.0861, -10.0861,
           -10.0861],
          [ -1.4790,  -1.4790,  -1.4790,  -1.4790,  -1.4790,  -1.4790,  -1.4790,
            -1.4790,  -1.4790,  -1.4790,  -1.4790,  -1.4790,  -1.4790,  -1.4790,
            -1.4790],
          [ -7.1261,  -7.1261,  -7.1261,  -7.1261,  -7.1261,  -7.1261,  -7.1261,
            -7.1261,  -7.1261,  -7.1261,  -7.1261,  -7.1261,  -7.1261,  -7.1261,
            -7.1261],
          [ -9.0334,  -9.0334,  -9.0334,  -9.0334,  -9.0334,  -9.0334,  -9.0334,
            -9.0334,  -9.0334,  -9.0334,  -9.0334,  -9.0334,  -9.0334,  -9.0334,
            -9.0334],
          [ -1.4790,  -1.4790,  -1.4790,  -1.4790,  -1.4790,  -1.4790,  -1.4790,
            -1.4790,  -1.4790,  -1.4790,  -1.4790,  -1.4790,  -1.4790,  -1.4790,
            -1.4790],
          [-10.0861, -10.0861, -10.0861, -10.0861, -10.0861, -10.0861, -10.0861,
           -10.0861, -10.0861, -10.0861, -10.0861, -10.0861, -10.0861, -10.0861,
           -10.0861],
          [ -2.9241,  -2.9241,  -2.9241,  -2.9241,  -2.9241,  -2.9241,  -2.9241,
            -2.9241,  -2.9241,  -2.9241,  -2.9241,  -2.9241,  -2.9241,  -2.9241,
            -2.9241],
          [-10.0861, -10.0861, -10.0861, -10.0861, -10.0861, -10.0861, -10.0861,
           -10.0861, -10.0861, -10.0861, -10.0861, -10.0861, -10.0861, -10.0861,
           -10.0861],
          [-10.0861, -10.0861, -10.0861, -10.0861, -10.0861, -10.0861, -10.0861,
           -10.0861, -10.0861, -10.0861, -10.0861, -10.0861, -10.0861, -10.0861,
           -10.0861],
          [ -1.9529,  -1.9529,  -1.9529,  -1.9529,  -1.9529,  -1.9529,  -1.9529,
            -1.9529,  -1.9529,  -1.9529,  -1.9529,  -1.9529,  -1.9529,  -1.9529,
            -1.9529],
          [ -7.4934,  -7.4934,  -7.4934,  -7.4934,  -7.4934,  -7.4934,  -7.4934,
            -7.4934,  -7.4934,  -7.4934,  -7.4934,  -7.4934,  -7.4934,  -7.4934,
            -7.4934],
          [-10.0861, -10.0861, -10.0861, -10.0861, -10.0861, -10.0861, -10.0861,
           -10.0861, -10.0861, -10.0861, -10.0861, -10.0861, -10.0861, -10.0861,
           -10.0861],
          [ -2.9241,  -2.9241,  -2.9241,  -2.9241,  -2.9241,  -2.9241,  -2.9241,
            -2.9241,  -2.9241,  -2.9241,  -2.9241,  -2.9241,  -2.9241,  -2.9241,
            -2.9241]]]], grad_fn=<SliceBackward0>)
train_step: Return scale: 1.2575386791568117
train_step: Scaled advantages shape: torch.Size([16, 15, 16, 15])
train_step: Scaled advantages sample: tensor([[[[-4.4000, -4.4000, -4.4000, -4.4000, -4.4000, -4.4000, -4.4000,
           -4.4000, -4.4000, -4.4000, -4.4000, -4.4000, -4.4000, -4.4000,
           -4.4000],
          [-1.0012, -1.0012, -1.0012, -1.0012, -1.0012, -1.0012, -1.0012,
           -1.0012, -1.0012, -1.0012, -1.0012, -1.0012, -1.0012, -1.0012,
           -1.0012],
          [-4.9254, -4.9254, -4.9254, -4.9254, -4.9254, -4.9254, -4.9254,
           -4.9254, -4.9254, -4.9254, -4.9254, -4.9254, -4.9254, -4.9254,
           -4.9254],
          [-4.9254, -4.9254, -4.9254, -4.9254, -4.9254, -4.9254, -4.9254,
           -4.9254, -4.9254, -4.9254, -4.9254, -4.9254, -4.9254, -4.9254,
           -4.9254],
          [-0.8530, -0.8530, -0.8530, -0.8530, -0.8530, -0.8530, -0.8530,
           -0.8530, -0.8530, -0.8530, -0.8530, -0.8530, -0.8530, -0.8530,
           -0.8530],
          [-2.4729, -2.4729, -2.4729, -2.4729, -2.4729, -2.4729, -2.4729,
           -2.4729, -2.4729, -2.4729, -2.4729, -2.4729, -2.4729, -2.4729,
           -2.4729],
          [-4.5002, -4.5002, -4.5002, -4.5002, -4.5002, -4.5002, -4.5002,
           -4.5002, -4.5002, -4.5002, -4.5002, -4.5002, -4.5002, -4.5002,
           -4.5002],
          [-0.5933, -0.5933, -0.5933, -0.5933, -0.5933, -0.5933, -0.5933,
           -0.5933, -0.5933, -0.5933, -0.5933, -0.5933, -0.5933, -0.5933,
           -0.5933],
          [-4.9254, -4.9254, -4.9254, -4.9254, -4.9254, -4.9254, -4.9254,
           -4.9254, -4.9254, -4.9254, -4.9254, -4.9254, -4.9254, -4.9254,
           -4.9254],
          [-1.4972, -1.4971, -1.4971, -1.4971, -1.4971, -1.4971, -1.4971,
           -1.4971, -1.4971, -1.4971, -1.4971, -1.4971, -1.4971, -1.4971,
           -1.4972],
          [-4.9254, -4.9254, -4.9254, -4.9254, -4.9254, -4.9254, -4.9254,
           -4.9254, -4.9254, -4.9254, -4.9254, -4.9254, -4.9254, -4.9254,
           -4.9254],
          [-4.9254, -4.9254, -4.9254, -4.9254, -4.9254, -4.9254, -4.9254,
           -4.9254, -4.9254, -4.9254, -4.9254, -4.9254, -4.9254, -4.9254,
           -4.9254],
          [-1.0012, -1.0012, -1.0012, -1.0012, -1.0012, -1.0012, -1.0012,
           -1.0012, -1.0012, -1.0012, -1.0012, -1.0012, -1.0012, -1.0012,
           -1.0012],
          [-3.6419, -3.6419, -3.6419, -3.6419, -3.6419, -3.6419, -3.6419,
           -3.6419, -3.6419, -3.6419, -3.6419, -3.6419, -3.6419, -3.6419,
           -3.6419],
          [-4.9254, -4.9254, -4.9254, -4.9254, -4.9254, -4.9254, -4.9254,
           -4.9254, -4.9254, -4.9254, -4.9254, -4.9254, -4.9254, -4.9254,
           -4.9254],
          [-1.4972, -1.4971, -1.4971, -1.4971, -1.4971, -1.4971, -1.4971,
           -1.4971, -1.4971, -1.4971, -1.4971, -1.4971, -1.4971, -1.4971,
           -1.4972]],

         [[-4.1474, -4.1474, -4.1474, -4.1474, -4.1474, -4.1474, -4.1474,
           -4.1474, -4.1474, -4.1474, -4.1474, -4.1474, -4.1474, -4.1474,
           -4.1474],
          [-0.7028, -0.7028, -0.7028, -0.7028, -0.7028, -0.7028, -0.7028,
           -0.7028, -0.7028, -0.7028, -0.7028, -0.7028, -0.7028, -0.7028,
           -0.7028],
          [-4.7021, -4.7021, -4.7021, -4.7021, -4.7021, -4.7021, -4.7021,
           -4.7021, -4.7021, -4.7021, -4.7021, -4.7021, -4.7021, -4.7021,
           -4.7021],
          [-4.7021, -4.7021, -4.7021, -4.7021, -4.7021, -4.7021, -4.7021,
           -4.7021, -4.7021, -4.7021, -4.7021, -4.7021, -4.7021, -4.7021,
           -4.7021],
          [-0.2742, -0.2742, -0.2742, -0.2742, -0.2742, -0.2742, -0.2742,
           -0.2742, -0.2742, -0.2742, -0.2742, -0.2742, -0.2742, -0.2742,
           -0.2742],
          [-2.1127, -2.1127, -2.1127, -2.1127, -2.1127, -2.1127, -2.1127,
           -2.1127, -2.1127, -2.1127, -2.1127, -2.1127, -2.1127, -2.1127,
           -2.1127],
          [-4.2532, -4.2532, -4.2532, -4.2532, -4.2532, -4.2532, -4.2532,
           -4.2532, -4.2532, -4.2532, -4.2532, -4.2532, -4.2532, -4.2532,
           -4.2532],
          [-0.2742, -0.2742, -0.2742, -0.2742, -0.2742, -0.2742, -0.2742,
           -0.2742, -0.2742, -0.2742, -0.2742, -0.2742, -0.2742, -0.2742,
           -0.2742],
          [-4.7021, -4.7021, -4.7021, -4.7021, -4.7021, -4.7021, -4.7021,
           -4.7021, -4.7021, -4.7021, -4.7021, -4.7021, -4.7021, -4.7021,
           -4.7021],
          [-1.0825, -1.0825, -1.0825, -1.0825, -1.0825, -1.0825, -1.0825,
           -1.0825, -1.0825, -1.0825, -1.0825, -1.0825, -1.0825, -1.0825,
           -1.0825],
          [-4.7021, -4.7021, -4.7021, -4.7021, -4.7021, -4.7021, -4.7021,
           -4.7021, -4.7021, -4.7021, -4.7021, -4.7021, -4.7021, -4.7021,
           -4.7021],
          [-4.7021, -4.7021, -4.7021, -4.7021, -4.7021, -4.7021, -4.7021,
           -4.7021, -4.7021, -4.7021, -4.7021, -4.7021, -4.7021, -4.7021,
           -4.7021],
          [-0.7028, -0.7028, -0.7028, -0.7028, -0.7028, -0.7028, -0.7028,
           -0.7028, -0.7028, -0.7028, -0.7028, -0.7028, -0.7028, -0.7028,
           -0.7028],
          [-3.3469, -3.3469, -3.3469, -3.3469, -3.3469, -3.3469, -3.3469,
           -3.3469, -3.3469, -3.3469, -3.3469, -3.3469, -3.3469, -3.3469,
           -3.3469],
          [-4.7021, -4.7021, -4.7021, -4.7021, -4.7021, -4.7021, -4.7021,
           -4.7021, -4.7021, -4.7021, -4.7021, -4.7021, -4.7021, -4.7021,
           -4.7021],
          [-1.0825, -1.0825, -1.0825, -1.0825, -1.0825, -1.0825, -1.0825,
           -1.0825, -1.0825, -1.0825, -1.0825, -1.0825, -1.0825, -1.0825,
           -1.0825]]],


        [[[-6.8035, -6.8035, -6.8035, -6.8035, -6.8035, -6.8035, -6.8035,
           -6.8035, -6.8035, -6.8035, -6.8035, -6.8035, -6.8035, -6.8035,
           -6.8035],
          [-1.8297, -1.8297, -1.8297, -1.8297, -1.8297, -1.8297, -1.8297,
           -1.8297, -1.8297, -1.8297, -1.8297, -1.8297, -1.8297, -1.8297,
           -1.8297],
          [-7.9555, -7.9555, -7.9555, -7.9555, -7.9555, -7.9555, -7.9555,
           -7.9555, -7.9555, -7.9555, -7.9555, -7.9555, -7.9555, -7.9555,
           -7.9555],
          [-7.9555, -7.9555, -7.9555, -7.9555, -7.9555, -7.9555, -7.9555,
           -7.9555, -7.9555, -7.9555, -7.9555, -7.9555, -7.9555, -7.9555,
           -7.9555],
          [-1.4728, -1.4728, -1.4728, -1.4728, -1.4728, -1.4728, -1.4728,
           -1.4728, -1.4728, -1.4728, -1.4728, -1.4728, -1.4728, -1.4728,
           -1.4728],
          [-5.7261, -5.7261, -5.7261, -5.7261, -5.7261, -5.7261, -5.7261,
           -5.7261, -5.7261, -5.7261, -5.7261, -5.7261, -5.7261, -5.7261,
           -5.7261],
          [-7.1626, -7.1626, -7.1626, -7.1626, -7.1626, -7.1626, -7.1626,
           -7.1626, -7.1626, -7.1626, -7.1626, -7.1626, -7.1626, -7.1626,
           -7.1626],
          [-0.4513, -0.4513, -0.4513, -0.4513, -0.4513, -0.4513, -0.4513,
           -0.4513, -0.4513, -0.4513, -0.4513, -0.4513, -0.4513, -0.4513,
           -0.4513],
          [-7.9555, -7.9555, -7.9555, -7.9555, -7.9555, -7.9555, -7.9555,
           -7.9555, -7.9555, -7.9555, -7.9555, -7.9555, -7.9555, -7.9555,
           -7.9555],
          [-2.5612, -2.5612, -2.5612, -2.5612, -2.5612, -2.5612, -2.5612,
           -2.5612, -2.5612, -2.5612, -2.5612, -2.5612, -2.5612, -2.5612,
           -2.5612],
          [-7.9555, -7.9555, -7.9555, -7.9555, -7.9555, -7.9555, -7.9555,
           -7.9555, -7.9555, -7.9555, -7.9555, -7.9555, -7.9555, -7.9555,
           -7.9555],
          [-7.9555, -7.9555, -7.9555, -7.9555, -7.9555, -7.9555, -7.9555,
           -7.9555, -7.9555, -7.9555, -7.9555, -7.9555, -7.9555, -7.9555,
           -7.9555],
          [-1.8297, -1.8297, -1.8297, -1.8297, -1.8297, -1.8297, -1.8297,
           -1.8297, -1.8297, -1.8297, -1.8297, -1.8297, -1.8297, -1.8297,
           -1.8297],
          [-6.0027, -6.0027, -6.0027, -6.0027, -6.0027, -6.0027, -6.0027,
           -6.0027, -6.0027, -6.0027, -6.0027, -6.0027, -6.0027, -6.0027,
           -6.0027],
          [-7.9555, -7.9555, -7.9555, -7.9555, -7.9555, -7.9555, -7.9555,
           -7.9555, -7.9555, -7.9555, -7.9555, -7.9555, -7.9555, -7.9555,
           -7.9555],
          [-2.5612, -2.5612, -2.5612, -2.5612, -2.5612, -2.5612, -2.5612,
           -2.5612, -2.5612, -2.5612, -2.5612, -2.5612, -2.5612, -2.5612,
           -2.5612]],

         [[-6.8042, -6.8042, -6.8042, -6.8042, -6.8042, -6.8042, -6.8042,
           -6.8042, -6.8042, -6.8042, -6.8042, -6.8042, -6.8042, -6.8042,
           -6.8042],
          [-1.5529, -1.5529, -1.5529, -1.5529, -1.5529, -1.5529, -1.5529,
           -1.5529, -1.5529, -1.5529, -1.5529, -1.5529, -1.5529, -1.5529,
           -1.5529],
          [-8.0205, -8.0205, -8.0205, -8.0205, -8.0205, -8.0205, -8.0205,
           -8.0205, -8.0205, -8.0205, -8.0205, -8.0205, -8.0205, -8.0205,
           -8.0205],
          [-8.0205, -8.0205, -8.0205, -8.0205, -8.0205, -8.0205, -8.0205,
           -8.0205, -8.0205, -8.0205, -8.0205, -8.0205, -8.0205, -8.0205,
           -8.0205],
          [-1.1761, -1.1761, -1.1761, -1.1761, -1.1761, -1.1761, -1.1761,
           -1.1761, -1.1761, -1.1761, -1.1761, -1.1761, -1.1761, -1.1761,
           -1.1761],
          [-5.6667, -5.6667, -5.6667, -5.6667, -5.6667, -5.6667, -5.6667,
           -5.6667, -5.6667, -5.6667, -5.6667, -5.6667, -5.6667, -5.6667,
           -5.6667],
          [-7.1834, -7.1834, -7.1834, -7.1834, -7.1834, -7.1834, -7.1834,
           -7.1834, -7.1834, -7.1834, -7.1834, -7.1834, -7.1834, -7.1834,
           -7.1834],
          [-1.1761, -1.1761, -1.1761, -1.1761, -1.1761, -1.1761, -1.1761,
           -1.1761, -1.1761, -1.1761, -1.1761, -1.1761, -1.1761, -1.1761,
           -1.1761],
          [-8.0205, -8.0205, -8.0205, -8.0205, -8.0205, -8.0205, -8.0205,
           -8.0205, -8.0205, -8.0205, -8.0205, -8.0205, -8.0205, -8.0205,
           -8.0205],
          [-2.3253, -2.3253, -2.3253, -2.3253, -2.3253, -2.3253, -2.3253,
           -2.3253, -2.3253, -2.3253, -2.3253, -2.3253, -2.3253, -2.3253,
           -2.3253],
          [-8.0205, -8.0205, -8.0205, -8.0205, -8.0205, -8.0205, -8.0205,
           -8.0205, -8.0205, -8.0205, -8.0205, -8.0205, -8.0205, -8.0205,
           -8.0205],
          [-8.0205, -8.0205, -8.0205, -8.0205, -8.0205, -8.0205, -8.0205,
           -8.0205, -8.0205, -8.0205, -8.0205, -8.0205, -8.0205, -8.0205,
           -8.0205],
          [-1.5529, -1.5529, -1.5529, -1.5529, -1.5529, -1.5529, -1.5529,
           -1.5529, -1.5529, -1.5529, -1.5529, -1.5529, -1.5529, -1.5529,
           -1.5529],
          [-5.9588, -5.9588, -5.9588, -5.9588, -5.9588, -5.9588, -5.9588,
           -5.9588, -5.9588, -5.9588, -5.9588, -5.9588, -5.9588, -5.9588,
           -5.9588],
          [-8.0205, -8.0205, -8.0205, -8.0205, -8.0205, -8.0205, -8.0205,
           -8.0205, -8.0205, -8.0205, -8.0205, -8.0205, -8.0205, -8.0205,
           -8.0205],
          [-2.3253, -2.3253, -2.3253, -2.3253, -2.3253, -2.3253, -2.3253,
           -2.3253, -2.3253, -2.3253, -2.3253, -2.3253, -2.3253, -2.3253,
           -2.3253]]]], grad_fn=<SliceBackward0>)
train_step: Entropy shape: torch.Size([16, 15])
train_step: Entropy sample: tensor([[0.4563, 0.4815],
        [0.6755, 0.4192]], grad_fn=<SliceBackward0>)
train_step: Entropy coefficient: 0.01
train_step: Actor loss: -1.7151374816894531
train_step: returns shape after mean: torch.Size([16, 15])
train_step: target_indices shape: torch.Size([16, 15])
train_step: value_logits shape: torch.Size([16, 15, 255])
train_step: target_twohot shape: torch.Size([16, 15, 255])
--- Starting train_step at 2025-04-01 01:51:56 ---
Full starting_state: {'deter': tensor([[[-0.0515,  0.0041, -0.0042,  ...,  0.0328, -0.1807,  0.0181],
         [-0.1004, -0.0216, -0.2487,  ...,  0.0348,  0.0799,  0.0396],
         [-0.1070, -0.0516, -0.0235,  ..., -0.0677,  0.0088, -0.0648],
         ...,
         [-0.2195,  0.0668, -0.0837,  ...,  0.0849, -0.0148, -0.1486],
         [-0.0851,  0.0165, -0.0675,  ..., -0.1443, -0.0868, -0.0098],
         [-0.0273,  0.0467, -0.0367,  ..., -0.0203,  0.2037, -0.0341]],

        [[-0.0786, -0.0573, -0.1645,  ..., -0.0700, -0.0443, -0.0453],
         [-0.0699,  0.0227, -0.0962,  ...,  0.1600,  0.0702,  0.0623],
         [ 0.0048, -0.0598, -0.2289,  ...,  0.0652, -0.0107,  0.0610],
         ...,
         [-0.1710, -0.1084,  0.0085,  ..., -0.1489,  0.1696, -0.0210],
         [-0.1461, -0.0870, -0.1743,  ..., -0.0113, -0.0401, -0.0429],
         [ 0.1034, -0.0256, -0.0161,  ...,  0.0759,  0.2091,  0.0094]],

        [[ 0.0014,  0.1496, -0.0839,  ..., -0.1041, -0.0881,  0.0463],
         [-0.0256,  0.0815,  0.2135,  ..., -0.0411, -0.0383,  0.0577],
         [-0.0424,  0.0221, -0.0086,  ...,  0.0957,  0.0307, -0.0909],
         ...,
         [-0.0175, -0.0234,  0.0587,  ..., -0.0096, -0.0593,  0.1417],
         [-0.0663,  0.0769, -0.0144,  ..., -0.0160,  0.0343,  0.0057],
         [-0.0560,  0.0697, -0.0781,  ...,  0.0643, -0.0925, -0.0678]],

        ...,

        [[-0.0649, -0.1702,  0.0087,  ...,  0.0389,  0.0669, -0.2235],
         [-0.0640, -0.0843, -0.0085,  ..., -0.0492,  0.0625, -0.1022],
         [-0.0874, -0.0805,  0.0742,  ...,  0.0333,  0.0019,  0.1521],
         ...,
         [-0.0209,  0.0423,  0.0463,  ..., -0.1741, -0.0233, -0.0018],
         [-0.1165,  0.0579, -0.0887,  ..., -0.1927, -0.0565,  0.0389],
         [-0.0606, -0.0502,  0.0276,  ..., -0.0609, -0.0340, -0.0112]],

        [[-0.0205,  0.1763,  0.0132,  ..., -0.1014, -0.1736, -0.0691],
         [-0.0010,  0.1373,  0.1578,  ..., -0.1135,  0.0039,  0.0720],
         [-0.0105, -0.0718,  0.0755,  ...,  0.0705,  0.0537, -0.1697],
         ...,
         [-0.0355, -0.0193,  0.0811,  ..., -0.1678,  0.0801, -0.1623],
         [-0.1898, -0.0880, -0.0432,  ..., -0.0027,  0.0344, -0.0984],
         [ 0.0195, -0.0310, -0.0478,  ...,  0.0925, -0.0056, -0.0140]],

        [[-0.0851, -0.0631, -0.1374,  ...,  0.0279,  0.1216,  0.1793],
         [-0.0063, -0.0030, -0.1495,  ..., -0.0157, -0.0342,  0.0461],
         [-0.1840, -0.1675,  0.1291,  ..., -0.0322,  0.0226, -0.0146],
         ...,
         [ 0.1124,  0.0080,  0.0505,  ..., -0.0239, -0.0139,  0.0634],
         [ 0.1560, -0.0137,  0.0597,  ...,  0.0274,  0.0571, -0.0132],
         [-0.0094,  0.1223, -0.0417,  ..., -0.0224,  0.0728, -0.0136]]],
       grad_fn=<StackBackward0>), 'stoch': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [1., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 1., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 1.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [1., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 1., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 1., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]])}
train_step: Starting state deter shape: torch.Size([16, 50, 128])
train_step: Starting state stoch shape: torch.Size([16, 50, 1024])
After ensuring logits/stoch: {'deter': tensor([[[-0.0515,  0.0041, -0.0042,  ...,  0.0328, -0.1807,  0.0181],
         [-0.1004, -0.0216, -0.2487,  ...,  0.0348,  0.0799,  0.0396],
         [-0.1070, -0.0516, -0.0235,  ..., -0.0677,  0.0088, -0.0648],
         ...,
         [-0.2195,  0.0668, -0.0837,  ...,  0.0849, -0.0148, -0.1486],
         [-0.0851,  0.0165, -0.0675,  ..., -0.1443, -0.0868, -0.0098],
         [-0.0273,  0.0467, -0.0367,  ..., -0.0203,  0.2037, -0.0341]],

        [[-0.0786, -0.0573, -0.1645,  ..., -0.0700, -0.0443, -0.0453],
         [-0.0699,  0.0227, -0.0962,  ...,  0.1600,  0.0702,  0.0623],
         [ 0.0048, -0.0598, -0.2289,  ...,  0.0652, -0.0107,  0.0610],
         ...,
         [-0.1710, -0.1084,  0.0085,  ..., -0.1489,  0.1696, -0.0210],
         [-0.1461, -0.0870, -0.1743,  ..., -0.0113, -0.0401, -0.0429],
         [ 0.1034, -0.0256, -0.0161,  ...,  0.0759,  0.2091,  0.0094]],

        [[ 0.0014,  0.1496, -0.0839,  ..., -0.1041, -0.0881,  0.0463],
         [-0.0256,  0.0815,  0.2135,  ..., -0.0411, -0.0383,  0.0577],
         [-0.0424,  0.0221, -0.0086,  ...,  0.0957,  0.0307, -0.0909],
         ...,
         [-0.0175, -0.0234,  0.0587,  ..., -0.0096, -0.0593,  0.1417],
         [-0.0663,  0.0769, -0.0144,  ..., -0.0160,  0.0343,  0.0057],
         [-0.0560,  0.0697, -0.0781,  ...,  0.0643, -0.0925, -0.0678]],

        ...,

        [[-0.0649, -0.1702,  0.0087,  ...,  0.0389,  0.0669, -0.2235],
         [-0.0640, -0.0843, -0.0085,  ..., -0.0492,  0.0625, -0.1022],
         [-0.0874, -0.0805,  0.0742,  ...,  0.0333,  0.0019,  0.1521],
         ...,
         [-0.0209,  0.0423,  0.0463,  ..., -0.1741, -0.0233, -0.0018],
         [-0.1165,  0.0579, -0.0887,  ..., -0.1927, -0.0565,  0.0389],
         [-0.0606, -0.0502,  0.0276,  ..., -0.0609, -0.0340, -0.0112]],

        [[-0.0205,  0.1763,  0.0132,  ..., -0.1014, -0.1736, -0.0691],
         [-0.0010,  0.1373,  0.1578,  ..., -0.1135,  0.0039,  0.0720],
         [-0.0105, -0.0718,  0.0755,  ...,  0.0705,  0.0537, -0.1697],
         ...,
         [-0.0355, -0.0193,  0.0811,  ..., -0.1678,  0.0801, -0.1623],
         [-0.1898, -0.0880, -0.0432,  ..., -0.0027,  0.0344, -0.0984],
         [ 0.0195, -0.0310, -0.0478,  ...,  0.0925, -0.0056, -0.0140]],

        [[-0.0851, -0.0631, -0.1374,  ...,  0.0279,  0.1216,  0.1793],
         [-0.0063, -0.0030, -0.1495,  ..., -0.0157, -0.0342,  0.0461],
         [-0.1840, -0.1675,  0.1291,  ..., -0.0322,  0.0226, -0.0146],
         ...,
         [ 0.1124,  0.0080,  0.0505,  ..., -0.0239, -0.0139,  0.0634],
         [ 0.1560, -0.0137,  0.0597,  ...,  0.0274,  0.0571, -0.0132],
         [-0.0094,  0.1223, -0.0417,  ..., -0.0224,  0.0728, -0.0136]]],
       grad_fn=<StackBackward0>), 'stoch': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [1., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 1., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 1.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [1., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 1., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 1., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]]), 'logits': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]])}
train_step: Normalized hidden_state shape: torch.Size([1, 16, 128])
train_step: Normalized stoch shape: torch.Size([16, 1024])
train_step: Normalized deter shape: torch.Size([16, 128])
train_step: Post-imagine_trajectory: Imagined features shape: torch.Size([16, 15, 1152])
train_step: Post-imagine_trajectory: Imagined actions shape: torch.Size([16, 15, 2])
train_step: Post-imagine_trajectory: Imagined action indices shape: torch.Size([16, 15])
train_step: Post-imagine_trajectory: Imagined state deter shape: torch.Size([16, 15, 128])
train_step: Post-imagine_trajectory: Imagined state stoch shape: torch.Size([16, 15, 1024])
Reward shape: torch.Size([16, 15, 1]), Value shape: torch.Size([16, 15, 1]), Slow Value shape: torch.Size([16, 15, 1]), Discount shape: torch.Size([16, 15, 1, 1])
Return targets length: 15, First target shape: torch.Size([16, 16, 1])
train_step: Actor distribution shape: torch.Size([16, 15, 2])
train_step: Action log probabilities shape: torch.Size([16, 15])
train_step: Action log probabilities sample: tensor([[-1.2611, -0.3360],
        [-0.4660, -0.7131]], grad_fn=<SliceBackward0>)
train_step: Advantages shape: torch.Size([16, 15, 16, 15])
train_step: Advantages sample: tensor([[[[-7.4704, -7.4704, -7.4704, -7.4704, -7.4704, -7.4704, -7.4704,
           -7.4704, -7.4704, -7.4704, -7.4704, -7.4704, -7.4704, -7.4704,
           -7.4704],
          [-1.5172, -1.5172, -1.5172, -1.5172, -1.5172, -1.5172, -1.5172,
           -1.5172, -1.5172, -1.5172, -1.5172, -1.5172, -1.5172, -1.5172,
           -1.5172],
          [-4.0764, -4.0764, -4.0764, -4.0764, -4.0764, -4.0764, -4.0764,
           -4.0764, -4.0764, -4.0764, -4.0764, -4.0764, -4.0764, -4.0764,
           -4.0764],
          [-6.5828, -6.5828, -6.5828, -6.5828, -6.5828, -6.5828, -6.5828,
           -6.5828, -6.5828, -6.5828, -6.5828, -6.5828, -6.5828, -6.5828,
           -6.5828],
          [-1.5172, -1.5172, -1.5172, -1.5172, -1.5172, -1.5172, -1.5172,
           -1.5172, -1.5172, -1.5172, -1.5172, -1.5172, -1.5172, -1.5172,
           -1.5172],
          [-7.4704, -7.4704, -7.4704, -7.4704, -7.4704, -7.4704, -7.4704,
           -7.4704, -7.4704, -7.4704, -7.4704, -7.4704, -7.4704, -7.4704,
           -7.4704],
          [-7.4704, -7.4704, -7.4704, -7.4704, -7.4704, -7.4704, -7.4704,
           -7.4704, -7.4704, -7.4704, -7.4704, -7.4704, -7.4704, -7.4704,
           -7.4704],
          [-7.4704, -7.4704, -7.4704, -7.4704, -7.4704, -7.4704, -7.4704,
           -7.4704, -7.4704, -7.4704, -7.4704, -7.4704, -7.4704, -7.4704,
           -7.4704],
          [-7.4704, -7.4704, -7.4704, -7.4704, -7.4704, -7.4704, -7.4704,
           -7.4704, -7.4704, -7.4704, -7.4704, -7.4704, -7.4704, -7.4704,
           -7.4704],
          [-7.4704, -7.4704, -7.4704, -7.4704, -7.4704, -7.4704, -7.4704,
           -7.4704, -7.4704, -7.4704, -7.4704, -7.4704, -7.4704, -7.4704,
           -7.4704],
          [-6.3778, -6.3778, -6.3778, -6.3778, -6.3778, -6.3778, -6.3778,
           -6.3778, -6.3778, -6.3778, -6.3778, -6.3778, -6.3778, -6.3778,
           -6.3778],
          [-6.7126, -6.7126, -6.7126, -6.7126, -6.7126, -6.7126, -6.7126,
           -6.7126, -6.7126, -6.7126, -6.7126, -6.7126, -6.7126, -6.7126,
           -6.7126],
          [-2.4841, -2.4841, -2.4841, -2.4841, -2.4841, -2.4841, -2.4841,
           -2.4841, -2.4841, -2.4841, -2.4841, -2.4841, -2.4841, -2.4841,
           -2.4841],
          [-7.4704, -7.4704, -7.4704, -7.4704, -7.4704, -7.4704, -7.4704,
           -7.4704, -7.4704, -7.4704, -7.4704, -7.4704, -7.4704, -7.4704,
           -7.4704],
          [-7.4704, -7.4704, -7.4704, -7.4704, -7.4704, -7.4704, -7.4704,
           -7.4704, -7.4704, -7.4704, -7.4704, -7.4704, -7.4704, -7.4704,
           -7.4704],
          [-7.1861, -7.1861, -7.1861, -7.1861, -7.1861, -7.1861, -7.1861,
           -7.1861, -7.1861, -7.1861, -7.1861, -7.1861, -7.1861, -7.1861,
           -7.1861]],

         [[-6.2854, -6.2854, -6.2854, -6.2854, -6.2854, -6.2854, -6.2854,
           -6.2854, -6.2854, -6.2854, -6.2854, -6.2854, -6.2854, -6.2854,
           -6.2854],
          [-6.2854, -6.2854, -6.2854, -6.2854, -6.2854, -6.2854, -6.2854,
           -6.2854, -6.2854, -6.2854, -6.2854, -6.2854, -6.2854, -6.2854,
           -6.2854],
          [-2.7020, -2.7020, -2.7020, -2.7020, -2.7020, -2.7020, -2.7020,
           -2.7020, -2.7020, -2.7020, -2.7020, -2.7020, -2.7020, -2.7020,
           -2.7020],
          [-5.3482, -5.3482, -5.3482, -5.3482, -5.3482, -5.3482, -5.3482,
           -5.3482, -5.3482, -5.3482, -5.3482, -5.3482, -5.3482, -5.3482,
           -5.3482],
          [-4.0866, -4.0866, -4.0866, -4.0866, -4.0866, -4.0866, -4.0866,
           -4.0866, -4.0866, -4.0866, -4.0866, -4.0866, -4.0866, -4.0866,
           -4.0866],
          [-6.2854, -6.2854, -6.2854, -6.2854, -6.2854, -6.2854, -6.2854,
           -6.2854, -6.2854, -6.2854, -6.2854, -6.2854, -6.2854, -6.2854,
           -6.2854],
          [-6.2854, -6.2854, -6.2854, -6.2854, -6.2854, -6.2854, -6.2854,
           -6.2854, -6.2854, -6.2854, -6.2854, -6.2854, -6.2854, -6.2854,
           -6.2854],
          [-6.2854, -6.2854, -6.2854, -6.2854, -6.2854, -6.2854, -6.2854,
           -6.2854, -6.2854, -6.2854, -6.2854, -6.2854, -6.2854, -6.2854,
           -6.2854],
          [-6.2854, -6.2854, -6.2854, -6.2854, -6.2854, -6.2854, -6.2854,
           -6.2854, -6.2854, -6.2854, -6.2854, -6.2854, -6.2854, -6.2854,
           -6.2854],
          [-6.2854, -6.2854, -6.2854, -6.2854, -6.2854, -6.2854, -6.2854,
           -6.2854, -6.2854, -6.2854, -6.2854, -6.2854, -6.2854, -6.2854,
           -6.2854],
          [-5.1318, -5.1318, -5.1318, -5.1318, -5.1318, -5.1318, -5.1318,
           -5.1318, -5.1318, -5.1318, -5.1318, -5.1318, -5.1318, -5.1318,
           -5.1318],
          [-5.4852, -5.4852, -5.4852, -5.4852, -5.4852, -5.4852, -5.4853,
           -5.4852, -5.4852, -5.4852, -5.4852, -5.4852, -5.4852, -5.4852,
           -5.4852],
          [-1.0208, -1.0208, -1.0208, -1.0208, -1.0208, -1.0208, -1.0208,
           -1.0208, -1.0208, -1.0208, -1.0208, -1.0208, -1.0208, -1.0208,
           -1.0208],
          [-6.2854, -6.2854, -6.2854, -6.2854, -6.2854, -6.2854, -6.2854,
           -6.2854, -6.2854, -6.2854, -6.2854, -6.2854, -6.2854, -6.2854,
           -6.2854],
          [-6.2854, -6.2854, -6.2854, -6.2854, -6.2854, -6.2854, -6.2854,
           -6.2854, -6.2854, -6.2854, -6.2854, -6.2854, -6.2854, -6.2854,
           -6.2854],
          [-5.9852, -5.9852, -5.9852, -5.9852, -5.9852, -5.9852, -5.9852,
           -5.9852, -5.9852, -5.9852, -5.9852, -5.9852, -5.9852, -5.9852,
           -5.9852]]],


        [[[-6.5384, -6.5384, -6.5384, -6.5384, -6.5384, -6.5384, -6.5384,
           -6.5384, -6.5384, -6.5384, -6.5384, -6.5384, -6.5384, -6.5384,
           -6.5384],
          [-0.2450, -0.2450, -0.2450, -0.2450, -0.2450, -0.2450, -0.2450,
           -0.2450, -0.2450, -0.2450, -0.2450, -0.2450, -0.2450, -0.2450,
           -0.2450],
          [-4.1144, -4.1144, -4.1144, -4.1144, -4.1144, -4.1144, -4.1144,
           -4.1144, -4.1144, -4.1144, -4.1144, -4.1144, -4.1144, -4.1144,
           -4.1144],
          [-5.7473, -5.7473, -5.7473, -5.7473, -5.7473, -5.7473, -5.7473,
           -5.7473, -5.7473, -5.7473, -5.7473, -5.7473, -5.7473, -5.7473,
           -5.7473],
          [-0.2450, -0.2450, -0.2450, -0.2450, -0.2450, -0.2450, -0.2450,
           -0.2450, -0.2450, -0.2450, -0.2450, -0.2450, -0.2450, -0.2450,
           -0.2450],
          [-6.5384, -6.5384, -6.5384, -6.5384, -6.5384, -6.5384, -6.5384,
           -6.5384, -6.5384, -6.5384, -6.5384, -6.5384, -6.5384, -6.5384,
           -6.5384],
          [-6.5384, -6.5384, -6.5384, -6.5384, -6.5384, -6.5384, -6.5384,
           -6.5384, -6.5384, -6.5384, -6.5384, -6.5384, -6.5384, -6.5384,
           -6.5384],
          [-6.5384, -6.5384, -6.5384, -6.5384, -6.5384, -6.5384, -6.5384,
           -6.5384, -6.5384, -6.5384, -6.5384, -6.5384, -6.5384, -6.5384,
           -6.5384],
          [-6.5384, -6.5384, -6.5384, -6.5384, -6.5384, -6.5384, -6.5384,
           -6.5384, -6.5384, -6.5384, -6.5384, -6.5384, -6.5384, -6.5384,
           -6.5384],
          [-6.5384, -6.5384, -6.5384, -6.5384, -6.5384, -6.5384, -6.5384,
           -6.5384, -6.5384, -6.5384, -6.5384, -6.5384, -6.5384, -6.5384,
           -6.5384],
          [-5.4645, -5.4645, -5.4645, -5.4645, -5.4645, -5.4645, -5.4645,
           -5.4645, -5.4645, -5.4645, -5.4645, -5.4645, -5.4645, -5.4645,
           -5.4645],
          [-5.9564, -5.9564, -5.9564, -5.9564, -5.9564, -5.9564, -5.9564,
           -5.9564, -5.9564, -5.9564, -5.9564, -5.9564, -5.9564, -5.9564,
           -5.9564],
          [-1.4805, -1.4805, -1.4805, -1.4805, -1.4806, -1.4805, -1.4806,
           -1.4806, -1.4805, -1.4805, -1.4805, -1.4806, -1.4805, -1.4805,
           -1.4805],
          [-6.5384, -6.5384, -6.5384, -6.5384, -6.5384, -6.5384, -6.5384,
           -6.5384, -6.5384, -6.5384, -6.5384, -6.5384, -6.5384, -6.5384,
           -6.5384],
          [-6.5384, -6.5384, -6.5384, -6.5384, -6.5384, -6.5384, -6.5384,
           -6.5384, -6.5384, -6.5384, -6.5384, -6.5384, -6.5384, -6.5384,
           -6.5384],
          [-6.4190, -6.4190, -6.4190, -6.4190, -6.4190, -6.4190, -6.4190,
           -6.4190, -6.4190, -6.4190, -6.4190, -6.4190, -6.4190, -6.4190,
           -6.4190]],

         [[-6.6445, -6.6445, -6.6445, -6.6445, -6.6445, -6.6445, -6.6445,
           -6.6445, -6.6445, -6.6445, -6.6445, -6.6445, -6.6445, -6.6445,
           -6.6445],
          [-6.6445, -6.6445, -6.6445, -6.6445, -6.6445, -6.6445, -6.6445,
           -6.6445, -6.6445, -6.6445, -6.6445, -6.6445, -6.6445, -6.6445,
           -6.6445],
          [-4.0852, -4.0852, -4.0852, -4.0852, -4.0852, -4.0852, -4.0852,
           -4.0852, -4.0852, -4.0852, -4.0852, -4.0852, -4.0852, -4.0852,
           -4.0852],
          [-5.8093, -5.8093, -5.8093, -5.8093, -5.8093, -5.8093, -5.8093,
           -5.8093, -5.8093, -5.8093, -5.8093, -5.8093, -5.8093, -5.8093,
           -5.8093],
          [-4.1803, -4.1803, -4.1803, -4.1803, -4.1803, -4.1803, -4.1803,
           -4.1803, -4.1803, -4.1803, -4.1803, -4.1803, -4.1803, -4.1803,
           -4.1803],
          [-6.6445, -6.6445, -6.6445, -6.6445, -6.6445, -6.6445, -6.6445,
           -6.6445, -6.6445, -6.6445, -6.6445, -6.6445, -6.6445, -6.6445,
           -6.6445],
          [-6.6445, -6.6445, -6.6445, -6.6445, -6.6445, -6.6445, -6.6445,
           -6.6445, -6.6445, -6.6445, -6.6445, -6.6445, -6.6445, -6.6445,
           -6.6445],
          [-6.6445, -6.6445, -6.6445, -6.6445, -6.6445, -6.6445, -6.6445,
           -6.6445, -6.6445, -6.6445, -6.6445, -6.6445, -6.6445, -6.6445,
           -6.6445],
          [-6.6445, -6.6445, -6.6445, -6.6445, -6.6445, -6.6445, -6.6445,
           -6.6445, -6.6445, -6.6445, -6.6445, -6.6445, -6.6445, -6.6445,
           -6.6445],
          [-6.6445, -6.6445, -6.6445, -6.6445, -6.6445, -6.6445, -6.6445,
           -6.6445, -6.6445, -6.6445, -6.6445, -6.6445, -6.6445, -6.6445,
           -6.6445],
          [-5.5107, -5.5107, -5.5107, -5.5107, -5.5107, -5.5107, -5.5107,
           -5.5107, -5.5107, -5.5107, -5.5107, -5.5107, -5.5107, -5.5107,
           -5.5107],
          [-6.0301, -6.0301, -6.0301, -6.0301, -6.0301, -6.0301, -6.0301,
           -6.0301, -6.0301, -6.0301, -6.0301, -6.0301, -6.0301, -6.0301,
           -6.0301],
          [-1.3045, -1.3045, -1.3045, -1.3045, -1.3045, -1.3045, -1.3045,
           -1.3045, -1.3045, -1.3045, -1.3045, -1.3045, -1.3045, -1.3045,
           -1.3045],
          [-6.6445, -6.6445, -6.6445, -6.6445, -6.6445, -6.6445, -6.6445,
           -6.6445, -6.6445, -6.6445, -6.6445, -6.6445, -6.6445, -6.6445,
           -6.6445],
          [-6.6445, -6.6445, -6.6445, -6.6445, -6.6445, -6.6445, -6.6445,
           -6.6445, -6.6445, -6.6445, -6.6445, -6.6445, -6.6445, -6.6445,
           -6.6445],
          [-6.5185, -6.5185, -6.5185, -6.5185, -6.5185, -6.5185, -6.5185,
           -6.5185, -6.5185, -6.5185, -6.5185, -6.5185, -6.5185, -6.5185,
           -6.5185]]]], grad_fn=<SliceBackward0>)
train_step: Return scale: 1.320788500194719
train_step: Scaled advantages shape: torch.Size([16, 15, 16, 15])
train_step: Scaled advantages sample: tensor([[[[-5.6560, -5.6560, -5.6560, -5.6560, -5.6560, -5.6560, -5.6560,
           -5.6560, -5.6560, -5.6560, -5.6560, -5.6560, -5.6560, -5.6560,
           -5.6560],
          [-1.1487, -1.1487, -1.1487, -1.1487, -1.1487, -1.1487, -1.1487,
           -1.1487, -1.1487, -1.1487, -1.1487, -1.1487, -1.1487, -1.1487,
           -1.1487],
          [-3.0864, -3.0864, -3.0864, -3.0864, -3.0864, -3.0864, -3.0864,
           -3.0864, -3.0864, -3.0864, -3.0864, -3.0864, -3.0864, -3.0864,
           -3.0864],
          [-4.9840, -4.9840, -4.9840, -4.9840, -4.9840, -4.9840, -4.9840,
           -4.9840, -4.9840, -4.9840, -4.9840, -4.9840, -4.9840, -4.9840,
           -4.9840],
          [-1.1487, -1.1487, -1.1487, -1.1487, -1.1487, -1.1487, -1.1487,
           -1.1487, -1.1487, -1.1487, -1.1487, -1.1487, -1.1487, -1.1487,
           -1.1487],
          [-5.6560, -5.6560, -5.6560, -5.6560, -5.6560, -5.6560, -5.6560,
           -5.6560, -5.6560, -5.6560, -5.6560, -5.6560, -5.6560, -5.6560,
           -5.6560],
          [-5.6560, -5.6560, -5.6560, -5.6560, -5.6560, -5.6560, -5.6560,
           -5.6560, -5.6560, -5.6560, -5.6560, -5.6560, -5.6560, -5.6560,
           -5.6560],
          [-5.6560, -5.6560, -5.6560, -5.6560, -5.6560, -5.6560, -5.6560,
           -5.6560, -5.6560, -5.6560, -5.6560, -5.6560, -5.6560, -5.6560,
           -5.6560],
          [-5.6560, -5.6560, -5.6560, -5.6560, -5.6560, -5.6560, -5.6560,
           -5.6560, -5.6560, -5.6560, -5.6560, -5.6560, -5.6560, -5.6560,
           -5.6560],
          [-5.6560, -5.6560, -5.6560, -5.6560, -5.6560, -5.6560, -5.6560,
           -5.6560, -5.6560, -5.6560, -5.6560, -5.6560, -5.6560, -5.6560,
           -5.6560],
          [-4.8288, -4.8288, -4.8288, -4.8288, -4.8288, -4.8288, -4.8288,
           -4.8288, -4.8288, -4.8288, -4.8288, -4.8288, -4.8288, -4.8288,
           -4.8288],
          [-5.0822, -5.0822, -5.0822, -5.0822, -5.0822, -5.0822, -5.0822,
           -5.0822, -5.0822, -5.0822, -5.0822, -5.0822, -5.0822, -5.0822,
           -5.0822],
          [-1.8808, -1.8808, -1.8808, -1.8808, -1.8808, -1.8808, -1.8808,
           -1.8808, -1.8808, -1.8808, -1.8808, -1.8808, -1.8808, -1.8808,
           -1.8808],
          [-5.6560, -5.6560, -5.6560, -5.6560, -5.6560, -5.6560, -5.6560,
           -5.6560, -5.6560, -5.6560, -5.6560, -5.6560, -5.6560, -5.6560,
           -5.6560],
          [-5.6560, -5.6560, -5.6560, -5.6560, -5.6560, -5.6560, -5.6560,
           -5.6560, -5.6560, -5.6560, -5.6560, -5.6560, -5.6560, -5.6560,
           -5.6560],
          [-5.4408, -5.4408, -5.4408, -5.4408, -5.4408, -5.4408, -5.4408,
           -5.4408, -5.4408, -5.4408, -5.4408, -5.4408, -5.4408, -5.4408,
           -5.4408]],

         [[-4.7588, -4.7588, -4.7588, -4.7588, -4.7588, -4.7588, -4.7588,
           -4.7588, -4.7588, -4.7588, -4.7588, -4.7588, -4.7588, -4.7588,
           -4.7588],
          [-4.7588, -4.7588, -4.7588, -4.7588, -4.7588, -4.7588, -4.7588,
           -4.7588, -4.7588, -4.7588, -4.7588, -4.7588, -4.7588, -4.7588,
           -4.7588],
          [-2.0458, -2.0458, -2.0458, -2.0458, -2.0458, -2.0458, -2.0458,
           -2.0458, -2.0458, -2.0458, -2.0458, -2.0458, -2.0458, -2.0458,
           -2.0458],
          [-4.0492, -4.0492, -4.0492, -4.0492, -4.0492, -4.0492, -4.0492,
           -4.0492, -4.0492, -4.0492, -4.0492, -4.0492, -4.0492, -4.0492,
           -4.0492],
          [-3.0941, -3.0941, -3.0941, -3.0941, -3.0941, -3.0941, -3.0941,
           -3.0941, -3.0941, -3.0941, -3.0941, -3.0941, -3.0941, -3.0941,
           -3.0941],
          [-4.7588, -4.7588, -4.7588, -4.7588, -4.7588, -4.7588, -4.7588,
           -4.7588, -4.7588, -4.7588, -4.7588, -4.7588, -4.7588, -4.7588,
           -4.7588],
          [-4.7588, -4.7588, -4.7588, -4.7588, -4.7588, -4.7588, -4.7588,
           -4.7588, -4.7588, -4.7588, -4.7588, -4.7588, -4.7588, -4.7588,
           -4.7588],
          [-4.7588, -4.7588, -4.7588, -4.7588, -4.7588, -4.7588, -4.7588,
           -4.7588, -4.7588, -4.7588, -4.7588, -4.7588, -4.7588, -4.7588,
           -4.7588],
          [-4.7588, -4.7588, -4.7588, -4.7588, -4.7588, -4.7588, -4.7588,
           -4.7588, -4.7588, -4.7588, -4.7588, -4.7588, -4.7588, -4.7588,
           -4.7588],
          [-4.7588, -4.7588, -4.7588, -4.7588, -4.7588, -4.7588, -4.7588,
           -4.7588, -4.7588, -4.7588, -4.7588, -4.7588, -4.7588, -4.7588,
           -4.7588],
          [-3.8854, -3.8854, -3.8854, -3.8854, -3.8854, -3.8854, -3.8854,
           -3.8854, -3.8854, -3.8854, -3.8854, -3.8854, -3.8854, -3.8854,
           -3.8854],
          [-4.1530, -4.1530, -4.1530, -4.1530, -4.1530, -4.1530, -4.1530,
           -4.1530, -4.1530, -4.1530, -4.1530, -4.1530, -4.1530, -4.1530,
           -4.1530],
          [-0.7729, -0.7729, -0.7729, -0.7729, -0.7729, -0.7729, -0.7729,
           -0.7729, -0.7729, -0.7729, -0.7729, -0.7729, -0.7729, -0.7729,
           -0.7729],
          [-4.7588, -4.7588, -4.7588, -4.7588, -4.7588, -4.7588, -4.7588,
           -4.7588, -4.7588, -4.7588, -4.7588, -4.7588, -4.7588, -4.7588,
           -4.7588],
          [-4.7588, -4.7588, -4.7588, -4.7588, -4.7588, -4.7588, -4.7588,
           -4.7588, -4.7588, -4.7588, -4.7588, -4.7588, -4.7588, -4.7588,
           -4.7588],
          [-4.5315, -4.5315, -4.5315, -4.5315, -4.5315, -4.5315, -4.5315,
           -4.5315, -4.5315, -4.5315, -4.5315, -4.5315, -4.5315, -4.5315,
           -4.5315]]],


        [[[-4.9504, -4.9504, -4.9504, -4.9504, -4.9504, -4.9504, -4.9504,
           -4.9504, -4.9504, -4.9504, -4.9504, -4.9504, -4.9504, -4.9504,
           -4.9504],
          [-0.2450, -0.2450, -0.2450, -0.2450, -0.2450, -0.2450, -0.2450,
           -0.2450, -0.2450, -0.2450, -0.2450, -0.2450, -0.2450, -0.2450,
           -0.2450],
          [-3.1151, -3.1151, -3.1151, -3.1151, -3.1151, -3.1151, -3.1151,
           -3.1151, -3.1151, -3.1151, -3.1151, -3.1151, -3.1151, -3.1151,
           -3.1151],
          [-4.3514, -4.3514, -4.3514, -4.3514, -4.3514, -4.3514, -4.3514,
           -4.3514, -4.3514, -4.3514, -4.3514, -4.3514, -4.3514, -4.3514,
           -4.3514],
          [-0.2450, -0.2450, -0.2450, -0.2450, -0.2450, -0.2450, -0.2450,
           -0.2450, -0.2450, -0.2450, -0.2450, -0.2450, -0.2450, -0.2450,
           -0.2450],
          [-4.9504, -4.9504, -4.9504, -4.9504, -4.9504, -4.9504, -4.9504,
           -4.9504, -4.9504, -4.9504, -4.9504, -4.9504, -4.9504, -4.9504,
           -4.9504],
          [-4.9504, -4.9504, -4.9504, -4.9504, -4.9504, -4.9504, -4.9504,
           -4.9504, -4.9504, -4.9504, -4.9504, -4.9504, -4.9504, -4.9504,
           -4.9504],
          [-4.9504, -4.9504, -4.9504, -4.9504, -4.9504, -4.9504, -4.9504,
           -4.9504, -4.9504, -4.9504, -4.9504, -4.9504, -4.9504, -4.9504,
           -4.9504],
          [-4.9504, -4.9504, -4.9504, -4.9504, -4.9504, -4.9504, -4.9504,
           -4.9504, -4.9504, -4.9504, -4.9504, -4.9504, -4.9504, -4.9504,
           -4.9504],
          [-4.9504, -4.9504, -4.9504, -4.9504, -4.9504, -4.9504, -4.9504,
           -4.9504, -4.9504, -4.9504, -4.9504, -4.9504, -4.9504, -4.9504,
           -4.9504],
          [-4.1373, -4.1373, -4.1373, -4.1373, -4.1373, -4.1373, -4.1373,
           -4.1373, -4.1373, -4.1373, -4.1373, -4.1373, -4.1373, -4.1373,
           -4.1373],
          [-4.5097, -4.5097, -4.5097, -4.5097, -4.5098, -4.5097, -4.5098,
           -4.5097, -4.5097, -4.5097, -4.5097, -4.5098, -4.5097, -4.5097,
           -4.5097],
          [-1.1210, -1.1210, -1.1210, -1.1210, -1.1210, -1.1210, -1.1210,
           -1.1210, -1.1210, -1.1210, -1.1210, -1.1210, -1.1210, -1.1210,
           -1.1210],
          [-4.9504, -4.9504, -4.9504, -4.9504, -4.9504, -4.9504, -4.9504,
           -4.9504, -4.9504, -4.9504, -4.9504, -4.9504, -4.9504, -4.9504,
           -4.9504],
          [-4.9504, -4.9504, -4.9504, -4.9504, -4.9504, -4.9504, -4.9504,
           -4.9504, -4.9504, -4.9504, -4.9504, -4.9504, -4.9504, -4.9504,
           -4.9504],
          [-4.8600, -4.8600, -4.8600, -4.8600, -4.8600, -4.8600, -4.8600,
           -4.8600, -4.8600, -4.8600, -4.8600, -4.8600, -4.8600, -4.8600,
           -4.8600]],

         [[-5.0307, -5.0307, -5.0307, -5.0307, -5.0307, -5.0307, -5.0307,
           -5.0307, -5.0307, -5.0307, -5.0307, -5.0307, -5.0307, -5.0307,
           -5.0307],
          [-5.0307, -5.0307, -5.0307, -5.0307, -5.0307, -5.0307, -5.0307,
           -5.0307, -5.0307, -5.0307, -5.0307, -5.0307, -5.0307, -5.0307,
           -5.0307],
          [-3.0930, -3.0930, -3.0930, -3.0930, -3.0930, -3.0930, -3.0930,
           -3.0930, -3.0930, -3.0930, -3.0930, -3.0930, -3.0930, -3.0930,
           -3.0930],
          [-4.3984, -4.3984, -4.3984, -4.3984, -4.3984, -4.3984, -4.3984,
           -4.3984, -4.3984, -4.3984, -4.3984, -4.3984, -4.3984, -4.3984,
           -4.3984],
          [-3.1650, -3.1650, -3.1650, -3.1650, -3.1650, -3.1650, -3.1650,
           -3.1650, -3.1650, -3.1650, -3.1650, -3.1650, -3.1650, -3.1650,
           -3.1650],
          [-5.0307, -5.0307, -5.0307, -5.0307, -5.0307, -5.0307, -5.0307,
           -5.0307, -5.0307, -5.0307, -5.0307, -5.0307, -5.0307, -5.0307,
           -5.0307],
          [-5.0307, -5.0307, -5.0307, -5.0307, -5.0307, -5.0307, -5.0307,
           -5.0307, -5.0307, -5.0307, -5.0307, -5.0307, -5.0307, -5.0307,
           -5.0307],
          [-5.0307, -5.0307, -5.0307, -5.0307, -5.0307, -5.0307, -5.0307,
           -5.0307, -5.0307, -5.0307, -5.0307, -5.0307, -5.0307, -5.0307,
           -5.0307],
          [-5.0307, -5.0307, -5.0307, -5.0307, -5.0307, -5.0307, -5.0307,
           -5.0307, -5.0307, -5.0307, -5.0307, -5.0307, -5.0307, -5.0307,
           -5.0307],
          [-5.0307, -5.0307, -5.0307, -5.0307, -5.0307, -5.0307, -5.0307,
           -5.0307, -5.0307, -5.0307, -5.0307, -5.0307, -5.0307, -5.0307,
           -5.0307],
          [-4.1723, -4.1723, -4.1723, -4.1723, -4.1723, -4.1723, -4.1723,
           -4.1723, -4.1723, -4.1723, -4.1723, -4.1723, -4.1723, -4.1723,
           -4.1723],
          [-4.5655, -4.5655, -4.5655, -4.5655, -4.5655, -4.5655, -4.5655,
           -4.5655, -4.5655, -4.5655, -4.5655, -4.5655, -4.5655, -4.5655,
           -4.5655],
          [-0.9876, -0.9876, -0.9876, -0.9876, -0.9876, -0.9876, -0.9876,
           -0.9876, -0.9876, -0.9876, -0.9876, -0.9876, -0.9876, -0.9876,
           -0.9876],
          [-5.0307, -5.0307, -5.0307, -5.0307, -5.0307, -5.0307, -5.0307,
           -5.0307, -5.0307, -5.0307, -5.0307, -5.0307, -5.0307, -5.0307,
           -5.0307],
          [-5.0307, -5.0307, -5.0307, -5.0307, -5.0307, -5.0307, -5.0307,
           -5.0307, -5.0307, -5.0307, -5.0307, -5.0307, -5.0307, -5.0307,
           -5.0307],
          [-4.9353, -4.9353, -4.9353, -4.9353, -4.9353, -4.9353, -4.9353,
           -4.9353, -4.9353, -4.9353, -4.9353, -4.9353, -4.9353, -4.9353,
           -4.9353]]]], grad_fn=<SliceBackward0>)
train_step: Entropy shape: torch.Size([16, 15])
train_step: Entropy sample: tensor([[0.5961, 0.5980],
        [0.6603, 0.6930]], grad_fn=<SliceBackward0>)
train_step: Entropy coefficient: 0.01
train_step: Actor loss: -1.4908298254013062
train_step: returns shape after mean: torch.Size([16, 15])
train_step: target_indices shape: torch.Size([16, 15])
train_step: value_logits shape: torch.Size([16, 15, 255])
train_step: target_twohot shape: torch.Size([16, 15, 255])
--- Starting train_step at 2025-04-01 01:52:16 ---
Full starting_state: {'deter': tensor([[[-0.0656, -0.1184, -0.0869,  ...,  0.0052,  0.0389, -0.1182],
         [-0.0548, -0.0162,  0.0283,  ..., -0.1556,  0.0339,  0.0533],
         [-0.1102, -0.0257, -0.0164,  ...,  0.0198,  0.0145, -0.0596],
         ...,
         [ 0.0315,  0.1329, -0.0712,  ..., -0.1089, -0.0216, -0.0527],
         [-0.0337,  0.1266,  0.0351,  ..., -0.0189,  0.0342,  0.0077],
         [ 0.1313,  0.0870, -0.1059,  ...,  0.0492,  0.0880, -0.0327]],

        [[ 0.0056,  0.1078, -0.1798,  ...,  0.0411,  0.0551, -0.1640],
         [ 0.0333, -0.0705, -0.1604,  ..., -0.0109, -0.1591,  0.0174],
         [ 0.1679, -0.0196, -0.0307,  ...,  0.0477, -0.0255, -0.0016],
         ...,
         [-0.1221,  0.2292, -0.1552,  ..., -0.0386, -0.0559, -0.1040],
         [-0.0859,  0.1206, -0.0240,  ...,  0.0326,  0.0192, -0.1467],
         [-0.2897,  0.1288, -0.1619,  ..., -0.1235, -0.1199, -0.0484]],

        [[-0.0339, -0.0196,  0.1160,  ..., -0.0613, -0.0743,  0.0647],
         [-0.0891,  0.0616,  0.0934,  ..., -0.0473, -0.0170,  0.0178],
         [ 0.0809,  0.0260, -0.0489,  ..., -0.0027,  0.0738, -0.0433],
         ...,
         [-0.2234, -0.0839, -0.0581,  ...,  0.0180, -0.1197, -0.0427],
         [-0.0092, -0.0768,  0.0498,  ..., -0.0408,  0.1284,  0.0024],
         [ 0.0181, -0.0922, -0.0178,  ..., -0.0271, -0.0566,  0.0682]],

        ...,

        [[-0.0020,  0.0086, -0.1472,  ..., -0.1343, -0.1416,  0.0293],
         [-0.0359,  0.1442,  0.0045,  ...,  0.1179,  0.0082,  0.0337],
         [-0.0629,  0.0227, -0.0018,  ..., -0.0842,  0.0309, -0.0327],
         ...,
         [-0.0863, -0.1202, -0.0091,  ..., -0.0763,  0.0952, -0.0622],
         [ 0.0505, -0.1717, -0.1136,  ..., -0.0507,  0.0964,  0.0876],
         [-0.0209, -0.1750,  0.0075,  ...,  0.2587,  0.0223,  0.0537]],

        [[-0.0588, -0.0256, -0.0313,  ..., -0.0684, -0.0480, -0.1614],
         [-0.1335, -0.0380,  0.0263,  ...,  0.1374, -0.0901,  0.0537],
         [ 0.0482, -0.1329, -0.0589,  ..., -0.1119, -0.0693, -0.1095],
         ...,
         [-0.0014,  0.0560, -0.1456,  ...,  0.0457, -0.1100, -0.1774],
         [-0.0417, -0.0462, -0.0308,  ..., -0.1128,  0.0423, -0.0511],
         [-0.0649,  0.2001, -0.0045,  ...,  0.0938, -0.0818, -0.0605]],

        [[ 0.0745, -0.1252, -0.0022,  ..., -0.0300,  0.0383,  0.0192],
         [-0.0966,  0.0371, -0.1153,  ..., -0.0710,  0.0114, -0.0350],
         [-0.0993, -0.0422, -0.0260,  ..., -0.1330, -0.0364, -0.0847],
         ...,
         [ 0.0062,  0.0076, -0.0639,  ..., -0.0381, -0.0045, -0.0151],
         [-0.0035,  0.1247, -0.0401,  ..., -0.1024,  0.0528, -0.0550],
         [-0.0955, -0.0741, -0.0660,  ..., -0.1130,  0.0720, -0.0505]]],
       grad_fn=<StackBackward0>), 'stoch': tensor([[[1., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 1.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[1., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 1.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 1., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]])}
train_step: Starting state deter shape: torch.Size([16, 50, 128])
train_step: Starting state stoch shape: torch.Size([16, 50, 1024])
After ensuring logits/stoch: {'deter': tensor([[[-0.0656, -0.1184, -0.0869,  ...,  0.0052,  0.0389, -0.1182],
         [-0.0548, -0.0162,  0.0283,  ..., -0.1556,  0.0339,  0.0533],
         [-0.1102, -0.0257, -0.0164,  ...,  0.0198,  0.0145, -0.0596],
         ...,
         [ 0.0315,  0.1329, -0.0712,  ..., -0.1089, -0.0216, -0.0527],
         [-0.0337,  0.1266,  0.0351,  ..., -0.0189,  0.0342,  0.0077],
         [ 0.1313,  0.0870, -0.1059,  ...,  0.0492,  0.0880, -0.0327]],

        [[ 0.0056,  0.1078, -0.1798,  ...,  0.0411,  0.0551, -0.1640],
         [ 0.0333, -0.0705, -0.1604,  ..., -0.0109, -0.1591,  0.0174],
         [ 0.1679, -0.0196, -0.0307,  ...,  0.0477, -0.0255, -0.0016],
         ...,
         [-0.1221,  0.2292, -0.1552,  ..., -0.0386, -0.0559, -0.1040],
         [-0.0859,  0.1206, -0.0240,  ...,  0.0326,  0.0192, -0.1467],
         [-0.2897,  0.1288, -0.1619,  ..., -0.1235, -0.1199, -0.0484]],

        [[-0.0339, -0.0196,  0.1160,  ..., -0.0613, -0.0743,  0.0647],
         [-0.0891,  0.0616,  0.0934,  ..., -0.0473, -0.0170,  0.0178],
         [ 0.0809,  0.0260, -0.0489,  ..., -0.0027,  0.0738, -0.0433],
         ...,
         [-0.2234, -0.0839, -0.0581,  ...,  0.0180, -0.1197, -0.0427],
         [-0.0092, -0.0768,  0.0498,  ..., -0.0408,  0.1284,  0.0024],
         [ 0.0181, -0.0922, -0.0178,  ..., -0.0271, -0.0566,  0.0682]],

        ...,

        [[-0.0020,  0.0086, -0.1472,  ..., -0.1343, -0.1416,  0.0293],
         [-0.0359,  0.1442,  0.0045,  ...,  0.1179,  0.0082,  0.0337],
         [-0.0629,  0.0227, -0.0018,  ..., -0.0842,  0.0309, -0.0327],
         ...,
         [-0.0863, -0.1202, -0.0091,  ..., -0.0763,  0.0952, -0.0622],
         [ 0.0505, -0.1717, -0.1136,  ..., -0.0507,  0.0964,  0.0876],
         [-0.0209, -0.1750,  0.0075,  ...,  0.2587,  0.0223,  0.0537]],

        [[-0.0588, -0.0256, -0.0313,  ..., -0.0684, -0.0480, -0.1614],
         [-0.1335, -0.0380,  0.0263,  ...,  0.1374, -0.0901,  0.0537],
         [ 0.0482, -0.1329, -0.0589,  ..., -0.1119, -0.0693, -0.1095],
         ...,
         [-0.0014,  0.0560, -0.1456,  ...,  0.0457, -0.1100, -0.1774],
         [-0.0417, -0.0462, -0.0308,  ..., -0.1128,  0.0423, -0.0511],
         [-0.0649,  0.2001, -0.0045,  ...,  0.0938, -0.0818, -0.0605]],

        [[ 0.0745, -0.1252, -0.0022,  ..., -0.0300,  0.0383,  0.0192],
         [-0.0966,  0.0371, -0.1153,  ..., -0.0710,  0.0114, -0.0350],
         [-0.0993, -0.0422, -0.0260,  ..., -0.1330, -0.0364, -0.0847],
         ...,
         [ 0.0062,  0.0076, -0.0639,  ..., -0.0381, -0.0045, -0.0151],
         [-0.0035,  0.1247, -0.0401,  ..., -0.1024,  0.0528, -0.0550],
         [-0.0955, -0.0741, -0.0660,  ..., -0.1130,  0.0720, -0.0505]]],
       grad_fn=<StackBackward0>), 'stoch': tensor([[[1., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 1.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[1., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 1.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 1., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]]), 'logits': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]])}
train_step: Normalized hidden_state shape: torch.Size([1, 16, 128])
train_step: Normalized stoch shape: torch.Size([16, 1024])
train_step: Normalized deter shape: torch.Size([16, 128])
train_step: Post-imagine_trajectory: Imagined features shape: torch.Size([16, 15, 1152])
train_step: Post-imagine_trajectory: Imagined actions shape: torch.Size([16, 15, 2])
train_step: Post-imagine_trajectory: Imagined action indices shape: torch.Size([16, 15])
train_step: Post-imagine_trajectory: Imagined state deter shape: torch.Size([16, 15, 128])
train_step: Post-imagine_trajectory: Imagined state stoch shape: torch.Size([16, 15, 1024])
Reward shape: torch.Size([16, 15, 1]), Value shape: torch.Size([16, 15, 1]), Slow Value shape: torch.Size([16, 15, 1]), Discount shape: torch.Size([16, 15, 1, 1])
Return targets length: 15, First target shape: torch.Size([16, 16, 1])
train_step: Actor distribution shape: torch.Size([16, 15, 2])
train_step: Action log probabilities shape: torch.Size([16, 15])
train_step: Action log probabilities sample: tensor([[-0.6901, -0.2392],
        [-0.2532, -0.3237]], grad_fn=<SliceBackward0>)
train_step: Advantages shape: torch.Size([16, 15, 16, 15])
train_step: Advantages sample: tensor([[[[-7.6303, -7.6303, -7.6303, -7.6303, -7.6303, -7.6303, -7.6303,
           -7.6303, -7.6303, -7.6303, -7.6303, -7.6303, -7.6303, -7.6303,
           -7.6303],
          [-4.8028, -4.8028, -4.8028, -4.8028, -4.8028, -4.8028, -4.8028,
           -4.8028, -4.8028, -4.8028, -4.8028, -4.8028, -4.8028, -4.8028,
           -4.8028],
          [-5.5013, -5.5013, -5.5013, -5.5013, -5.5013, -5.5013, -5.5013,
           -5.5013, -5.5013, -5.5013, -5.5013, -5.5013, -5.5013, -5.5013,
           -5.5013],
          [-7.6303, -7.6303, -7.6303, -7.6303, -7.6303, -7.6303, -7.6303,
           -7.6303, -7.6303, -7.6303, -7.6303, -7.6303, -7.6303, -7.6303,
           -7.6303],
          [-6.6166, -6.6166, -6.6166, -6.6166, -6.6166, -6.6166, -6.6166,
           -6.6166, -6.6166, -6.6166, -6.6166, -6.6166, -6.6166, -6.6166,
           -6.6166],
          [-6.5496, -6.5496, -6.5496, -6.5496, -6.5496, -6.5496, -6.5496,
           -6.5496, -6.5496, -6.5496, -6.5496, -6.5496, -6.5496, -6.5496,
           -6.5496],
          [-7.6303, -7.6303, -7.6303, -7.6303, -7.6303, -7.6303, -7.6303,
           -7.6303, -7.6303, -7.6303, -7.6303, -7.6303, -7.6303, -7.6303,
           -7.6303],
          [-7.6303, -7.6303, -7.6303, -7.6303, -7.6303, -7.6303, -7.6303,
           -7.6303, -7.6303, -7.6303, -7.6303, -7.6303, -7.6303, -7.6303,
           -7.6303],
          [-1.3657, -1.3656, -1.3657, -1.3656, -1.3657, -1.3656, -1.3656,
           -1.3656, -1.3657, -1.3656, -1.3656, -1.3656, -1.3656, -1.3656,
           -1.3656],
          [-2.3473, -2.3473, -2.3473, -2.3473, -2.3473, -2.3473, -2.3473,
           -2.3473, -2.3473, -2.3473, -2.3473, -2.3473, -2.3473, -2.3473,
           -2.3473],
          [-7.6303, -7.6303, -7.6303, -7.6303, -7.6303, -7.6303, -7.6303,
           -7.6303, -7.6303, -7.6303, -7.6303, -7.6303, -7.6303, -7.6303,
           -7.6303],
          [-5.5013, -5.5013, -5.5013, -5.5013, -5.5013, -5.5013, -5.5013,
           -5.5013, -5.5013, -5.5013, -5.5013, -5.5013, -5.5013, -5.5013,
           -5.5013],
          [-3.3032, -3.3032, -3.3032, -3.3032, -3.3032, -3.3032, -3.3032,
           -3.3032, -3.3032, -3.3032, -3.3032, -3.3032, -3.3032, -3.3032,
           -3.3032],
          [-5.8046, -5.8046, -5.8046, -5.8046, -5.8046, -5.8046, -5.8046,
           -5.8046, -5.8046, -5.8046, -5.8046, -5.8046, -5.8046, -5.8046,
           -5.8046],
          [-5.8046, -5.8046, -5.8046, -5.8046, -5.8046, -5.8046, -5.8046,
           -5.8046, -5.8046, -5.8046, -5.8046, -5.8046, -5.8046, -5.8046,
           -5.8046],
          [-7.6303, -7.6303, -7.6303, -7.6303, -7.6303, -7.6303, -7.6303,
           -7.6303, -7.6303, -7.6303, -7.6303, -7.6303, -7.6303, -7.6303,
           -7.6303]],

         [[-7.1795, -7.1795, -7.1795, -7.1795, -7.1795, -7.1795, -7.1795,
           -7.1795, -7.1795, -7.1795, -7.1795, -7.1795, -7.1795, -7.1795,
           -7.1795],
          [-4.1942, -4.1942, -4.1942, -4.1942, -4.1942, -4.1942, -4.1942,
           -4.1942, -4.1942, -4.1942, -4.1942, -4.1942, -4.1942, -4.1942,
           -4.1942],
          [-4.9317, -4.9317, -4.9317, -4.9317, -4.9317, -4.9317, -4.9317,
           -4.9317, -4.9317, -4.9317, -4.9317, -4.9317, -4.9317, -4.9317,
           -4.9317],
          [-7.1795, -7.1795, -7.1795, -7.1795, -7.1795, -7.1795, -7.1795,
           -7.1795, -7.1795, -7.1795, -7.1795, -7.1795, -7.1795, -7.1795,
           -7.1795],
          [-6.1093, -6.1092, -6.1093, -6.1093, -6.1093, -6.1093, -6.1093,
           -6.1093, -6.1093, -6.1093, -6.1093, -6.1093, -6.1093, -6.1093,
           -6.1093],
          [-6.0385, -6.0385, -6.0385, -6.0385, -6.0385, -6.0385, -6.0385,
           -6.0385, -6.0385, -6.0385, -6.0385, -6.0385, -6.0385, -6.0385,
           -6.0385],
          [-7.1795, -7.1795, -7.1795, -7.1795, -7.1795, -7.1795, -7.1795,
           -7.1795, -7.1795, -7.1795, -7.1795, -7.1795, -7.1795, -7.1795,
           -7.1795],
          [-7.1795, -7.1795, -7.1795, -7.1795, -7.1795, -7.1795, -7.1795,
           -7.1795, -7.1795, -7.1795, -7.1795, -7.1795, -7.1795, -7.1795,
           -7.1795],
          [-0.5653, -0.5653, -0.5653, -0.5653, -0.5653, -0.5653, -0.5653,
           -0.5653, -0.5653, -0.5653, -0.5653, -0.5653, -0.5653, -0.5653,
           -0.5653],
          [-1.6017, -1.6017, -1.6017, -1.6017, -1.6017, -1.6017, -1.6017,
           -1.6017, -1.6017, -1.6017, -1.6017, -1.6017, -1.6017, -1.6017,
           -1.6017],
          [-7.1795, -7.1795, -7.1795, -7.1795, -7.1795, -7.1795, -7.1795,
           -7.1795, -7.1795, -7.1795, -7.1795, -7.1795, -7.1795, -7.1795,
           -7.1795],
          [-4.9317, -4.9317, -4.9317, -4.9317, -4.9317, -4.9317, -4.9317,
           -4.9317, -4.9317, -4.9317, -4.9317, -4.9317, -4.9317, -4.9317,
           -4.9317],
          [-2.6110, -2.6110, -2.6110, -2.6110, -2.6110, -2.6110, -2.6110,
           -2.6110, -2.6110, -2.6110, -2.6110, -2.6110, -2.6110, -2.6110,
           -2.6110],
          [-5.2519, -5.2519, -5.2519, -5.2519, -5.2519, -5.2519, -5.2519,
           -5.2519, -5.2519, -5.2519, -5.2519, -5.2519, -5.2519, -5.2519,
           -5.2519],
          [-5.2519, -5.2519, -5.2519, -5.2519, -5.2519, -5.2519, -5.2519,
           -5.2519, -5.2519, -5.2519, -5.2519, -5.2519, -5.2519, -5.2519,
           -5.2519],
          [-7.1795, -7.1795, -7.1795, -7.1795, -7.1795, -7.1795, -7.1795,
           -7.1795, -7.1795, -7.1795, -7.1795, -7.1795, -7.1795, -7.1795,
           -7.1795]]],


        [[[-7.7611, -7.7611, -7.7612, -7.7611, -7.7612, -7.7611, -7.7611,
           -7.7611, -7.7611, -7.7611, -7.7611, -7.7611, -7.7611, -7.7611,
           -7.7611],
          [-5.4589, -5.4589, -5.4589, -5.4589, -5.4589, -5.4589, -5.4589,
           -5.4589, -5.4589, -5.4589, -5.4589, -5.4589, -5.4589, -5.4589,
           -5.4589],
          [-5.5695, -5.5695, -5.5695, -5.5695, -5.5695, -5.5695, -5.5695,
           -5.5695, -5.5695, -5.5695, -5.5695, -5.5695, -5.5695, -5.5695,
           -5.5695],
          [-7.7611, -7.7611, -7.7612, -7.7611, -7.7612, -7.7611, -7.7611,
           -7.7611, -7.7611, -7.7611, -7.7611, -7.7611, -7.7611, -7.7611,
           -7.7611],
          [-6.6802, -6.6802, -6.6802, -6.6802, -6.6802, -6.6802, -6.6802,
           -6.6802, -6.6802, -6.6802, -6.6802, -6.6802, -6.6802, -6.6802,
           -6.6802],
          [-6.9180, -6.9180, -6.9180, -6.9180, -6.9180, -6.9180, -6.9180,
           -6.9180, -6.9180, -6.9180, -6.9180, -6.9180, -6.9180, -6.9180,
           -6.9180],
          [-7.7611, -7.7611, -7.7612, -7.7611, -7.7612, -7.7611, -7.7611,
           -7.7611, -7.7611, -7.7611, -7.7611, -7.7611, -7.7611, -7.7611,
           -7.7611],
          [-7.7611, -7.7611, -7.7612, -7.7611, -7.7612, -7.7611, -7.7611,
           -7.7611, -7.7611, -7.7611, -7.7611, -7.7611, -7.7611, -7.7611,
           -7.7611],
          [-2.2472, -2.2471, -2.2472, -2.2472, -2.2472, -2.2472, -2.2472,
           -2.2472, -2.2472, -2.2472, -2.2472, -2.2472, -2.2472, -2.2472,
           -2.2472],
          [-3.6576, -3.6576, -3.6576, -3.6576, -3.6576, -3.6576, -3.6576,
           -3.6576, -3.6576, -3.6576, -3.6576, -3.6576, -3.6576, -3.6576,
           -3.6576],
          [-7.7611, -7.7611, -7.7612, -7.7611, -7.7612, -7.7611, -7.7611,
           -7.7611, -7.7611, -7.7611, -7.7611, -7.7611, -7.7611, -7.7611,
           -7.7611],
          [-5.5695, -5.5695, -5.5695, -5.5695, -5.5695, -5.5695, -5.5695,
           -5.5695, -5.5695, -5.5695, -5.5695, -5.5695, -5.5695, -5.5695,
           -5.5695],
          [-4.5881, -4.5880, -4.5881, -4.5881, -4.5881, -4.5881, -4.5881,
           -4.5880, -4.5881, -4.5880, -4.5880, -4.5880, -4.5880, -4.5880,
           -4.5880],
          [-6.2169, -6.2169, -6.2169, -6.2169, -6.2169, -6.2169, -6.2169,
           -6.2169, -6.2169, -6.2169, -6.2169, -6.2169, -6.2169, -6.2169,
           -6.2169],
          [-6.2169, -6.2169, -6.2169, -6.2169, -6.2169, -6.2169, -6.2169,
           -6.2169, -6.2169, -6.2169, -6.2169, -6.2169, -6.2169, -6.2169,
           -6.2169],
          [-7.7611, -7.7611, -7.7612, -7.7611, -7.7612, -7.7611, -7.7611,
           -7.7611, -7.7611, -7.7611, -7.7611, -7.7611, -7.7611, -7.7611,
           -7.7611]],

         [[-7.6393, -7.6393, -7.6393, -7.6393, -7.6393, -7.6393, -7.6393,
           -7.6393, -7.6393, -7.6393, -7.6393, -7.6393, -7.6393, -7.6393,
           -7.6393],
          [-5.2086, -5.2086, -5.2086, -5.2086, -5.2086, -5.2086, -5.2086,
           -5.2086, -5.2086, -5.2086, -5.2086, -5.2086, -5.2086, -5.2086,
           -5.2086],
          [-5.3254, -5.3254, -5.3254, -5.3254, -5.3254, -5.3254, -5.3254,
           -5.3254, -5.3254, -5.3254, -5.3254, -5.3254, -5.3254, -5.3254,
           -5.3254],
          [-7.6393, -7.6393, -7.6393, -7.6393, -7.6393, -7.6393, -7.6393,
           -7.6393, -7.6393, -7.6393, -7.6393, -7.6393, -7.6393, -7.6393,
           -7.6393],
          [-6.4981, -6.4981, -6.4981, -6.4981, -6.4981, -6.4981, -6.4981,
           -6.4981, -6.4981, -6.4981, -6.4981, -6.4981, -6.4981, -6.4981,
           -6.4981],
          [-6.7491, -6.7491, -6.7491, -6.7491, -6.7491, -6.7491, -6.7491,
           -6.7491, -6.7491, -6.7491, -6.7491, -6.7491, -6.7491, -6.7491,
           -6.7491],
          [-7.6393, -7.6393, -7.6393, -7.6393, -7.6393, -7.6393, -7.6393,
           -7.6393, -7.6393, -7.6393, -7.6393, -7.6393, -7.6393, -7.6393,
           -7.6393],
          [-7.6393, -7.6393, -7.6393, -7.6393, -7.6393, -7.6393, -7.6393,
           -7.6393, -7.6393, -7.6393, -7.6393, -7.6393, -7.6393, -7.6393,
           -7.6393],
          [-1.8177, -1.8177, -1.8177, -1.8177, -1.8177, -1.8177, -1.8177,
           -1.8177, -1.8177, -1.8177, -1.8177, -1.8177, -1.8177, -1.8177,
           -1.8177],
          [-3.3068, -3.3068, -3.3068, -3.3068, -3.3068, -3.3068, -3.3068,
           -3.3068, -3.3068, -3.3068, -3.3068, -3.3068, -3.3068, -3.3068,
           -3.3068],
          [-7.6393, -7.6393, -7.6393, -7.6393, -7.6393, -7.6393, -7.6393,
           -7.6393, -7.6393, -7.6393, -7.6393, -7.6393, -7.6393, -7.6393,
           -7.6393],
          [-5.3254, -5.3254, -5.3254, -5.3254, -5.3254, -5.3254, -5.3254,
           -5.3254, -5.3254, -5.3254, -5.3254, -5.3254, -5.3254, -5.3254,
           -5.3254],
          [-4.2892, -4.2892, -4.2892, -4.2892, -4.2892, -4.2892, -4.2892,
           -4.2892, -4.2892, -4.2892, -4.2892, -4.2892, -4.2892, -4.2892,
           -4.2892],
          [-6.0089, -6.0089, -6.0089, -6.0089, -6.0089, -6.0089, -6.0089,
           -6.0089, -6.0089, -6.0089, -6.0089, -6.0089, -6.0089, -6.0089,
           -6.0089],
          [-6.0089, -6.0089, -6.0089, -6.0089, -6.0089, -6.0089, -6.0089,
           -6.0089, -6.0089, -6.0089, -6.0089, -6.0089, -6.0089, -6.0089,
           -6.0089],
          [-7.6393, -7.6393, -7.6393, -7.6393, -7.6393, -7.6393, -7.6393,
           -7.6393, -7.6393, -7.6393, -7.6393, -7.6393, -7.6393, -7.6393,
           -7.6393]]]], grad_fn=<SliceBackward0>)
train_step: Return scale: 1.378615589350582
train_step: Scaled advantages shape: torch.Size([16, 15, 16, 15])
train_step: Scaled advantages sample: tensor([[[[-5.5348, -5.5348, -5.5348, -5.5348, -5.5348, -5.5348, -5.5348,
           -5.5348, -5.5348, -5.5348, -5.5348, -5.5348, -5.5348, -5.5348,
           -5.5348],
          [-3.4838, -3.4838, -3.4838, -3.4838, -3.4838, -3.4838, -3.4838,
           -3.4838, -3.4838, -3.4838, -3.4838, -3.4838, -3.4838, -3.4838,
           -3.4838],
          [-3.9904, -3.9904, -3.9905, -3.9904, -3.9905, -3.9904, -3.9904,
           -3.9904, -3.9904, -3.9904, -3.9904, -3.9904, -3.9904, -3.9904,
           -3.9904],
          [-5.5348, -5.5348, -5.5348, -5.5348, -5.5348, -5.5348, -5.5348,
           -5.5348, -5.5348, -5.5348, -5.5348, -5.5348, -5.5348, -5.5348,
           -5.5348],
          [-4.7995, -4.7995, -4.7995, -4.7995, -4.7995, -4.7995, -4.7995,
           -4.7995, -4.7995, -4.7995, -4.7995, -4.7995, -4.7995, -4.7995,
           -4.7995],
          [-4.7509, -4.7509, -4.7509, -4.7509, -4.7509, -4.7509, -4.7509,
           -4.7509, -4.7509, -4.7509, -4.7509, -4.7509, -4.7509, -4.7509,
           -4.7509],
          [-5.5348, -5.5348, -5.5348, -5.5348, -5.5348, -5.5348, -5.5348,
           -5.5348, -5.5348, -5.5348, -5.5348, -5.5348, -5.5348, -5.5348,
           -5.5348],
          [-5.5348, -5.5348, -5.5348, -5.5348, -5.5348, -5.5348, -5.5348,
           -5.5348, -5.5348, -5.5348, -5.5348, -5.5348, -5.5348, -5.5348,
           -5.5348],
          [-0.9906, -0.9906, -0.9906, -0.9906, -0.9906, -0.9906, -0.9906,
           -0.9906, -0.9906, -0.9906, -0.9906, -0.9906, -0.9906, -0.9906,
           -0.9906],
          [-1.7027, -1.7026, -1.7027, -1.7027, -1.7027, -1.7027, -1.7027,
           -1.7026, -1.7027, -1.7026, -1.7026, -1.7026, -1.7026, -1.7026,
           -1.7026],
          [-5.5348, -5.5348, -5.5348, -5.5348, -5.5348, -5.5348, -5.5348,
           -5.5348, -5.5348, -5.5348, -5.5348, -5.5348, -5.5348, -5.5348,
           -5.5348],
          [-3.9904, -3.9904, -3.9905, -3.9904, -3.9905, -3.9904, -3.9904,
           -3.9904, -3.9904, -3.9904, -3.9904, -3.9904, -3.9904, -3.9904,
           -3.9904],
          [-2.3961, -2.3960, -2.3961, -2.3961, -2.3961, -2.3961, -2.3961,
           -2.3961, -2.3961, -2.3960, -2.3961, -2.3960, -2.3960, -2.3961,
           -2.3961],
          [-4.2104, -4.2104, -4.2104, -4.2104, -4.2104, -4.2104, -4.2104,
           -4.2104, -4.2104, -4.2104, -4.2104, -4.2104, -4.2104, -4.2104,
           -4.2104],
          [-4.2104, -4.2104, -4.2104, -4.2104, -4.2104, -4.2104, -4.2104,
           -4.2104, -4.2104, -4.2104, -4.2104, -4.2104, -4.2104, -4.2104,
           -4.2104],
          [-5.5348, -5.5348, -5.5348, -5.5348, -5.5348, -5.5348, -5.5348,
           -5.5348, -5.5348, -5.5348, -5.5348, -5.5348, -5.5348, -5.5348,
           -5.5348]],

         [[-5.2077, -5.2077, -5.2077, -5.2077, -5.2077, -5.2077, -5.2077,
           -5.2077, -5.2077, -5.2077, -5.2077, -5.2077, -5.2077, -5.2077,
           -5.2077],
          [-3.0423, -3.0423, -3.0423, -3.0423, -3.0423, -3.0423, -3.0423,
           -3.0423, -3.0423, -3.0423, -3.0423, -3.0423, -3.0423, -3.0423,
           -3.0423],
          [-3.5773, -3.5773, -3.5773, -3.5773, -3.5773, -3.5773, -3.5773,
           -3.5773, -3.5773, -3.5773, -3.5773, -3.5773, -3.5773, -3.5773,
           -3.5773],
          [-5.2077, -5.2077, -5.2077, -5.2077, -5.2077, -5.2077, -5.2077,
           -5.2077, -5.2077, -5.2077, -5.2077, -5.2077, -5.2077, -5.2077,
           -5.2077],
          [-4.4314, -4.4314, -4.4314, -4.4314, -4.4314, -4.4314, -4.4314,
           -4.4314, -4.4314, -4.4314, -4.4314, -4.4314, -4.4314, -4.4314,
           -4.4314],
          [-4.3801, -4.3801, -4.3801, -4.3801, -4.3801, -4.3801, -4.3801,
           -4.3801, -4.3801, -4.3801, -4.3801, -4.3801, -4.3801, -4.3801,
           -4.3801],
          [-5.2077, -5.2077, -5.2077, -5.2077, -5.2077, -5.2077, -5.2077,
           -5.2077, -5.2077, -5.2077, -5.2077, -5.2077, -5.2077, -5.2077,
           -5.2077],
          [-5.2077, -5.2077, -5.2077, -5.2077, -5.2077, -5.2077, -5.2077,
           -5.2077, -5.2077, -5.2077, -5.2077, -5.2077, -5.2077, -5.2077,
           -5.2077],
          [-0.5653, -0.5653, -0.5653, -0.5653, -0.5653, -0.5653, -0.5653,
           -0.5653, -0.5653, -0.5653, -0.5653, -0.5653, -0.5653, -0.5653,
           -0.5653],
          [-1.1618, -1.1618, -1.1618, -1.1618, -1.1618, -1.1618, -1.1618,
           -1.1618, -1.1618, -1.1618, -1.1618, -1.1618, -1.1618, -1.1618,
           -1.1618],
          [-5.2077, -5.2077, -5.2077, -5.2077, -5.2077, -5.2077, -5.2077,
           -5.2077, -5.2077, -5.2077, -5.2077, -5.2077, -5.2077, -5.2077,
           -5.2077],
          [-3.5773, -3.5773, -3.5773, -3.5773, -3.5773, -3.5773, -3.5773,
           -3.5773, -3.5773, -3.5773, -3.5773, -3.5773, -3.5773, -3.5773,
           -3.5773],
          [-1.8939, -1.8939, -1.8939, -1.8939, -1.8939, -1.8939, -1.8939,
           -1.8939, -1.8939, -1.8939, -1.8939, -1.8939, -1.8939, -1.8939,
           -1.8939],
          [-3.8095, -3.8095, -3.8095, -3.8095, -3.8095, -3.8095, -3.8095,
           -3.8095, -3.8095, -3.8095, -3.8095, -3.8095, -3.8095, -3.8095,
           -3.8095],
          [-3.8095, -3.8095, -3.8095, -3.8095, -3.8095, -3.8095, -3.8095,
           -3.8095, -3.8095, -3.8095, -3.8095, -3.8095, -3.8095, -3.8095,
           -3.8095],
          [-5.2077, -5.2077, -5.2077, -5.2077, -5.2077, -5.2077, -5.2077,
           -5.2077, -5.2077, -5.2077, -5.2077, -5.2077, -5.2077, -5.2077,
           -5.2077]]],


        [[[-5.6297, -5.6297, -5.6297, -5.6297, -5.6297, -5.6297, -5.6297,
           -5.6297, -5.6297, -5.6297, -5.6297, -5.6297, -5.6297, -5.6297,
           -5.6297],
          [-3.9597, -3.9597, -3.9597, -3.9597, -3.9597, -3.9597, -3.9597,
           -3.9597, -3.9597, -3.9597, -3.9597, -3.9597, -3.9597, -3.9597,
           -3.9597],
          [-4.0399, -4.0399, -4.0399, -4.0399, -4.0399, -4.0399, -4.0399,
           -4.0399, -4.0399, -4.0399, -4.0399, -4.0399, -4.0399, -4.0399,
           -4.0399],
          [-5.6297, -5.6297, -5.6297, -5.6297, -5.6297, -5.6297, -5.6297,
           -5.6297, -5.6297, -5.6297, -5.6297, -5.6297, -5.6297, -5.6297,
           -5.6297],
          [-4.8456, -4.8456, -4.8456, -4.8456, -4.8456, -4.8456, -4.8456,
           -4.8456, -4.8456, -4.8456, -4.8456, -4.8456, -4.8456, -4.8456,
           -4.8456],
          [-5.0181, -5.0180, -5.0181, -5.0181, -5.0181, -5.0181, -5.0181,
           -5.0181, -5.0181, -5.0180, -5.0180, -5.0180, -5.0180, -5.0180,
           -5.0181],
          [-5.6297, -5.6297, -5.6297, -5.6297, -5.6297, -5.6297, -5.6297,
           -5.6297, -5.6297, -5.6297, -5.6297, -5.6297, -5.6297, -5.6297,
           -5.6297],
          [-5.6297, -5.6297, -5.6297, -5.6297, -5.6297, -5.6297, -5.6297,
           -5.6297, -5.6297, -5.6297, -5.6297, -5.6297, -5.6297, -5.6297,
           -5.6297],
          [-1.6300, -1.6300, -1.6300, -1.6300, -1.6300, -1.6300, -1.6300,
           -1.6300, -1.6300, -1.6300, -1.6300, -1.6300, -1.6300, -1.6300,
           -1.6300],
          [-2.6531, -2.6531, -2.6531, -2.6531, -2.6531, -2.6531, -2.6531,
           -2.6531, -2.6531, -2.6531, -2.6531, -2.6531, -2.6531, -2.6531,
           -2.6531],
          [-5.6297, -5.6297, -5.6297, -5.6297, -5.6297, -5.6297, -5.6297,
           -5.6297, -5.6297, -5.6297, -5.6297, -5.6297, -5.6297, -5.6297,
           -5.6297],
          [-4.0399, -4.0399, -4.0399, -4.0399, -4.0399, -4.0399, -4.0399,
           -4.0399, -4.0399, -4.0399, -4.0399, -4.0399, -4.0399, -4.0399,
           -4.0399],
          [-3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280,
           -3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280,
           -3.3280],
          [-4.5095, -4.5095, -4.5095, -4.5095, -4.5095, -4.5095, -4.5095,
           -4.5095, -4.5095, -4.5095, -4.5095, -4.5095, -4.5095, -4.5095,
           -4.5095],
          [-4.5095, -4.5095, -4.5095, -4.5095, -4.5095, -4.5095, -4.5095,
           -4.5095, -4.5095, -4.5095, -4.5095, -4.5095, -4.5095, -4.5095,
           -4.5095],
          [-5.6297, -5.6297, -5.6297, -5.6297, -5.6297, -5.6297, -5.6297,
           -5.6297, -5.6297, -5.6297, -5.6297, -5.6297, -5.6297, -5.6297,
           -5.6297]],

         [[-5.5413, -5.5413, -5.5413, -5.5413, -5.5413, -5.5413, -5.5413,
           -5.5413, -5.5413, -5.5413, -5.5413, -5.5413, -5.5413, -5.5413,
           -5.5413],
          [-3.7782, -3.7782, -3.7782, -3.7782, -3.7782, -3.7782, -3.7782,
           -3.7782, -3.7782, -3.7782, -3.7782, -3.7782, -3.7782, -3.7782,
           -3.7782],
          [-3.8629, -3.8629, -3.8629, -3.8629, -3.8629, -3.8629, -3.8629,
           -3.8629, -3.8629, -3.8629, -3.8629, -3.8629, -3.8629, -3.8629,
           -3.8629],
          [-5.5413, -5.5413, -5.5413, -5.5413, -5.5413, -5.5413, -5.5413,
           -5.5413, -5.5413, -5.5413, -5.5413, -5.5413, -5.5413, -5.5413,
           -5.5413],
          [-4.7135, -4.7135, -4.7135, -4.7135, -4.7135, -4.7135, -4.7135,
           -4.7135, -4.7135, -4.7135, -4.7135, -4.7135, -4.7135, -4.7135,
           -4.7135],
          [-4.8956, -4.8956, -4.8956, -4.8956, -4.8956, -4.8956, -4.8956,
           -4.8956, -4.8956, -4.8956, -4.8956, -4.8956, -4.8956, -4.8956,
           -4.8956],
          [-5.5413, -5.5413, -5.5413, -5.5413, -5.5413, -5.5413, -5.5413,
           -5.5413, -5.5413, -5.5413, -5.5413, -5.5413, -5.5413, -5.5413,
           -5.5413],
          [-5.5413, -5.5413, -5.5413, -5.5413, -5.5413, -5.5413, -5.5413,
           -5.5413, -5.5413, -5.5413, -5.5413, -5.5413, -5.5413, -5.5413,
           -5.5413],
          [-1.3185, -1.3185, -1.3185, -1.3185, -1.3185, -1.3185, -1.3185,
           -1.3185, -1.3185, -1.3185, -1.3185, -1.3185, -1.3185, -1.3185,
           -1.3185],
          [-2.3986, -2.3986, -2.3986, -2.3986, -2.3986, -2.3986, -2.3986,
           -2.3986, -2.3986, -2.3986, -2.3986, -2.3986, -2.3986, -2.3986,
           -2.3986],
          [-5.5413, -5.5413, -5.5413, -5.5413, -5.5413, -5.5413, -5.5413,
           -5.5413, -5.5413, -5.5413, -5.5413, -5.5413, -5.5413, -5.5413,
           -5.5413],
          [-3.8629, -3.8629, -3.8629, -3.8629, -3.8629, -3.8629, -3.8629,
           -3.8629, -3.8629, -3.8629, -3.8629, -3.8629, -3.8629, -3.8629,
           -3.8629],
          [-3.1112, -3.1112, -3.1112, -3.1112, -3.1112, -3.1112, -3.1112,
           -3.1112, -3.1112, -3.1112, -3.1112, -3.1112, -3.1112, -3.1112,
           -3.1112],
          [-4.3587, -4.3587, -4.3587, -4.3587, -4.3587, -4.3587, -4.3587,
           -4.3587, -4.3587, -4.3587, -4.3587, -4.3587, -4.3587, -4.3587,
           -4.3587],
          [-4.3587, -4.3587, -4.3587, -4.3587, -4.3587, -4.3587, -4.3587,
           -4.3587, -4.3587, -4.3587, -4.3587, -4.3587, -4.3587, -4.3587,
           -4.3587],
          [-5.5413, -5.5413, -5.5413, -5.5413, -5.5413, -5.5413, -5.5413,
           -5.5413, -5.5413, -5.5413, -5.5413, -5.5413, -5.5413, -5.5413,
           -5.5413]]]], grad_fn=<SliceBackward0>)
train_step: Entropy shape: torch.Size([16, 15])
train_step: Entropy sample: tensor([[0.6931, 0.5175],
        [0.5315, 0.5896]], grad_fn=<SliceBackward0>)
train_step: Entropy coefficient: 0.01
train_step: Actor loss: -1.3528915643692017
train_step: returns shape after mean: torch.Size([16, 15])
train_step: target_indices shape: torch.Size([16, 15])
train_step: value_logits shape: torch.Size([16, 15, 255])
train_step: target_twohot shape: torch.Size([16, 15, 255])
--- Starting train_step at 2025-04-01 01:52:33 ---
Full starting_state: {'deter': tensor([[[ 0.0394, -0.0452, -0.0737,  ..., -0.0091, -0.0820,  0.0630],
         [ 0.0392,  0.0346, -0.1684,  ..., -0.1461,  0.0391, -0.1077],
         [ 0.0841,  0.1268,  0.0110,  ...,  0.0023,  0.1945, -0.1641],
         ...,
         [-0.0371,  0.1065,  0.0924,  ..., -0.1234, -0.0505, -0.0604],
         [-0.0229,  0.1517, -0.0748,  ..., -0.0336,  0.0027, -0.0312],
         [-0.1437, -0.0638, -0.1217,  ..., -0.1163, -0.0183,  0.0359]],

        [[ 0.1032, -0.0606,  0.0847,  ...,  0.0133, -0.0736,  0.1046],
         [-0.1284,  0.0566, -0.0607,  ..., -0.0421,  0.0254, -0.0705],
         [-0.0988, -0.1366, -0.0718,  ..., -0.2614,  0.0699, -0.0137],
         ...,
         [-0.0581, -0.1171, -0.1657,  ..., -0.1080, -0.0778, -0.2403],
         [-0.0543, -0.0104,  0.0543,  ..., -0.0681, -0.0399, -0.1339],
         [ 0.0144, -0.1198, -0.0890,  ...,  0.0447,  0.0614, -0.1551]],

        [[ 0.0421,  0.1073,  0.0426,  ...,  0.0502, -0.0669, -0.2501],
         [ 0.0976, -0.0764,  0.0130,  ...,  0.0072,  0.0058, -0.0871],
         [ 0.0669,  0.0641, -0.0663,  ...,  0.1739, -0.0362, -0.1008],
         ...,
         [ 0.1397,  0.0866,  0.0049,  ...,  0.0129,  0.0040, -0.0131],
         [ 0.0101, -0.0419, -0.1718,  ...,  0.1035, -0.0813,  0.0485],
         [ 0.0506,  0.0614, -0.0258,  ...,  0.1398, -0.0631, -0.1060]],

        ...,

        [[-0.0843, -0.0585, -0.0525,  ...,  0.1939,  0.0363, -0.1973],
         [ 0.0589,  0.1033, -0.1091,  ..., -0.0355,  0.0707, -0.0816],
         [ 0.0302, -0.0086,  0.0672,  ..., -0.0079,  0.0145,  0.0385],
         ...,
         [-0.2085,  0.0018, -0.0945,  ..., -0.0961,  0.0700, -0.1336],
         [-0.0864,  0.1013,  0.0868,  ...,  0.1628, -0.0953,  0.0979],
         [-0.0118,  0.0279, -0.0310,  ..., -0.0667,  0.0646, -0.0840]],

        [[-0.1536, -0.1312,  0.0620,  ..., -0.0804, -0.0476,  0.0566],
         [ 0.0929, -0.0206, -0.1260,  ..., -0.0271, -0.0902, -0.0220],
         [-0.1370, -0.0966, -0.0463,  ..., -0.0958,  0.0167, -0.0552],
         ...,
         [ 0.0499, -0.1003, -0.0039,  ...,  0.0267, -0.0160, -0.0469],
         [-0.0554, -0.1159, -0.1697,  ..., -0.0030,  0.0009, -0.0045],
         [-0.1575, -0.1124, -0.0271,  ..., -0.2149,  0.0279, -0.1475]],

        [[-0.0662, -0.1215, -0.0864,  ...,  0.0786, -0.0030,  0.0666],
         [-0.1116,  0.0224, -0.0596,  ..., -0.0341,  0.0566, -0.0785],
         [ 0.0245,  0.0801, -0.1487,  ..., -0.0974, -0.0915,  0.0841],
         ...,
         [-0.0253,  0.0804,  0.0556,  ...,  0.1501,  0.0160, -0.0998],
         [-0.0824,  0.0899, -0.0213,  ...,  0.0544, -0.0135,  0.0102],
         [-0.0100,  0.1071, -0.1272,  ...,  0.1909,  0.0347,  0.0382]]],
       grad_fn=<StackBackward0>), 'stoch': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 1., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 1., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 1., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]])}
train_step: Starting state deter shape: torch.Size([16, 50, 128])
train_step: Starting state stoch shape: torch.Size([16, 50, 1024])
After ensuring logits/stoch: {'deter': tensor([[[ 0.0394, -0.0452, -0.0737,  ..., -0.0091, -0.0820,  0.0630],
         [ 0.0392,  0.0346, -0.1684,  ..., -0.1461,  0.0391, -0.1077],
         [ 0.0841,  0.1268,  0.0110,  ...,  0.0023,  0.1945, -0.1641],
         ...,
         [-0.0371,  0.1065,  0.0924,  ..., -0.1234, -0.0505, -0.0604],
         [-0.0229,  0.1517, -0.0748,  ..., -0.0336,  0.0027, -0.0312],
         [-0.1437, -0.0638, -0.1217,  ..., -0.1163, -0.0183,  0.0359]],

        [[ 0.1032, -0.0606,  0.0847,  ...,  0.0133, -0.0736,  0.1046],
         [-0.1284,  0.0566, -0.0607,  ..., -0.0421,  0.0254, -0.0705],
         [-0.0988, -0.1366, -0.0718,  ..., -0.2614,  0.0699, -0.0137],
         ...,
         [-0.0581, -0.1171, -0.1657,  ..., -0.1080, -0.0778, -0.2403],
         [-0.0543, -0.0104,  0.0543,  ..., -0.0681, -0.0399, -0.1339],
         [ 0.0144, -0.1198, -0.0890,  ...,  0.0447,  0.0614, -0.1551]],

        [[ 0.0421,  0.1073,  0.0426,  ...,  0.0502, -0.0669, -0.2501],
         [ 0.0976, -0.0764,  0.0130,  ...,  0.0072,  0.0058, -0.0871],
         [ 0.0669,  0.0641, -0.0663,  ...,  0.1739, -0.0362, -0.1008],
         ...,
         [ 0.1397,  0.0866,  0.0049,  ...,  0.0129,  0.0040, -0.0131],
         [ 0.0101, -0.0419, -0.1718,  ...,  0.1035, -0.0813,  0.0485],
         [ 0.0506,  0.0614, -0.0258,  ...,  0.1398, -0.0631, -0.1060]],

        ...,

        [[-0.0843, -0.0585, -0.0525,  ...,  0.1939,  0.0363, -0.1973],
         [ 0.0589,  0.1033, -0.1091,  ..., -0.0355,  0.0707, -0.0816],
         [ 0.0302, -0.0086,  0.0672,  ..., -0.0079,  0.0145,  0.0385],
         ...,
         [-0.2085,  0.0018, -0.0945,  ..., -0.0961,  0.0700, -0.1336],
         [-0.0864,  0.1013,  0.0868,  ...,  0.1628, -0.0953,  0.0979],
         [-0.0118,  0.0279, -0.0310,  ..., -0.0667,  0.0646, -0.0840]],

        [[-0.1536, -0.1312,  0.0620,  ..., -0.0804, -0.0476,  0.0566],
         [ 0.0929, -0.0206, -0.1260,  ..., -0.0271, -0.0902, -0.0220],
         [-0.1370, -0.0966, -0.0463,  ..., -0.0958,  0.0167, -0.0552],
         ...,
         [ 0.0499, -0.1003, -0.0039,  ...,  0.0267, -0.0160, -0.0469],
         [-0.0554, -0.1159, -0.1697,  ..., -0.0030,  0.0009, -0.0045],
         [-0.1575, -0.1124, -0.0271,  ..., -0.2149,  0.0279, -0.1475]],

        [[-0.0662, -0.1215, -0.0864,  ...,  0.0786, -0.0030,  0.0666],
         [-0.1116,  0.0224, -0.0596,  ..., -0.0341,  0.0566, -0.0785],
         [ 0.0245,  0.0801, -0.1487,  ..., -0.0974, -0.0915,  0.0841],
         ...,
         [-0.0253,  0.0804,  0.0556,  ...,  0.1501,  0.0160, -0.0998],
         [-0.0824,  0.0899, -0.0213,  ...,  0.0544, -0.0135,  0.0102],
         [-0.0100,  0.1071, -0.1272,  ...,  0.1909,  0.0347,  0.0382]]],
       grad_fn=<StackBackward0>), 'stoch': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 1., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 1., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 1., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]]), 'logits': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]])}
train_step: Normalized hidden_state shape: torch.Size([1, 16, 128])
train_step: Normalized stoch shape: torch.Size([16, 1024])
train_step: Normalized deter shape: torch.Size([16, 128])
train_step: Post-imagine_trajectory: Imagined features shape: torch.Size([16, 15, 1152])
train_step: Post-imagine_trajectory: Imagined actions shape: torch.Size([16, 15, 2])
train_step: Post-imagine_trajectory: Imagined action indices shape: torch.Size([16, 15])
train_step: Post-imagine_trajectory: Imagined state deter shape: torch.Size([16, 15, 128])
train_step: Post-imagine_trajectory: Imagined state stoch shape: torch.Size([16, 15, 1024])
Reward shape: torch.Size([16, 15, 1]), Value shape: torch.Size([16, 15, 1]), Slow Value shape: torch.Size([16, 15, 1]), Discount shape: torch.Size([16, 15, 1, 1])
Return targets length: 15, First target shape: torch.Size([16, 16, 1])
train_step: Actor distribution shape: torch.Size([16, 15, 2])
train_step: Action log probabilities shape: torch.Size([16, 15])
train_step: Action log probabilities sample: tensor([[-0.0861, -0.2562],
        [-1.5885, -0.2882]], grad_fn=<SliceBackward0>)
train_step: Advantages shape: torch.Size([16, 15, 16, 15])
train_step: Advantages sample: tensor([[[[-7.2929, -7.2929, -7.2929, -7.2929, -7.2929, -7.2929, -7.2929,
           -7.2929, -7.2929, -7.2929, -7.2929, -7.2929, -7.2929, -7.2929,
           -7.2929],
          [-7.2929, -7.2929, -7.2929, -7.2929, -7.2929, -7.2929, -7.2929,
           -7.2929, -7.2929, -7.2929, -7.2929, -7.2929, -7.2929, -7.2929,
           -7.2929],
          [-4.4009, -4.4009, -4.4009, -4.4009, -4.4009, -4.4009, -4.4009,
           -4.4009, -4.4009, -4.4009, -4.4009, -4.4010, -4.4009, -4.4009,
           -4.4010],
          [-7.2929, -7.2929, -7.2929, -7.2929, -7.2929, -7.2929, -7.2929,
           -7.2929, -7.2929, -7.2929, -7.2929, -7.2929, -7.2929, -7.2929,
           -7.2929],
          [-7.2929, -7.2929, -7.2929, -7.2929, -7.2929, -7.2929, -7.2929,
           -7.2929, -7.2929, -7.2929, -7.2929, -7.2929, -7.2929, -7.2929,
           -7.2929],
          [-0.7926, -0.7926, -0.7926, -0.7926, -0.7926, -0.7926, -0.7926,
           -0.7926, -0.7926, -0.7926, -0.7926, -0.7926, -0.7926, -0.7926,
           -0.7926],
          [-7.2929, -7.2929, -7.2929, -7.2929, -7.2929, -7.2929, -7.2929,
           -7.2929, -7.2929, -7.2929, -7.2929, -7.2929, -7.2929, -7.2929,
           -7.2929],
          [-6.2060, -6.2060, -6.2060, -6.2060, -6.2060, -6.2060, -6.2060,
           -6.2060, -6.2060, -6.2060, -6.2060, -6.2060, -6.2060, -6.2060,
           -6.2060],
          [-7.2929, -7.2929, -7.2929, -7.2929, -7.2929, -7.2929, -7.2929,
           -7.2929, -7.2929, -7.2929, -7.2929, -7.2929, -7.2929, -7.2929,
           -7.2929],
          [-2.8730, -2.8730, -2.8730, -2.8729, -2.8730, -2.8730, -2.8730,
           -2.8730, -2.8730, -2.8730, -2.8730, -2.8730, -2.8730, -2.8730,
           -2.8730],
          [-7.2929, -7.2929, -7.2929, -7.2929, -7.2929, -7.2929, -7.2929,
           -7.2929, -7.2929, -7.2929, -7.2929, -7.2929, -7.2929, -7.2929,
           -7.2929],
          [-7.2929, -7.2929, -7.2929, -7.2929, -7.2929, -7.2929, -7.2929,
           -7.2929, -7.2929, -7.2929, -7.2929, -7.2929, -7.2929, -7.2929,
           -7.2929],
          [-6.6435, -6.6435, -6.6435, -6.6435, -6.6435, -6.6435, -6.6435,
           -6.6435, -6.6435, -6.6435, -6.6435, -6.6435, -6.6435, -6.6435,
           -6.6435],
          [-7.2929, -7.2929, -7.2929, -7.2929, -7.2929, -7.2929, -7.2929,
           -7.2929, -7.2929, -7.2929, -7.2929, -7.2929, -7.2929, -7.2929,
           -7.2929],
          [-7.2929, -7.2929, -7.2929, -7.2929, -7.2929, -7.2929, -7.2929,
           -7.2929, -7.2929, -7.2929, -7.2929, -7.2929, -7.2929, -7.2929,
           -7.2929],
          [-6.0830, -6.0830, -6.0830, -6.0830, -6.0830, -6.0830, -6.0830,
           -6.0830, -6.0830, -6.0830, -6.0830, -6.0830, -6.0830, -6.0830,
           -6.0830]],

         [[-6.8629, -6.8629, -6.8629, -6.8629, -6.8629, -6.8629, -6.8629,
           -6.8629, -6.8629, -6.8629, -6.8629, -6.8629, -6.8629, -6.8629,
           -6.8629],
          [-6.8629, -6.8629, -6.8629, -6.8629, -6.8629, -6.8629, -6.8629,
           -6.8629, -6.8629, -6.8629, -6.8629, -6.8629, -6.8629, -6.8629,
           -6.8629],
          [-3.8096, -3.8096, -3.8096, -3.8096, -3.8096, -3.8096, -3.8096,
           -3.8096, -3.8096, -3.8096, -3.8096, -3.8096, -3.8096, -3.8096,
           -3.8096],
          [-6.8629, -6.8629, -6.8629, -6.8629, -6.8629, -6.8629, -6.8629,
           -6.8629, -6.8629, -6.8629, -6.8629, -6.8629, -6.8629, -6.8629,
           -6.8629],
          [-6.8629, -6.8629, -6.8629, -6.8629, -6.8629, -6.8629, -6.8629,
           -6.8629, -6.8629, -6.8629, -6.8629, -6.8629, -6.8629, -6.8629,
           -6.8629],
          [-6.8629, -6.8629, -6.8629, -6.8629, -6.8629, -6.8629, -6.8629,
           -6.8629, -6.8629, -6.8629, -6.8629, -6.8629, -6.8629, -6.8629,
           -6.8629],
          [-6.8629, -6.8629, -6.8629, -6.8629, -6.8629, -6.8629, -6.8629,
           -6.8629, -6.8629, -6.8629, -6.8629, -6.8629, -6.8629, -6.8629,
           -6.8629],
          [-5.7155, -5.7154, -5.7155, -5.7154, -5.7154, -5.7155, -5.7155,
           -5.7155, -5.7155, -5.7155, -5.7154, -5.7154, -5.7155, -5.7155,
           -5.7154],
          [-6.8629, -6.8629, -6.8629, -6.8629, -6.8629, -6.8629, -6.8629,
           -6.8629, -6.8629, -6.8629, -6.8629, -6.8629, -6.8629, -6.8629,
           -6.8629],
          [-2.1964, -2.1964, -2.1964, -2.1964, -2.1964, -2.1964, -2.1964,
           -2.1964, -2.1964, -2.1964, -2.1964, -2.1964, -2.1964, -2.1964,
           -2.1964],
          [-6.8629, -6.8629, -6.8629, -6.8629, -6.8629, -6.8629, -6.8629,
           -6.8629, -6.8629, -6.8629, -6.8629, -6.8629, -6.8629, -6.8629,
           -6.8629],
          [-6.8629, -6.8629, -6.8629, -6.8629, -6.8629, -6.8629, -6.8629,
           -6.8629, -6.8629, -6.8629, -6.8629, -6.8629, -6.8629, -6.8629,
           -6.8629],
          [-6.1773, -6.1773, -6.1773, -6.1773, -6.1773, -6.1773, -6.1773,
           -6.1773, -6.1773, -6.1773, -6.1773, -6.1773, -6.1773, -6.1773,
           -6.1773],
          [-6.8629, -6.8629, -6.8629, -6.8629, -6.8629, -6.8629, -6.8629,
           -6.8629, -6.8629, -6.8629, -6.8629, -6.8629, -6.8629, -6.8629,
           -6.8629],
          [-6.8629, -6.8629, -6.8629, -6.8629, -6.8629, -6.8629, -6.8629,
           -6.8629, -6.8629, -6.8629, -6.8629, -6.8629, -6.8629, -6.8629,
           -6.8629],
          [-5.5856, -5.5855, -5.5856, -5.5855, -5.5855, -5.5856, -5.5856,
           -5.5856, -5.5856, -5.5856, -5.5855, -5.5855, -5.5855, -5.5856,
           -5.5855]]],


        [[[-7.4630, -7.4630, -7.4630, -7.4630, -7.4630, -7.4630, -7.4630,
           -7.4630, -7.4630, -7.4630, -7.4630, -7.4630, -7.4630, -7.4630,
           -7.4630],
          [-7.4630, -7.4630, -7.4630, -7.4630, -7.4630, -7.4630, -7.4630,
           -7.4630, -7.4630, -7.4630, -7.4630, -7.4630, -7.4630, -7.4630,
           -7.4630],
          [-4.8057, -4.8057, -4.8057, -4.8057, -4.8057, -4.8057, -4.8057,
           -4.8057, -4.8057, -4.8057, -4.8057, -4.8057, -4.8057, -4.8057,
           -4.8057],
          [-7.4630, -7.4630, -7.4630, -7.4630, -7.4630, -7.4630, -7.4630,
           -7.4630, -7.4630, -7.4630, -7.4630, -7.4630, -7.4630, -7.4630,
           -7.4630],
          [-7.4630, -7.4630, -7.4630, -7.4630, -7.4630, -7.4630, -7.4630,
           -7.4630, -7.4630, -7.4630, -7.4630, -7.4630, -7.4630, -7.4630,
           -7.4630],
          [-1.5369, -1.5369, -1.5369, -1.5369, -1.5369, -1.5369, -1.5369,
           -1.5369, -1.5369, -1.5369, -1.5369, -1.5369, -1.5369, -1.5369,
           -1.5369],
          [-7.4630, -7.4630, -7.4630, -7.4630, -7.4630, -7.4630, -7.4630,
           -7.4630, -7.4630, -7.4630, -7.4630, -7.4630, -7.4630, -7.4630,
           -7.4630],
          [-6.9128, -6.9128, -6.9128, -6.9128, -6.9128, -6.9128, -6.9128,
           -6.9128, -6.9128, -6.9128, -6.9128, -6.9128, -6.9128, -6.9128,
           -6.9128],
          [-7.4630, -7.4630, -7.4630, -7.4630, -7.4630, -7.4630, -7.4630,
           -7.4630, -7.4630, -7.4630, -7.4630, -7.4630, -7.4630, -7.4630,
           -7.4630],
          [-4.3191, -4.3191, -4.3191, -4.3191, -4.3191, -4.3191, -4.3191,
           -4.3191, -4.3191, -4.3191, -4.3191, -4.3191, -4.3191, -4.3191,
           -4.3191],
          [-7.4630, -7.4630, -7.4630, -7.4630, -7.4630, -7.4630, -7.4630,
           -7.4630, -7.4630, -7.4630, -7.4630, -7.4630, -7.4630, -7.4630,
           -7.4630],
          [-7.4630, -7.4630, -7.4630, -7.4630, -7.4630, -7.4630, -7.4630,
           -7.4630, -7.4630, -7.4630, -7.4630, -7.4630, -7.4630, -7.4630,
           -7.4630],
          [-7.0856, -7.0856, -7.0856, -7.0856, -7.0856, -7.0856, -7.0856,
           -7.0856, -7.0856, -7.0856, -7.0856, -7.0856, -7.0856, -7.0856,
           -7.0856],
          [-7.4630, -7.4630, -7.4630, -7.4630, -7.4630, -7.4630, -7.4630,
           -7.4630, -7.4630, -7.4630, -7.4630, -7.4630, -7.4630, -7.4630,
           -7.4630],
          [-7.4630, -7.4630, -7.4630, -7.4630, -7.4630, -7.4630, -7.4630,
           -7.4630, -7.4630, -7.4630, -7.4630, -7.4630, -7.4630, -7.4630,
           -7.4630],
          [-6.5803, -6.5803, -6.5803, -6.5803, -6.5803, -6.5803, -6.5803,
           -6.5803, -6.5803, -6.5803, -6.5803, -6.5803, -6.5803, -6.5803,
           -6.5803]],

         [[-6.2567, -6.2567, -6.2567, -6.2567, -6.2567, -6.2567, -6.2567,
           -6.2567, -6.2567, -6.2567, -6.2567, -6.2567, -6.2567, -6.2567,
           -6.2567],
          [-6.2567, -6.2567, -6.2567, -6.2567, -6.2567, -6.2567, -6.2567,
           -6.2567, -6.2567, -6.2567, -6.2567, -6.2567, -6.2567, -6.2567,
           -6.2567],
          [-3.4511, -3.4511, -3.4511, -3.4511, -3.4511, -3.4511, -3.4511,
           -3.4511, -3.4511, -3.4511, -3.4511, -3.4511, -3.4511, -3.4511,
           -3.4511],
          [-6.2567, -6.2567, -6.2567, -6.2567, -6.2567, -6.2567, -6.2567,
           -6.2567, -6.2567, -6.2567, -6.2567, -6.2567, -6.2567, -6.2567,
           -6.2567],
          [-6.2567, -6.2567, -6.2567, -6.2567, -6.2567, -6.2567, -6.2567,
           -6.2567, -6.2567, -6.2567, -6.2567, -6.2567, -6.2567, -6.2567,
           -6.2567],
          [-6.2567, -6.2567, -6.2567, -6.2567, -6.2567, -6.2567, -6.2567,
           -6.2567, -6.2567, -6.2567, -6.2567, -6.2567, -6.2567, -6.2567,
           -6.2567],
          [-6.2567, -6.2567, -6.2567, -6.2567, -6.2567, -6.2567, -6.2567,
           -6.2567, -6.2567, -6.2567, -6.2567, -6.2567, -6.2567, -6.2567,
           -6.2567],
          [-5.6758, -5.6758, -5.6758, -5.6758, -5.6758, -5.6758, -5.6758,
           -5.6758, -5.6758, -5.6758, -5.6758, -5.6758, -5.6758, -5.6758,
           -5.6758],
          [-6.2567, -6.2567, -6.2567, -6.2567, -6.2567, -6.2567, -6.2567,
           -6.2567, -6.2567, -6.2567, -6.2567, -6.2567, -6.2567, -6.2567,
           -6.2567],
          [-2.9374, -2.9374, -2.9374, -2.9374, -2.9374, -2.9374, -2.9374,
           -2.9374, -2.9374, -2.9374, -2.9374, -2.9374, -2.9374, -2.9374,
           -2.9374],
          [-6.2567, -6.2567, -6.2567, -6.2567, -6.2567, -6.2567, -6.2567,
           -6.2567, -6.2567, -6.2567, -6.2567, -6.2567, -6.2567, -6.2567,
           -6.2567],
          [-6.2567, -6.2567, -6.2567, -6.2567, -6.2567, -6.2567, -6.2567,
           -6.2567, -6.2567, -6.2567, -6.2567, -6.2567, -6.2567, -6.2567,
           -6.2567],
          [-5.8582, -5.8582, -5.8582, -5.8582, -5.8582, -5.8582, -5.8582,
           -5.8582, -5.8582, -5.8582, -5.8582, -5.8582, -5.8582, -5.8582,
           -5.8582],
          [-6.2567, -6.2567, -6.2567, -6.2567, -6.2567, -6.2567, -6.2567,
           -6.2567, -6.2567, -6.2567, -6.2567, -6.2567, -6.2567, -6.2567,
           -6.2567],
          [-6.2567, -6.2567, -6.2567, -6.2567, -6.2567, -6.2567, -6.2567,
           -6.2567, -6.2567, -6.2567, -6.2567, -6.2567, -6.2567, -6.2567,
           -6.2567],
          [-5.3248, -5.3248, -5.3248, -5.3248, -5.3248, -5.3248, -5.3248,
           -5.3248, -5.3248, -5.3248, -5.3248, -5.3248, -5.3248, -5.3248,
           -5.3248]]]], grad_fn=<SliceBackward0>)
train_step: Return scale: 1.4354782276312705
train_step: Scaled advantages shape: torch.Size([16, 15, 16, 15])
train_step: Scaled advantages sample: tensor([[[[-5.0804, -5.0804, -5.0804, -5.0804, -5.0804, -5.0804, -5.0804,
           -5.0804, -5.0804, -5.0804, -5.0804, -5.0804, -5.0804, -5.0804,
           -5.0804],
          [-5.0804, -5.0804, -5.0804, -5.0804, -5.0804, -5.0804, -5.0804,
           -5.0804, -5.0804, -5.0804, -5.0804, -5.0804, -5.0804, -5.0804,
           -5.0804],
          [-3.0658, -3.0658, -3.0658, -3.0658, -3.0658, -3.0658, -3.0658,
           -3.0658, -3.0658, -3.0658, -3.0658, -3.0658, -3.0658, -3.0658,
           -3.0658],
          [-5.0804, -5.0804, -5.0804, -5.0804, -5.0804, -5.0804, -5.0804,
           -5.0804, -5.0804, -5.0804, -5.0804, -5.0804, -5.0804, -5.0804,
           -5.0804],
          [-5.0804, -5.0804, -5.0804, -5.0804, -5.0804, -5.0804, -5.0804,
           -5.0804, -5.0804, -5.0804, -5.0804, -5.0804, -5.0804, -5.0804,
           -5.0804],
          [-0.7926, -0.7926, -0.7926, -0.7926, -0.7926, -0.7926, -0.7926,
           -0.7926, -0.7926, -0.7926, -0.7926, -0.7926, -0.7926, -0.7926,
           -0.7926],
          [-5.0804, -5.0804, -5.0804, -5.0804, -5.0804, -5.0804, -5.0804,
           -5.0804, -5.0804, -5.0804, -5.0804, -5.0804, -5.0804, -5.0804,
           -5.0804],
          [-4.3233, -4.3233, -4.3233, -4.3233, -4.3233, -4.3233, -4.3233,
           -4.3233, -4.3233, -4.3233, -4.3233, -4.3233, -4.3233, -4.3233,
           -4.3233],
          [-5.0804, -5.0804, -5.0804, -5.0804, -5.0804, -5.0804, -5.0804,
           -5.0804, -5.0804, -5.0804, -5.0804, -5.0804, -5.0804, -5.0804,
           -5.0804],
          [-2.0014, -2.0014, -2.0014, -2.0014, -2.0014, -2.0014, -2.0014,
           -2.0014, -2.0014, -2.0014, -2.0014, -2.0014, -2.0014, -2.0014,
           -2.0014],
          [-5.0804, -5.0804, -5.0804, -5.0804, -5.0804, -5.0804, -5.0804,
           -5.0804, -5.0804, -5.0804, -5.0804, -5.0804, -5.0804, -5.0804,
           -5.0804],
          [-5.0804, -5.0804, -5.0804, -5.0804, -5.0804, -5.0804, -5.0804,
           -5.0804, -5.0804, -5.0804, -5.0804, -5.0804, -5.0804, -5.0804,
           -5.0804],
          [-4.6281, -4.6281, -4.6281, -4.6281, -4.6281, -4.6281, -4.6281,
           -4.6281, -4.6281, -4.6281, -4.6281, -4.6281, -4.6281, -4.6281,
           -4.6281],
          [-5.0804, -5.0804, -5.0804, -5.0804, -5.0804, -5.0804, -5.0804,
           -5.0804, -5.0804, -5.0804, -5.0804, -5.0804, -5.0804, -5.0804,
           -5.0804],
          [-5.0804, -5.0804, -5.0804, -5.0804, -5.0804, -5.0804, -5.0804,
           -5.0804, -5.0804, -5.0804, -5.0804, -5.0804, -5.0804, -5.0804,
           -5.0804],
          [-4.2376, -4.2376, -4.2376, -4.2376, -4.2376, -4.2376, -4.2376,
           -4.2376, -4.2376, -4.2376, -4.2376, -4.2376, -4.2376, -4.2376,
           -4.2376]],

         [[-4.7809, -4.7809, -4.7809, -4.7809, -4.7809, -4.7809, -4.7809,
           -4.7809, -4.7809, -4.7809, -4.7809, -4.7809, -4.7809, -4.7809,
           -4.7809],
          [-4.7809, -4.7809, -4.7809, -4.7809, -4.7809, -4.7809, -4.7809,
           -4.7809, -4.7809, -4.7809, -4.7809, -4.7809, -4.7809, -4.7809,
           -4.7809],
          [-2.6539, -2.6539, -2.6539, -2.6539, -2.6539, -2.6539, -2.6539,
           -2.6539, -2.6539, -2.6539, -2.6539, -2.6539, -2.6539, -2.6539,
           -2.6539],
          [-4.7809, -4.7809, -4.7809, -4.7809, -4.7809, -4.7809, -4.7809,
           -4.7809, -4.7809, -4.7809, -4.7809, -4.7809, -4.7809, -4.7809,
           -4.7809],
          [-4.7809, -4.7809, -4.7809, -4.7809, -4.7809, -4.7809, -4.7809,
           -4.7809, -4.7809, -4.7809, -4.7809, -4.7809, -4.7809, -4.7809,
           -4.7809],
          [-4.7809, -4.7809, -4.7809, -4.7809, -4.7809, -4.7809, -4.7809,
           -4.7809, -4.7809, -4.7809, -4.7809, -4.7809, -4.7809, -4.7809,
           -4.7809],
          [-4.7809, -4.7809, -4.7809, -4.7809, -4.7809, -4.7809, -4.7809,
           -4.7809, -4.7809, -4.7809, -4.7809, -4.7809, -4.7809, -4.7809,
           -4.7809],
          [-3.9816, -3.9816, -3.9816, -3.9816, -3.9816, -3.9816, -3.9816,
           -3.9816, -3.9816, -3.9816, -3.9816, -3.9816, -3.9816, -3.9816,
           -3.9816],
          [-4.7809, -4.7809, -4.7809, -4.7809, -4.7809, -4.7809, -4.7809,
           -4.7809, -4.7809, -4.7809, -4.7809, -4.7809, -4.7809, -4.7809,
           -4.7809],
          [-1.5301, -1.5301, -1.5301, -1.5301, -1.5301, -1.5301, -1.5301,
           -1.5301, -1.5301, -1.5301, -1.5301, -1.5301, -1.5301, -1.5301,
           -1.5301],
          [-4.7809, -4.7809, -4.7809, -4.7809, -4.7809, -4.7809, -4.7809,
           -4.7809, -4.7809, -4.7809, -4.7809, -4.7809, -4.7809, -4.7809,
           -4.7809],
          [-4.7809, -4.7809, -4.7809, -4.7809, -4.7809, -4.7809, -4.7809,
           -4.7809, -4.7809, -4.7809, -4.7809, -4.7809, -4.7809, -4.7809,
           -4.7809],
          [-4.3033, -4.3033, -4.3033, -4.3033, -4.3033, -4.3033, -4.3033,
           -4.3033, -4.3033, -4.3033, -4.3033, -4.3033, -4.3033, -4.3033,
           -4.3033],
          [-4.7809, -4.7809, -4.7809, -4.7809, -4.7809, -4.7809, -4.7809,
           -4.7809, -4.7809, -4.7809, -4.7809, -4.7809, -4.7809, -4.7809,
           -4.7809],
          [-4.7809, -4.7809, -4.7809, -4.7809, -4.7809, -4.7809, -4.7809,
           -4.7809, -4.7809, -4.7809, -4.7809, -4.7809, -4.7809, -4.7809,
           -4.7809],
          [-3.8911, -3.8911, -3.8911, -3.8911, -3.8911, -3.8911, -3.8911,
           -3.8911, -3.8911, -3.8911, -3.8911, -3.8911, -3.8911, -3.8911,
           -3.8911]]],


        [[[-5.1990, -5.1989, -5.1989, -5.1989, -5.1989, -5.1989, -5.1989,
           -5.1989, -5.1989, -5.1989, -5.1989, -5.1990, -5.1989, -5.1989,
           -5.1990],
          [-5.1990, -5.1989, -5.1989, -5.1989, -5.1989, -5.1989, -5.1989,
           -5.1989, -5.1989, -5.1989, -5.1989, -5.1990, -5.1989, -5.1989,
           -5.1990],
          [-3.3478, -3.3478, -3.3478, -3.3478, -3.3478, -3.3478, -3.3478,
           -3.3478, -3.3478, -3.3478, -3.3478, -3.3478, -3.3478, -3.3478,
           -3.3478],
          [-5.1990, -5.1989, -5.1989, -5.1989, -5.1989, -5.1989, -5.1989,
           -5.1989, -5.1989, -5.1989, -5.1989, -5.1990, -5.1989, -5.1989,
           -5.1990],
          [-5.1990, -5.1989, -5.1989, -5.1989, -5.1989, -5.1989, -5.1989,
           -5.1989, -5.1989, -5.1989, -5.1989, -5.1990, -5.1989, -5.1989,
           -5.1990],
          [-1.0707, -1.0707, -1.0707, -1.0707, -1.0707, -1.0707, -1.0707,
           -1.0707, -1.0707, -1.0707, -1.0707, -1.0707, -1.0707, -1.0707,
           -1.0707],
          [-5.1990, -5.1989, -5.1989, -5.1989, -5.1989, -5.1989, -5.1989,
           -5.1989, -5.1989, -5.1989, -5.1989, -5.1990, -5.1989, -5.1989,
           -5.1990],
          [-4.8157, -4.8157, -4.8157, -4.8157, -4.8157, -4.8157, -4.8157,
           -4.8157, -4.8157, -4.8157, -4.8157, -4.8157, -4.8157, -4.8157,
           -4.8157],
          [-5.1990, -5.1989, -5.1989, -5.1989, -5.1989, -5.1989, -5.1989,
           -5.1989, -5.1989, -5.1989, -5.1989, -5.1990, -5.1989, -5.1989,
           -5.1990],
          [-3.0088, -3.0088, -3.0088, -3.0088, -3.0088, -3.0088, -3.0088,
           -3.0088, -3.0088, -3.0088, -3.0088, -3.0088, -3.0088, -3.0088,
           -3.0088],
          [-5.1990, -5.1989, -5.1989, -5.1989, -5.1989, -5.1989, -5.1989,
           -5.1989, -5.1989, -5.1989, -5.1989, -5.1990, -5.1989, -5.1989,
           -5.1990],
          [-5.1990, -5.1989, -5.1989, -5.1989, -5.1989, -5.1989, -5.1989,
           -5.1989, -5.1989, -5.1989, -5.1989, -5.1990, -5.1989, -5.1989,
           -5.1990],
          [-4.9361, -4.9361, -4.9361, -4.9360, -4.9361, -4.9360, -4.9361,
           -4.9361, -4.9361, -4.9361, -4.9361, -4.9361, -4.9361, -4.9361,
           -4.9361],
          [-5.1990, -5.1989, -5.1989, -5.1989, -5.1989, -5.1989, -5.1989,
           -5.1989, -5.1989, -5.1989, -5.1989, -5.1990, -5.1989, -5.1989,
           -5.1990],
          [-5.1990, -5.1989, -5.1989, -5.1989, -5.1989, -5.1989, -5.1989,
           -5.1989, -5.1989, -5.1989, -5.1989, -5.1990, -5.1989, -5.1989,
           -5.1990],
          [-4.5841, -4.5841, -4.5841, -4.5841, -4.5841, -4.5841, -4.5841,
           -4.5841, -4.5841, -4.5841, -4.5841, -4.5841, -4.5841, -4.5841,
           -4.5841]],

         [[-4.3586, -4.3586, -4.3586, -4.3586, -4.3586, -4.3586, -4.3586,
           -4.3586, -4.3586, -4.3586, -4.3586, -4.3586, -4.3586, -4.3586,
           -4.3586],
          [-4.3586, -4.3586, -4.3586, -4.3586, -4.3586, -4.3586, -4.3586,
           -4.3586, -4.3586, -4.3586, -4.3586, -4.3586, -4.3586, -4.3586,
           -4.3586],
          [-2.4042, -2.4042, -2.4042, -2.4041, -2.4042, -2.4042, -2.4042,
           -2.4042, -2.4042, -2.4042, -2.4041, -2.4042, -2.4042, -2.4042,
           -2.4042],
          [-4.3586, -4.3586, -4.3586, -4.3586, -4.3586, -4.3586, -4.3586,
           -4.3586, -4.3586, -4.3586, -4.3586, -4.3586, -4.3586, -4.3586,
           -4.3586],
          [-4.3586, -4.3586, -4.3586, -4.3586, -4.3586, -4.3586, -4.3586,
           -4.3586, -4.3586, -4.3586, -4.3586, -4.3586, -4.3586, -4.3586,
           -4.3586],
          [-4.3586, -4.3586, -4.3586, -4.3586, -4.3586, -4.3586, -4.3586,
           -4.3586, -4.3586, -4.3586, -4.3586, -4.3586, -4.3586, -4.3586,
           -4.3586],
          [-4.3586, -4.3586, -4.3586, -4.3586, -4.3586, -4.3586, -4.3586,
           -4.3586, -4.3586, -4.3586, -4.3586, -4.3586, -4.3586, -4.3586,
           -4.3586],
          [-3.9539, -3.9539, -3.9539, -3.9539, -3.9539, -3.9539, -3.9539,
           -3.9539, -3.9539, -3.9539, -3.9539, -3.9539, -3.9539, -3.9539,
           -3.9539],
          [-4.3586, -4.3586, -4.3586, -4.3586, -4.3586, -4.3586, -4.3586,
           -4.3586, -4.3586, -4.3586, -4.3586, -4.3586, -4.3586, -4.3586,
           -4.3586],
          [-2.0463, -2.0463, -2.0463, -2.0463, -2.0463, -2.0463, -2.0463,
           -2.0463, -2.0463, -2.0463, -2.0463, -2.0463, -2.0463, -2.0463,
           -2.0463],
          [-4.3586, -4.3586, -4.3586, -4.3586, -4.3586, -4.3586, -4.3586,
           -4.3586, -4.3586, -4.3586, -4.3586, -4.3586, -4.3586, -4.3586,
           -4.3586],
          [-4.3586, -4.3586, -4.3586, -4.3586, -4.3586, -4.3586, -4.3586,
           -4.3586, -4.3586, -4.3586, -4.3586, -4.3586, -4.3586, -4.3586,
           -4.3586],
          [-4.0810, -4.0810, -4.0810, -4.0810, -4.0810, -4.0810, -4.0810,
           -4.0810, -4.0810, -4.0810, -4.0810, -4.0810, -4.0810, -4.0810,
           -4.0810],
          [-4.3586, -4.3586, -4.3586, -4.3586, -4.3586, -4.3586, -4.3586,
           -4.3586, -4.3586, -4.3586, -4.3586, -4.3586, -4.3586, -4.3586,
           -4.3586],
          [-4.3586, -4.3586, -4.3586, -4.3586, -4.3586, -4.3586, -4.3586,
           -4.3586, -4.3586, -4.3586, -4.3586, -4.3586, -4.3586, -4.3586,
           -4.3586],
          [-3.7094, -3.7094, -3.7094, -3.7094, -3.7094, -3.7094, -3.7094,
           -3.7094, -3.7094, -3.7094, -3.7094, -3.7094, -3.7094, -3.7094,
           -3.7094]]]], grad_fn=<SliceBackward0>)
train_step: Entropy shape: torch.Size([16, 15])
train_step: Entropy sample: tensor([[0.2848, 0.5344],
        [0.5062, 0.5627]], grad_fn=<SliceBackward0>)
train_step: Entropy coefficient: 0.01
train_step: Actor loss: -1.5860259532928467
train_step: returns shape after mean: torch.Size([16, 15])
train_step: target_indices shape: torch.Size([16, 15])
train_step: value_logits shape: torch.Size([16, 15, 255])
train_step: target_twohot shape: torch.Size([16, 15, 255])
--- Starting train_step at 2025-04-01 01:52:51 ---
Full starting_state: {'deter': tensor([[[-0.0987,  0.0251, -0.0369,  ...,  0.0428, -0.0091,  0.0102],
         [-0.2458,  0.0863, -0.0586,  ...,  0.0118,  0.0748,  0.1715],
         [-0.1640,  0.0127, -0.0888,  ..., -0.0960,  0.1522, -0.0775],
         ...,
         [ 0.0748, -0.0113, -0.1089,  ...,  0.1286,  0.1222, -0.0870],
         [-0.0275, -0.1009,  0.0440,  ..., -0.0297, -0.1096, -0.0072],
         [-0.1395,  0.0848, -0.1431,  ..., -0.1084, -0.1859, -0.1092]],

        [[-0.1126, -0.0784, -0.0209,  ...,  0.1610, -0.0127,  0.0585],
         [-0.1131,  0.0760, -0.0771,  ...,  0.0056, -0.0678,  0.0561],
         [-0.0315, -0.0314, -0.1144,  ..., -0.1506,  0.0656, -0.1580],
         ...,
         [-0.0346, -0.0590, -0.0488,  ...,  0.1345, -0.0158,  0.0566],
         [ 0.0019,  0.1859,  0.1605,  ...,  0.0681, -0.0380, -0.1719],
         [ 0.0935, -0.2191, -0.0331,  ...,  0.0714, -0.1528, -0.2465]],

        [[-0.1911, -0.0475,  0.0404,  ...,  0.0367,  0.0863, -0.0192],
         [ 0.0660,  0.1041, -0.0974,  ..., -0.0371, -0.1207, -0.0110],
         [-0.0547,  0.0443, -0.1360,  ...,  0.0445,  0.1229, -0.1538],
         ...,
         [-0.1803,  0.1594,  0.0279,  ..., -0.0218, -0.0084,  0.0047],
         [-0.0520,  0.0539, -0.0450,  ..., -0.1059,  0.1017, -0.0770],
         [ 0.1522,  0.1569,  0.0917,  ...,  0.0157,  0.0926, -0.0153]],

        ...,

        [[ 0.1240,  0.0037, -0.1153,  ..., -0.1081, -0.0291,  0.0919],
         [-0.0299,  0.0680,  0.0116,  ..., -0.1048, -0.1497,  0.0230],
         [-0.0623,  0.0030,  0.1329,  ...,  0.0508,  0.0461, -0.0489],
         ...,
         [ 0.0079, -0.0077, -0.0600,  ...,  0.1898, -0.1193, -0.0630],
         [-0.0526,  0.0156,  0.0219,  ..., -0.0201, -0.0718, -0.0259],
         [ 0.0110,  0.0665, -0.1461,  ...,  0.1182,  0.0544, -0.0017]],

        [[ 0.0890, -0.0223,  0.0863,  ...,  0.0485, -0.0109,  0.0421],
         [-0.0378,  0.0879,  0.1549,  ...,  0.1232,  0.0174, -0.0364],
         [ 0.0830, -0.1261, -0.0610,  ...,  0.0012, -0.1322,  0.0747],
         ...,
         [-0.0499,  0.0142,  0.1286,  ..., -0.1176, -0.1692, -0.0133],
         [-0.0620,  0.0383, -0.0686,  ..., -0.1256,  0.0746, -0.0556],
         [ 0.0330,  0.0412, -0.0598,  ...,  0.0230, -0.0385,  0.0291]],

        [[-0.1008,  0.0220, -0.1416,  ...,  0.0839,  0.1593, -0.0639],
         [-0.0317,  0.0820,  0.1006,  ...,  0.0479,  0.0492, -0.0039],
         [-0.0501, -0.0245, -0.1597,  ..., -0.0476, -0.0661, -0.0869],
         ...,
         [-0.0801, -0.0595, -0.1225,  ..., -0.1752,  0.0701, -0.1656],
         [ 0.0072,  0.1463, -0.1367,  ...,  0.0834, -0.0060,  0.0449],
         [-0.1004, -0.0169, -0.1886,  ...,  0.0762,  0.0977, -0.1064]]],
       grad_fn=<StackBackward0>), 'stoch': tensor([[[0., 0., 0.,  ..., 1., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 1.,  ..., 0., 0., 1.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 1.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 1.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]])}
train_step: Starting state deter shape: torch.Size([16, 50, 128])
train_step: Starting state stoch shape: torch.Size([16, 50, 1024])
After ensuring logits/stoch: {'deter': tensor([[[-0.0987,  0.0251, -0.0369,  ...,  0.0428, -0.0091,  0.0102],
         [-0.2458,  0.0863, -0.0586,  ...,  0.0118,  0.0748,  0.1715],
         [-0.1640,  0.0127, -0.0888,  ..., -0.0960,  0.1522, -0.0775],
         ...,
         [ 0.0748, -0.0113, -0.1089,  ...,  0.1286,  0.1222, -0.0870],
         [-0.0275, -0.1009,  0.0440,  ..., -0.0297, -0.1096, -0.0072],
         [-0.1395,  0.0848, -0.1431,  ..., -0.1084, -0.1859, -0.1092]],

        [[-0.1126, -0.0784, -0.0209,  ...,  0.1610, -0.0127,  0.0585],
         [-0.1131,  0.0760, -0.0771,  ...,  0.0056, -0.0678,  0.0561],
         [-0.0315, -0.0314, -0.1144,  ..., -0.1506,  0.0656, -0.1580],
         ...,
         [-0.0346, -0.0590, -0.0488,  ...,  0.1345, -0.0158,  0.0566],
         [ 0.0019,  0.1859,  0.1605,  ...,  0.0681, -0.0380, -0.1719],
         [ 0.0935, -0.2191, -0.0331,  ...,  0.0714, -0.1528, -0.2465]],

        [[-0.1911, -0.0475,  0.0404,  ...,  0.0367,  0.0863, -0.0192],
         [ 0.0660,  0.1041, -0.0974,  ..., -0.0371, -0.1207, -0.0110],
         [-0.0547,  0.0443, -0.1360,  ...,  0.0445,  0.1229, -0.1538],
         ...,
         [-0.1803,  0.1594,  0.0279,  ..., -0.0218, -0.0084,  0.0047],
         [-0.0520,  0.0539, -0.0450,  ..., -0.1059,  0.1017, -0.0770],
         [ 0.1522,  0.1569,  0.0917,  ...,  0.0157,  0.0926, -0.0153]],

        ...,

        [[ 0.1240,  0.0037, -0.1153,  ..., -0.1081, -0.0291,  0.0919],
         [-0.0299,  0.0680,  0.0116,  ..., -0.1048, -0.1497,  0.0230],
         [-0.0623,  0.0030,  0.1329,  ...,  0.0508,  0.0461, -0.0489],
         ...,
         [ 0.0079, -0.0077, -0.0600,  ...,  0.1898, -0.1193, -0.0630],
         [-0.0526,  0.0156,  0.0219,  ..., -0.0201, -0.0718, -0.0259],
         [ 0.0110,  0.0665, -0.1461,  ...,  0.1182,  0.0544, -0.0017]],

        [[ 0.0890, -0.0223,  0.0863,  ...,  0.0485, -0.0109,  0.0421],
         [-0.0378,  0.0879,  0.1549,  ...,  0.1232,  0.0174, -0.0364],
         [ 0.0830, -0.1261, -0.0610,  ...,  0.0012, -0.1322,  0.0747],
         ...,
         [-0.0499,  0.0142,  0.1286,  ..., -0.1176, -0.1692, -0.0133],
         [-0.0620,  0.0383, -0.0686,  ..., -0.1256,  0.0746, -0.0556],
         [ 0.0330,  0.0412, -0.0598,  ...,  0.0230, -0.0385,  0.0291]],

        [[-0.1008,  0.0220, -0.1416,  ...,  0.0839,  0.1593, -0.0639],
         [-0.0317,  0.0820,  0.1006,  ...,  0.0479,  0.0492, -0.0039],
         [-0.0501, -0.0245, -0.1597,  ..., -0.0476, -0.0661, -0.0869],
         ...,
         [-0.0801, -0.0595, -0.1225,  ..., -0.1752,  0.0701, -0.1656],
         [ 0.0072,  0.1463, -0.1367,  ...,  0.0834, -0.0060,  0.0449],
         [-0.1004, -0.0169, -0.1886,  ...,  0.0762,  0.0977, -0.1064]]],
       grad_fn=<StackBackward0>), 'stoch': tensor([[[0., 0., 0.,  ..., 1., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 1.,  ..., 0., 0., 1.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 1.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 1.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]]), 'logits': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]])}
train_step: Normalized hidden_state shape: torch.Size([1, 16, 128])
train_step: Normalized stoch shape: torch.Size([16, 1024])
train_step: Normalized deter shape: torch.Size([16, 128])
train_step: Post-imagine_trajectory: Imagined features shape: torch.Size([16, 15, 1152])
train_step: Post-imagine_trajectory: Imagined actions shape: torch.Size([16, 15, 2])
train_step: Post-imagine_trajectory: Imagined action indices shape: torch.Size([16, 15])
train_step: Post-imagine_trajectory: Imagined state deter shape: torch.Size([16, 15, 128])
train_step: Post-imagine_trajectory: Imagined state stoch shape: torch.Size([16, 15, 1024])
Reward shape: torch.Size([16, 15, 1]), Value shape: torch.Size([16, 15, 1]), Slow Value shape: torch.Size([16, 15, 1]), Discount shape: torch.Size([16, 15, 1, 1])
Return targets length: 15, First target shape: torch.Size([16, 16, 1])
train_step: Actor distribution shape: torch.Size([16, 15, 2])
train_step: Action log probabilities shape: torch.Size([16, 15])
train_step: Action log probabilities sample: tensor([[-0.3531, -0.9280],
        [-0.2824, -0.1850]], grad_fn=<SliceBackward0>)
train_step: Advantages shape: torch.Size([16, 15, 16, 15])
train_step: Advantages sample: tensor([[[[-8.1270, -8.1270, -8.1270, -8.1270, -8.1270, -8.1270, -8.1270,
           -8.1270, -8.1270, -8.1270, -8.1270, -8.1270, -8.1270, -8.1270,
           -8.1270],
          [-6.6432, -6.6432, -6.6432, -6.6432, -6.6432, -6.6432, -6.6432,
           -6.6432, -6.6432, -6.6432, -6.6432, -6.6432, -6.6432, -6.6432,
           -6.6432],
          [-8.1270, -8.1270, -8.1270, -8.1270, -8.1270, -8.1270, -8.1270,
           -8.1270, -8.1270, -8.1270, -8.1270, -8.1270, -8.1270, -8.1270,
           -8.1270],
          [-8.1270, -8.1270, -8.1270, -8.1270, -8.1270, -8.1270, -8.1270,
           -8.1270, -8.1270, -8.1270, -8.1270, -8.1270, -8.1270, -8.1270,
           -8.1270],
          [-4.7489, -4.7489, -4.7489, -4.7489, -4.7489, -4.7489, -4.7489,
           -4.7489, -4.7489, -4.7489, -4.7489, -4.7489, -4.7489, -4.7489,
           -4.7489],
          [-8.1270, -8.1270, -8.1270, -8.1270, -8.1270, -8.1270, -8.1270,
           -8.1270, -8.1270, -8.1270, -8.1270, -8.1270, -8.1270, -8.1270,
           -8.1270],
          [-8.1270, -8.1270, -8.1270, -8.1270, -8.1270, -8.1270, -8.1270,
           -8.1270, -8.1270, -8.1270, -8.1270, -8.1270, -8.1270, -8.1270,
           -8.1270],
          [-8.1270, -8.1270, -8.1270, -8.1270, -8.1270, -8.1270, -8.1270,
           -8.1270, -8.1270, -8.1270, -8.1270, -8.1270, -8.1270, -8.1270,
           -8.1270],
          [-8.1270, -8.1270, -8.1270, -8.1270, -8.1270, -8.1270, -8.1270,
           -8.1270, -8.1270, -8.1270, -8.1270, -8.1270, -8.1270, -8.1270,
           -8.1270],
          [-1.3376, -1.3375, -1.3376, -1.3376, -1.3376, -1.3376, -1.3376,
           -1.3376, -1.3375, -1.3376, -1.3376, -1.3376, -1.3376, -1.3376,
           -1.3376],
          [-8.1270, -8.1270, -8.1270, -8.1270, -8.1270, -8.1270, -8.1270,
           -8.1270, -8.1270, -8.1270, -8.1270, -8.1270, -8.1270, -8.1270,
           -8.1270],
          [-8.1270, -8.1270, -8.1270, -8.1270, -8.1270, -8.1270, -8.1270,
           -8.1270, -8.1270, -8.1270, -8.1270, -8.1270, -8.1270, -8.1270,
           -8.1270],
          [-3.2758, -3.2758, -3.2758, -3.2758, -3.2758, -3.2758, -3.2758,
           -3.2758, -3.2758, -3.2758, -3.2758, -3.2758, -3.2758, -3.2758,
           -3.2758],
          [-8.1270, -8.1270, -8.1270, -8.1270, -8.1270, -8.1270, -8.1270,
           -8.1270, -8.1270, -8.1270, -8.1270, -8.1270, -8.1270, -8.1270,
           -8.1270],
          [-8.1270, -8.1270, -8.1270, -8.1270, -8.1270, -8.1270, -8.1270,
           -8.1270, -8.1270, -8.1270, -8.1270, -8.1270, -8.1270, -8.1270,
           -8.1270],
          [-4.7489, -4.7489, -4.7489, -4.7489, -4.7489, -4.7489, -4.7489,
           -4.7489, -4.7489, -4.7489, -4.7489, -4.7489, -4.7489, -4.7489,
           -4.7489]],

         [[-7.1682, -7.1682, -7.1682, -7.1682, -7.1682, -7.1682, -7.1682,
           -7.1682, -7.1682, -7.1682, -7.1682, -7.1682, -7.1682, -7.1682,
           -7.1682],
          [-5.6016, -5.6016, -5.6016, -5.6016, -5.6016, -5.6016, -5.6016,
           -5.6016, -5.6016, -5.6016, -5.6016, -5.6016, -5.6016, -5.6016,
           -5.6016],
          [-7.1682, -7.1682, -7.1682, -7.1682, -7.1682, -7.1682, -7.1682,
           -7.1682, -7.1682, -7.1682, -7.1682, -7.1682, -7.1682, -7.1682,
           -7.1682],
          [-7.1682, -7.1682, -7.1682, -7.1682, -7.1682, -7.1682, -7.1682,
           -7.1682, -7.1682, -7.1682, -7.1682, -7.1682, -7.1682, -7.1682,
           -7.1682],
          [-3.6016, -3.6016, -3.6016, -3.6016, -3.6016, -3.6016, -3.6016,
           -3.6016, -3.6016, -3.6016, -3.6016, -3.6016, -3.6016, -3.6016,
           -3.6016],
          [-7.1682, -7.1682, -7.1682, -7.1682, -7.1682, -7.1682, -7.1682,
           -7.1682, -7.1682, -7.1682, -7.1682, -7.1682, -7.1682, -7.1682,
           -7.1682],
          [-7.1682, -7.1682, -7.1682, -7.1682, -7.1682, -7.1682, -7.1682,
           -7.1682, -7.1682, -7.1682, -7.1682, -7.1682, -7.1682, -7.1682,
           -7.1682],
          [-7.1682, -7.1682, -7.1682, -7.1682, -7.1682, -7.1682, -7.1682,
           -7.1682, -7.1682, -7.1682, -7.1682, -7.1682, -7.1682, -7.1682,
           -7.1682],
          [-7.1682, -7.1681, -7.1682, -7.1682, -7.1682, -7.1681, -7.1682,
           -7.1681, -7.1682, -7.1682, -7.1682, -7.1682, -7.1681, -7.1682,
           -7.1682],
          [-7.1682, -7.1682, -7.1682, -7.1682, -7.1682, -7.1682, -7.1682,
           -7.1682, -7.1682, -7.1682, -7.1682, -7.1682, -7.1682, -7.1682,
           -7.1682],
          [-7.1682, -7.1682, -7.1682, -7.1682, -7.1682, -7.1682, -7.1682,
           -7.1682, -7.1682, -7.1682, -7.1682, -7.1682, -7.1682, -7.1682,
           -7.1682],
          [-7.1682, -7.1682, -7.1682, -7.1682, -7.1682, -7.1682, -7.1682,
           -7.1682, -7.1682, -7.1682, -7.1682, -7.1682, -7.1682, -7.1682,
           -7.1682],
          [-2.0463, -2.0463, -2.0463, -2.0463, -2.0463, -2.0463, -2.0463,
           -2.0463, -2.0463, -2.0463, -2.0463, -2.0463, -2.0463, -2.0463,
           -2.0463],
          [-7.1682, -7.1682, -7.1682, -7.1682, -7.1682, -7.1682, -7.1682,
           -7.1682, -7.1682, -7.1682, -7.1682, -7.1682, -7.1682, -7.1682,
           -7.1682],
          [-7.1682, -7.1682, -7.1682, -7.1682, -7.1682, -7.1682, -7.1682,
           -7.1682, -7.1682, -7.1682, -7.1682, -7.1682, -7.1682, -7.1682,
           -7.1682],
          [-3.6016, -3.6016, -3.6016, -3.6016, -3.6016, -3.6016, -3.6016,
           -3.6016, -3.6016, -3.6016, -3.6016, -3.6016, -3.6016, -3.6016,
           -3.6016]]],


        [[[-6.7381, -6.7381, -6.7381, -6.7381, -6.7381, -6.7381, -6.7381,
           -6.7381, -6.7381, -6.7381, -6.7381, -6.7381, -6.7381, -6.7381,
           -6.7381],
          [-5.7709, -5.7709, -5.7709, -5.7709, -5.7709, -5.7709, -5.7709,
           -5.7709, -5.7709, -5.7709, -5.7709, -5.7709, -5.7709, -5.7709,
           -5.7709],
          [-6.7381, -6.7381, -6.7381, -6.7381, -6.7381, -6.7381, -6.7381,
           -6.7381, -6.7381, -6.7381, -6.7381, -6.7381, -6.7381, -6.7381,
           -6.7381],
          [-6.7381, -6.7381, -6.7381, -6.7381, -6.7381, -6.7381, -6.7381,
           -6.7381, -6.7381, -6.7381, -6.7381, -6.7381, -6.7381, -6.7381,
           -6.7381],
          [-4.0047, -4.0047, -4.0047, -4.0047, -4.0047, -4.0047, -4.0047,
           -4.0047, -4.0047, -4.0047, -4.0047, -4.0047, -4.0047, -4.0047,
           -4.0047],
          [-6.7381, -6.7381, -6.7381, -6.7381, -6.7381, -6.7381, -6.7381,
           -6.7381, -6.7381, -6.7381, -6.7381, -6.7381, -6.7381, -6.7381,
           -6.7381],
          [-6.7381, -6.7381, -6.7381, -6.7381, -6.7381, -6.7381, -6.7381,
           -6.7381, -6.7381, -6.7381, -6.7381, -6.7381, -6.7381, -6.7381,
           -6.7381],
          [-6.7381, -6.7381, -6.7381, -6.7381, -6.7381, -6.7381, -6.7381,
           -6.7381, -6.7381, -6.7381, -6.7381, -6.7381, -6.7381, -6.7381,
           -6.7381],
          [-6.7380, -6.7380, -6.7380, -6.7380, -6.7380, -6.7380, -6.7380,
           -6.7380, -6.7380, -6.7380, -6.7380, -6.7380, -6.7380, -6.7380,
           -6.7380],
          [-0.6109, -0.6109, -0.6109, -0.6109, -0.6109, -0.6109, -0.6109,
           -0.6109, -0.6109, -0.6109, -0.6109, -0.6109, -0.6109, -0.6109,
           -0.6109],
          [-6.7381, -6.7381, -6.7381, -6.7381, -6.7381, -6.7381, -6.7381,
           -6.7381, -6.7381, -6.7381, -6.7381, -6.7381, -6.7381, -6.7381,
           -6.7381],
          [-6.7381, -6.7381, -6.7381, -6.7381, -6.7381, -6.7381, -6.7381,
           -6.7381, -6.7381, -6.7381, -6.7381, -6.7381, -6.7381, -6.7381,
           -6.7381],
          [-1.6881, -1.6881, -1.6881, -1.6881, -1.6881, -1.6881, -1.6881,
           -1.6881, -1.6881, -1.6881, -1.6881, -1.6881, -1.6881, -1.6881,
           -1.6881],
          [-6.7381, -6.7381, -6.7381, -6.7381, -6.7381, -6.7381, -6.7381,
           -6.7381, -6.7381, -6.7381, -6.7381, -6.7381, -6.7381, -6.7381,
           -6.7381],
          [-6.7381, -6.7381, -6.7381, -6.7381, -6.7381, -6.7381, -6.7381,
           -6.7381, -6.7381, -6.7381, -6.7381, -6.7381, -6.7381, -6.7381,
           -6.7381],
          [-4.0047, -4.0047, -4.0047, -4.0047, -4.0047, -4.0047, -4.0047,
           -4.0047, -4.0047, -4.0047, -4.0047, -4.0047, -4.0047, -4.0047,
           -4.0047]],

         [[-6.4689, -6.4689, -6.4689, -6.4690, -6.4689, -6.4689, -6.4689,
           -6.4689, -6.4689, -6.4689, -6.4689, -6.4689, -6.4689, -6.4689,
           -6.4689],
          [-5.4478, -5.4478, -5.4478, -5.4479, -5.4479, -5.4478, -5.4478,
           -5.4478, -5.4478, -5.4478, -5.4478, -5.4478, -5.4478, -5.4478,
           -5.4478],
          [-6.4689, -6.4689, -6.4689, -6.4690, -6.4689, -6.4689, -6.4689,
           -6.4689, -6.4689, -6.4689, -6.4689, -6.4689, -6.4689, -6.4689,
           -6.4689],
          [-6.4689, -6.4689, -6.4689, -6.4690, -6.4689, -6.4689, -6.4689,
           -6.4689, -6.4689, -6.4689, -6.4689, -6.4689, -6.4689, -6.4689,
           -6.4689],
          [-3.5830, -3.5830, -3.5830, -3.5830, -3.5830, -3.5830, -3.5830,
           -3.5830, -3.5830, -3.5830, -3.5830, -3.5830, -3.5830, -3.5830,
           -3.5830],
          [-6.4689, -6.4689, -6.4689, -6.4690, -6.4689, -6.4689, -6.4689,
           -6.4689, -6.4689, -6.4689, -6.4689, -6.4689, -6.4689, -6.4689,
           -6.4689],
          [-6.4689, -6.4689, -6.4689, -6.4690, -6.4689, -6.4689, -6.4689,
           -6.4689, -6.4689, -6.4689, -6.4689, -6.4689, -6.4689, -6.4689,
           -6.4689],
          [-6.4689, -6.4689, -6.4689, -6.4690, -6.4689, -6.4689, -6.4689,
           -6.4689, -6.4689, -6.4689, -6.4689, -6.4689, -6.4689, -6.4689,
           -6.4689],
          [-6.4689, -6.4689, -6.4689, -6.4689, -6.4689, -6.4689, -6.4689,
           -6.4689, -6.4689, -6.4689, -6.4689, -6.4689, -6.4689, -6.4689,
           -6.4689],
          [-6.4689, -6.4689, -6.4689, -6.4690, -6.4689, -6.4689, -6.4689,
           -6.4689, -6.4689, -6.4689, -6.4689, -6.4689, -6.4689, -6.4689,
           -6.4689],
          [-6.4689, -6.4689, -6.4689, -6.4690, -6.4689, -6.4689, -6.4689,
           -6.4689, -6.4689, -6.4689, -6.4689, -6.4689, -6.4689, -6.4689,
           -6.4689],
          [-6.4689, -6.4689, -6.4689, -6.4690, -6.4689, -6.4689, -6.4689,
           -6.4689, -6.4689, -6.4689, -6.4689, -6.4689, -6.4689, -6.4689,
           -6.4689],
          [-1.1372, -1.1372, -1.1372, -1.1372, -1.1372, -1.1372, -1.1372,
           -1.1372, -1.1372, -1.1372, -1.1372, -1.1372, -1.1372, -1.1372,
           -1.1372],
          [-6.4689, -6.4689, -6.4689, -6.4690, -6.4689, -6.4689, -6.4689,
           -6.4689, -6.4689, -6.4689, -6.4689, -6.4689, -6.4689, -6.4689,
           -6.4689],
          [-6.4689, -6.4689, -6.4689, -6.4690, -6.4689, -6.4689, -6.4689,
           -6.4689, -6.4689, -6.4689, -6.4689, -6.4689, -6.4689, -6.4689,
           -6.4689],
          [-3.5830, -3.5830, -3.5830, -3.5830, -3.5830, -3.5830, -3.5830,
           -3.5830, -3.5830, -3.5830, -3.5830, -3.5830, -3.5830, -3.5830,
           -3.5830]]]], grad_fn=<SliceBackward0>)
train_step: Return scale: 1.4953026142945482
train_step: Scaled advantages shape: torch.Size([16, 15, 16, 15])
train_step: Scaled advantages sample: tensor([[[[-5.4350, -5.4350, -5.4350, -5.4350, -5.4350, -5.4350, -5.4350,
           -5.4350, -5.4350, -5.4350, -5.4350, -5.4350, -5.4350, -5.4350,
           -5.4350],
          [-4.4427, -4.4427, -4.4427, -4.4427, -4.4427, -4.4427, -4.4427,
           -4.4427, -4.4427, -4.4427, -4.4427, -4.4427, -4.4427, -4.4427,
           -4.4427],
          [-5.4350, -5.4350, -5.4350, -5.4350, -5.4350, -5.4350, -5.4350,
           -5.4350, -5.4350, -5.4350, -5.4350, -5.4350, -5.4350, -5.4350,
           -5.4350],
          [-5.4350, -5.4350, -5.4350, -5.4350, -5.4350, -5.4350, -5.4350,
           -5.4350, -5.4350, -5.4350, -5.4350, -5.4350, -5.4350, -5.4350,
           -5.4350],
          [-3.1759, -3.1759, -3.1759, -3.1759, -3.1759, -3.1759, -3.1759,
           -3.1759, -3.1759, -3.1759, -3.1759, -3.1759, -3.1759, -3.1759,
           -3.1759],
          [-5.4350, -5.4350, -5.4350, -5.4350, -5.4350, -5.4350, -5.4350,
           -5.4350, -5.4350, -5.4350, -5.4350, -5.4350, -5.4350, -5.4350,
           -5.4350],
          [-5.4350, -5.4350, -5.4350, -5.4350, -5.4350, -5.4350, -5.4350,
           -5.4350, -5.4350, -5.4350, -5.4350, -5.4350, -5.4350, -5.4350,
           -5.4350],
          [-5.4350, -5.4350, -5.4350, -5.4350, -5.4350, -5.4350, -5.4350,
           -5.4350, -5.4350, -5.4350, -5.4350, -5.4350, -5.4350, -5.4350,
           -5.4350],
          [-5.4350, -5.4350, -5.4350, -5.4350, -5.4350, -5.4350, -5.4350,
           -5.4350, -5.4350, -5.4350, -5.4350, -5.4350, -5.4350, -5.4350,
           -5.4350],
          [-0.8945, -0.8945, -0.8945, -0.8945, -0.8945, -0.8945, -0.8945,
           -0.8945, -0.8945, -0.8945, -0.8945, -0.8945, -0.8945, -0.8945,
           -0.8945],
          [-5.4350, -5.4350, -5.4350, -5.4350, -5.4350, -5.4350, -5.4350,
           -5.4350, -5.4350, -5.4350, -5.4350, -5.4350, -5.4350, -5.4350,
           -5.4350],
          [-5.4350, -5.4350, -5.4350, -5.4350, -5.4350, -5.4350, -5.4350,
           -5.4350, -5.4350, -5.4350, -5.4350, -5.4350, -5.4350, -5.4350,
           -5.4350],
          [-2.1907, -2.1907, -2.1907, -2.1907, -2.1907, -2.1907, -2.1907,
           -2.1907, -2.1907, -2.1907, -2.1907, -2.1907, -2.1907, -2.1907,
           -2.1907],
          [-5.4350, -5.4350, -5.4350, -5.4350, -5.4350, -5.4350, -5.4350,
           -5.4350, -5.4350, -5.4350, -5.4350, -5.4350, -5.4350, -5.4350,
           -5.4350],
          [-5.4350, -5.4350, -5.4350, -5.4350, -5.4350, -5.4350, -5.4350,
           -5.4350, -5.4350, -5.4350, -5.4350, -5.4350, -5.4350, -5.4350,
           -5.4350],
          [-3.1759, -3.1759, -3.1759, -3.1759, -3.1759, -3.1759, -3.1759,
           -3.1759, -3.1759, -3.1759, -3.1759, -3.1759, -3.1759, -3.1759,
           -3.1759]],

         [[-4.7938, -4.7938, -4.7938, -4.7938, -4.7938, -4.7938, -4.7938,
           -4.7938, -4.7938, -4.7938, -4.7938, -4.7938, -4.7938, -4.7938,
           -4.7938],
          [-3.7461, -3.7461, -3.7461, -3.7462, -3.7462, -3.7461, -3.7461,
           -3.7461, -3.7461, -3.7461, -3.7461, -3.7461, -3.7461, -3.7461,
           -3.7461],
          [-4.7938, -4.7938, -4.7938, -4.7938, -4.7938, -4.7938, -4.7938,
           -4.7938, -4.7938, -4.7938, -4.7938, -4.7938, -4.7938, -4.7938,
           -4.7938],
          [-4.7938, -4.7938, -4.7938, -4.7938, -4.7938, -4.7938, -4.7938,
           -4.7938, -4.7938, -4.7938, -4.7938, -4.7938, -4.7938, -4.7938,
           -4.7938],
          [-2.4086, -2.4086, -2.4086, -2.4086, -2.4086, -2.4086, -2.4086,
           -2.4086, -2.4086, -2.4086, -2.4086, -2.4086, -2.4086, -2.4086,
           -2.4086],
          [-4.7938, -4.7938, -4.7938, -4.7938, -4.7938, -4.7938, -4.7938,
           -4.7938, -4.7938, -4.7938, -4.7938, -4.7938, -4.7938, -4.7938,
           -4.7938],
          [-4.7938, -4.7938, -4.7938, -4.7938, -4.7938, -4.7938, -4.7938,
           -4.7938, -4.7938, -4.7938, -4.7938, -4.7938, -4.7938, -4.7938,
           -4.7938],
          [-4.7938, -4.7938, -4.7938, -4.7938, -4.7938, -4.7938, -4.7938,
           -4.7938, -4.7938, -4.7938, -4.7938, -4.7938, -4.7938, -4.7938,
           -4.7938],
          [-4.7938, -4.7938, -4.7938, -4.7938, -4.7938, -4.7938, -4.7938,
           -4.7938, -4.7938, -4.7938, -4.7938, -4.7938, -4.7938, -4.7938,
           -4.7938],
          [-4.7938, -4.7938, -4.7938, -4.7938, -4.7938, -4.7938, -4.7938,
           -4.7938, -4.7938, -4.7938, -4.7938, -4.7938, -4.7938, -4.7938,
           -4.7938],
          [-4.7938, -4.7938, -4.7938, -4.7938, -4.7938, -4.7938, -4.7938,
           -4.7938, -4.7938, -4.7938, -4.7938, -4.7938, -4.7938, -4.7938,
           -4.7938],
          [-4.7938, -4.7938, -4.7938, -4.7938, -4.7938, -4.7938, -4.7938,
           -4.7938, -4.7938, -4.7938, -4.7938, -4.7938, -4.7938, -4.7938,
           -4.7938],
          [-1.3685, -1.3685, -1.3685, -1.3685, -1.3685, -1.3685, -1.3685,
           -1.3685, -1.3685, -1.3685, -1.3685, -1.3685, -1.3685, -1.3685,
           -1.3685],
          [-4.7938, -4.7938, -4.7938, -4.7938, -4.7938, -4.7938, -4.7938,
           -4.7938, -4.7938, -4.7938, -4.7938, -4.7938, -4.7938, -4.7938,
           -4.7938],
          [-4.7938, -4.7938, -4.7938, -4.7938, -4.7938, -4.7938, -4.7938,
           -4.7938, -4.7938, -4.7938, -4.7938, -4.7938, -4.7938, -4.7938,
           -4.7938],
          [-2.4086, -2.4086, -2.4086, -2.4086, -2.4086, -2.4086, -2.4086,
           -2.4086, -2.4086, -2.4086, -2.4086, -2.4086, -2.4086, -2.4086,
           -2.4086]]],


        [[[-4.5062, -4.5061, -4.5062, -4.5062, -4.5062, -4.5062, -4.5062,
           -4.5062, -4.5061, -4.5062, -4.5062, -4.5062, -4.5062, -4.5062,
           -4.5062],
          [-3.8594, -3.8594, -3.8594, -3.8594, -3.8594, -3.8594, -3.8594,
           -3.8594, -3.8594, -3.8594, -3.8594, -3.8594, -3.8594, -3.8594,
           -3.8594],
          [-4.5062, -4.5061, -4.5062, -4.5062, -4.5062, -4.5062, -4.5062,
           -4.5062, -4.5061, -4.5062, -4.5062, -4.5062, -4.5062, -4.5062,
           -4.5062],
          [-4.5062, -4.5061, -4.5062, -4.5062, -4.5062, -4.5062, -4.5062,
           -4.5062, -4.5061, -4.5062, -4.5062, -4.5062, -4.5062, -4.5062,
           -4.5062],
          [-2.6782, -2.6782, -2.6782, -2.6782, -2.6782, -2.6782, -2.6782,
           -2.6782, -2.6782, -2.6782, -2.6782, -2.6782, -2.6782, -2.6782,
           -2.6782],
          [-4.5062, -4.5061, -4.5062, -4.5062, -4.5062, -4.5062, -4.5062,
           -4.5062, -4.5061, -4.5062, -4.5062, -4.5062, -4.5062, -4.5062,
           -4.5062],
          [-4.5062, -4.5061, -4.5062, -4.5062, -4.5062, -4.5062, -4.5062,
           -4.5062, -4.5061, -4.5062, -4.5062, -4.5062, -4.5062, -4.5062,
           -4.5062],
          [-4.5062, -4.5061, -4.5062, -4.5062, -4.5062, -4.5062, -4.5062,
           -4.5062, -4.5061, -4.5062, -4.5062, -4.5062, -4.5062, -4.5062,
           -4.5062],
          [-4.5061, -4.5061, -4.5061, -4.5061, -4.5061, -4.5061, -4.5061,
           -4.5061, -4.5061, -4.5061, -4.5061, -4.5061, -4.5061, -4.5061,
           -4.5061],
          [-0.6109, -0.6109, -0.6109, -0.6109, -0.6109, -0.6109, -0.6109,
           -0.6109, -0.6109, -0.6109, -0.6109, -0.6109, -0.6109, -0.6109,
           -0.6109],
          [-4.5062, -4.5061, -4.5062, -4.5062, -4.5062, -4.5062, -4.5062,
           -4.5062, -4.5061, -4.5062, -4.5062, -4.5062, -4.5062, -4.5062,
           -4.5062],
          [-4.5062, -4.5061, -4.5062, -4.5062, -4.5062, -4.5062, -4.5062,
           -4.5062, -4.5061, -4.5062, -4.5062, -4.5062, -4.5062, -4.5062,
           -4.5062],
          [-1.1289, -1.1289, -1.1289, -1.1289, -1.1289, -1.1289, -1.1289,
           -1.1289, -1.1289, -1.1289, -1.1289, -1.1289, -1.1289, -1.1289,
           -1.1289],
          [-4.5062, -4.5061, -4.5062, -4.5062, -4.5062, -4.5062, -4.5062,
           -4.5062, -4.5061, -4.5062, -4.5062, -4.5062, -4.5062, -4.5062,
           -4.5062],
          [-4.5062, -4.5061, -4.5062, -4.5062, -4.5062, -4.5062, -4.5062,
           -4.5062, -4.5061, -4.5062, -4.5062, -4.5062, -4.5062, -4.5062,
           -4.5062],
          [-2.6782, -2.6782, -2.6782, -2.6782, -2.6782, -2.6782, -2.6782,
           -2.6782, -2.6782, -2.6782, -2.6782, -2.6782, -2.6782, -2.6782,
           -2.6782]],

         [[-4.3262, -4.3262, -4.3262, -4.3262, -4.3262, -4.3262, -4.3262,
           -4.3262, -4.3262, -4.3262, -4.3262, -4.3262, -4.3262, -4.3262,
           -4.3262],
          [-3.6433, -3.6433, -3.6433, -3.6433, -3.6433, -3.6433, -3.6433,
           -3.6433, -3.6433, -3.6433, -3.6433, -3.6433, -3.6433, -3.6433,
           -3.6433],
          [-4.3262, -4.3262, -4.3262, -4.3262, -4.3262, -4.3262, -4.3262,
           -4.3262, -4.3262, -4.3262, -4.3262, -4.3262, -4.3262, -4.3262,
           -4.3262],
          [-4.3262, -4.3262, -4.3262, -4.3262, -4.3262, -4.3262, -4.3262,
           -4.3262, -4.3262, -4.3262, -4.3262, -4.3262, -4.3262, -4.3262,
           -4.3262],
          [-2.3962, -2.3962, -2.3962, -2.3962, -2.3962, -2.3962, -2.3962,
           -2.3962, -2.3962, -2.3962, -2.3962, -2.3962, -2.3962, -2.3962,
           -2.3962],
          [-4.3262, -4.3262, -4.3262, -4.3262, -4.3262, -4.3262, -4.3262,
           -4.3262, -4.3262, -4.3262, -4.3262, -4.3262, -4.3262, -4.3262,
           -4.3262],
          [-4.3262, -4.3262, -4.3262, -4.3262, -4.3262, -4.3262, -4.3262,
           -4.3262, -4.3262, -4.3262, -4.3262, -4.3262, -4.3262, -4.3262,
           -4.3262],
          [-4.3262, -4.3262, -4.3262, -4.3262, -4.3262, -4.3262, -4.3262,
           -4.3262, -4.3262, -4.3262, -4.3262, -4.3262, -4.3262, -4.3262,
           -4.3262],
          [-4.3261, -4.3261, -4.3261, -4.3262, -4.3261, -4.3261, -4.3261,
           -4.3261, -4.3261, -4.3261, -4.3261, -4.3261, -4.3261, -4.3261,
           -4.3261],
          [-4.3262, -4.3262, -4.3262, -4.3262, -4.3262, -4.3262, -4.3262,
           -4.3262, -4.3262, -4.3262, -4.3262, -4.3262, -4.3262, -4.3262,
           -4.3262],
          [-4.3262, -4.3262, -4.3262, -4.3262, -4.3262, -4.3262, -4.3262,
           -4.3262, -4.3262, -4.3262, -4.3262, -4.3262, -4.3262, -4.3262,
           -4.3262],
          [-4.3262, -4.3262, -4.3262, -4.3262, -4.3262, -4.3262, -4.3262,
           -4.3262, -4.3262, -4.3262, -4.3262, -4.3262, -4.3262, -4.3262,
           -4.3262],
          [-0.7605, -0.7605, -0.7605, -0.7605, -0.7605, -0.7605, -0.7605,
           -0.7605, -0.7605, -0.7605, -0.7605, -0.7605, -0.7605, -0.7605,
           -0.7605],
          [-4.3262, -4.3262, -4.3262, -4.3262, -4.3262, -4.3262, -4.3262,
           -4.3262, -4.3262, -4.3262, -4.3262, -4.3262, -4.3262, -4.3262,
           -4.3262],
          [-4.3262, -4.3262, -4.3262, -4.3262, -4.3262, -4.3262, -4.3262,
           -4.3262, -4.3262, -4.3262, -4.3262, -4.3262, -4.3262, -4.3262,
           -4.3262],
          [-2.3962, -2.3962, -2.3962, -2.3962, -2.3962, -2.3962, -2.3962,
           -2.3962, -2.3962, -2.3962, -2.3962, -2.3962, -2.3962, -2.3962,
           -2.3962]]]], grad_fn=<SliceBackward0>)
train_step: Entropy shape: torch.Size([16, 15])
train_step: Entropy sample: tensor([[0.6088, 0.6711],
        [0.5580, 0.4541]], grad_fn=<SliceBackward0>)
train_step: Entropy coefficient: 0.01
train_step: Actor loss: -1.5717432498931885
train_step: returns shape after mean: torch.Size([16, 15])
train_step: target_indices shape: torch.Size([16, 15])
train_step: value_logits shape: torch.Size([16, 15, 255])
train_step: target_twohot shape: torch.Size([16, 15, 255])
--- Starting train_step at 2025-04-01 01:53:07 ---
Full starting_state: {'deter': tensor([[[-1.2039e-01, -5.0085e-02,  1.1254e-02,  ...,  1.3582e-01,
           2.4214e-02,  1.4200e-01],
         [-8.5053e-02,  9.3494e-02,  1.1506e-01,  ...,  7.0803e-02,
           6.5952e-02, -2.7656e-02],
         [-8.0316e-02,  9.0548e-02, -3.0629e-02,  ..., -3.3739e-01,
           2.4970e-02,  8.6477e-02],
         ...,
         [-1.3821e-01,  6.6003e-02, -1.0066e-01,  ..., -3.5443e-02,
           2.2942e-02, -4.8674e-02],
         [ 1.4059e-01, -1.2318e-01, -6.0387e-02,  ...,  7.5423e-02,
          -4.0139e-03, -8.3149e-02],
         [-1.7161e-01, -3.4045e-02, -1.4643e-01,  ..., -9.2091e-02,
           1.2041e-02,  1.5766e-01]],

        [[-6.6839e-02,  8.1597e-02, -2.7429e-02,  ..., -3.2795e-02,
           8.6463e-02, -3.3705e-05],
         [ 6.1063e-04, -5.9260e-02,  1.3186e-02,  ..., -6.4685e-03,
          -6.2640e-02,  3.2539e-02],
         [-2.2061e-01, -6.8968e-02, -1.1710e-01,  ..., -1.2505e-01,
          -6.6373e-02,  1.0873e-03],
         ...,
         [ 8.1525e-02,  3.3452e-02, -7.2324e-02,  ...,  9.3714e-02,
          -9.7236e-03,  1.8230e-02],
         [-4.0592e-02,  1.5382e-02,  1.4324e-02,  ..., -1.5757e-02,
          -5.9397e-02, -2.6954e-02],
         [-1.0965e-01,  1.7851e-03, -9.7256e-02,  ..., -8.4737e-02,
           1.2852e-02,  1.0922e-01]],

        [[ 4.0855e-02,  3.0536e-02, -8.6186e-02,  ...,  1.3490e-02,
           1.5324e-02, -8.1559e-03],
         [ 5.9061e-03,  2.3045e-02, -6.1014e-02,  ...,  5.8747e-02,
           7.1819e-02, -2.1853e-02],
         [-1.1548e-01, -8.1970e-02, -1.5258e-01,  ..., -2.0889e-03,
           7.8306e-02,  3.4069e-02],
         ...,
         [-6.2891e-03,  4.6435e-02, -8.9650e-02,  ...,  1.9849e-02,
          -2.6817e-02, -8.6130e-02],
         [-9.5860e-02,  1.6589e-02,  1.1245e-01,  ..., -7.9708e-03,
          -3.8515e-02,  1.7699e-02],
         [-2.2787e-01, -7.0752e-02,  1.9476e-03,  ..., -2.8231e-02,
           1.1617e-01, -8.6861e-02]],

        ...,

        [[-1.0801e-02, -4.0978e-02,  1.0361e-01,  ..., -6.1927e-02,
          -4.6508e-02,  5.9379e-02],
         [ 5.1529e-02, -5.0987e-02, -2.0409e-01,  ..., -4.0414e-02,
           1.9528e-02, -3.5043e-02],
         [-1.7611e-02, -8.4441e-02,  2.7702e-02,  ...,  1.4168e-01,
          -1.4714e-01,  9.3477e-02],
         ...,
         [ 9.5320e-02, -1.0104e-01, -2.2161e-01,  ..., -1.1773e-03,
           9.6880e-02,  1.1462e-02],
         [-1.6462e-01,  2.7027e-02, -5.6919e-02,  ..., -2.4391e-02,
           6.6996e-02,  2.7922e-02],
         [-9.1687e-02,  9.7956e-02, -1.7226e-01,  ...,  1.8033e-02,
           6.9526e-02,  6.6914e-03]],

        [[-1.0817e-01,  1.2836e-01,  5.7404e-02,  ..., -1.4755e-02,
           8.1021e-03, -6.1208e-02],
         [-1.6067e-01, -8.2176e-02,  3.8065e-02,  ...,  2.8465e-02,
          -4.6417e-02, -1.0911e-01],
         [-1.9506e-01,  7.2582e-03,  5.9733e-02,  ..., -1.3244e-03,
           4.9283e-03,  3.3808e-03],
         ...,
         [-5.2707e-02,  3.4489e-02, -1.6024e-01,  ...,  2.0524e-02,
          -1.3741e-01,  7.0692e-02],
         [-1.2271e-01,  7.4379e-02,  3.2905e-02,  ..., -3.0207e-02,
           7.8480e-02,  1.5782e-03],
         [ 9.8573e-03,  6.5529e-02, -1.6756e-01,  ...,  3.7259e-02,
           2.7304e-02, -1.3244e-01]],

        [[-1.7702e-01,  1.9765e-01, -6.3985e-02,  ...,  2.7347e-02,
          -5.8023e-02, -6.5136e-02],
         [ 6.7029e-02,  6.5942e-02, -2.0061e-02,  ...,  5.1772e-02,
           5.4674e-02, -5.2406e-02],
         [-1.0272e-01, -5.5269e-02, -2.0440e-01,  ..., -1.4312e-01,
          -7.1257e-02,  3.8405e-02],
         ...,
         [-1.1490e-01, -8.1225e-02,  1.2462e-02,  ...,  2.4147e-02,
          -6.5051e-02, -1.4361e-01],
         [-1.9520e-01, -5.3338e-02, -7.5335e-02,  ...,  3.5472e-02,
          -9.1295e-02,  7.3535e-02],
         [ 8.9432e-03, -6.0478e-02, -8.0532e-02,  ..., -2.4471e-01,
           1.1058e-01, -6.6120e-03]]], grad_fn=<StackBackward0>), 'stoch': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [1., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 1., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 1., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 1., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 1.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [1., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]])}
train_step: Starting state deter shape: torch.Size([16, 50, 128])
train_step: Starting state stoch shape: torch.Size([16, 50, 1024])
After ensuring logits/stoch: {'deter': tensor([[[-1.2039e-01, -5.0085e-02,  1.1254e-02,  ...,  1.3582e-01,
           2.4214e-02,  1.4200e-01],
         [-8.5053e-02,  9.3494e-02,  1.1506e-01,  ...,  7.0803e-02,
           6.5952e-02, -2.7656e-02],
         [-8.0316e-02,  9.0548e-02, -3.0629e-02,  ..., -3.3739e-01,
           2.4970e-02,  8.6477e-02],
         ...,
         [-1.3821e-01,  6.6003e-02, -1.0066e-01,  ..., -3.5443e-02,
           2.2942e-02, -4.8674e-02],
         [ 1.4059e-01, -1.2318e-01, -6.0387e-02,  ...,  7.5423e-02,
          -4.0139e-03, -8.3149e-02],
         [-1.7161e-01, -3.4045e-02, -1.4643e-01,  ..., -9.2091e-02,
           1.2041e-02,  1.5766e-01]],

        [[-6.6839e-02,  8.1597e-02, -2.7429e-02,  ..., -3.2795e-02,
           8.6463e-02, -3.3705e-05],
         [ 6.1063e-04, -5.9260e-02,  1.3186e-02,  ..., -6.4685e-03,
          -6.2640e-02,  3.2539e-02],
         [-2.2061e-01, -6.8968e-02, -1.1710e-01,  ..., -1.2505e-01,
          -6.6373e-02,  1.0873e-03],
         ...,
         [ 8.1525e-02,  3.3452e-02, -7.2324e-02,  ...,  9.3714e-02,
          -9.7236e-03,  1.8230e-02],
         [-4.0592e-02,  1.5382e-02,  1.4324e-02,  ..., -1.5757e-02,
          -5.9397e-02, -2.6954e-02],
         [-1.0965e-01,  1.7851e-03, -9.7256e-02,  ..., -8.4737e-02,
           1.2852e-02,  1.0922e-01]],

        [[ 4.0855e-02,  3.0536e-02, -8.6186e-02,  ...,  1.3490e-02,
           1.5324e-02, -8.1559e-03],
         [ 5.9061e-03,  2.3045e-02, -6.1014e-02,  ...,  5.8747e-02,
           7.1819e-02, -2.1853e-02],
         [-1.1548e-01, -8.1970e-02, -1.5258e-01,  ..., -2.0889e-03,
           7.8306e-02,  3.4069e-02],
         ...,
         [-6.2891e-03,  4.6435e-02, -8.9650e-02,  ...,  1.9849e-02,
          -2.6817e-02, -8.6130e-02],
         [-9.5860e-02,  1.6589e-02,  1.1245e-01,  ..., -7.9708e-03,
          -3.8515e-02,  1.7699e-02],
         [-2.2787e-01, -7.0752e-02,  1.9476e-03,  ..., -2.8231e-02,
           1.1617e-01, -8.6861e-02]],

        ...,

        [[-1.0801e-02, -4.0978e-02,  1.0361e-01,  ..., -6.1927e-02,
          -4.6508e-02,  5.9379e-02],
         [ 5.1529e-02, -5.0987e-02, -2.0409e-01,  ..., -4.0414e-02,
           1.9528e-02, -3.5043e-02],
         [-1.7611e-02, -8.4441e-02,  2.7702e-02,  ...,  1.4168e-01,
          -1.4714e-01,  9.3477e-02],
         ...,
         [ 9.5320e-02, -1.0104e-01, -2.2161e-01,  ..., -1.1773e-03,
           9.6880e-02,  1.1462e-02],
         [-1.6462e-01,  2.7027e-02, -5.6919e-02,  ..., -2.4391e-02,
           6.6996e-02,  2.7922e-02],
         [-9.1687e-02,  9.7956e-02, -1.7226e-01,  ...,  1.8033e-02,
           6.9526e-02,  6.6914e-03]],

        [[-1.0817e-01,  1.2836e-01,  5.7404e-02,  ..., -1.4755e-02,
           8.1021e-03, -6.1208e-02],
         [-1.6067e-01, -8.2176e-02,  3.8065e-02,  ...,  2.8465e-02,
          -4.6417e-02, -1.0911e-01],
         [-1.9506e-01,  7.2582e-03,  5.9733e-02,  ..., -1.3244e-03,
           4.9283e-03,  3.3808e-03],
         ...,
         [-5.2707e-02,  3.4489e-02, -1.6024e-01,  ...,  2.0524e-02,
          -1.3741e-01,  7.0692e-02],
         [-1.2271e-01,  7.4379e-02,  3.2905e-02,  ..., -3.0207e-02,
           7.8480e-02,  1.5782e-03],
         [ 9.8573e-03,  6.5529e-02, -1.6756e-01,  ...,  3.7259e-02,
           2.7304e-02, -1.3244e-01]],

        [[-1.7702e-01,  1.9765e-01, -6.3985e-02,  ...,  2.7347e-02,
          -5.8023e-02, -6.5136e-02],
         [ 6.7029e-02,  6.5942e-02, -2.0061e-02,  ...,  5.1772e-02,
           5.4674e-02, -5.2406e-02],
         [-1.0272e-01, -5.5269e-02, -2.0440e-01,  ..., -1.4312e-01,
          -7.1257e-02,  3.8405e-02],
         ...,
         [-1.1490e-01, -8.1225e-02,  1.2462e-02,  ...,  2.4147e-02,
          -6.5051e-02, -1.4361e-01],
         [-1.9520e-01, -5.3338e-02, -7.5335e-02,  ...,  3.5472e-02,
          -9.1295e-02,  7.3535e-02],
         [ 8.9432e-03, -6.0478e-02, -8.0532e-02,  ..., -2.4471e-01,
           1.1058e-01, -6.6120e-03]]], grad_fn=<StackBackward0>), 'stoch': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [1., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 1., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 1., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 1., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 1.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [1., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]]), 'logits': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]])}
train_step: Normalized hidden_state shape: torch.Size([1, 16, 128])
train_step: Normalized stoch shape: torch.Size([16, 1024])
train_step: Normalized deter shape: torch.Size([16, 128])
train_step: Post-imagine_trajectory: Imagined features shape: torch.Size([16, 15, 1152])
train_step: Post-imagine_trajectory: Imagined actions shape: torch.Size([16, 15, 2])
train_step: Post-imagine_trajectory: Imagined action indices shape: torch.Size([16, 15])
train_step: Post-imagine_trajectory: Imagined state deter shape: torch.Size([16, 15, 128])
train_step: Post-imagine_trajectory: Imagined state stoch shape: torch.Size([16, 15, 1024])
Reward shape: torch.Size([16, 15, 1]), Value shape: torch.Size([16, 15, 1]), Slow Value shape: torch.Size([16, 15, 1]), Discount shape: torch.Size([16, 15, 1, 1])
Return targets length: 15, First target shape: torch.Size([16, 16, 1])
train_step: Actor distribution shape: torch.Size([16, 15, 2])
train_step: Action log probabilities shape: torch.Size([16, 15])
train_step: Action log probabilities sample: tensor([[-0.1862, -0.1808],
        [-2.5575, -2.1554]], grad_fn=<SliceBackward0>)
train_step: Advantages shape: torch.Size([16, 15, 16, 15])
train_step: Advantages sample: tensor([[[[-3.5562, -3.5562, -3.5562, -3.5562, -3.5562, -3.5562, -3.5562,
           -3.5562, -3.5562, -3.5562, -3.5562, -3.5562, -3.5562, -3.5562,
           -3.5562],
          [-8.7209, -8.7209, -8.7209, -8.7209, -8.7209, -8.7209, -8.7209,
           -8.7209, -8.7209, -8.7209, -8.7209, -8.7209, -8.7209, -8.7209,
           -8.7209],
          [-0.9291, -0.9291, -0.9291, -0.9291, -0.9291, -0.9291, -0.9292,
           -0.9292, -0.9291, -0.9291, -0.9291, -0.9291, -0.9291, -0.9292,
           -0.9291],
          [-8.7209, -8.7209, -8.7209, -8.7209, -8.7209, -8.7209, -8.7209,
           -8.7209, -8.7209, -8.7209, -8.7209, -8.7209, -8.7209, -8.7209,
           -8.7209],
          [-8.7209, -8.7209, -8.7209, -8.7209, -8.7209, -8.7209, -8.7209,
           -8.7209, -8.7209, -8.7209, -8.7209, -8.7209, -8.7209, -8.7209,
           -8.7209],
          [-8.7209, -8.7209, -8.7209, -8.7209, -8.7209, -8.7209, -8.7209,
           -8.7209, -8.7209, -8.7209, -8.7209, -8.7209, -8.7209, -8.7209,
           -8.7209],
          [-8.7209, -8.7209, -8.7209, -8.7209, -8.7209, -8.7209, -8.7209,
           -8.7209, -8.7209, -8.7209, -8.7209, -8.7209, -8.7209, -8.7209,
           -8.7209],
          [-7.6949, -7.6949, -7.6949, -7.6949, -7.6949, -7.6949, -7.6949,
           -7.6949, -7.6949, -7.6949, -7.6949, -7.6949, -7.6949, -7.6949,
           -7.6949],
          [-8.7209, -8.7209, -8.7209, -8.7209, -8.7209, -8.7209, -8.7209,
           -8.7209, -8.7209, -8.7209, -8.7209, -8.7209, -8.7209, -8.7209,
           -8.7209],
          [-8.7209, -8.7209, -8.7209, -8.7209, -8.7209, -8.7209, -8.7209,
           -8.7209, -8.7209, -8.7209, -8.7209, -8.7209, -8.7209, -8.7209,
           -8.7209],
          [-3.9077, -3.9077, -3.9076, -3.9077, -3.9077, -3.9077, -3.9077,
           -3.9077, -3.9077, -3.9077, -3.9077, -3.9077, -3.9076, -3.9077,
           -3.9077],
          [-8.7209, -8.7209, -8.7209, -8.7209, -8.7209, -8.7209, -8.7209,
           -8.7209, -8.7209, -8.7209, -8.7209, -8.7209, -8.7209, -8.7209,
           -8.7209],
          [-8.7209, -8.7209, -8.7209, -8.7209, -8.7209, -8.7209, -8.7209,
           -8.7209, -8.7209, -8.7209, -8.7209, -8.7209, -8.7209, -8.7209,
           -8.7209],
          [-8.7209, -8.7209, -8.7209, -8.7209, -8.7209, -8.7209, -8.7209,
           -8.7209, -8.7209, -8.7209, -8.7209, -8.7209, -8.7209, -8.7209,
           -8.7209],
          [-8.7209, -8.7209, -8.7209, -8.7209, -8.7209, -8.7209, -8.7209,
           -8.7209, -8.7209, -8.7209, -8.7209, -8.7209, -8.7209, -8.7209,
           -8.7209],
          [-8.7209, -8.7209, -8.7209, -8.7209, -8.7209, -8.7209, -8.7209,
           -8.7209, -8.7209, -8.7209, -8.7209, -8.7209, -8.7209, -8.7209,
           -8.7209]],

         [[-2.7736, -2.7735, -2.7736, -2.7735, -2.7735, -2.7735, -2.7735,
           -2.7735, -2.7736, -2.7735, -2.7735, -2.7735, -2.7735, -2.7735,
           -2.7735],
          [-8.2264, -8.2264, -8.2264, -8.2264, -8.2264, -8.2264, -8.2264,
           -8.2264, -8.2264, -8.2264, -8.2264, -8.2264, -8.2264, -8.2264,
           -8.2264],
          [-8.2264, -8.2264, -8.2264, -8.2264, -8.2264, -8.2264, -8.2264,
           -8.2264, -8.2264, -8.2264, -8.2264, -8.2264, -8.2264, -8.2264,
           -8.2264],
          [-8.2264, -8.2264, -8.2264, -8.2264, -8.2264, -8.2264, -8.2264,
           -8.2264, -8.2264, -8.2264, -8.2264, -8.2264, -8.2264, -8.2264,
           -8.2264],
          [-8.2264, -8.2264, -8.2264, -8.2264, -8.2264, -8.2264, -8.2264,
           -8.2264, -8.2264, -8.2264, -8.2264, -8.2264, -8.2264, -8.2264,
           -8.2264],
          [-8.2264, -8.2264, -8.2264, -8.2264, -8.2264, -8.2264, -8.2264,
           -8.2264, -8.2264, -8.2264, -8.2264, -8.2264, -8.2264, -8.2264,
           -8.2264],
          [-8.2264, -8.2264, -8.2264, -8.2264, -8.2264, -8.2264, -8.2264,
           -8.2264, -8.2264, -8.2264, -8.2264, -8.2264, -8.2264, -8.2264,
           -8.2264],
          [-7.1432, -7.1432, -7.1432, -7.1432, -7.1432, -7.1431, -7.1432,
           -7.1432, -7.1432, -7.1431, -7.1431, -7.1432, -7.1431, -7.1431,
           -7.1432],
          [-8.2264, -8.2264, -8.2264, -8.2264, -8.2264, -8.2264, -8.2264,
           -8.2264, -8.2264, -8.2264, -8.2264, -8.2264, -8.2264, -8.2264,
           -8.2264],
          [-8.2264, -8.2264, -8.2264, -8.2264, -8.2264, -8.2264, -8.2264,
           -8.2264, -8.2264, -8.2264, -8.2264, -8.2264, -8.2264, -8.2264,
           -8.2264],
          [-3.1446, -3.1446, -3.1446, -3.1446, -3.1446, -3.1446, -3.1446,
           -3.1446, -3.1446, -3.1446, -3.1446, -3.1446, -3.1446, -3.1446,
           -3.1446],
          [-8.2264, -8.2264, -8.2264, -8.2264, -8.2264, -8.2264, -8.2264,
           -8.2264, -8.2264, -8.2264, -8.2264, -8.2264, -8.2264, -8.2264,
           -8.2264],
          [-8.2264, -8.2264, -8.2264, -8.2264, -8.2264, -8.2264, -8.2264,
           -8.2264, -8.2264, -8.2264, -8.2264, -8.2264, -8.2264, -8.2264,
           -8.2264],
          [-8.2264, -8.2264, -8.2264, -8.2264, -8.2264, -8.2264, -8.2264,
           -8.2264, -8.2264, -8.2264, -8.2264, -8.2264, -8.2264, -8.2264,
           -8.2264],
          [-8.2264, -8.2264, -8.2264, -8.2264, -8.2264, -8.2264, -8.2264,
           -8.2264, -8.2264, -8.2264, -8.2264, -8.2264, -8.2264, -8.2264,
           -8.2264],
          [-8.2264, -8.2264, -8.2264, -8.2264, -8.2264, -8.2264, -8.2264,
           -8.2264, -8.2264, -8.2264, -8.2264, -8.2264, -8.2264, -8.2264,
           -8.2264]]],


        [[[-1.3818, -1.3818, -1.3818, -1.3818, -1.3818, -1.3818, -1.3818,
           -1.3818, -1.3818, -1.3818, -1.3818, -1.3818, -1.3818, -1.3818,
           -1.3818],
          [-7.5567, -7.5567, -7.5567, -7.5567, -7.5568, -7.5567, -7.5568,
           -7.5568, -7.5568, -7.5568, -7.5567, -7.5567, -7.5567, -7.5568,
           -7.5567],
          [-0.1643, -0.1643, -0.1642, -0.1642, -0.1643, -0.1643, -0.1643,
           -0.1643, -0.1643, -0.1643, -0.1643, -0.1643, -0.1642, -0.1643,
           -0.1643],
          [-7.5567, -7.5567, -7.5567, -7.5567, -7.5568, -7.5567, -7.5568,
           -7.5568, -7.5568, -7.5568, -7.5567, -7.5567, -7.5567, -7.5568,
           -7.5567],
          [-7.5567, -7.5567, -7.5567, -7.5567, -7.5568, -7.5567, -7.5568,
           -7.5568, -7.5568, -7.5568, -7.5567, -7.5567, -7.5567, -7.5568,
           -7.5567],
          [-7.5567, -7.5567, -7.5567, -7.5567, -7.5568, -7.5567, -7.5568,
           -7.5568, -7.5568, -7.5568, -7.5567, -7.5567, -7.5567, -7.5568,
           -7.5567],
          [-7.5567, -7.5567, -7.5567, -7.5567, -7.5568, -7.5567, -7.5568,
           -7.5568, -7.5568, -7.5568, -7.5567, -7.5567, -7.5567, -7.5568,
           -7.5567],
          [-6.5749, -6.5749, -6.5748, -6.5749, -6.5749, -6.5749, -6.5749,
           -6.5749, -6.5749, -6.5749, -6.5749, -6.5749, -6.5748, -6.5749,
           -6.5749],
          [-7.5567, -7.5567, -7.5567, -7.5567, -7.5568, -7.5567, -7.5568,
           -7.5568, -7.5568, -7.5568, -7.5567, -7.5567, -7.5567, -7.5568,
           -7.5567],
          [-7.5567, -7.5567, -7.5567, -7.5567, -7.5568, -7.5567, -7.5568,
           -7.5568, -7.5568, -7.5568, -7.5567, -7.5567, -7.5567, -7.5568,
           -7.5567],
          [-1.6979, -1.6979, -1.6978, -1.6978, -1.6979, -1.6979, -1.6979,
           -1.6979, -1.6979, -1.6979, -1.6979, -1.6979, -1.6978, -1.6979,
           -1.6979],
          [-7.5567, -7.5567, -7.5567, -7.5567, -7.5568, -7.5567, -7.5568,
           -7.5568, -7.5568, -7.5568, -7.5567, -7.5567, -7.5567, -7.5568,
           -7.5567],
          [-7.5567, -7.5567, -7.5567, -7.5567, -7.5568, -7.5567, -7.5568,
           -7.5568, -7.5568, -7.5568, -7.5567, -7.5567, -7.5567, -7.5568,
           -7.5567],
          [-7.5567, -7.5567, -7.5567, -7.5567, -7.5568, -7.5567, -7.5568,
           -7.5568, -7.5568, -7.5568, -7.5567, -7.5567, -7.5567, -7.5568,
           -7.5567],
          [-7.5567, -7.5567, -7.5567, -7.5567, -7.5568, -7.5567, -7.5568,
           -7.5568, -7.5568, -7.5568, -7.5567, -7.5567, -7.5567, -7.5568,
           -7.5567],
          [-7.5567, -7.5567, -7.5567, -7.5567, -7.5568, -7.5567, -7.5568,
           -7.5568, -7.5568, -7.5568, -7.5567, -7.5567, -7.5567, -7.5568,
           -7.5567]],

         [[-1.2854, -1.2854, -1.2854, -1.2854, -1.2854, -1.2854, -1.2854,
           -1.2854, -1.2854, -1.2853, -1.2853, -1.2854, -1.2854, -1.2854,
           -1.2854],
          [-7.8049, -7.8048, -7.8049, -7.8048, -7.8048, -7.8048, -7.8048,
           -7.8048, -7.8049, -7.8048, -7.8048, -7.8048, -7.8048, -7.8048,
           -7.8048],
          [-7.8049, -7.8048, -7.8049, -7.8048, -7.8048, -7.8048, -7.8048,
           -7.8048, -7.8049, -7.8048, -7.8048, -7.8048, -7.8048, -7.8048,
           -7.8048],
          [-7.8049, -7.8048, -7.8049, -7.8048, -7.8048, -7.8048, -7.8048,
           -7.8048, -7.8049, -7.8048, -7.8048, -7.8048, -7.8048, -7.8048,
           -7.8048],
          [-7.8049, -7.8048, -7.8049, -7.8048, -7.8048, -7.8048, -7.8048,
           -7.8048, -7.8049, -7.8048, -7.8048, -7.8048, -7.8048, -7.8048,
           -7.8048],
          [-7.8049, -7.8048, -7.8049, -7.8048, -7.8048, -7.8048, -7.8048,
           -7.8048, -7.8049, -7.8048, -7.8048, -7.8048, -7.8048, -7.8048,
           -7.8048],
          [-7.8049, -7.8048, -7.8049, -7.8048, -7.8048, -7.8048, -7.8048,
           -7.8048, -7.8049, -7.8048, -7.8048, -7.8048, -7.8048, -7.8048,
           -7.8048],
          [-6.7682, -6.7682, -6.7682, -6.7682, -6.7682, -6.7682, -6.7682,
           -6.7682, -6.7682, -6.7682, -6.7682, -6.7682, -6.7682, -6.7682,
           -6.7682],
          [-7.8049, -7.8048, -7.8049, -7.8048, -7.8048, -7.8048, -7.8048,
           -7.8048, -7.8049, -7.8048, -7.8048, -7.8048, -7.8048, -7.8048,
           -7.8048],
          [-7.8049, -7.8048, -7.8049, -7.8048, -7.8048, -7.8048, -7.8048,
           -7.8048, -7.8049, -7.8048, -7.8048, -7.8048, -7.8048, -7.8048,
           -7.8048],
          [-1.6191, -1.6190, -1.6190, -1.6190, -1.6190, -1.6190, -1.6190,
           -1.6190, -1.6191, -1.6190, -1.6190, -1.6190, -1.6190, -1.6190,
           -1.6190],
          [-7.8049, -7.8048, -7.8049, -7.8048, -7.8048, -7.8048, -7.8048,
           -7.8048, -7.8049, -7.8048, -7.8048, -7.8048, -7.8048, -7.8048,
           -7.8048],
          [-7.8049, -7.8048, -7.8049, -7.8048, -7.8048, -7.8048, -7.8048,
           -7.8048, -7.8049, -7.8048, -7.8048, -7.8048, -7.8048, -7.8048,
           -7.8048],
          [-7.8049, -7.8048, -7.8049, -7.8048, -7.8048, -7.8048, -7.8048,
           -7.8048, -7.8049, -7.8048, -7.8048, -7.8048, -7.8048, -7.8048,
           -7.8048],
          [-7.8049, -7.8048, -7.8049, -7.8048, -7.8048, -7.8048, -7.8048,
           -7.8048, -7.8049, -7.8048, -7.8048, -7.8048, -7.8048, -7.8048,
           -7.8048],
          [-7.8049, -7.8048, -7.8049, -7.8048, -7.8048, -7.8048, -7.8048,
           -7.8048, -7.8049, -7.8048, -7.8048, -7.8048, -7.8048, -7.8048,
           -7.8048]]]], grad_fn=<SliceBackward0>)
train_step: Return scale: 1.5564621565300512
train_step: Scaled advantages shape: torch.Size([16, 15, 16, 15])
train_step: Scaled advantages sample: tensor([[[[-2.2848, -2.2848, -2.2848, -2.2848, -2.2848, -2.2848, -2.2848,
           -2.2848, -2.2848, -2.2848, -2.2848, -2.2848, -2.2848, -2.2848,
           -2.2848],
          [-5.6030, -5.6030, -5.6030, -5.6030, -5.6030, -5.6030, -5.6030,
           -5.6030, -5.6030, -5.6030, -5.6030, -5.6030, -5.6030, -5.6030,
           -5.6030],
          [-0.9291, -0.9291, -0.9291, -0.9291, -0.9291, -0.9291, -0.9292,
           -0.9292, -0.9291, -0.9291, -0.9291, -0.9291, -0.9291, -0.9292,
           -0.9291],
          [-5.6030, -5.6030, -5.6030, -5.6030, -5.6030, -5.6030, -5.6030,
           -5.6030, -5.6030, -5.6030, -5.6030, -5.6030, -5.6030, -5.6030,
           -5.6030],
          [-5.6030, -5.6030, -5.6030, -5.6030, -5.6030, -5.6030, -5.6030,
           -5.6030, -5.6030, -5.6030, -5.6030, -5.6030, -5.6030, -5.6030,
           -5.6030],
          [-5.6030, -5.6030, -5.6030, -5.6030, -5.6030, -5.6030, -5.6030,
           -5.6030, -5.6030, -5.6030, -5.6030, -5.6030, -5.6030, -5.6030,
           -5.6030],
          [-5.6030, -5.6030, -5.6030, -5.6030, -5.6030, -5.6030, -5.6030,
           -5.6030, -5.6030, -5.6030, -5.6030, -5.6030, -5.6030, -5.6030,
           -5.6030],
          [-4.9438, -4.9438, -4.9438, -4.9438, -4.9439, -4.9438, -4.9439,
           -4.9439, -4.9439, -4.9439, -4.9438, -4.9438, -4.9438, -4.9439,
           -4.9438],
          [-5.6030, -5.6030, -5.6030, -5.6030, -5.6030, -5.6030, -5.6030,
           -5.6030, -5.6030, -5.6030, -5.6030, -5.6030, -5.6030, -5.6030,
           -5.6030],
          [-5.6030, -5.6030, -5.6030, -5.6030, -5.6030, -5.6030, -5.6030,
           -5.6030, -5.6030, -5.6030, -5.6030, -5.6030, -5.6030, -5.6030,
           -5.6030],
          [-2.5106, -2.5106, -2.5106, -2.5106, -2.5106, -2.5106, -2.5106,
           -2.5106, -2.5106, -2.5106, -2.5106, -2.5106, -2.5106, -2.5106,
           -2.5106],
          [-5.6030, -5.6030, -5.6030, -5.6030, -5.6030, -5.6030, -5.6030,
           -5.6030, -5.6030, -5.6030, -5.6030, -5.6030, -5.6030, -5.6030,
           -5.6030],
          [-5.6030, -5.6030, -5.6030, -5.6030, -5.6030, -5.6030, -5.6030,
           -5.6030, -5.6030, -5.6030, -5.6030, -5.6030, -5.6030, -5.6030,
           -5.6030],
          [-5.6030, -5.6030, -5.6030, -5.6030, -5.6030, -5.6030, -5.6030,
           -5.6030, -5.6030, -5.6030, -5.6030, -5.6030, -5.6030, -5.6030,
           -5.6030],
          [-5.6030, -5.6030, -5.6030, -5.6030, -5.6030, -5.6030, -5.6030,
           -5.6030, -5.6030, -5.6030, -5.6030, -5.6030, -5.6030, -5.6030,
           -5.6030],
          [-5.6030, -5.6030, -5.6030, -5.6030, -5.6030, -5.6030, -5.6030,
           -5.6030, -5.6030, -5.6030, -5.6030, -5.6030, -5.6030, -5.6030,
           -5.6030]],

         [[-1.7820, -1.7820, -1.7820, -1.7819, -1.7819, -1.7819, -1.7820,
           -1.7819, -1.7820, -1.7819, -1.7819, -1.7819, -1.7819, -1.7819,
           -1.7820],
          [-5.2853, -5.2853, -5.2853, -5.2853, -5.2853, -5.2853, -5.2853,
           -5.2853, -5.2853, -5.2853, -5.2853, -5.2853, -5.2853, -5.2853,
           -5.2853],
          [-5.2853, -5.2853, -5.2853, -5.2853, -5.2853, -5.2853, -5.2853,
           -5.2853, -5.2853, -5.2853, -5.2853, -5.2853, -5.2853, -5.2853,
           -5.2853],
          [-5.2853, -5.2853, -5.2853, -5.2853, -5.2853, -5.2853, -5.2853,
           -5.2853, -5.2853, -5.2853, -5.2853, -5.2853, -5.2853, -5.2853,
           -5.2853],
          [-5.2853, -5.2853, -5.2853, -5.2853, -5.2853, -5.2853, -5.2853,
           -5.2853, -5.2853, -5.2853, -5.2853, -5.2853, -5.2853, -5.2853,
           -5.2853],
          [-5.2853, -5.2853, -5.2853, -5.2853, -5.2853, -5.2853, -5.2853,
           -5.2853, -5.2853, -5.2853, -5.2853, -5.2853, -5.2853, -5.2853,
           -5.2853],
          [-5.2853, -5.2853, -5.2853, -5.2853, -5.2853, -5.2853, -5.2853,
           -5.2853, -5.2853, -5.2853, -5.2853, -5.2853, -5.2853, -5.2853,
           -5.2853],
          [-4.5894, -4.5894, -4.5894, -4.5894, -4.5894, -4.5894, -4.5894,
           -4.5894, -4.5894, -4.5893, -4.5893, -4.5894, -4.5893, -4.5893,
           -4.5894],
          [-5.2853, -5.2853, -5.2853, -5.2853, -5.2853, -5.2853, -5.2853,
           -5.2853, -5.2853, -5.2853, -5.2853, -5.2853, -5.2853, -5.2853,
           -5.2853],
          [-5.2853, -5.2853, -5.2853, -5.2853, -5.2853, -5.2853, -5.2853,
           -5.2853, -5.2853, -5.2853, -5.2853, -5.2853, -5.2853, -5.2853,
           -5.2853],
          [-2.0204, -2.0203, -2.0204, -2.0203, -2.0203, -2.0203, -2.0203,
           -2.0203, -2.0204, -2.0203, -2.0203, -2.0203, -2.0203, -2.0203,
           -2.0203],
          [-5.2853, -5.2853, -5.2853, -5.2853, -5.2853, -5.2853, -5.2853,
           -5.2853, -5.2853, -5.2853, -5.2853, -5.2853, -5.2853, -5.2853,
           -5.2853],
          [-5.2853, -5.2853, -5.2853, -5.2853, -5.2853, -5.2853, -5.2853,
           -5.2853, -5.2853, -5.2853, -5.2853, -5.2853, -5.2853, -5.2853,
           -5.2853],
          [-5.2853, -5.2853, -5.2853, -5.2853, -5.2853, -5.2853, -5.2853,
           -5.2853, -5.2853, -5.2853, -5.2853, -5.2853, -5.2853, -5.2853,
           -5.2853],
          [-5.2853, -5.2853, -5.2853, -5.2853, -5.2853, -5.2853, -5.2853,
           -5.2853, -5.2853, -5.2853, -5.2853, -5.2853, -5.2853, -5.2853,
           -5.2853],
          [-5.2853, -5.2853, -5.2853, -5.2853, -5.2853, -5.2853, -5.2853,
           -5.2853, -5.2853, -5.2853, -5.2853, -5.2853, -5.2853, -5.2853,
           -5.2853]]],


        [[[-0.8878, -0.8878, -0.8878, -0.8878, -0.8878, -0.8878, -0.8878,
           -0.8878, -0.8878, -0.8878, -0.8878, -0.8878, -0.8878, -0.8878,
           -0.8878],
          [-4.8551, -4.8551, -4.8551, -4.8551, -4.8551, -4.8551, -4.8551,
           -4.8551, -4.8551, -4.8551, -4.8551, -4.8551, -4.8551, -4.8551,
           -4.8551],
          [-0.1643, -0.1643, -0.1642, -0.1642, -0.1643, -0.1643, -0.1643,
           -0.1643, -0.1643, -0.1643, -0.1643, -0.1643, -0.1642, -0.1643,
           -0.1643],
          [-4.8551, -4.8551, -4.8551, -4.8551, -4.8551, -4.8551, -4.8551,
           -4.8551, -4.8551, -4.8551, -4.8551, -4.8551, -4.8551, -4.8551,
           -4.8551],
          [-4.8551, -4.8551, -4.8551, -4.8551, -4.8551, -4.8551, -4.8551,
           -4.8551, -4.8551, -4.8551, -4.8551, -4.8551, -4.8551, -4.8551,
           -4.8551],
          [-4.8551, -4.8551, -4.8551, -4.8551, -4.8551, -4.8551, -4.8551,
           -4.8551, -4.8551, -4.8551, -4.8551, -4.8551, -4.8551, -4.8551,
           -4.8551],
          [-4.8551, -4.8551, -4.8551, -4.8551, -4.8551, -4.8551, -4.8551,
           -4.8551, -4.8551, -4.8551, -4.8551, -4.8551, -4.8551, -4.8551,
           -4.8551],
          [-4.2242, -4.2242, -4.2242, -4.2242, -4.2242, -4.2242, -4.2243,
           -4.2242, -4.2242, -4.2242, -4.2242, -4.2242, -4.2242, -4.2242,
           -4.2242],
          [-4.8551, -4.8551, -4.8551, -4.8551, -4.8551, -4.8551, -4.8551,
           -4.8551, -4.8551, -4.8551, -4.8551, -4.8551, -4.8551, -4.8551,
           -4.8551],
          [-4.8551, -4.8551, -4.8551, -4.8551, -4.8551, -4.8551, -4.8551,
           -4.8551, -4.8551, -4.8551, -4.8551, -4.8551, -4.8551, -4.8551,
           -4.8551],
          [-1.0908, -1.0908, -1.0908, -1.0908, -1.0908, -1.0908, -1.0909,
           -1.0909, -1.0909, -1.0908, -1.0908, -1.0908, -1.0908, -1.0909,
           -1.0908],
          [-4.8551, -4.8551, -4.8551, -4.8551, -4.8551, -4.8551, -4.8551,
           -4.8551, -4.8551, -4.8551, -4.8551, -4.8551, -4.8551, -4.8551,
           -4.8551],
          [-4.8551, -4.8551, -4.8551, -4.8551, -4.8551, -4.8551, -4.8551,
           -4.8551, -4.8551, -4.8551, -4.8551, -4.8551, -4.8551, -4.8551,
           -4.8551],
          [-4.8551, -4.8551, -4.8551, -4.8551, -4.8551, -4.8551, -4.8551,
           -4.8551, -4.8551, -4.8551, -4.8551, -4.8551, -4.8551, -4.8551,
           -4.8551],
          [-4.8551, -4.8551, -4.8551, -4.8551, -4.8551, -4.8551, -4.8551,
           -4.8551, -4.8551, -4.8551, -4.8551, -4.8551, -4.8551, -4.8551,
           -4.8551],
          [-4.8551, -4.8551, -4.8551, -4.8551, -4.8551, -4.8551, -4.8551,
           -4.8551, -4.8551, -4.8551, -4.8551, -4.8551, -4.8551, -4.8551,
           -4.8551]],

         [[-0.8258, -0.8258, -0.8258, -0.8258, -0.8258, -0.8258, -0.8258,
           -0.8258, -0.8258, -0.8258, -0.8258, -0.8258, -0.8258, -0.8258,
           -0.8258],
          [-5.0145, -5.0145, -5.0145, -5.0145, -5.0145, -5.0145, -5.0145,
           -5.0145, -5.0145, -5.0145, -5.0145, -5.0145, -5.0145, -5.0145,
           -5.0145],
          [-5.0145, -5.0145, -5.0145, -5.0145, -5.0145, -5.0145, -5.0145,
           -5.0145, -5.0145, -5.0145, -5.0145, -5.0145, -5.0145, -5.0145,
           -5.0145],
          [-5.0145, -5.0145, -5.0145, -5.0145, -5.0145, -5.0145, -5.0145,
           -5.0145, -5.0145, -5.0145, -5.0145, -5.0145, -5.0145, -5.0145,
           -5.0145],
          [-5.0145, -5.0145, -5.0145, -5.0145, -5.0145, -5.0145, -5.0145,
           -5.0145, -5.0145, -5.0145, -5.0145, -5.0145, -5.0145, -5.0145,
           -5.0145],
          [-5.0145, -5.0145, -5.0145, -5.0145, -5.0145, -5.0145, -5.0145,
           -5.0145, -5.0145, -5.0145, -5.0145, -5.0145, -5.0145, -5.0145,
           -5.0145],
          [-5.0145, -5.0145, -5.0145, -5.0145, -5.0145, -5.0145, -5.0145,
           -5.0145, -5.0145, -5.0145, -5.0145, -5.0145, -5.0145, -5.0145,
           -5.0145],
          [-4.3484, -4.3484, -4.3484, -4.3484, -4.3484, -4.3484, -4.3484,
           -4.3484, -4.3484, -4.3484, -4.3484, -4.3484, -4.3484, -4.3484,
           -4.3484],
          [-5.0145, -5.0145, -5.0145, -5.0145, -5.0145, -5.0145, -5.0145,
           -5.0145, -5.0145, -5.0145, -5.0145, -5.0145, -5.0145, -5.0145,
           -5.0145],
          [-5.0145, -5.0145, -5.0145, -5.0145, -5.0145, -5.0145, -5.0145,
           -5.0145, -5.0145, -5.0145, -5.0145, -5.0145, -5.0145, -5.0145,
           -5.0145],
          [-1.0402, -1.0402, -1.0402, -1.0402, -1.0402, -1.0402, -1.0402,
           -1.0402, -1.0402, -1.0402, -1.0402, -1.0402, -1.0402, -1.0402,
           -1.0402],
          [-5.0145, -5.0145, -5.0145, -5.0145, -5.0145, -5.0145, -5.0145,
           -5.0145, -5.0145, -5.0145, -5.0145, -5.0145, -5.0145, -5.0145,
           -5.0145],
          [-5.0145, -5.0145, -5.0145, -5.0145, -5.0145, -5.0145, -5.0145,
           -5.0145, -5.0145, -5.0145, -5.0145, -5.0145, -5.0145, -5.0145,
           -5.0145],
          [-5.0145, -5.0145, -5.0145, -5.0145, -5.0145, -5.0145, -5.0145,
           -5.0145, -5.0145, -5.0145, -5.0145, -5.0145, -5.0145, -5.0145,
           -5.0145],
          [-5.0145, -5.0145, -5.0145, -5.0145, -5.0145, -5.0145, -5.0145,
           -5.0145, -5.0145, -5.0145, -5.0145, -5.0145, -5.0145, -5.0145,
           -5.0145],
          [-5.0145, -5.0145, -5.0145, -5.0145, -5.0145, -5.0145, -5.0145,
           -5.0145, -5.0145, -5.0145, -5.0145, -5.0145, -5.0145, -5.0145,
           -5.0145]]]], grad_fn=<SliceBackward0>)
train_step: Entropy shape: torch.Size([16, 15])
train_step: Entropy sample: tensor([[0.4558, 0.4485],
        [0.2726, 0.3586]], grad_fn=<SliceBackward0>)
train_step: Entropy coefficient: 0.01
train_step: Actor loss: -1.3769447803497314
train_step: returns shape after mean: torch.Size([16, 15])
train_step: target_indices shape: torch.Size([16, 15])
train_step: value_logits shape: torch.Size([16, 15, 255])
train_step: target_twohot shape: torch.Size([16, 15, 255])
--- Starting train_step at 2025-04-01 01:53:22 ---
Full starting_state: {'deter': tensor([[[-0.0359, -0.0160, -0.0159,  ...,  0.0049, -0.0457,  0.0128],
         [-0.0753, -0.1063, -0.1394,  ..., -0.0795,  0.0500, -0.0225],
         [ 0.0504, -0.0399, -0.0387,  ..., -0.1872,  0.1491, -0.0970],
         ...,
         [-0.1079,  0.0611,  0.0924,  ..., -0.1385,  0.0674, -0.0677],
         [-0.1354, -0.1156,  0.0499,  ..., -0.0998, -0.0862,  0.0302],
         [ 0.0264,  0.0129, -0.2178,  ...,  0.0862, -0.0223,  0.0523]],

        [[ 0.1125,  0.0233, -0.0519,  ...,  0.1548,  0.0107,  0.1043],
         [-0.1070,  0.0338, -0.1491,  ...,  0.0344,  0.0880, -0.1317],
         [-0.0119,  0.0346, -0.0875,  ..., -0.0925, -0.0244, -0.0642],
         ...,
         [-0.0581, -0.0088, -0.1910,  ..., -0.0134, -0.0743, -0.0111],
         [-0.0039, -0.0580, -0.0771,  ..., -0.0371,  0.0305, -0.0206],
         [ 0.1899, -0.1236,  0.0616,  ...,  0.1765, -0.0087,  0.0767]],

        [[-0.0411, -0.0232, -0.0985,  ..., -0.0901,  0.0185,  0.0384],
         [-0.1042,  0.0357, -0.1287,  ..., -0.1161, -0.0871,  0.0408],
         [-0.1065,  0.0620, -0.0222,  ...,  0.0427, -0.0207,  0.0842],
         ...,
         [-0.2646,  0.1162,  0.0537,  ...,  0.0294,  0.1398,  0.1029],
         [ 0.0040, -0.0225,  0.0457,  ..., -0.0771,  0.0923,  0.0364],
         [-0.1306,  0.0068, -0.1749,  ...,  0.0162, -0.0814, -0.0317]],

        ...,

        [[ 0.0201, -0.0897,  0.0333,  ...,  0.0257,  0.0233, -0.0695],
         [-0.0807, -0.0444,  0.0502,  ...,  0.0104,  0.0474,  0.0340],
         [ 0.0446,  0.0179, -0.0152,  ..., -0.0965,  0.0233,  0.0556],
         ...,
         [ 0.0800,  0.1159, -0.1364,  ..., -0.0599, -0.0198,  0.0180],
         [-0.0041,  0.0660, -0.1207,  ..., -0.0538, -0.1256, -0.0418],
         [-0.1059,  0.1178, -0.2157,  ...,  0.1301,  0.1421, -0.0460]],

        [[-0.1095,  0.0679, -0.0864,  ...,  0.0145,  0.1083, -0.0107],
         [-0.1525,  0.0084, -0.0210,  ...,  0.1440,  0.1211, -0.1500],
         [ 0.1173, -0.0373, -0.1198,  ...,  0.0008,  0.0018, -0.0323],
         ...,
         [ 0.0878, -0.1196,  0.0389,  ..., -0.0938,  0.0821,  0.1236],
         [-0.1276,  0.0446,  0.0008,  ..., -0.0169,  0.0630,  0.0073],
         [-0.0758, -0.0235,  0.0156,  ...,  0.0051, -0.0245, -0.1003]],

        [[ 0.0131, -0.1085, -0.0343,  ..., -0.0147, -0.0081,  0.0156],
         [ 0.1703,  0.1536,  0.0584,  ...,  0.0527, -0.0145,  0.0150],
         [-0.1257, -0.1284,  0.0419,  ..., -0.1011, -0.0337, -0.1026],
         ...,
         [ 0.1043,  0.0614, -0.0076,  ...,  0.0009,  0.0020, -0.1471],
         [-0.0168,  0.1078, -0.0075,  ..., -0.0213, -0.1943, -0.0017],
         [ 0.0086, -0.0589, -0.1037,  ...,  0.0817,  0.0511, -0.0596]]],
       grad_fn=<StackBackward0>), 'stoch': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 1., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[1., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]])}
train_step: Starting state deter shape: torch.Size([16, 50, 128])
train_step: Starting state stoch shape: torch.Size([16, 50, 1024])
After ensuring logits/stoch: {'deter': tensor([[[-0.0359, -0.0160, -0.0159,  ...,  0.0049, -0.0457,  0.0128],
         [-0.0753, -0.1063, -0.1394,  ..., -0.0795,  0.0500, -0.0225],
         [ 0.0504, -0.0399, -0.0387,  ..., -0.1872,  0.1491, -0.0970],
         ...,
         [-0.1079,  0.0611,  0.0924,  ..., -0.1385,  0.0674, -0.0677],
         [-0.1354, -0.1156,  0.0499,  ..., -0.0998, -0.0862,  0.0302],
         [ 0.0264,  0.0129, -0.2178,  ...,  0.0862, -0.0223,  0.0523]],

        [[ 0.1125,  0.0233, -0.0519,  ...,  0.1548,  0.0107,  0.1043],
         [-0.1070,  0.0338, -0.1491,  ...,  0.0344,  0.0880, -0.1317],
         [-0.0119,  0.0346, -0.0875,  ..., -0.0925, -0.0244, -0.0642],
         ...,
         [-0.0581, -0.0088, -0.1910,  ..., -0.0134, -0.0743, -0.0111],
         [-0.0039, -0.0580, -0.0771,  ..., -0.0371,  0.0305, -0.0206],
         [ 0.1899, -0.1236,  0.0616,  ...,  0.1765, -0.0087,  0.0767]],

        [[-0.0411, -0.0232, -0.0985,  ..., -0.0901,  0.0185,  0.0384],
         [-0.1042,  0.0357, -0.1287,  ..., -0.1161, -0.0871,  0.0408],
         [-0.1065,  0.0620, -0.0222,  ...,  0.0427, -0.0207,  0.0842],
         ...,
         [-0.2646,  0.1162,  0.0537,  ...,  0.0294,  0.1398,  0.1029],
         [ 0.0040, -0.0225,  0.0457,  ..., -0.0771,  0.0923,  0.0364],
         [-0.1306,  0.0068, -0.1749,  ...,  0.0162, -0.0814, -0.0317]],

        ...,

        [[ 0.0201, -0.0897,  0.0333,  ...,  0.0257,  0.0233, -0.0695],
         [-0.0807, -0.0444,  0.0502,  ...,  0.0104,  0.0474,  0.0340],
         [ 0.0446,  0.0179, -0.0152,  ..., -0.0965,  0.0233,  0.0556],
         ...,
         [ 0.0800,  0.1159, -0.1364,  ..., -0.0599, -0.0198,  0.0180],
         [-0.0041,  0.0660, -0.1207,  ..., -0.0538, -0.1256, -0.0418],
         [-0.1059,  0.1178, -0.2157,  ...,  0.1301,  0.1421, -0.0460]],

        [[-0.1095,  0.0679, -0.0864,  ...,  0.0145,  0.1083, -0.0107],
         [-0.1525,  0.0084, -0.0210,  ...,  0.1440,  0.1211, -0.1500],
         [ 0.1173, -0.0373, -0.1198,  ...,  0.0008,  0.0018, -0.0323],
         ...,
         [ 0.0878, -0.1196,  0.0389,  ..., -0.0938,  0.0821,  0.1236],
         [-0.1276,  0.0446,  0.0008,  ..., -0.0169,  0.0630,  0.0073],
         [-0.0758, -0.0235,  0.0156,  ...,  0.0051, -0.0245, -0.1003]],

        [[ 0.0131, -0.1085, -0.0343,  ..., -0.0147, -0.0081,  0.0156],
         [ 0.1703,  0.1536,  0.0584,  ...,  0.0527, -0.0145,  0.0150],
         [-0.1257, -0.1284,  0.0419,  ..., -0.1011, -0.0337, -0.1026],
         ...,
         [ 0.1043,  0.0614, -0.0076,  ...,  0.0009,  0.0020, -0.1471],
         [-0.0168,  0.1078, -0.0075,  ..., -0.0213, -0.1943, -0.0017],
         [ 0.0086, -0.0589, -0.1037,  ...,  0.0817,  0.0511, -0.0596]]],
       grad_fn=<StackBackward0>), 'stoch': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 1., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[1., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]]), 'logits': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]])}
train_step: Normalized hidden_state shape: torch.Size([1, 16, 128])
train_step: Normalized stoch shape: torch.Size([16, 1024])
train_step: Normalized deter shape: torch.Size([16, 128])
train_step: Post-imagine_trajectory: Imagined features shape: torch.Size([16, 15, 1152])
train_step: Post-imagine_trajectory: Imagined actions shape: torch.Size([16, 15, 2])
train_step: Post-imagine_trajectory: Imagined action indices shape: torch.Size([16, 15])
train_step: Post-imagine_trajectory: Imagined state deter shape: torch.Size([16, 15, 128])
train_step: Post-imagine_trajectory: Imagined state stoch shape: torch.Size([16, 15, 1024])
Reward shape: torch.Size([16, 15, 1]), Value shape: torch.Size([16, 15, 1]), Slow Value shape: torch.Size([16, 15, 1]), Discount shape: torch.Size([16, 15, 1, 1])
Return targets length: 15, First target shape: torch.Size([16, 16, 1])
train_step: Actor distribution shape: torch.Size([16, 15, 2])
train_step: Action log probabilities shape: torch.Size([16, 15])
train_step: Action log probabilities sample: tensor([[-0.1358, -1.0740],
        [-1.2315, -0.2844]], grad_fn=<SliceBackward0>)
train_step: Advantages shape: torch.Size([16, 15, 16, 15])
train_step: Advantages sample: tensor([[[[-4.9176, -4.9176, -4.9177, -4.9176, -4.9176, -4.9176, -4.9176,
           -4.9177, -4.9176, -4.9176, -4.9176, -4.9176, -4.9176, -4.9176,
           -4.9177],
          [-4.9176, -4.9176, -4.9177, -4.9176, -4.9176, -4.9176, -4.9176,
           -4.9177, -4.9176, -4.9176, -4.9176, -4.9176, -4.9176, -4.9176,
           -4.9177],
          [-3.3532, -3.3532, -3.3532, -3.3532, -3.3532, -3.3532, -3.3532,
           -3.3532, -3.3532, -3.3532, -3.3532, -3.3532, -3.3532, -3.3532,
           -3.3532],
          [-0.4332, -0.4332, -0.4332, -0.4332, -0.4332, -0.4332, -0.4332,
           -0.4332, -0.4332, -0.4332, -0.4332, -0.4332, -0.4332, -0.4332,
           -0.4332],
          [-1.7066, -1.7065, -1.7066, -1.7066, -1.7065, -1.7066, -1.7066,
           -1.7066, -1.7065, -1.7066, -1.7066, -1.7065, -1.7065, -1.7066,
           -1.7066],
          [-0.4332, -0.4332, -0.4332, -0.4332, -0.4332, -0.4332, -0.4332,
           -0.4332, -0.4332, -0.4332, -0.4332, -0.4332, -0.4332, -0.4332,
           -0.4332],
          [-4.9176, -4.9176, -4.9177, -4.9176, -4.9176, -4.9176, -4.9176,
           -4.9177, -4.9176, -4.9176, -4.9176, -4.9176, -4.9176, -4.9176,
           -4.9177],
          [-4.9176, -4.9176, -4.9177, -4.9176, -4.9176, -4.9176, -4.9176,
           -4.9177, -4.9176, -4.9176, -4.9176, -4.9176, -4.9176, -4.9176,
           -4.9177],
          [-4.9176, -4.9176, -4.9177, -4.9176, -4.9176, -4.9176, -4.9176,
           -4.9177, -4.9176, -4.9176, -4.9176, -4.9176, -4.9176, -4.9176,
           -4.9177],
          [-4.9176, -4.9176, -4.9177, -4.9176, -4.9176, -4.9176, -4.9176,
           -4.9177, -4.9176, -4.9176, -4.9176, -4.9176, -4.9176, -4.9176,
           -4.9177],
          [-4.9176, -4.9176, -4.9177, -4.9176, -4.9176, -4.9176, -4.9176,
           -4.9177, -4.9176, -4.9176, -4.9176, -4.9176, -4.9176, -4.9176,
           -4.9177],
          [-1.3062, -1.3062, -1.3062, -1.3062, -1.3062, -1.3062, -1.3062,
           -1.3062, -1.3062, -1.3062, -1.3062, -1.3062, -1.3062, -1.3062,
           -1.3062],
          [-1.9606, -1.9606, -1.9606, -1.9606, -1.9606, -1.9606, -1.9606,
           -1.9606, -1.9606, -1.9606, -1.9606, -1.9606, -1.9606, -1.9606,
           -1.9606],
          [-4.9176, -4.9176, -4.9177, -4.9176, -4.9176, -4.9176, -4.9176,
           -4.9177, -4.9176, -4.9176, -4.9176, -4.9176, -4.9176, -4.9176,
           -4.9177],
          [-4.9176, -4.9176, -4.9177, -4.9176, -4.9176, -4.9176, -4.9176,
           -4.9177, -4.9176, -4.9176, -4.9176, -4.9176, -4.9176, -4.9176,
           -4.9177],
          [-4.9176, -4.9176, -4.9177, -4.9176, -4.9176, -4.9176, -4.9176,
           -4.9177, -4.9176, -4.9176, -4.9176, -4.9176, -4.9176, -4.9176,
           -4.9177]],

         [[-4.7345, -4.7345, -4.7345, -4.7345, -4.7345, -4.7345, -4.7345,
           -4.7345, -4.7345, -4.7345, -4.7345, -4.7345, -4.7345, -4.7345,
           -4.7345],
          [-4.7345, -4.7345, -4.7345, -4.7345, -4.7345, -4.7345, -4.7345,
           -4.7345, -4.7345, -4.7345, -4.7345, -4.7345, -4.7345, -4.7345,
           -4.7345],
          [-3.0828, -3.0828, -3.0827, -3.0828, -3.0828, -3.0827, -3.0828,
           -3.0828, -3.0828, -3.0828, -3.0828, -3.0828, -3.0827, -3.0827,
           -3.0828],
          [-4.7345, -4.7345, -4.7345, -4.7345, -4.7345, -4.7345, -4.7345,
           -4.7345, -4.7345, -4.7345, -4.7345, -4.7345, -4.7345, -4.7345,
           -4.7345],
          [-1.3442, -1.3442, -1.3442, -1.3442, -1.3442, -1.3442, -1.3442,
           -1.3442, -1.3442, -1.3442, -1.3442, -1.3442, -1.3442, -1.3442,
           -1.3442],
          [-4.7345, -4.7345, -4.7345, -4.7345, -4.7345, -4.7345, -4.7345,
           -4.7345, -4.7345, -4.7345, -4.7345, -4.7345, -4.7345, -4.7345,
           -4.7345],
          [-4.7345, -4.7345, -4.7345, -4.7345, -4.7345, -4.7345, -4.7345,
           -4.7345, -4.7345, -4.7345, -4.7345, -4.7345, -4.7345, -4.7345,
           -4.7345],
          [-4.7345, -4.7345, -4.7345, -4.7345, -4.7345, -4.7345, -4.7345,
           -4.7345, -4.7345, -4.7345, -4.7345, -4.7345, -4.7345, -4.7345,
           -4.7345],
          [-4.7345, -4.7345, -4.7345, -4.7345, -4.7345, -4.7345, -4.7345,
           -4.7345, -4.7345, -4.7345, -4.7345, -4.7345, -4.7345, -4.7345,
           -4.7345],
          [-4.7345, -4.7345, -4.7345, -4.7345, -4.7345, -4.7345, -4.7345,
           -4.7345, -4.7345, -4.7345, -4.7345, -4.7345, -4.7345, -4.7345,
           -4.7345],
          [-4.7345, -4.7345, -4.7345, -4.7345, -4.7345, -4.7345, -4.7345,
           -4.7345, -4.7345, -4.7345, -4.7345, -4.7345, -4.7345, -4.7345,
           -4.7345],
          [-0.9215, -0.9215, -0.9215, -0.9215, -0.9215, -0.9215, -0.9215,
           -0.9215, -0.9215, -0.9215, -0.9215, -0.9215, -0.9215, -0.9215,
           -0.9215],
          [-1.6125, -1.6124, -1.6124, -1.6125, -1.6125, -1.6124, -1.6125,
           -1.6125, -1.6125, -1.6124, -1.6125, -1.6125, -1.6124, -1.6124,
           -1.6125],
          [-4.7345, -4.7345, -4.7345, -4.7345, -4.7345, -4.7345, -4.7345,
           -4.7345, -4.7345, -4.7345, -4.7345, -4.7345, -4.7345, -4.7345,
           -4.7345],
          [-4.7345, -4.7345, -4.7345, -4.7345, -4.7345, -4.7345, -4.7345,
           -4.7345, -4.7345, -4.7345, -4.7345, -4.7345, -4.7345, -4.7345,
           -4.7345],
          [-4.7345, -4.7345, -4.7345, -4.7345, -4.7345, -4.7345, -4.7345,
           -4.7345, -4.7345, -4.7345, -4.7345, -4.7345, -4.7345, -4.7345,
           -4.7345]]],


        [[[-7.0989, -7.0989, -7.0989, -7.0989, -7.0989, -7.0989, -7.0989,
           -7.0989, -7.0989, -7.0989, -7.0989, -7.0989, -7.0989, -7.0989,
           -7.0989],
          [-7.0989, -7.0989, -7.0989, -7.0989, -7.0989, -7.0989, -7.0989,
           -7.0989, -7.0989, -7.0989, -7.0989, -7.0989, -7.0989, -7.0989,
           -7.0989],
          [-3.4794, -3.4794, -3.4794, -3.4794, -3.4794, -3.4794, -3.4794,
           -3.4794, -3.4794, -3.4794, -3.4794, -3.4793, -3.4793, -3.4794,
           -3.4794],
          [-0.4531, -0.4531, -0.4531, -0.4531, -0.4531, -0.4531, -0.4531,
           -0.4531, -0.4531, -0.4531, -0.4531, -0.4531, -0.4531, -0.4531,
           -0.4531],
          [-1.1516, -1.1516, -1.1516, -1.1516, -1.1516, -1.1516, -1.1516,
           -1.1516, -1.1516, -1.1516, -1.1516, -1.1516, -1.1516, -1.1516,
           -1.1516],
          [-0.4531, -0.4531, -0.4531, -0.4531, -0.4531, -0.4531, -0.4531,
           -0.4531, -0.4531, -0.4531, -0.4531, -0.4531, -0.4531, -0.4531,
           -0.4531],
          [-7.0989, -7.0989, -7.0989, -7.0989, -7.0989, -7.0989, -7.0989,
           -7.0989, -7.0989, -7.0989, -7.0989, -7.0989, -7.0989, -7.0989,
           -7.0989],
          [-7.0989, -7.0989, -7.0989, -7.0989, -7.0989, -7.0989, -7.0989,
           -7.0989, -7.0989, -7.0989, -7.0989, -7.0989, -7.0989, -7.0989,
           -7.0989],
          [-7.0989, -7.0989, -7.0989, -7.0989, -7.0989, -7.0989, -7.0989,
           -7.0989, -7.0989, -7.0989, -7.0989, -7.0989, -7.0989, -7.0989,
           -7.0989],
          [-7.0989, -7.0989, -7.0989, -7.0989, -7.0989, -7.0989, -7.0989,
           -7.0989, -7.0989, -7.0989, -7.0989, -7.0989, -7.0989, -7.0989,
           -7.0989],
          [-7.0989, -7.0989, -7.0989, -7.0989, -7.0989, -7.0989, -7.0989,
           -7.0989, -7.0989, -7.0989, -7.0989, -7.0989, -7.0989, -7.0989,
           -7.0989],
          [-0.4381, -0.4381, -0.4381, -0.4381, -0.4381, -0.4381, -0.4381,
           -0.4381, -0.4381, -0.4381, -0.4381, -0.4381, -0.4381, -0.4381,
           -0.4382],
          [-1.8262, -1.8262, -1.8262, -1.8262, -1.8262, -1.8262, -1.8262,
           -1.8262, -1.8262, -1.8262, -1.8262, -1.8262, -1.8262, -1.8262,
           -1.8262],
          [-7.0989, -7.0989, -7.0989, -7.0989, -7.0989, -7.0989, -7.0989,
           -7.0989, -7.0989, -7.0989, -7.0989, -7.0989, -7.0989, -7.0989,
           -7.0989],
          [-7.0989, -7.0989, -7.0989, -7.0989, -7.0989, -7.0989, -7.0989,
           -7.0989, -7.0989, -7.0989, -7.0989, -7.0989, -7.0989, -7.0989,
           -7.0989],
          [-7.0989, -7.0989, -7.0989, -7.0989, -7.0989, -7.0989, -7.0989,
           -7.0989, -7.0989, -7.0989, -7.0989, -7.0989, -7.0989, -7.0989,
           -7.0989]],

         [[-7.0165, -7.0165, -7.0164, -7.0165, -7.0165, -7.0165, -7.0165,
           -7.0165, -7.0165, -7.0165, -7.0165, -7.0165, -7.0165, -7.0164,
           -7.0165],
          [-7.0165, -7.0165, -7.0164, -7.0165, -7.0165, -7.0165, -7.0165,
           -7.0165, -7.0165, -7.0165, -7.0165, -7.0165, -7.0165, -7.0164,
           -7.0165],
          [-3.1950, -3.1950, -3.1949, -3.1950, -3.1950, -3.1950, -3.1950,
           -3.1950, -3.1950, -3.1950, -3.1950, -3.1950, -3.1950, -3.1949,
           -3.1950],
          [-7.0165, -7.0165, -7.0164, -7.0165, -7.0165, -7.0165, -7.0165,
           -7.0165, -7.0165, -7.0165, -7.0165, -7.0165, -7.0165, -7.0164,
           -7.0165],
          [-0.7374, -0.7373, -0.7373, -0.7373, -0.7373, -0.7373, -0.7373,
           -0.7373, -0.7373, -0.7373, -0.7373, -0.7373, -0.7373, -0.7373,
           -0.7373],
          [-7.0165, -7.0165, -7.0164, -7.0165, -7.0165, -7.0165, -7.0165,
           -7.0165, -7.0165, -7.0165, -7.0165, -7.0165, -7.0165, -7.0164,
           -7.0165],
          [-7.0165, -7.0165, -7.0164, -7.0165, -7.0165, -7.0165, -7.0165,
           -7.0165, -7.0165, -7.0165, -7.0165, -7.0165, -7.0165, -7.0164,
           -7.0165],
          [-7.0165, -7.0165, -7.0164, -7.0165, -7.0165, -7.0165, -7.0165,
           -7.0165, -7.0165, -7.0165, -7.0165, -7.0165, -7.0165, -7.0164,
           -7.0165],
          [-7.0165, -7.0165, -7.0164, -7.0165, -7.0165, -7.0165, -7.0165,
           -7.0165, -7.0165, -7.0165, -7.0165, -7.0165, -7.0165, -7.0164,
           -7.0165],
          [-7.0165, -7.0165, -7.0164, -7.0165, -7.0165, -7.0165, -7.0165,
           -7.0165, -7.0165, -7.0165, -7.0165, -7.0165, -7.0165, -7.0164,
           -7.0165],
          [-7.0165, -7.0165, -7.0164, -7.0165, -7.0165, -7.0165, -7.0165,
           -7.0165, -7.0165, -7.0165, -7.0165, -7.0165, -7.0165, -7.0164,
           -7.0165],
          [ 0.0159,  0.0160,  0.0160,  0.0159,  0.0160,  0.0160,  0.0160,
            0.0160,  0.0160,  0.0160,  0.0159,  0.0159,  0.0160,  0.0160,
            0.0159],
          [-1.4496, -1.4496, -1.4496, -1.4496, -1.4496, -1.4496, -1.4496,
           -1.4496, -1.4496, -1.4496, -1.4496, -1.4496, -1.4496, -1.4496,
           -1.4496],
          [-7.0165, -7.0165, -7.0164, -7.0165, -7.0165, -7.0165, -7.0165,
           -7.0165, -7.0165, -7.0165, -7.0165, -7.0165, -7.0165, -7.0164,
           -7.0165],
          [-7.0165, -7.0165, -7.0164, -7.0165, -7.0165, -7.0165, -7.0165,
           -7.0165, -7.0165, -7.0165, -7.0165, -7.0165, -7.0165, -7.0164,
           -7.0165],
          [-7.0165, -7.0165, -7.0164, -7.0165, -7.0165, -7.0165, -7.0165,
           -7.0165, -7.0165, -7.0165, -7.0165, -7.0165, -7.0165, -7.0164,
           -7.0165]]]], grad_fn=<SliceBackward0>)
train_step: Return scale: 1.6113063667995438
train_step: Scaled advantages shape: torch.Size([16, 15, 16, 15])
train_step: Scaled advantages sample: tensor([[[[-3.0520, -3.0520, -3.0520, -3.0520, -3.0520, -3.0520, -3.0520,
           -3.0520, -3.0520, -3.0520, -3.0520, -3.0519, -3.0520, -3.0520,
           -3.0520],
          [-3.0520, -3.0520, -3.0520, -3.0520, -3.0520, -3.0520, -3.0520,
           -3.0520, -3.0520, -3.0520, -3.0520, -3.0519, -3.0520, -3.0520,
           -3.0520],
          [-2.0811, -2.0810, -2.0811, -2.0811, -2.0810, -2.0811, -2.0811,
           -2.0811, -2.0810, -2.0811, -2.0811, -2.0810, -2.0810, -2.0811,
           -2.0811],
          [-0.4332, -0.4332, -0.4332, -0.4332, -0.4332, -0.4332, -0.4332,
           -0.4332, -0.4332, -0.4332, -0.4332, -0.4332, -0.4332, -0.4332,
           -0.4332],
          [-1.0591, -1.0591, -1.0591, -1.0591, -1.0591, -1.0591, -1.0591,
           -1.0591, -1.0591, -1.0591, -1.0591, -1.0591, -1.0591, -1.0591,
           -1.0591],
          [-0.4332, -0.4332, -0.4332, -0.4332, -0.4332, -0.4332, -0.4332,
           -0.4332, -0.4332, -0.4332, -0.4332, -0.4332, -0.4332, -0.4332,
           -0.4332],
          [-3.0520, -3.0520, -3.0520, -3.0520, -3.0520, -3.0520, -3.0520,
           -3.0520, -3.0520, -3.0520, -3.0520, -3.0519, -3.0520, -3.0520,
           -3.0520],
          [-3.0520, -3.0520, -3.0520, -3.0520, -3.0520, -3.0520, -3.0520,
           -3.0520, -3.0520, -3.0520, -3.0520, -3.0519, -3.0520, -3.0520,
           -3.0520],
          [-3.0520, -3.0520, -3.0520, -3.0520, -3.0520, -3.0520, -3.0520,
           -3.0520, -3.0520, -3.0520, -3.0520, -3.0519, -3.0520, -3.0520,
           -3.0520],
          [-3.0520, -3.0520, -3.0520, -3.0520, -3.0520, -3.0520, -3.0520,
           -3.0520, -3.0520, -3.0520, -3.0520, -3.0519, -3.0520, -3.0520,
           -3.0520],
          [-3.0520, -3.0520, -3.0520, -3.0520, -3.0520, -3.0520, -3.0520,
           -3.0520, -3.0520, -3.0520, -3.0520, -3.0519, -3.0520, -3.0520,
           -3.0520],
          [-0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106,
           -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106,
           -0.8106],
          [-1.2168, -1.2168, -1.2168, -1.2168, -1.2168, -1.2168, -1.2168,
           -1.2168, -1.2168, -1.2168, -1.2168, -1.2168, -1.2168, -1.2168,
           -1.2168],
          [-3.0520, -3.0520, -3.0520, -3.0520, -3.0520, -3.0520, -3.0520,
           -3.0520, -3.0520, -3.0520, -3.0520, -3.0519, -3.0520, -3.0520,
           -3.0520],
          [-3.0520, -3.0520, -3.0520, -3.0520, -3.0520, -3.0520, -3.0520,
           -3.0520, -3.0520, -3.0520, -3.0520, -3.0519, -3.0520, -3.0520,
           -3.0520],
          [-3.0520, -3.0520, -3.0520, -3.0520, -3.0520, -3.0520, -3.0520,
           -3.0520, -3.0520, -3.0520, -3.0520, -3.0519, -3.0520, -3.0520,
           -3.0520]],

         [[-2.9383, -2.9383, -2.9383, -2.9383, -2.9383, -2.9383, -2.9383,
           -2.9383, -2.9383, -2.9383, -2.9383, -2.9383, -2.9383, -2.9383,
           -2.9383],
          [-2.9383, -2.9383, -2.9383, -2.9383, -2.9383, -2.9383, -2.9383,
           -2.9383, -2.9383, -2.9383, -2.9383, -2.9383, -2.9383, -2.9383,
           -2.9383],
          [-1.9132, -1.9132, -1.9132, -1.9132, -1.9132, -1.9132, -1.9132,
           -1.9132, -1.9132, -1.9132, -1.9132, -1.9132, -1.9132, -1.9132,
           -1.9132],
          [-2.9383, -2.9383, -2.9383, -2.9383, -2.9383, -2.9383, -2.9383,
           -2.9383, -2.9383, -2.9383, -2.9383, -2.9383, -2.9383, -2.9383,
           -2.9383],
          [-0.8343, -0.8342, -0.8342, -0.8342, -0.8342, -0.8342, -0.8342,
           -0.8342, -0.8342, -0.8342, -0.8342, -0.8342, -0.8342, -0.8342,
           -0.8342],
          [-2.9383, -2.9383, -2.9383, -2.9383, -2.9383, -2.9383, -2.9383,
           -2.9383, -2.9383, -2.9383, -2.9383, -2.9383, -2.9383, -2.9383,
           -2.9383],
          [-2.9383, -2.9383, -2.9383, -2.9383, -2.9383, -2.9383, -2.9383,
           -2.9383, -2.9383, -2.9383, -2.9383, -2.9383, -2.9383, -2.9383,
           -2.9383],
          [-2.9383, -2.9383, -2.9383, -2.9383, -2.9383, -2.9383, -2.9383,
           -2.9383, -2.9383, -2.9383, -2.9383, -2.9383, -2.9383, -2.9383,
           -2.9383],
          [-2.9383, -2.9383, -2.9383, -2.9383, -2.9383, -2.9383, -2.9383,
           -2.9383, -2.9383, -2.9383, -2.9383, -2.9383, -2.9383, -2.9383,
           -2.9383],
          [-2.9383, -2.9383, -2.9383, -2.9383, -2.9383, -2.9383, -2.9383,
           -2.9383, -2.9383, -2.9383, -2.9383, -2.9383, -2.9383, -2.9383,
           -2.9383],
          [-2.9383, -2.9383, -2.9383, -2.9383, -2.9383, -2.9383, -2.9383,
           -2.9383, -2.9383, -2.9383, -2.9383, -2.9383, -2.9383, -2.9383,
           -2.9383],
          [-0.9215, -0.9215, -0.9215, -0.9215, -0.9215, -0.9215, -0.9215,
           -0.9215, -0.9215, -0.9215, -0.9215, -0.9215, -0.9215, -0.9215,
           -0.9215],
          [-1.0007, -1.0007, -1.0007, -1.0007, -1.0007, -1.0007, -1.0007,
           -1.0007, -1.0007, -1.0007, -1.0007, -1.0007, -1.0007, -1.0007,
           -1.0007],
          [-2.9383, -2.9383, -2.9383, -2.9383, -2.9383, -2.9383, -2.9383,
           -2.9383, -2.9383, -2.9383, -2.9383, -2.9383, -2.9383, -2.9383,
           -2.9383],
          [-2.9383, -2.9383, -2.9383, -2.9383, -2.9383, -2.9383, -2.9383,
           -2.9383, -2.9383, -2.9383, -2.9383, -2.9383, -2.9383, -2.9383,
           -2.9383],
          [-2.9383, -2.9383, -2.9383, -2.9383, -2.9383, -2.9383, -2.9383,
           -2.9383, -2.9383, -2.9383, -2.9383, -2.9383, -2.9383, -2.9383,
           -2.9383]]],


        [[[-4.4057, -4.4057, -4.4057, -4.4057, -4.4057, -4.4057, -4.4057,
           -4.4057, -4.4057, -4.4057, -4.4057, -4.4057, -4.4057, -4.4057,
           -4.4057],
          [-4.4057, -4.4057, -4.4057, -4.4057, -4.4057, -4.4057, -4.4057,
           -4.4057, -4.4057, -4.4057, -4.4057, -4.4057, -4.4057, -4.4057,
           -4.4057],
          [-2.1593, -2.1593, -2.1594, -2.1593, -2.1593, -2.1593, -2.1593,
           -2.1594, -2.1593, -2.1593, -2.1593, -2.1593, -2.1593, -2.1593,
           -2.1594],
          [-0.4531, -0.4531, -0.4531, -0.4531, -0.4531, -0.4531, -0.4531,
           -0.4531, -0.4531, -0.4531, -0.4531, -0.4531, -0.4531, -0.4531,
           -0.4531],
          [-0.7147, -0.7147, -0.7147, -0.7147, -0.7147, -0.7147, -0.7147,
           -0.7147, -0.7147, -0.7147, -0.7147, -0.7147, -0.7147, -0.7147,
           -0.7147],
          [-0.4531, -0.4531, -0.4531, -0.4531, -0.4531, -0.4531, -0.4531,
           -0.4531, -0.4531, -0.4531, -0.4531, -0.4531, -0.4531, -0.4531,
           -0.4531],
          [-4.4057, -4.4057, -4.4057, -4.4057, -4.4057, -4.4057, -4.4057,
           -4.4057, -4.4057, -4.4057, -4.4057, -4.4057, -4.4057, -4.4057,
           -4.4057],
          [-4.4057, -4.4057, -4.4057, -4.4057, -4.4057, -4.4057, -4.4057,
           -4.4057, -4.4057, -4.4057, -4.4057, -4.4057, -4.4057, -4.4057,
           -4.4057],
          [-4.4057, -4.4057, -4.4057, -4.4057, -4.4057, -4.4057, -4.4057,
           -4.4057, -4.4057, -4.4057, -4.4057, -4.4057, -4.4057, -4.4057,
           -4.4057],
          [-4.4057, -4.4057, -4.4057, -4.4057, -4.4057, -4.4057, -4.4057,
           -4.4057, -4.4057, -4.4057, -4.4057, -4.4057, -4.4057, -4.4057,
           -4.4057],
          [-4.4057, -4.4057, -4.4057, -4.4057, -4.4057, -4.4057, -4.4057,
           -4.4057, -4.4057, -4.4057, -4.4057, -4.4057, -4.4057, -4.4057,
           -4.4057],
          [-0.4381, -0.4381, -0.4381, -0.4381, -0.4381, -0.4381, -0.4381,
           -0.4381, -0.4381, -0.4381, -0.4381, -0.4381, -0.4381, -0.4381,
           -0.4382],
          [-1.1334, -1.1334, -1.1334, -1.1334, -1.1334, -1.1334, -1.1334,
           -1.1334, -1.1334, -1.1334, -1.1334, -1.1334, -1.1334, -1.1334,
           -1.1334],
          [-4.4057, -4.4057, -4.4057, -4.4057, -4.4057, -4.4057, -4.4057,
           -4.4057, -4.4057, -4.4057, -4.4057, -4.4057, -4.4057, -4.4057,
           -4.4057],
          [-4.4057, -4.4057, -4.4057, -4.4057, -4.4057, -4.4057, -4.4057,
           -4.4057, -4.4057, -4.4057, -4.4057, -4.4057, -4.4057, -4.4057,
           -4.4057],
          [-4.4057, -4.4057, -4.4057, -4.4057, -4.4057, -4.4057, -4.4057,
           -4.4057, -4.4057, -4.4057, -4.4057, -4.4057, -4.4057, -4.4057,
           -4.4057]],

         [[-4.3545, -4.3545, -4.3545, -4.3545, -4.3545, -4.3545, -4.3545,
           -4.3545, -4.3545, -4.3545, -4.3545, -4.3545, -4.3545, -4.3545,
           -4.3545],
          [-4.3545, -4.3545, -4.3545, -4.3545, -4.3545, -4.3545, -4.3545,
           -4.3545, -4.3545, -4.3545, -4.3545, -4.3545, -4.3545, -4.3545,
           -4.3545],
          [-1.9829, -1.9828, -1.9828, -1.9829, -1.9828, -1.9828, -1.9828,
           -1.9828, -1.9828, -1.9828, -1.9829, -1.9829, -1.9828, -1.9828,
           -1.9829],
          [-4.3545, -4.3545, -4.3545, -4.3545, -4.3545, -4.3545, -4.3545,
           -4.3545, -4.3545, -4.3545, -4.3545, -4.3545, -4.3545, -4.3545,
           -4.3545],
          [-0.7374, -0.7373, -0.7373, -0.7373, -0.7373, -0.7373, -0.7373,
           -0.7373, -0.7373, -0.7373, -0.7373, -0.7373, -0.7373, -0.7373,
           -0.7373],
          [-4.3545, -4.3545, -4.3545, -4.3545, -4.3545, -4.3545, -4.3545,
           -4.3545, -4.3545, -4.3545, -4.3545, -4.3545, -4.3545, -4.3545,
           -4.3545],
          [-4.3545, -4.3545, -4.3545, -4.3545, -4.3545, -4.3545, -4.3545,
           -4.3545, -4.3545, -4.3545, -4.3545, -4.3545, -4.3545, -4.3545,
           -4.3545],
          [-4.3545, -4.3545, -4.3545, -4.3545, -4.3545, -4.3545, -4.3545,
           -4.3545, -4.3545, -4.3545, -4.3545, -4.3545, -4.3545, -4.3545,
           -4.3545],
          [-4.3545, -4.3545, -4.3545, -4.3545, -4.3545, -4.3545, -4.3545,
           -4.3545, -4.3545, -4.3545, -4.3545, -4.3545, -4.3545, -4.3545,
           -4.3545],
          [-4.3545, -4.3545, -4.3545, -4.3545, -4.3545, -4.3545, -4.3545,
           -4.3545, -4.3545, -4.3545, -4.3545, -4.3545, -4.3545, -4.3545,
           -4.3545],
          [-4.3545, -4.3545, -4.3545, -4.3545, -4.3545, -4.3545, -4.3545,
           -4.3545, -4.3545, -4.3545, -4.3545, -4.3545, -4.3545, -4.3545,
           -4.3545],
          [ 0.0159,  0.0160,  0.0160,  0.0159,  0.0160,  0.0160,  0.0160,
            0.0160,  0.0160,  0.0160,  0.0159,  0.0159,  0.0160,  0.0160,
            0.0159],
          [-0.8997, -0.8996, -0.8996, -0.8996, -0.8996, -0.8996, -0.8996,
           -0.8996, -0.8996, -0.8996, -0.8996, -0.8996, -0.8996, -0.8996,
           -0.8996],
          [-4.3545, -4.3545, -4.3545, -4.3545, -4.3545, -4.3545, -4.3545,
           -4.3545, -4.3545, -4.3545, -4.3545, -4.3545, -4.3545, -4.3545,
           -4.3545],
          [-4.3545, -4.3545, -4.3545, -4.3545, -4.3545, -4.3545, -4.3545,
           -4.3545, -4.3545, -4.3545, -4.3545, -4.3545, -4.3545, -4.3545,
           -4.3545],
          [-4.3545, -4.3545, -4.3545, -4.3545, -4.3545, -4.3545, -4.3545,
           -4.3545, -4.3545, -4.3545, -4.3545, -4.3545, -4.3545, -4.3545,
           -4.3545]]]], grad_fn=<SliceBackward0>)
train_step: Entropy shape: torch.Size([16, 15])
train_step: Entropy sample: tensor([[0.3807, 0.6421],
        [0.6038, 0.5596]], grad_fn=<SliceBackward0>)
train_step: Entropy coefficient: 0.01
train_step: Actor loss: -1.3636630773544312
train_step: returns shape after mean: torch.Size([16, 15])
train_step: target_indices shape: torch.Size([16, 15])
train_step: value_logits shape: torch.Size([16, 15, 255])
train_step: target_twohot shape: torch.Size([16, 15, 255])
--- Starting train_step at 2025-04-01 01:53:37 ---
Full starting_state: {'deter': tensor([[[ 0.0144, -0.0839,  0.0510,  ...,  0.0099,  0.0711,  0.0660],
         [ 0.0725, -0.0309, -0.1301,  ...,  0.0689, -0.1268, -0.0303],
         [-0.0636, -0.0694, -0.0193,  ...,  0.1374,  0.0637,  0.0821],
         ...,
         [-0.2440, -0.0326,  0.0157,  ..., -0.0807,  0.0125, -0.1117],
         [-0.1327,  0.0267, -0.0797,  ...,  0.0261,  0.2460,  0.0029],
         [-0.0019,  0.0487, -0.0320,  ...,  0.0911,  0.1128, -0.0656]],

        [[-0.0479,  0.0153, -0.0595,  ...,  0.1126,  0.0709, -0.1588],
         [ 0.0819, -0.0641, -0.0542,  ..., -0.0909,  0.1341,  0.0031],
         [-0.0298, -0.0747,  0.0685,  ..., -0.0467,  0.0784, -0.0864],
         ...,
         [-0.0182,  0.0092,  0.0094,  ...,  0.0312,  0.1638, -0.1460],
         [-0.0046, -0.0538, -0.0794,  ...,  0.1671, -0.1150, -0.1300],
         [-0.1703, -0.0325, -0.0059,  ...,  0.0532,  0.0906,  0.0431]],

        [[-0.0625,  0.0042,  0.0584,  ...,  0.0609,  0.0423, -0.0361],
         [-0.1316,  0.1499, -0.0434,  ..., -0.0385,  0.0120, -0.0513],
         [ 0.0885,  0.1533, -0.0862,  ...,  0.2331,  0.0960,  0.0191],
         ...,
         [-0.0474, -0.0277,  0.0590,  ..., -0.1218,  0.1475,  0.0215],
         [ 0.0407,  0.0255, -0.0125,  ...,  0.0733,  0.1416, -0.0540],
         [ 0.0928,  0.0666, -0.0162,  ...,  0.0497,  0.0895,  0.0573]],

        ...,

        [[ 0.1199, -0.0359, -0.0667,  ..., -0.2532, -0.1040,  0.0370],
         [ 0.0356, -0.0780,  0.1368,  ...,  0.0383, -0.0445, -0.0357],
         [ 0.0607,  0.0278, -0.0057,  ..., -0.0067,  0.0261, -0.0030],
         ...,
         [-0.0900, -0.0559, -0.1343,  ..., -0.0597,  0.0209,  0.0231],
         [-0.1063,  0.0110, -0.0705,  ...,  0.1001,  0.0026,  0.0446],
         [-0.0160,  0.1083, -0.0756,  ...,  0.0644, -0.0661, -0.0696]],

        [[-0.1425,  0.0274, -0.0679,  ..., -0.0033, -0.0495,  0.0744],
         [-0.1271,  0.0790, -0.1637,  ...,  0.1831,  0.0528,  0.0297],
         [-0.1377, -0.1899, -0.1164,  ...,  0.0739,  0.1129, -0.0079],
         ...,
         [-0.1385, -0.1495,  0.0307,  ..., -0.0919,  0.0521, -0.1446],
         [-0.0556,  0.0479, -0.0866,  ...,  0.0850, -0.0965, -0.0204],
         [-0.0927,  0.1609, -0.1044,  ...,  0.2064,  0.1234, -0.1372]],

        [[-0.0313,  0.0747, -0.0285,  ..., -0.0091, -0.0199,  0.0321],
         [-0.0423,  0.0354, -0.1188,  ...,  0.1439, -0.1905,  0.0094],
         [-0.1009,  0.1022, -0.0499,  ..., -0.0261,  0.1172,  0.0166],
         ...,
         [-0.1020,  0.0440, -0.1541,  ..., -0.0829,  0.1796,  0.0242],
         [-0.0496, -0.0175, -0.1106,  ...,  0.0363, -0.0285, -0.1120],
         [-0.1565,  0.1662, -0.0880,  ...,  0.0915,  0.0441, -0.0309]]],
       grad_fn=<StackBackward0>), 'stoch': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 1.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 1.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 1., 0., 0.],
         [0., 1., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 1., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 1., 0.,  ..., 0., 0., 1.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 1., 0.]]])}
train_step: Starting state deter shape: torch.Size([16, 50, 128])
train_step: Starting state stoch shape: torch.Size([16, 50, 1024])
After ensuring logits/stoch: {'deter': tensor([[[ 0.0144, -0.0839,  0.0510,  ...,  0.0099,  0.0711,  0.0660],
         [ 0.0725, -0.0309, -0.1301,  ...,  0.0689, -0.1268, -0.0303],
         [-0.0636, -0.0694, -0.0193,  ...,  0.1374,  0.0637,  0.0821],
         ...,
         [-0.2440, -0.0326,  0.0157,  ..., -0.0807,  0.0125, -0.1117],
         [-0.1327,  0.0267, -0.0797,  ...,  0.0261,  0.2460,  0.0029],
         [-0.0019,  0.0487, -0.0320,  ...,  0.0911,  0.1128, -0.0656]],

        [[-0.0479,  0.0153, -0.0595,  ...,  0.1126,  0.0709, -0.1588],
         [ 0.0819, -0.0641, -0.0542,  ..., -0.0909,  0.1341,  0.0031],
         [-0.0298, -0.0747,  0.0685,  ..., -0.0467,  0.0784, -0.0864],
         ...,
         [-0.0182,  0.0092,  0.0094,  ...,  0.0312,  0.1638, -0.1460],
         [-0.0046, -0.0538, -0.0794,  ...,  0.1671, -0.1150, -0.1300],
         [-0.1703, -0.0325, -0.0059,  ...,  0.0532,  0.0906,  0.0431]],

        [[-0.0625,  0.0042,  0.0584,  ...,  0.0609,  0.0423, -0.0361],
         [-0.1316,  0.1499, -0.0434,  ..., -0.0385,  0.0120, -0.0513],
         [ 0.0885,  0.1533, -0.0862,  ...,  0.2331,  0.0960,  0.0191],
         ...,
         [-0.0474, -0.0277,  0.0590,  ..., -0.1218,  0.1475,  0.0215],
         [ 0.0407,  0.0255, -0.0125,  ...,  0.0733,  0.1416, -0.0540],
         [ 0.0928,  0.0666, -0.0162,  ...,  0.0497,  0.0895,  0.0573]],

        ...,

        [[ 0.1199, -0.0359, -0.0667,  ..., -0.2532, -0.1040,  0.0370],
         [ 0.0356, -0.0780,  0.1368,  ...,  0.0383, -0.0445, -0.0357],
         [ 0.0607,  0.0278, -0.0057,  ..., -0.0067,  0.0261, -0.0030],
         ...,
         [-0.0900, -0.0559, -0.1343,  ..., -0.0597,  0.0209,  0.0231],
         [-0.1063,  0.0110, -0.0705,  ...,  0.1001,  0.0026,  0.0446],
         [-0.0160,  0.1083, -0.0756,  ...,  0.0644, -0.0661, -0.0696]],

        [[-0.1425,  0.0274, -0.0679,  ..., -0.0033, -0.0495,  0.0744],
         [-0.1271,  0.0790, -0.1637,  ...,  0.1831,  0.0528,  0.0297],
         [-0.1377, -0.1899, -0.1164,  ...,  0.0739,  0.1129, -0.0079],
         ...,
         [-0.1385, -0.1495,  0.0307,  ..., -0.0919,  0.0521, -0.1446],
         [-0.0556,  0.0479, -0.0866,  ...,  0.0850, -0.0965, -0.0204],
         [-0.0927,  0.1609, -0.1044,  ...,  0.2064,  0.1234, -0.1372]],

        [[-0.0313,  0.0747, -0.0285,  ..., -0.0091, -0.0199,  0.0321],
         [-0.0423,  0.0354, -0.1188,  ...,  0.1439, -0.1905,  0.0094],
         [-0.1009,  0.1022, -0.0499,  ..., -0.0261,  0.1172,  0.0166],
         ...,
         [-0.1020,  0.0440, -0.1541,  ..., -0.0829,  0.1796,  0.0242],
         [-0.0496, -0.0175, -0.1106,  ...,  0.0363, -0.0285, -0.1120],
         [-0.1565,  0.1662, -0.0880,  ...,  0.0915,  0.0441, -0.0309]]],
       grad_fn=<StackBackward0>), 'stoch': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 1.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 1.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 1., 0., 0.],
         [0., 1., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 1., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 1., 0.,  ..., 0., 0., 1.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 1., 0.]]]), 'logits': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]])}
train_step: Normalized hidden_state shape: torch.Size([1, 16, 128])
train_step: Normalized stoch shape: torch.Size([16, 1024])
train_step: Normalized deter shape: torch.Size([16, 128])
train_step: Post-imagine_trajectory: Imagined features shape: torch.Size([16, 15, 1152])
train_step: Post-imagine_trajectory: Imagined actions shape: torch.Size([16, 15, 2])
train_step: Post-imagine_trajectory: Imagined action indices shape: torch.Size([16, 15])
train_step: Post-imagine_trajectory: Imagined state deter shape: torch.Size([16, 15, 128])
train_step: Post-imagine_trajectory: Imagined state stoch shape: torch.Size([16, 15, 1024])
Reward shape: torch.Size([16, 15, 1]), Value shape: torch.Size([16, 15, 1]), Slow Value shape: torch.Size([16, 15, 1]), Discount shape: torch.Size([16, 15, 1, 1])
Return targets length: 15, First target shape: torch.Size([16, 16, 1])
train_step: Actor distribution shape: torch.Size([16, 15, 2])
train_step: Action log probabilities shape: torch.Size([16, 15])
train_step: Action log probabilities sample: tensor([[-0.2646, -0.0861],
        [-1.3885, -0.3375]], grad_fn=<SliceBackward0>)
train_step: Advantages shape: torch.Size([16, 15, 16, 15])
train_step: Advantages sample: tensor([[[[-10.5142, -10.5141, -10.5142, -10.5142, -10.5142, -10.5142, -10.5142,
           -10.5142, -10.5142, -10.5142, -10.5142, -10.5142, -10.5142, -10.5142,
           -10.5141],
          [-10.5142, -10.5141, -10.5142, -10.5142, -10.5142, -10.5142, -10.5142,
           -10.5142, -10.5142, -10.5142, -10.5142, -10.5142, -10.5142, -10.5142,
           -10.5141],
          [-10.5142, -10.5141, -10.5142, -10.5142, -10.5142, -10.5142, -10.5142,
           -10.5142, -10.5142, -10.5142, -10.5142, -10.5142, -10.5142, -10.5142,
           -10.5141],
          [-10.5142, -10.5141, -10.5142, -10.5142, -10.5142, -10.5142, -10.5142,
           -10.5142, -10.5142, -10.5142, -10.5142, -10.5142, -10.5142, -10.5142,
           -10.5141],
          [-10.5142, -10.5141, -10.5142, -10.5142, -10.5142, -10.5142, -10.5142,
           -10.5142, -10.5142, -10.5142, -10.5142, -10.5142, -10.5142, -10.5142,
           -10.5141],
          [-10.5142, -10.5141, -10.5142, -10.5142, -10.5142, -10.5142, -10.5142,
           -10.5142, -10.5142, -10.5142, -10.5142, -10.5142, -10.5142, -10.5142,
           -10.5141],
          [-10.5142, -10.5141, -10.5142, -10.5142, -10.5142, -10.5142, -10.5142,
           -10.5142, -10.5142, -10.5142, -10.5142, -10.5142, -10.5142, -10.5142,
           -10.5141],
          [ -7.2351,  -7.2351,  -7.2351,  -7.2351,  -7.2351,  -7.2351,  -7.2351,
            -7.2351,  -7.2351,  -7.2351,  -7.2351,  -7.2351,  -7.2351,  -7.2351,
            -7.2351],
          [-10.5142, -10.5141, -10.5142, -10.5142, -10.5142, -10.5142, -10.5142,
           -10.5142, -10.5142, -10.5142, -10.5142, -10.5142, -10.5142, -10.5142,
           -10.5141],
          [-10.5142, -10.5141, -10.5142, -10.5142, -10.5142, -10.5142, -10.5142,
           -10.5142, -10.5142, -10.5142, -10.5142, -10.5142, -10.5142, -10.5142,
           -10.5141],
          [ -5.0291,  -5.0291,  -5.0291,  -5.0291,  -5.0291,  -5.0291,  -5.0291,
            -5.0291,  -5.0291,  -5.0291,  -5.0291,  -5.0291,  -5.0291,  -5.0291,
            -5.0290],
          [-10.5142, -10.5141, -10.5142, -10.5142, -10.5142, -10.5142, -10.5142,
           -10.5142, -10.5142, -10.5142, -10.5142, -10.5142, -10.5142, -10.5142,
           -10.5141],
          [ -1.1674,  -1.1674,  -1.1674,  -1.1674,  -1.1674,  -1.1674,  -1.1674,
            -1.1674,  -1.1674,  -1.1674,  -1.1674,  -1.1674,  -1.1674,  -1.1674,
            -1.1674],
          [-10.5142, -10.5141, -10.5142, -10.5142, -10.5142, -10.5142, -10.5142,
           -10.5142, -10.5142, -10.5142, -10.5142, -10.5142, -10.5142, -10.5142,
           -10.5141],
          [ -1.4792,  -1.4792,  -1.4792,  -1.4792,  -1.4792,  -1.4792,  -1.4792,
            -1.4792,  -1.4792,  -1.4792,  -1.4792,  -1.4792,  -1.4792,  -1.4792,
            -1.4791],
          [ -7.8827,  -7.8827,  -7.8827,  -7.8828,  -7.8827,  -7.8827,  -7.8827,
            -7.8827,  -7.8827,  -7.8827,  -7.8827,  -7.8827,  -7.8827,  -7.8827,
            -7.8827]],

         [[ -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,
            -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,
            -9.8681],
          [ -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,
            -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,
            -9.8681],
          [ -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,
            -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,
            -9.8681],
          [ -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,
            -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,
            -9.8681],
          [ -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,
            -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,
            -9.8681],
          [ -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,
            -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,
            -9.8681],
          [ -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,
            -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,
            -9.8681],
          [ -6.4060,  -6.4060,  -6.4061,  -6.4061,  -6.4060,  -6.4061,  -6.4061,
            -6.4061,  -6.4060,  -6.4060,  -6.4060,  -6.4061,  -6.4060,  -6.4061,
            -6.4061],
          [ -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,
            -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,
            -9.8681],
          [ -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,
            -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,
            -9.8681],
          [ -4.0769,  -4.0769,  -4.0770,  -4.0770,  -4.0769,  -4.0770,  -4.0769,
            -4.0770,  -4.0769,  -4.0769,  -4.0769,  -4.0770,  -4.0769,  -4.0769,
            -4.0769],
          [ -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,
            -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,
            -9.8681],
          [ -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,
            -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,
            -9.8681],
          [ -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,
            -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,  -9.8681,
            -9.8681],
          [ -0.3289,  -0.3289,  -0.3290,  -0.3290,  -0.3289,  -0.3290,  -0.3290,
            -0.3290,  -0.3290,  -0.3290,  -0.3290,  -0.3290,  -0.3290,  -0.3290,
            -0.3290],
          [ -7.0898,  -7.0898,  -7.0898,  -7.0898,  -7.0898,  -7.0898,  -7.0898,
            -7.0898,  -7.0898,  -7.0898,  -7.0898,  -7.0898,  -7.0898,  -7.0898,
            -7.0898]]],


        [[[ -6.0446,  -6.0445,  -6.0446,  -6.0446,  -6.0446,  -6.0446,  -6.0446,
            -6.0446,  -6.0446,  -6.0446,  -6.0446,  -6.0446,  -6.0446,  -6.0446,
            -6.0445],
          [ -6.0446,  -6.0445,  -6.0446,  -6.0446,  -6.0446,  -6.0446,  -6.0446,
            -6.0446,  -6.0446,  -6.0446,  -6.0446,  -6.0446,  -6.0446,  -6.0446,
            -6.0445],
          [ -6.0446,  -6.0445,  -6.0446,  -6.0446,  -6.0446,  -6.0446,  -6.0446,
            -6.0446,  -6.0446,  -6.0446,  -6.0446,  -6.0446,  -6.0446,  -6.0446,
            -6.0445],
          [ -6.0446,  -6.0445,  -6.0446,  -6.0446,  -6.0446,  -6.0446,  -6.0446,
            -6.0446,  -6.0446,  -6.0446,  -6.0446,  -6.0446,  -6.0446,  -6.0446,
            -6.0445],
          [ -6.0446,  -6.0445,  -6.0446,  -6.0446,  -6.0446,  -6.0446,  -6.0446,
            -6.0446,  -6.0446,  -6.0446,  -6.0446,  -6.0446,  -6.0446,  -6.0446,
            -6.0445],
          [ -6.0446,  -6.0445,  -6.0446,  -6.0446,  -6.0446,  -6.0446,  -6.0446,
            -6.0446,  -6.0446,  -6.0446,  -6.0446,  -6.0446,  -6.0446,  -6.0446,
            -6.0445],
          [ -6.0446,  -6.0445,  -6.0446,  -6.0446,  -6.0446,  -6.0446,  -6.0446,
            -6.0446,  -6.0446,  -6.0446,  -6.0446,  -6.0446,  -6.0446,  -6.0446,
            -6.0445],
          [ -2.9355,  -2.9354,  -2.9355,  -2.9355,  -2.9355,  -2.9355,  -2.9355,
            -2.9355,  -2.9355,  -2.9355,  -2.9355,  -2.9355,  -2.9355,  -2.9355,
            -2.9354],
          [ -6.0446,  -6.0445,  -6.0446,  -6.0446,  -6.0446,  -6.0446,  -6.0446,
            -6.0446,  -6.0446,  -6.0446,  -6.0446,  -6.0446,  -6.0446,  -6.0446,
            -6.0445],
          [ -6.0446,  -6.0445,  -6.0446,  -6.0446,  -6.0446,  -6.0446,  -6.0446,
            -6.0446,  -6.0446,  -6.0446,  -6.0446,  -6.0446,  -6.0446,  -6.0446,
            -6.0445],
          [ -2.0730,  -2.0730,  -2.0730,  -2.0730,  -2.0730,  -2.0730,  -2.0730,
            -2.0730,  -2.0730,  -2.0730,  -2.0730,  -2.0730,  -2.0730,  -2.0730,
            -2.0730],
          [ -6.0446,  -6.0445,  -6.0446,  -6.0446,  -6.0446,  -6.0446,  -6.0446,
            -6.0446,  -6.0446,  -6.0446,  -6.0446,  -6.0446,  -6.0446,  -6.0446,
            -6.0445],
          [ -0.0345,  -0.0345,  -0.0345,  -0.0346,  -0.0345,  -0.0345,  -0.0345,
            -0.0345,  -0.0345,  -0.0345,  -0.0345,  -0.0345,  -0.0345,  -0.0345,
            -0.0345],
          [ -6.0446,  -6.0445,  -6.0446,  -6.0446,  -6.0446,  -6.0446,  -6.0446,
            -6.0446,  -6.0446,  -6.0446,  -6.0446,  -6.0446,  -6.0446,  -6.0446,
            -6.0445],
          [ -0.7697,  -0.7696,  -0.7697,  -0.7697,  -0.7697,  -0.7697,  -0.7697,
            -0.7697,  -0.7697,  -0.7697,  -0.7697,  -0.7697,  -0.7697,  -0.7697,
            -0.7696],
          [ -3.5916,  -3.5915,  -3.5916,  -3.5916,  -3.5916,  -3.5916,  -3.5916,
            -3.5916,  -3.5916,  -3.5916,  -3.5916,  -3.5916,  -3.5916,  -3.5916,
            -3.5915]],

         [[ -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,
            -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,
            -6.3452],
          [ -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,
            -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,
            -6.3452],
          [ -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,
            -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,
            -6.3452],
          [ -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,
            -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,
            -6.3452],
          [ -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,
            -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,
            -6.3452],
          [ -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,
            -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,
            -6.3452],
          [ -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,
            -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,
            -6.3452],
          [ -3.0626,  -3.0626,  -3.0626,  -3.0626,  -3.0626,  -3.0626,  -3.0626,
            -3.0626,  -3.0626,  -3.0626,  -3.0626,  -3.0626,  -3.0626,  -3.0626,
            -3.0626],
          [ -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,
            -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,
            -6.3452],
          [ -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,
            -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,
            -6.3452],
          [ -2.1520,  -2.1520,  -2.1520,  -2.1520,  -2.1520,  -2.1520,  -2.1520,
            -2.1520,  -2.1520,  -2.1520,  -2.1520,  -2.1520,  -2.1520,  -2.1520,
            -2.1520],
          [ -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,
            -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,
            -6.3452],
          [ -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,
            -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,
            -6.3452],
          [ -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,
            -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,  -6.3452,
            -6.3452],
          [ -0.7759,  -0.7759,  -0.7760,  -0.7760,  -0.7759,  -0.7760,  -0.7760,
            -0.7760,  -0.7759,  -0.7759,  -0.7759,  -0.7760,  -0.7759,  -0.7760,
            -0.7760],
          [ -3.7553,  -3.7553,  -3.7553,  -3.7553,  -3.7553,  -3.7553,  -3.7553,
            -3.7553,  -3.7553,  -3.7553,  -3.7553,  -3.7553,  -3.7553,  -3.7553,
            -3.7553]]]], grad_fn=<SliceBackward0>)
train_step: Return scale: 1.6677665107483544
train_step: Scaled advantages shape: torch.Size([16, 15, 16, 15])
train_step: Scaled advantages sample: tensor([[[[-6.3043, -6.3043, -6.3043, -6.3044, -6.3043, -6.3043, -6.3043,
           -6.3043, -6.3043, -6.3043, -6.3043, -6.3043, -6.3043, -6.3043,
           -6.3043],
          [-6.3043, -6.3043, -6.3043, -6.3044, -6.3043, -6.3043, -6.3043,
           -6.3043, -6.3043, -6.3043, -6.3043, -6.3043, -6.3043, -6.3043,
           -6.3043],
          [-6.3043, -6.3043, -6.3043, -6.3044, -6.3043, -6.3043, -6.3043,
           -6.3043, -6.3043, -6.3043, -6.3043, -6.3043, -6.3043, -6.3043,
           -6.3043],
          [-6.3043, -6.3043, -6.3043, -6.3044, -6.3043, -6.3043, -6.3043,
           -6.3043, -6.3043, -6.3043, -6.3043, -6.3043, -6.3043, -6.3043,
           -6.3043],
          [-6.3043, -6.3043, -6.3043, -6.3044, -6.3043, -6.3043, -6.3043,
           -6.3043, -6.3043, -6.3043, -6.3043, -6.3043, -6.3043, -6.3043,
           -6.3043],
          [-6.3043, -6.3043, -6.3043, -6.3044, -6.3043, -6.3043, -6.3043,
           -6.3043, -6.3043, -6.3043, -6.3043, -6.3043, -6.3043, -6.3043,
           -6.3043],
          [-6.3043, -6.3043, -6.3043, -6.3044, -6.3043, -6.3043, -6.3043,
           -6.3043, -6.3043, -6.3043, -6.3043, -6.3043, -6.3043, -6.3043,
           -6.3043],
          [-4.3382, -4.3382, -4.3382, -4.3382, -4.3382, -4.3382, -4.3382,
           -4.3382, -4.3382, -4.3382, -4.3382, -4.3382, -4.3382, -4.3382,
           -4.3382],
          [-6.3043, -6.3043, -6.3043, -6.3044, -6.3043, -6.3043, -6.3043,
           -6.3043, -6.3043, -6.3043, -6.3043, -6.3043, -6.3043, -6.3043,
           -6.3043],
          [-6.3043, -6.3043, -6.3043, -6.3044, -6.3043, -6.3043, -6.3043,
           -6.3043, -6.3043, -6.3043, -6.3043, -6.3043, -6.3043, -6.3043,
           -6.3043],
          [-3.0155, -3.0154, -3.0155, -3.0155, -3.0155, -3.0155, -3.0155,
           -3.0155, -3.0155, -3.0155, -3.0155, -3.0155, -3.0154, -3.0155,
           -3.0154],
          [-6.3043, -6.3043, -6.3043, -6.3044, -6.3043, -6.3043, -6.3043,
           -6.3043, -6.3043, -6.3043, -6.3043, -6.3043, -6.3043, -6.3043,
           -6.3043],
          [-0.7000, -0.7000, -0.7000, -0.7000, -0.7000, -0.7000, -0.7000,
           -0.7000, -0.7000, -0.7000, -0.7000, -0.7000, -0.7000, -0.7000,
           -0.7000],
          [-6.3043, -6.3043, -6.3043, -6.3044, -6.3043, -6.3043, -6.3043,
           -6.3043, -6.3043, -6.3043, -6.3043, -6.3043, -6.3043, -6.3043,
           -6.3043],
          [-0.8869, -0.8869, -0.8869, -0.8869, -0.8869, -0.8869, -0.8869,
           -0.8869, -0.8869, -0.8869, -0.8869, -0.8869, -0.8869, -0.8869,
           -0.8869],
          [-4.7265, -4.7265, -4.7265, -4.7265, -4.7265, -4.7265, -4.7265,
           -4.7265, -4.7265, -4.7265, -4.7265, -4.7265, -4.7265, -4.7265,
           -4.7265]],

         [[-5.9169, -5.9169, -5.9170, -5.9170, -5.9169, -5.9170, -5.9170,
           -5.9170, -5.9169, -5.9169, -5.9169, -5.9170, -5.9169, -5.9170,
           -5.9170],
          [-5.9169, -5.9169, -5.9170, -5.9170, -5.9169, -5.9170, -5.9170,
           -5.9170, -5.9169, -5.9169, -5.9169, -5.9170, -5.9169, -5.9170,
           -5.9170],
          [-5.9169, -5.9169, -5.9170, -5.9170, -5.9169, -5.9170, -5.9170,
           -5.9170, -5.9169, -5.9169, -5.9169, -5.9170, -5.9169, -5.9170,
           -5.9170],
          [-5.9169, -5.9169, -5.9170, -5.9170, -5.9169, -5.9170, -5.9170,
           -5.9170, -5.9169, -5.9169, -5.9169, -5.9170, -5.9169, -5.9170,
           -5.9170],
          [-5.9169, -5.9169, -5.9170, -5.9170, -5.9169, -5.9170, -5.9170,
           -5.9170, -5.9169, -5.9169, -5.9169, -5.9170, -5.9169, -5.9170,
           -5.9170],
          [-5.9169, -5.9169, -5.9170, -5.9170, -5.9169, -5.9170, -5.9170,
           -5.9170, -5.9169, -5.9169, -5.9169, -5.9170, -5.9169, -5.9170,
           -5.9170],
          [-5.9169, -5.9169, -5.9170, -5.9170, -5.9169, -5.9170, -5.9170,
           -5.9170, -5.9169, -5.9169, -5.9169, -5.9170, -5.9169, -5.9170,
           -5.9170],
          [-3.8411, -3.8411, -3.8411, -3.8411, -3.8411, -3.8411, -3.8411,
           -3.8411, -3.8411, -3.8411, -3.8411, -3.8411, -3.8411, -3.8411,
           -3.8411],
          [-5.9169, -5.9169, -5.9170, -5.9170, -5.9169, -5.9170, -5.9170,
           -5.9170, -5.9169, -5.9169, -5.9169, -5.9170, -5.9169, -5.9170,
           -5.9170],
          [-5.9169, -5.9169, -5.9170, -5.9170, -5.9169, -5.9170, -5.9170,
           -5.9170, -5.9169, -5.9169, -5.9169, -5.9170, -5.9169, -5.9170,
           -5.9170],
          [-2.4445, -2.4445, -2.4446, -2.4446, -2.4445, -2.4446, -2.4446,
           -2.4446, -2.4445, -2.4445, -2.4445, -2.4446, -2.4445, -2.4446,
           -2.4446],
          [-5.9169, -5.9169, -5.9170, -5.9170, -5.9169, -5.9170, -5.9170,
           -5.9170, -5.9169, -5.9169, -5.9169, -5.9170, -5.9169, -5.9170,
           -5.9170],
          [-5.9169, -5.9169, -5.9170, -5.9170, -5.9169, -5.9170, -5.9170,
           -5.9170, -5.9169, -5.9169, -5.9169, -5.9170, -5.9169, -5.9170,
           -5.9170],
          [-5.9169, -5.9169, -5.9170, -5.9170, -5.9169, -5.9170, -5.9170,
           -5.9170, -5.9169, -5.9169, -5.9169, -5.9170, -5.9169, -5.9170,
           -5.9170],
          [-0.3289, -0.3289, -0.3290, -0.3290, -0.3289, -0.3290, -0.3290,
           -0.3290, -0.3290, -0.3290, -0.3290, -0.3290, -0.3290, -0.3290,
           -0.3290],
          [-4.2511, -4.2511, -4.2511, -4.2511, -4.2511, -4.2511, -4.2511,
           -4.2511, -4.2511, -4.2511, -4.2511, -4.2511, -4.2511, -4.2511,
           -4.2511]]],


        [[[-3.6244, -3.6243, -3.6244, -3.6244, -3.6244, -3.6243, -3.6243,
           -3.6244, -3.6244, -3.6243, -3.6244, -3.6244, -3.6243, -3.6243,
           -3.6243],
          [-3.6244, -3.6243, -3.6244, -3.6244, -3.6244, -3.6243, -3.6243,
           -3.6244, -3.6244, -3.6243, -3.6244, -3.6244, -3.6243, -3.6243,
           -3.6243],
          [-3.6244, -3.6243, -3.6244, -3.6244, -3.6244, -3.6243, -3.6243,
           -3.6244, -3.6244, -3.6243, -3.6244, -3.6244, -3.6243, -3.6243,
           -3.6243],
          [-3.6244, -3.6243, -3.6244, -3.6244, -3.6244, -3.6243, -3.6243,
           -3.6244, -3.6244, -3.6243, -3.6244, -3.6244, -3.6243, -3.6243,
           -3.6243],
          [-3.6244, -3.6243, -3.6244, -3.6244, -3.6244, -3.6243, -3.6243,
           -3.6244, -3.6244, -3.6243, -3.6244, -3.6244, -3.6243, -3.6243,
           -3.6243],
          [-3.6244, -3.6243, -3.6244, -3.6244, -3.6244, -3.6243, -3.6243,
           -3.6244, -3.6244, -3.6243, -3.6244, -3.6244, -3.6243, -3.6243,
           -3.6243],
          [-3.6244, -3.6243, -3.6244, -3.6244, -3.6244, -3.6243, -3.6243,
           -3.6244, -3.6244, -3.6243, -3.6244, -3.6244, -3.6243, -3.6243,
           -3.6243],
          [-1.7601, -1.7601, -1.7601, -1.7601, -1.7601, -1.7601, -1.7601,
           -1.7601, -1.7601, -1.7601, -1.7601, -1.7601, -1.7601, -1.7601,
           -1.7601],
          [-3.6244, -3.6243, -3.6244, -3.6244, -3.6244, -3.6243, -3.6243,
           -3.6244, -3.6244, -3.6243, -3.6244, -3.6244, -3.6243, -3.6243,
           -3.6243],
          [-3.6244, -3.6243, -3.6244, -3.6244, -3.6244, -3.6243, -3.6243,
           -3.6244, -3.6244, -3.6243, -3.6244, -3.6244, -3.6243, -3.6243,
           -3.6243],
          [-1.2430, -1.2430, -1.2430, -1.2430, -1.2430, -1.2430, -1.2430,
           -1.2430, -1.2430, -1.2430, -1.2430, -1.2430, -1.2430, -1.2430,
           -1.2430],
          [-3.6244, -3.6243, -3.6244, -3.6244, -3.6244, -3.6243, -3.6243,
           -3.6244, -3.6244, -3.6243, -3.6244, -3.6244, -3.6243, -3.6243,
           -3.6243],
          [-0.0345, -0.0345, -0.0345, -0.0346, -0.0345, -0.0345, -0.0345,
           -0.0345, -0.0345, -0.0345, -0.0345, -0.0345, -0.0345, -0.0345,
           -0.0345],
          [-3.6244, -3.6243, -3.6244, -3.6244, -3.6244, -3.6243, -3.6243,
           -3.6244, -3.6244, -3.6243, -3.6244, -3.6244, -3.6243, -3.6243,
           -3.6243],
          [-0.7697, -0.7696, -0.7697, -0.7697, -0.7697, -0.7697, -0.7697,
           -0.7697, -0.7697, -0.7697, -0.7697, -0.7697, -0.7697, -0.7697,
           -0.7696],
          [-2.1535, -2.1535, -2.1535, -2.1535, -2.1535, -2.1535, -2.1535,
           -2.1535, -2.1535, -2.1535, -2.1535, -2.1535, -2.1535, -2.1535,
           -2.1535]],

         [[-3.8046, -3.8046, -3.8046, -3.8046, -3.8046, -3.8046, -3.8046,
           -3.8046, -3.8046, -3.8046, -3.8046, -3.8046, -3.8046, -3.8046,
           -3.8046],
          [-3.8046, -3.8046, -3.8046, -3.8046, -3.8046, -3.8046, -3.8046,
           -3.8046, -3.8046, -3.8046, -3.8046, -3.8046, -3.8046, -3.8046,
           -3.8046],
          [-3.8046, -3.8046, -3.8046, -3.8046, -3.8046, -3.8046, -3.8046,
           -3.8046, -3.8046, -3.8046, -3.8046, -3.8046, -3.8046, -3.8046,
           -3.8046],
          [-3.8046, -3.8046, -3.8046, -3.8046, -3.8046, -3.8046, -3.8046,
           -3.8046, -3.8046, -3.8046, -3.8046, -3.8046, -3.8046, -3.8046,
           -3.8046],
          [-3.8046, -3.8046, -3.8046, -3.8046, -3.8046, -3.8046, -3.8046,
           -3.8046, -3.8046, -3.8046, -3.8046, -3.8046, -3.8046, -3.8046,
           -3.8046],
          [-3.8046, -3.8046, -3.8046, -3.8046, -3.8046, -3.8046, -3.8046,
           -3.8046, -3.8046, -3.8046, -3.8046, -3.8046, -3.8046, -3.8046,
           -3.8046],
          [-3.8046, -3.8046, -3.8046, -3.8046, -3.8046, -3.8046, -3.8046,
           -3.8046, -3.8046, -3.8046, -3.8046, -3.8046, -3.8046, -3.8046,
           -3.8046],
          [-1.8363, -1.8363, -1.8364, -1.8364, -1.8363, -1.8364, -1.8364,
           -1.8364, -1.8363, -1.8363, -1.8363, -1.8364, -1.8363, -1.8364,
           -1.8364],
          [-3.8046, -3.8046, -3.8046, -3.8046, -3.8046, -3.8046, -3.8046,
           -3.8046, -3.8046, -3.8046, -3.8046, -3.8046, -3.8046, -3.8046,
           -3.8046],
          [-3.8046, -3.8046, -3.8046, -3.8046, -3.8046, -3.8046, -3.8046,
           -3.8046, -3.8046, -3.8046, -3.8046, -3.8046, -3.8046, -3.8046,
           -3.8046],
          [-1.2903, -1.2903, -1.2904, -1.2904, -1.2903, -1.2904, -1.2904,
           -1.2904, -1.2903, -1.2903, -1.2903, -1.2904, -1.2903, -1.2904,
           -1.2904],
          [-3.8046, -3.8046, -3.8046, -3.8046, -3.8046, -3.8046, -3.8046,
           -3.8046, -3.8046, -3.8046, -3.8046, -3.8046, -3.8046, -3.8046,
           -3.8046],
          [-3.8046, -3.8046, -3.8046, -3.8046, -3.8046, -3.8046, -3.8046,
           -3.8046, -3.8046, -3.8046, -3.8046, -3.8046, -3.8046, -3.8046,
           -3.8046],
          [-3.8046, -3.8046, -3.8046, -3.8046, -3.8046, -3.8046, -3.8046,
           -3.8046, -3.8046, -3.8046, -3.8046, -3.8046, -3.8046, -3.8046,
           -3.8046],
          [-0.7759, -0.7759, -0.7760, -0.7760, -0.7759, -0.7760, -0.7760,
           -0.7760, -0.7759, -0.7759, -0.7759, -0.7760, -0.7759, -0.7760,
           -0.7760],
          [-2.2517, -2.2517, -2.2517, -2.2517, -2.2517, -2.2517, -2.2517,
           -2.2517, -2.2517, -2.2517, -2.2517, -2.2517, -2.2517, -2.2517,
           -2.2517]]]], grad_fn=<SliceBackward0>)
train_step: Entropy shape: torch.Size([16, 15])
train_step: Entropy sample: tensor([[0.5422, 0.2849],
        [0.5617, 0.5990]], grad_fn=<SliceBackward0>)
train_step: Entropy coefficient: 0.01
train_step: Actor loss: -1.2295448780059814
train_step: returns shape after mean: torch.Size([16, 15])
train_step: target_indices shape: torch.Size([16, 15])
train_step: value_logits shape: torch.Size([16, 15, 255])
train_step: target_twohot shape: torch.Size([16, 15, 255])
--- Starting train_step at 2025-04-01 01:53:53 ---
Full starting_state: {'deter': tensor([[[ 0.0150,  0.0346, -0.0502,  ...,  0.0205,  0.0767,  0.0700],
         [-0.0425, -0.0300, -0.0357,  ...,  0.0201, -0.0207,  0.1071],
         [-0.0744, -0.0150, -0.0673,  ...,  0.1050, -0.1786, -0.0296],
         ...,
         [-0.0179, -0.0302, -0.0853,  ...,  0.0113,  0.1374,  0.0596],
         [-0.0753, -0.0817,  0.0383,  ...,  0.0756,  0.0279, -0.0856],
         [ 0.0058, -0.0016, -0.1534,  ..., -0.0351,  0.0452, -0.0137]],

        [[ 0.0224, -0.0987, -0.2255,  ..., -0.0761, -0.0715, -0.0961],
         [ 0.0247,  0.0178, -0.1779,  ..., -0.1069, -0.0234,  0.0005],
         [ 0.0495, -0.0480,  0.0312,  ..., -0.1430, -0.1187,  0.0354],
         ...,
         [-0.2667, -0.0163, -0.0391,  ..., -0.1533, -0.0997, -0.0259],
         [ 0.0234,  0.1027, -0.0927,  ...,  0.0093,  0.0196, -0.3048],
         [-0.2147, -0.0084, -0.0016,  ..., -0.0438, -0.1043,  0.0009]],

        [[ 0.0237, -0.0281, -0.1204,  ...,  0.1631, -0.0429, -0.0931],
         [ 0.0049, -0.1623, -0.1037,  ...,  0.0766,  0.0849, -0.1952],
         [-0.1723, -0.0103, -0.0591,  ..., -0.0480,  0.0498, -0.1192],
         ...,
         [ 0.1668,  0.1186, -0.0742,  ..., -0.1226, -0.1431, -0.0152],
         [ 0.0482, -0.0236, -0.1162,  ..., -0.0188, -0.0630,  0.0737],
         [-0.0914, -0.0263,  0.0543,  ..., -0.1720, -0.1261,  0.0006]],

        ...,

        [[-0.0848,  0.1502, -0.1062,  ...,  0.0118,  0.0589, -0.1330],
         [-0.1164, -0.1428,  0.1013,  ...,  0.1394,  0.0038,  0.0730],
         [-0.0307,  0.0264, -0.0847,  ...,  0.0717, -0.1095, -0.0793],
         ...,
         [-0.1607, -0.0147,  0.1246,  ..., -0.1530, -0.1374, -0.0460],
         [-0.1089,  0.1001,  0.1268,  ...,  0.0758,  0.2090, -0.0552],
         [ 0.1518, -0.0327, -0.2402,  ..., -0.1571, -0.0425, -0.0516]],

        [[ 0.0067,  0.0041,  0.0062,  ..., -0.0806,  0.1183, -0.0498],
         [ 0.1579, -0.1280, -0.0380,  ...,  0.1128, -0.1482,  0.0027],
         [-0.0153,  0.1650,  0.0547,  ..., -0.1424,  0.1275,  0.0262],
         ...,
         [-0.0931,  0.0669, -0.0128,  ..., -0.0505,  0.0518, -0.0597],
         [ 0.0620, -0.1149, -0.1638,  ..., -0.0757,  0.0270,  0.0185],
         [-0.0641, -0.0393, -0.1288,  ...,  0.1100,  0.1079, -0.0732]],

        [[-0.0114, -0.0950, -0.0601,  ...,  0.1143, -0.0050,  0.0661],
         [-0.0965, -0.0151, -0.0147,  ...,  0.0818,  0.1298, -0.0067],
         [-0.2036, -0.0840, -0.0211,  ...,  0.0212, -0.1542,  0.0583],
         ...,
         [-0.0049,  0.0522, -0.0115,  ...,  0.0082, -0.0685,  0.0485],
         [-0.1037, -0.0372, -0.0078,  ...,  0.0915, -0.0187, -0.0345],
         [ 0.0027,  0.0658, -0.1674,  ...,  0.0271,  0.0916, -0.0904]]],
       grad_fn=<StackBackward0>), 'stoch': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 1., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 1., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 1., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 1.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 1., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 1., 0.]],

        [[1., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]])}
train_step: Starting state deter shape: torch.Size([16, 50, 128])
train_step: Starting state stoch shape: torch.Size([16, 50, 1024])
After ensuring logits/stoch: {'deter': tensor([[[ 0.0150,  0.0346, -0.0502,  ...,  0.0205,  0.0767,  0.0700],
         [-0.0425, -0.0300, -0.0357,  ...,  0.0201, -0.0207,  0.1071],
         [-0.0744, -0.0150, -0.0673,  ...,  0.1050, -0.1786, -0.0296],
         ...,
         [-0.0179, -0.0302, -0.0853,  ...,  0.0113,  0.1374,  0.0596],
         [-0.0753, -0.0817,  0.0383,  ...,  0.0756,  0.0279, -0.0856],
         [ 0.0058, -0.0016, -0.1534,  ..., -0.0351,  0.0452, -0.0137]],

        [[ 0.0224, -0.0987, -0.2255,  ..., -0.0761, -0.0715, -0.0961],
         [ 0.0247,  0.0178, -0.1779,  ..., -0.1069, -0.0234,  0.0005],
         [ 0.0495, -0.0480,  0.0312,  ..., -0.1430, -0.1187,  0.0354],
         ...,
         [-0.2667, -0.0163, -0.0391,  ..., -0.1533, -0.0997, -0.0259],
         [ 0.0234,  0.1027, -0.0927,  ...,  0.0093,  0.0196, -0.3048],
         [-0.2147, -0.0084, -0.0016,  ..., -0.0438, -0.1043,  0.0009]],

        [[ 0.0237, -0.0281, -0.1204,  ...,  0.1631, -0.0429, -0.0931],
         [ 0.0049, -0.1623, -0.1037,  ...,  0.0766,  0.0849, -0.1952],
         [-0.1723, -0.0103, -0.0591,  ..., -0.0480,  0.0498, -0.1192],
         ...,
         [ 0.1668,  0.1186, -0.0742,  ..., -0.1226, -0.1431, -0.0152],
         [ 0.0482, -0.0236, -0.1162,  ..., -0.0188, -0.0630,  0.0737],
         [-0.0914, -0.0263,  0.0543,  ..., -0.1720, -0.1261,  0.0006]],

        ...,

        [[-0.0848,  0.1502, -0.1062,  ...,  0.0118,  0.0589, -0.1330],
         [-0.1164, -0.1428,  0.1013,  ...,  0.1394,  0.0038,  0.0730],
         [-0.0307,  0.0264, -0.0847,  ...,  0.0717, -0.1095, -0.0793],
         ...,
         [-0.1607, -0.0147,  0.1246,  ..., -0.1530, -0.1374, -0.0460],
         [-0.1089,  0.1001,  0.1268,  ...,  0.0758,  0.2090, -0.0552],
         [ 0.1518, -0.0327, -0.2402,  ..., -0.1571, -0.0425, -0.0516]],

        [[ 0.0067,  0.0041,  0.0062,  ..., -0.0806,  0.1183, -0.0498],
         [ 0.1579, -0.1280, -0.0380,  ...,  0.1128, -0.1482,  0.0027],
         [-0.0153,  0.1650,  0.0547,  ..., -0.1424,  0.1275,  0.0262],
         ...,
         [-0.0931,  0.0669, -0.0128,  ..., -0.0505,  0.0518, -0.0597],
         [ 0.0620, -0.1149, -0.1638,  ..., -0.0757,  0.0270,  0.0185],
         [-0.0641, -0.0393, -0.1288,  ...,  0.1100,  0.1079, -0.0732]],

        [[-0.0114, -0.0950, -0.0601,  ...,  0.1143, -0.0050,  0.0661],
         [-0.0965, -0.0151, -0.0147,  ...,  0.0818,  0.1298, -0.0067],
         [-0.2036, -0.0840, -0.0211,  ...,  0.0212, -0.1542,  0.0583],
         ...,
         [-0.0049,  0.0522, -0.0115,  ...,  0.0082, -0.0685,  0.0485],
         [-0.1037, -0.0372, -0.0078,  ...,  0.0915, -0.0187, -0.0345],
         [ 0.0027,  0.0658, -0.1674,  ...,  0.0271,  0.0916, -0.0904]]],
       grad_fn=<StackBackward0>), 'stoch': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 1., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 1., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 1., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 1.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 1., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 1., 0.]],

        [[1., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]]), 'logits': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]])}
train_step: Normalized hidden_state shape: torch.Size([1, 16, 128])
train_step: Normalized stoch shape: torch.Size([16, 1024])
train_step: Normalized deter shape: torch.Size([16, 128])
train_step: Post-imagine_trajectory: Imagined features shape: torch.Size([16, 15, 1152])
train_step: Post-imagine_trajectory: Imagined actions shape: torch.Size([16, 15, 2])
train_step: Post-imagine_trajectory: Imagined action indices shape: torch.Size([16, 15])
train_step: Post-imagine_trajectory: Imagined state deter shape: torch.Size([16, 15, 128])
train_step: Post-imagine_trajectory: Imagined state stoch shape: torch.Size([16, 15, 1024])
Reward shape: torch.Size([16, 15, 1]), Value shape: torch.Size([16, 15, 1]), Slow Value shape: torch.Size([16, 15, 1]), Discount shape: torch.Size([16, 15, 1, 1])
Return targets length: 15, First target shape: torch.Size([16, 16, 1])
train_step: Actor distribution shape: torch.Size([16, 15, 2])
train_step: Action log probabilities shape: torch.Size([16, 15])
train_step: Action log probabilities sample: tensor([[-0.2959, -0.5715],
        [-0.4706, -0.6246]], grad_fn=<SliceBackward0>)
train_step: Advantages shape: torch.Size([16, 15, 16, 15])
train_step: Advantages sample: tensor([[[[-7.2061, -7.2061, -7.2061, -7.2061, -7.2061, -7.2061, -7.2061,
           -7.2061, -7.2061, -7.2061, -7.2061, -7.2061, -7.2061, -7.2061,
           -7.2061],
          [-7.2061, -7.2061, -7.2061, -7.2061, -7.2061, -7.2061, -7.2061,
           -7.2061, -7.2061, -7.2061, -7.2061, -7.2061, -7.2061, -7.2061,
           -7.2061],
          [-7.2061, -7.2061, -7.2061, -7.2061, -7.2061, -7.2061, -7.2061,
           -7.2061, -7.2061, -7.2061, -7.2061, -7.2061, -7.2061, -7.2061,
           -7.2061],
          [-7.2061, -7.2061, -7.2061, -7.2061, -7.2061, -7.2061, -7.2061,
           -7.2061, -7.2061, -7.2061, -7.2061, -7.2061, -7.2061, -7.2061,
           -7.2061],
          [-7.2061, -7.2061, -7.2061, -7.2061, -7.2061, -7.2061, -7.2061,
           -7.2061, -7.2061, -7.2061, -7.2061, -7.2061, -7.2061, -7.2061,
           -7.2061],
          [-7.2061, -7.2061, -7.2061, -7.2061, -7.2061, -7.2061, -7.2061,
           -7.2061, -7.2061, -7.2061, -7.2061, -7.2061, -7.2061, -7.2061,
           -7.2061],
          [-7.2061, -7.2061, -7.2061, -7.2061, -7.2061, -7.2061, -7.2061,
           -7.2061, -7.2061, -7.2061, -7.2061, -7.2061, -7.2061, -7.2061,
           -7.2061],
          [-7.2061, -7.2061, -7.2061, -7.2061, -7.2061, -7.2061, -7.2061,
           -7.2061, -7.2061, -7.2061, -7.2061, -7.2061, -7.2061, -7.2061,
           -7.2061],
          [-7.2061, -7.2061, -7.2061, -7.2061, -7.2061, -7.2061, -7.2061,
           -7.2061, -7.2061, -7.2061, -7.2061, -7.2061, -7.2061, -7.2061,
           -7.2061],
          [-7.2061, -7.2061, -7.2061, -7.2061, -7.2061, -7.2061, -7.2061,
           -7.2061, -7.2061, -7.2061, -7.2061, -7.2061, -7.2061, -7.2061,
           -7.2061],
          [-7.2061, -7.2061, -7.2061, -7.2061, -7.2061, -7.2061, -7.2061,
           -7.2061, -7.2061, -7.2061, -7.2061, -7.2061, -7.2061, -7.2061,
           -7.2061],
          [-7.2061, -7.2061, -7.2061, -7.2061, -7.2061, -7.2061, -7.2061,
           -7.2061, -7.2061, -7.2061, -7.2061, -7.2061, -7.2061, -7.2061,
           -7.2061],
          [-7.2061, -7.2061, -7.2061, -7.2061, -7.2061, -7.2061, -7.2061,
           -7.2061, -7.2061, -7.2061, -7.2061, -7.2061, -7.2061, -7.2061,
           -7.2061],
          [-7.2061, -7.2061, -7.2061, -7.2061, -7.2061, -7.2061, -7.2061,
           -7.2061, -7.2061, -7.2061, -7.2061, -7.2061, -7.2061, -7.2061,
           -7.2061],
          [-7.2210, -7.2210, -7.2210, -7.2210, -7.2210, -7.2210, -7.2210,
           -7.2210, -7.2210, -7.2210, -7.2210, -7.2210, -7.2210, -7.2210,
           -7.2210],
          [-7.2061, -7.2061, -7.2061, -7.2061, -7.2061, -7.2061, -7.2061,
           -7.2061, -7.2061, -7.2061, -7.2061, -7.2061, -7.2061, -7.2061,
           -7.2061]],

         [[-6.7361, -6.7362, -6.7362, -6.7362, -6.7362, -6.7362, -6.7361,
           -6.7361, -6.7361, -6.7361, -6.7361, -6.7361, -6.7361, -6.7361,
           -6.7361],
          [-6.7361, -6.7362, -6.7362, -6.7362, -6.7362, -6.7362, -6.7361,
           -6.7361, -6.7361, -6.7361, -6.7361, -6.7361, -6.7361, -6.7361,
           -6.7361],
          [-6.7361, -6.7362, -6.7362, -6.7362, -6.7362, -6.7362, -6.7361,
           -6.7361, -6.7361, -6.7361, -6.7361, -6.7361, -6.7361, -6.7361,
           -6.7361],
          [-6.7361, -6.7362, -6.7362, -6.7362, -6.7362, -6.7362, -6.7361,
           -6.7361, -6.7361, -6.7361, -6.7361, -6.7361, -6.7361, -6.7361,
           -6.7361],
          [-6.7361, -6.7362, -6.7362, -6.7362, -6.7362, -6.7362, -6.7361,
           -6.7361, -6.7361, -6.7361, -6.7361, -6.7361, -6.7361, -6.7361,
           -6.7361],
          [-6.7361, -6.7362, -6.7362, -6.7362, -6.7362, -6.7362, -6.7361,
           -6.7361, -6.7361, -6.7361, -6.7361, -6.7361, -6.7361, -6.7361,
           -6.7361],
          [-6.7361, -6.7362, -6.7362, -6.7362, -6.7362, -6.7362, -6.7361,
           -6.7361, -6.7361, -6.7361, -6.7361, -6.7361, -6.7361, -6.7361,
           -6.7361],
          [-6.7361, -6.7362, -6.7362, -6.7362, -6.7362, -6.7362, -6.7361,
           -6.7361, -6.7361, -6.7361, -6.7361, -6.7361, -6.7361, -6.7361,
           -6.7361],
          [-6.7361, -6.7362, -6.7362, -6.7362, -6.7362, -6.7362, -6.7361,
           -6.7361, -6.7361, -6.7361, -6.7361, -6.7361, -6.7361, -6.7361,
           -6.7361],
          [-6.7361, -6.7362, -6.7362, -6.7362, -6.7362, -6.7362, -6.7361,
           -6.7361, -6.7361, -6.7361, -6.7361, -6.7361, -6.7361, -6.7361,
           -6.7361],
          [-6.7361, -6.7362, -6.7362, -6.7362, -6.7362, -6.7362, -6.7361,
           -6.7361, -6.7361, -6.7361, -6.7361, -6.7361, -6.7361, -6.7361,
           -6.7361],
          [-6.7361, -6.7362, -6.7362, -6.7362, -6.7362, -6.7362, -6.7361,
           -6.7361, -6.7361, -6.7361, -6.7361, -6.7361, -6.7361, -6.7361,
           -6.7361],
          [-6.7361, -6.7362, -6.7362, -6.7362, -6.7362, -6.7362, -6.7361,
           -6.7361, -6.7361, -6.7361, -6.7361, -6.7361, -6.7361, -6.7361,
           -6.7361],
          [-6.7361, -6.7362, -6.7362, -6.7362, -6.7362, -6.7362, -6.7361,
           -6.7361, -6.7361, -6.7361, -6.7361, -6.7361, -6.7361, -6.7361,
           -6.7361],
          [-6.7519, -6.7519, -6.7519, -6.7519, -6.7519, -6.7519, -6.7519,
           -6.7519, -6.7519, -6.7518, -6.7518, -6.7518, -6.7519, -6.7519,
           -6.7519],
          [-6.7361, -6.7362, -6.7362, -6.7362, -6.7362, -6.7362, -6.7361,
           -6.7361, -6.7361, -6.7361, -6.7361, -6.7361, -6.7361, -6.7361,
           -6.7361]]],


        [[[-7.9674, -7.9674, -7.9674, -7.9674, -7.9674, -7.9674, -7.9674,
           -7.9674, -7.9675, -7.9674, -7.9674, -7.9674, -7.9674, -7.9674,
           -7.9674],
          [-7.9674, -7.9674, -7.9674, -7.9674, -7.9674, -7.9674, -7.9674,
           -7.9674, -7.9675, -7.9674, -7.9674, -7.9674, -7.9674, -7.9674,
           -7.9674],
          [-7.9674, -7.9674, -7.9674, -7.9674, -7.9674, -7.9674, -7.9674,
           -7.9674, -7.9675, -7.9674, -7.9674, -7.9674, -7.9674, -7.9674,
           -7.9674],
          [-7.9674, -7.9674, -7.9674, -7.9674, -7.9674, -7.9674, -7.9674,
           -7.9674, -7.9675, -7.9674, -7.9674, -7.9674, -7.9674, -7.9674,
           -7.9674],
          [-7.9674, -7.9674, -7.9674, -7.9674, -7.9674, -7.9674, -7.9674,
           -7.9674, -7.9675, -7.9674, -7.9674, -7.9674, -7.9674, -7.9674,
           -7.9674],
          [-7.9674, -7.9674, -7.9674, -7.9674, -7.9674, -7.9674, -7.9674,
           -7.9674, -7.9675, -7.9674, -7.9674, -7.9674, -7.9674, -7.9674,
           -7.9674],
          [-7.9674, -7.9674, -7.9674, -7.9674, -7.9674, -7.9674, -7.9674,
           -7.9674, -7.9675, -7.9674, -7.9674, -7.9674, -7.9674, -7.9674,
           -7.9674],
          [-7.9674, -7.9674, -7.9674, -7.9674, -7.9674, -7.9674, -7.9674,
           -7.9674, -7.9675, -7.9674, -7.9674, -7.9674, -7.9674, -7.9674,
           -7.9674],
          [-7.9674, -7.9674, -7.9674, -7.9674, -7.9674, -7.9674, -7.9674,
           -7.9674, -7.9675, -7.9674, -7.9674, -7.9674, -7.9674, -7.9674,
           -7.9674],
          [-7.9674, -7.9674, -7.9674, -7.9674, -7.9674, -7.9674, -7.9674,
           -7.9674, -7.9675, -7.9674, -7.9674, -7.9674, -7.9674, -7.9674,
           -7.9674],
          [-7.9674, -7.9674, -7.9674, -7.9674, -7.9674, -7.9674, -7.9674,
           -7.9674, -7.9675, -7.9674, -7.9674, -7.9674, -7.9674, -7.9674,
           -7.9674],
          [-7.9674, -7.9674, -7.9674, -7.9674, -7.9674, -7.9674, -7.9674,
           -7.9674, -7.9675, -7.9674, -7.9674, -7.9674, -7.9674, -7.9674,
           -7.9674],
          [-7.9674, -7.9674, -7.9674, -7.9674, -7.9674, -7.9674, -7.9674,
           -7.9674, -7.9675, -7.9674, -7.9674, -7.9674, -7.9674, -7.9674,
           -7.9674],
          [-7.9674, -7.9674, -7.9674, -7.9674, -7.9674, -7.9674, -7.9674,
           -7.9674, -7.9675, -7.9674, -7.9674, -7.9674, -7.9674, -7.9674,
           -7.9674],
          [-7.5850, -7.5850, -7.5850, -7.5850, -7.5850, -7.5850, -7.5850,
           -7.5850, -7.5850, -7.5850, -7.5850, -7.5850, -7.5850, -7.5850,
           -7.5850],
          [-7.9674, -7.9674, -7.9674, -7.9674, -7.9674, -7.9674, -7.9674,
           -7.9674, -7.9675, -7.9674, -7.9674, -7.9674, -7.9674, -7.9674,
           -7.9674]],

         [[-7.6745, -7.6745, -7.6745, -7.6746, -7.6746, -7.6746, -7.6745,
           -7.6745, -7.6745, -7.6745, -7.6745, -7.6745, -7.6745, -7.6745,
           -7.6745],
          [-7.6745, -7.6745, -7.6745, -7.6746, -7.6746, -7.6746, -7.6745,
           -7.6745, -7.6745, -7.6745, -7.6745, -7.6745, -7.6745, -7.6745,
           -7.6745],
          [-7.6745, -7.6745, -7.6745, -7.6746, -7.6746, -7.6746, -7.6745,
           -7.6745, -7.6745, -7.6745, -7.6745, -7.6745, -7.6745, -7.6745,
           -7.6745],
          [-7.6745, -7.6745, -7.6745, -7.6746, -7.6746, -7.6746, -7.6745,
           -7.6745, -7.6745, -7.6745, -7.6745, -7.6745, -7.6745, -7.6745,
           -7.6745],
          [-7.6745, -7.6745, -7.6745, -7.6746, -7.6746, -7.6746, -7.6745,
           -7.6745, -7.6745, -7.6745, -7.6745, -7.6745, -7.6745, -7.6745,
           -7.6745],
          [-7.6745, -7.6745, -7.6745, -7.6746, -7.6746, -7.6746, -7.6745,
           -7.6745, -7.6745, -7.6745, -7.6745, -7.6745, -7.6745, -7.6745,
           -7.6745],
          [-7.6745, -7.6745, -7.6745, -7.6746, -7.6746, -7.6746, -7.6745,
           -7.6745, -7.6745, -7.6745, -7.6745, -7.6745, -7.6745, -7.6745,
           -7.6745],
          [-7.6745, -7.6745, -7.6745, -7.6746, -7.6746, -7.6746, -7.6745,
           -7.6745, -7.6745, -7.6745, -7.6745, -7.6745, -7.6745, -7.6745,
           -7.6745],
          [-7.6745, -7.6745, -7.6745, -7.6746, -7.6746, -7.6746, -7.6745,
           -7.6745, -7.6745, -7.6745, -7.6745, -7.6745, -7.6745, -7.6745,
           -7.6745],
          [-7.6745, -7.6745, -7.6745, -7.6746, -7.6746, -7.6746, -7.6745,
           -7.6745, -7.6745, -7.6745, -7.6745, -7.6745, -7.6745, -7.6745,
           -7.6745],
          [-7.6745, -7.6745, -7.6745, -7.6746, -7.6746, -7.6746, -7.6745,
           -7.6745, -7.6745, -7.6745, -7.6745, -7.6745, -7.6745, -7.6745,
           -7.6745],
          [-7.6745, -7.6745, -7.6745, -7.6746, -7.6746, -7.6746, -7.6745,
           -7.6745, -7.6745, -7.6745, -7.6745, -7.6745, -7.6745, -7.6745,
           -7.6745],
          [-7.6745, -7.6745, -7.6745, -7.6746, -7.6746, -7.6746, -7.6745,
           -7.6745, -7.6745, -7.6745, -7.6745, -7.6745, -7.6745, -7.6745,
           -7.6745],
          [-7.6745, -7.6745, -7.6745, -7.6746, -7.6746, -7.6746, -7.6745,
           -7.6745, -7.6745, -7.6745, -7.6745, -7.6745, -7.6745, -7.6745,
           -7.6745],
          [-7.2707, -7.2708, -7.2708, -7.2708, -7.2708, -7.2708, -7.2707,
           -7.2707, -7.2707, -7.2707, -7.2707, -7.2707, -7.2708, -7.2708,
           -7.2707],
          [-7.6745, -7.6745, -7.6745, -7.6746, -7.6746, -7.6746, -7.6745,
           -7.6745, -7.6745, -7.6745, -7.6745, -7.6745, -7.6745, -7.6745,
           -7.6745]]]], grad_fn=<SliceBackward0>)
train_step: Return scale: 1.719872223049852
train_step: Scaled advantages shape: torch.Size([16, 15, 16, 15])
train_step: Scaled advantages sample: tensor([[[[-4.1899, -4.1899, -4.1899, -4.1899, -4.1899, -4.1899, -4.1899,
           -4.1899, -4.1899, -4.1899, -4.1899, -4.1899, -4.1899, -4.1899,
           -4.1899],
          [-4.1899, -4.1899, -4.1899, -4.1899, -4.1899, -4.1899, -4.1899,
           -4.1899, -4.1899, -4.1899, -4.1899, -4.1899, -4.1899, -4.1899,
           -4.1899],
          [-4.1899, -4.1899, -4.1899, -4.1899, -4.1899, -4.1899, -4.1899,
           -4.1899, -4.1899, -4.1899, -4.1899, -4.1899, -4.1899, -4.1899,
           -4.1899],
          [-4.1899, -4.1899, -4.1899, -4.1899, -4.1899, -4.1899, -4.1899,
           -4.1899, -4.1899, -4.1899, -4.1899, -4.1899, -4.1899, -4.1899,
           -4.1899],
          [-4.1899, -4.1899, -4.1899, -4.1899, -4.1899, -4.1899, -4.1899,
           -4.1899, -4.1899, -4.1899, -4.1899, -4.1899, -4.1899, -4.1899,
           -4.1899],
          [-4.1899, -4.1899, -4.1899, -4.1899, -4.1899, -4.1899, -4.1899,
           -4.1899, -4.1899, -4.1899, -4.1899, -4.1899, -4.1899, -4.1899,
           -4.1899],
          [-4.1899, -4.1899, -4.1899, -4.1899, -4.1899, -4.1899, -4.1899,
           -4.1899, -4.1899, -4.1899, -4.1899, -4.1899, -4.1899, -4.1899,
           -4.1899],
          [-4.1899, -4.1899, -4.1899, -4.1899, -4.1899, -4.1899, -4.1899,
           -4.1899, -4.1899, -4.1899, -4.1899, -4.1899, -4.1899, -4.1899,
           -4.1899],
          [-4.1899, -4.1899, -4.1899, -4.1899, -4.1899, -4.1899, -4.1899,
           -4.1899, -4.1899, -4.1899, -4.1899, -4.1899, -4.1899, -4.1899,
           -4.1899],
          [-4.1899, -4.1899, -4.1899, -4.1899, -4.1899, -4.1899, -4.1899,
           -4.1899, -4.1899, -4.1899, -4.1899, -4.1899, -4.1899, -4.1899,
           -4.1899],
          [-4.1899, -4.1899, -4.1899, -4.1899, -4.1899, -4.1899, -4.1899,
           -4.1899, -4.1899, -4.1899, -4.1899, -4.1899, -4.1899, -4.1899,
           -4.1899],
          [-4.1899, -4.1899, -4.1899, -4.1899, -4.1899, -4.1899, -4.1899,
           -4.1899, -4.1899, -4.1899, -4.1899, -4.1899, -4.1899, -4.1899,
           -4.1899],
          [-4.1899, -4.1899, -4.1899, -4.1899, -4.1899, -4.1899, -4.1899,
           -4.1899, -4.1899, -4.1899, -4.1899, -4.1899, -4.1899, -4.1899,
           -4.1899],
          [-4.1899, -4.1899, -4.1899, -4.1899, -4.1899, -4.1899, -4.1899,
           -4.1899, -4.1899, -4.1899, -4.1899, -4.1899, -4.1899, -4.1899,
           -4.1899],
          [-4.1986, -4.1985, -4.1986, -4.1986, -4.1986, -4.1986, -4.1986,
           -4.1986, -4.1986, -4.1986, -4.1986, -4.1986, -4.1986, -4.1986,
           -4.1986],
          [-4.1899, -4.1899, -4.1899, -4.1899, -4.1899, -4.1899, -4.1899,
           -4.1899, -4.1899, -4.1899, -4.1899, -4.1899, -4.1899, -4.1899,
           -4.1899]],

         [[-3.9166, -3.9167, -3.9167, -3.9167, -3.9167, -3.9167, -3.9166,
           -3.9166, -3.9166, -3.9166, -3.9166, -3.9166, -3.9167, -3.9167,
           -3.9167],
          [-3.9166, -3.9167, -3.9167, -3.9167, -3.9167, -3.9167, -3.9166,
           -3.9166, -3.9166, -3.9166, -3.9166, -3.9166, -3.9167, -3.9167,
           -3.9167],
          [-3.9166, -3.9167, -3.9167, -3.9167, -3.9167, -3.9167, -3.9166,
           -3.9166, -3.9166, -3.9166, -3.9166, -3.9166, -3.9167, -3.9167,
           -3.9167],
          [-3.9166, -3.9167, -3.9167, -3.9167, -3.9167, -3.9167, -3.9166,
           -3.9166, -3.9166, -3.9166, -3.9166, -3.9166, -3.9167, -3.9167,
           -3.9167],
          [-3.9166, -3.9167, -3.9167, -3.9167, -3.9167, -3.9167, -3.9166,
           -3.9166, -3.9166, -3.9166, -3.9166, -3.9166, -3.9167, -3.9167,
           -3.9167],
          [-3.9166, -3.9167, -3.9167, -3.9167, -3.9167, -3.9167, -3.9166,
           -3.9166, -3.9166, -3.9166, -3.9166, -3.9166, -3.9167, -3.9167,
           -3.9167],
          [-3.9166, -3.9167, -3.9167, -3.9167, -3.9167, -3.9167, -3.9166,
           -3.9166, -3.9166, -3.9166, -3.9166, -3.9166, -3.9167, -3.9167,
           -3.9167],
          [-3.9166, -3.9167, -3.9167, -3.9167, -3.9167, -3.9167, -3.9166,
           -3.9166, -3.9166, -3.9166, -3.9166, -3.9166, -3.9167, -3.9167,
           -3.9167],
          [-3.9166, -3.9167, -3.9167, -3.9167, -3.9167, -3.9167, -3.9166,
           -3.9166, -3.9166, -3.9166, -3.9166, -3.9166, -3.9167, -3.9167,
           -3.9167],
          [-3.9166, -3.9167, -3.9167, -3.9167, -3.9167, -3.9167, -3.9166,
           -3.9166, -3.9166, -3.9166, -3.9166, -3.9166, -3.9167, -3.9167,
           -3.9167],
          [-3.9166, -3.9167, -3.9167, -3.9167, -3.9167, -3.9167, -3.9166,
           -3.9166, -3.9166, -3.9166, -3.9166, -3.9166, -3.9167, -3.9167,
           -3.9167],
          [-3.9166, -3.9167, -3.9167, -3.9167, -3.9167, -3.9167, -3.9166,
           -3.9166, -3.9166, -3.9166, -3.9166, -3.9166, -3.9167, -3.9167,
           -3.9167],
          [-3.9166, -3.9167, -3.9167, -3.9167, -3.9167, -3.9167, -3.9166,
           -3.9166, -3.9166, -3.9166, -3.9166, -3.9166, -3.9167, -3.9167,
           -3.9167],
          [-3.9166, -3.9167, -3.9167, -3.9167, -3.9167, -3.9167, -3.9166,
           -3.9166, -3.9166, -3.9166, -3.9166, -3.9166, -3.9167, -3.9167,
           -3.9167],
          [-3.9258, -3.9258, -3.9258, -3.9258, -3.9258, -3.9258, -3.9258,
           -3.9258, -3.9258, -3.9258, -3.9258, -3.9258, -3.9258, -3.9258,
           -3.9258],
          [-3.9166, -3.9167, -3.9167, -3.9167, -3.9167, -3.9167, -3.9166,
           -3.9166, -3.9166, -3.9166, -3.9166, -3.9166, -3.9167, -3.9167,
           -3.9167]]],


        [[[-4.6326, -4.6326, -4.6326, -4.6326, -4.6326, -4.6326, -4.6326,
           -4.6326, -4.6326, -4.6326, -4.6326, -4.6326, -4.6326, -4.6326,
           -4.6326],
          [-4.6326, -4.6326, -4.6326, -4.6326, -4.6326, -4.6326, -4.6326,
           -4.6326, -4.6326, -4.6326, -4.6326, -4.6326, -4.6326, -4.6326,
           -4.6326],
          [-4.6326, -4.6326, -4.6326, -4.6326, -4.6326, -4.6326, -4.6326,
           -4.6326, -4.6326, -4.6326, -4.6326, -4.6326, -4.6326, -4.6326,
           -4.6326],
          [-4.6326, -4.6326, -4.6326, -4.6326, -4.6326, -4.6326, -4.6326,
           -4.6326, -4.6326, -4.6326, -4.6326, -4.6326, -4.6326, -4.6326,
           -4.6326],
          [-4.6326, -4.6326, -4.6326, -4.6326, -4.6326, -4.6326, -4.6326,
           -4.6326, -4.6326, -4.6326, -4.6326, -4.6326, -4.6326, -4.6326,
           -4.6326],
          [-4.6326, -4.6326, -4.6326, -4.6326, -4.6326, -4.6326, -4.6326,
           -4.6326, -4.6326, -4.6326, -4.6326, -4.6326, -4.6326, -4.6326,
           -4.6326],
          [-4.6326, -4.6326, -4.6326, -4.6326, -4.6326, -4.6326, -4.6326,
           -4.6326, -4.6326, -4.6326, -4.6326, -4.6326, -4.6326, -4.6326,
           -4.6326],
          [-4.6326, -4.6326, -4.6326, -4.6326, -4.6326, -4.6326, -4.6326,
           -4.6326, -4.6326, -4.6326, -4.6326, -4.6326, -4.6326, -4.6326,
           -4.6326],
          [-4.6326, -4.6326, -4.6326, -4.6326, -4.6326, -4.6326, -4.6326,
           -4.6326, -4.6326, -4.6326, -4.6326, -4.6326, -4.6326, -4.6326,
           -4.6326],
          [-4.6326, -4.6326, -4.6326, -4.6326, -4.6326, -4.6326, -4.6326,
           -4.6326, -4.6326, -4.6326, -4.6326, -4.6326, -4.6326, -4.6326,
           -4.6326],
          [-4.6326, -4.6326, -4.6326, -4.6326, -4.6326, -4.6326, -4.6326,
           -4.6326, -4.6326, -4.6326, -4.6326, -4.6326, -4.6326, -4.6326,
           -4.6326],
          [-4.6326, -4.6326, -4.6326, -4.6326, -4.6326, -4.6326, -4.6326,
           -4.6326, -4.6326, -4.6326, -4.6326, -4.6326, -4.6326, -4.6326,
           -4.6326],
          [-4.6326, -4.6326, -4.6326, -4.6326, -4.6326, -4.6326, -4.6326,
           -4.6326, -4.6326, -4.6326, -4.6326, -4.6326, -4.6326, -4.6326,
           -4.6326],
          [-4.6326, -4.6326, -4.6326, -4.6326, -4.6326, -4.6326, -4.6326,
           -4.6326, -4.6326, -4.6326, -4.6326, -4.6326, -4.6326, -4.6326,
           -4.6326],
          [-4.4102, -4.4102, -4.4102, -4.4102, -4.4102, -4.4102, -4.4102,
           -4.4102, -4.4102, -4.4102, -4.4102, -4.4102, -4.4102, -4.4102,
           -4.4102],
          [-4.6326, -4.6326, -4.6326, -4.6326, -4.6326, -4.6326, -4.6326,
           -4.6326, -4.6326, -4.6326, -4.6326, -4.6326, -4.6326, -4.6326,
           -4.6326]],

         [[-4.4623, -4.4623, -4.4623, -4.4623, -4.4623, -4.4623, -4.4623,
           -4.4623, -4.4623, -4.4623, -4.4623, -4.4622, -4.4623, -4.4623,
           -4.4623],
          [-4.4623, -4.4623, -4.4623, -4.4623, -4.4623, -4.4623, -4.4623,
           -4.4623, -4.4623, -4.4623, -4.4623, -4.4622, -4.4623, -4.4623,
           -4.4623],
          [-4.4623, -4.4623, -4.4623, -4.4623, -4.4623, -4.4623, -4.4623,
           -4.4623, -4.4623, -4.4623, -4.4623, -4.4622, -4.4623, -4.4623,
           -4.4623],
          [-4.4623, -4.4623, -4.4623, -4.4623, -4.4623, -4.4623, -4.4623,
           -4.4623, -4.4623, -4.4623, -4.4623, -4.4622, -4.4623, -4.4623,
           -4.4623],
          [-4.4623, -4.4623, -4.4623, -4.4623, -4.4623, -4.4623, -4.4623,
           -4.4623, -4.4623, -4.4623, -4.4623, -4.4622, -4.4623, -4.4623,
           -4.4623],
          [-4.4623, -4.4623, -4.4623, -4.4623, -4.4623, -4.4623, -4.4623,
           -4.4623, -4.4623, -4.4623, -4.4623, -4.4622, -4.4623, -4.4623,
           -4.4623],
          [-4.4623, -4.4623, -4.4623, -4.4623, -4.4623, -4.4623, -4.4623,
           -4.4623, -4.4623, -4.4623, -4.4623, -4.4622, -4.4623, -4.4623,
           -4.4623],
          [-4.4623, -4.4623, -4.4623, -4.4623, -4.4623, -4.4623, -4.4623,
           -4.4623, -4.4623, -4.4623, -4.4623, -4.4622, -4.4623, -4.4623,
           -4.4623],
          [-4.4623, -4.4623, -4.4623, -4.4623, -4.4623, -4.4623, -4.4623,
           -4.4623, -4.4623, -4.4623, -4.4623, -4.4622, -4.4623, -4.4623,
           -4.4623],
          [-4.4623, -4.4623, -4.4623, -4.4623, -4.4623, -4.4623, -4.4623,
           -4.4623, -4.4623, -4.4623, -4.4623, -4.4622, -4.4623, -4.4623,
           -4.4623],
          [-4.4623, -4.4623, -4.4623, -4.4623, -4.4623, -4.4623, -4.4623,
           -4.4623, -4.4623, -4.4623, -4.4623, -4.4622, -4.4623, -4.4623,
           -4.4623],
          [-4.4623, -4.4623, -4.4623, -4.4623, -4.4623, -4.4623, -4.4623,
           -4.4623, -4.4623, -4.4623, -4.4623, -4.4622, -4.4623, -4.4623,
           -4.4623],
          [-4.4623, -4.4623, -4.4623, -4.4623, -4.4623, -4.4623, -4.4623,
           -4.4623, -4.4623, -4.4623, -4.4623, -4.4622, -4.4623, -4.4623,
           -4.4623],
          [-4.4623, -4.4623, -4.4623, -4.4623, -4.4623, -4.4623, -4.4623,
           -4.4623, -4.4623, -4.4623, -4.4623, -4.4622, -4.4623, -4.4623,
           -4.4623],
          [-4.2275, -4.2275, -4.2275, -4.2275, -4.2275, -4.2275, -4.2275,
           -4.2275, -4.2275, -4.2275, -4.2275, -4.2275, -4.2275, -4.2275,
           -4.2275],
          [-4.4623, -4.4623, -4.4623, -4.4623, -4.4623, -4.4623, -4.4623,
           -4.4623, -4.4623, -4.4623, -4.4623, -4.4622, -4.4623, -4.4623,
           -4.4623]]]], grad_fn=<SliceBackward0>)
train_step: Entropy shape: torch.Size([16, 15])
train_step: Entropy sample: tensor([[0.5690, 0.6848],
        [0.6618, 0.6906]], grad_fn=<SliceBackward0>)
train_step: Entropy coefficient: 0.01
train_step: Actor loss: -1.3416125774383545
train_step: returns shape after mean: torch.Size([16, 15])
train_step: target_indices shape: torch.Size([16, 15])
train_step: value_logits shape: torch.Size([16, 15, 255])
train_step: target_twohot shape: torch.Size([16, 15, 255])
--- Starting train_step at 2025-04-01 01:54:09 ---
Full starting_state: {'deter': tensor([[[-0.0664, -0.0078, -0.1132,  ...,  0.0905,  0.2305,  0.0139],
         [ 0.0064,  0.0859, -0.0413,  ...,  0.1361,  0.1964, -0.0422],
         [ 0.0172, -0.0857,  0.0952,  ...,  0.0117,  0.0459, -0.1188],
         ...,
         [ 0.0916, -0.0883, -0.0445,  ...,  0.1413,  0.0124, -0.0769],
         [-0.1377,  0.0215, -0.0612,  ..., -0.0603, -0.0806, -0.0864],
         [-0.1263, -0.0303, -0.0312,  ...,  0.0397,  0.0089, -0.1107]],

        [[ 0.0018,  0.0232, -0.1126,  ..., -0.0367, -0.0598, -0.1214],
         [-0.1586,  0.1247,  0.0412,  ..., -0.1629,  0.1532,  0.0509],
         [-0.0621,  0.0466,  0.0070,  ..., -0.1389, -0.1288, -0.0331],
         ...,
         [-0.0269, -0.0356, -0.0202,  ..., -0.0142, -0.0230, -0.0093],
         [-0.1148,  0.0117, -0.0390,  ...,  0.0061,  0.0847, -0.0651],
         [ 0.0576,  0.0640, -0.1677,  ...,  0.0617,  0.0441, -0.0512]],

        [[-0.0472,  0.0043, -0.0474,  ..., -0.0295,  0.0108,  0.0231],
         [-0.0546,  0.0618, -0.0488,  ..., -0.0150, -0.1539, -0.0833],
         [-0.0376, -0.0023, -0.0485,  ...,  0.0028, -0.0734,  0.0452],
         ...,
         [ 0.1598,  0.0305, -0.0725,  ..., -0.0913, -0.0370,  0.0895],
         [ 0.0608, -0.0372,  0.0101,  ...,  0.0639,  0.1024,  0.0547],
         [-0.1078, -0.0372, -0.0712,  ...,  0.0163,  0.2378, -0.0049]],

        ...,

        [[-0.0922, -0.0262,  0.1147,  ...,  0.2005, -0.2129,  0.0310],
         [-0.0022, -0.0491, -0.0384,  ...,  0.1200,  0.1259, -0.2323],
         [-0.0323, -0.0555, -0.1624,  ...,  0.1684,  0.0155,  0.0923],
         ...,
         [ 0.0826, -0.0423,  0.0006,  ..., -0.0673,  0.0876, -0.0664],
         [-0.0932,  0.0330,  0.0445,  ..., -0.0691, -0.1373, -0.0797],
         [-0.0323,  0.1292, -0.0491,  ..., -0.1449, -0.0105, -0.1297]],

        [[ 0.1028, -0.0148, -0.1524,  ...,  0.0697,  0.1066,  0.0726],
         [-0.1634, -0.0766,  0.0274,  ..., -0.0987, -0.1057, -0.1241],
         [-0.0564, -0.1257,  0.0617,  ..., -0.1978,  0.0475, -0.0038],
         ...,
         [ 0.0721,  0.1156, -0.1276,  ...,  0.0723,  0.1694,  0.0434],
         [-0.1521, -0.0296, -0.2152,  ..., -0.2553,  0.0142, -0.0429],
         [-0.0216,  0.0886, -0.1540,  ..., -0.0150,  0.0423,  0.0565]],

        [[-0.0052, -0.0759, -0.0299,  ...,  0.1162,  0.0815, -0.1208],
         [ 0.0938,  0.0835, -0.0828,  ...,  0.0362, -0.0729, -0.0244],
         [-0.1260, -0.0180, -0.1750,  ...,  0.0681,  0.1616, -0.1264],
         ...,
         [-0.1032, -0.0064,  0.1035,  ...,  0.0013,  0.0976, -0.0374],
         [ 0.0854, -0.0010, -0.0771,  ..., -0.0708, -0.0127,  0.0337],
         [-0.0617, -0.0503, -0.0756,  ..., -0.0620,  0.0612,  0.0609]]],
       grad_fn=<StackBackward0>), 'stoch': tensor([[[0., 0., 0.,  ..., 0., 1., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 1., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 1.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 1.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 1.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 1., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 1.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 1.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 1.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 1., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 1.,  ..., 0., 0., 0.]]])}
train_step: Starting state deter shape: torch.Size([16, 50, 128])
train_step: Starting state stoch shape: torch.Size([16, 50, 1024])
After ensuring logits/stoch: {'deter': tensor([[[-0.0664, -0.0078, -0.1132,  ...,  0.0905,  0.2305,  0.0139],
         [ 0.0064,  0.0859, -0.0413,  ...,  0.1361,  0.1964, -0.0422],
         [ 0.0172, -0.0857,  0.0952,  ...,  0.0117,  0.0459, -0.1188],
         ...,
         [ 0.0916, -0.0883, -0.0445,  ...,  0.1413,  0.0124, -0.0769],
         [-0.1377,  0.0215, -0.0612,  ..., -0.0603, -0.0806, -0.0864],
         [-0.1263, -0.0303, -0.0312,  ...,  0.0397,  0.0089, -0.1107]],

        [[ 0.0018,  0.0232, -0.1126,  ..., -0.0367, -0.0598, -0.1214],
         [-0.1586,  0.1247,  0.0412,  ..., -0.1629,  0.1532,  0.0509],
         [-0.0621,  0.0466,  0.0070,  ..., -0.1389, -0.1288, -0.0331],
         ...,
         [-0.0269, -0.0356, -0.0202,  ..., -0.0142, -0.0230, -0.0093],
         [-0.1148,  0.0117, -0.0390,  ...,  0.0061,  0.0847, -0.0651],
         [ 0.0576,  0.0640, -0.1677,  ...,  0.0617,  0.0441, -0.0512]],

        [[-0.0472,  0.0043, -0.0474,  ..., -0.0295,  0.0108,  0.0231],
         [-0.0546,  0.0618, -0.0488,  ..., -0.0150, -0.1539, -0.0833],
         [-0.0376, -0.0023, -0.0485,  ...,  0.0028, -0.0734,  0.0452],
         ...,
         [ 0.1598,  0.0305, -0.0725,  ..., -0.0913, -0.0370,  0.0895],
         [ 0.0608, -0.0372,  0.0101,  ...,  0.0639,  0.1024,  0.0547],
         [-0.1078, -0.0372, -0.0712,  ...,  0.0163,  0.2378, -0.0049]],

        ...,

        [[-0.0922, -0.0262,  0.1147,  ...,  0.2005, -0.2129,  0.0310],
         [-0.0022, -0.0491, -0.0384,  ...,  0.1200,  0.1259, -0.2323],
         [-0.0323, -0.0555, -0.1624,  ...,  0.1684,  0.0155,  0.0923],
         ...,
         [ 0.0826, -0.0423,  0.0006,  ..., -0.0673,  0.0876, -0.0664],
         [-0.0932,  0.0330,  0.0445,  ..., -0.0691, -0.1373, -0.0797],
         [-0.0323,  0.1292, -0.0491,  ..., -0.1449, -0.0105, -0.1297]],

        [[ 0.1028, -0.0148, -0.1524,  ...,  0.0697,  0.1066,  0.0726],
         [-0.1634, -0.0766,  0.0274,  ..., -0.0987, -0.1057, -0.1241],
         [-0.0564, -0.1257,  0.0617,  ..., -0.1978,  0.0475, -0.0038],
         ...,
         [ 0.0721,  0.1156, -0.1276,  ...,  0.0723,  0.1694,  0.0434],
         [-0.1521, -0.0296, -0.2152,  ..., -0.2553,  0.0142, -0.0429],
         [-0.0216,  0.0886, -0.1540,  ..., -0.0150,  0.0423,  0.0565]],

        [[-0.0052, -0.0759, -0.0299,  ...,  0.1162,  0.0815, -0.1208],
         [ 0.0938,  0.0835, -0.0828,  ...,  0.0362, -0.0729, -0.0244],
         [-0.1260, -0.0180, -0.1750,  ...,  0.0681,  0.1616, -0.1264],
         ...,
         [-0.1032, -0.0064,  0.1035,  ...,  0.0013,  0.0976, -0.0374],
         [ 0.0854, -0.0010, -0.0771,  ..., -0.0708, -0.0127,  0.0337],
         [-0.0617, -0.0503, -0.0756,  ..., -0.0620,  0.0612,  0.0609]]],
       grad_fn=<StackBackward0>), 'stoch': tensor([[[0., 0., 0.,  ..., 0., 1., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 1., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 1.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 1.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 1.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 1., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 1.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 1.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 1.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 1., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 1.,  ..., 0., 0., 0.]]]), 'logits': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]])}
train_step: Normalized hidden_state shape: torch.Size([1, 16, 128])
train_step: Normalized stoch shape: torch.Size([16, 1024])
train_step: Normalized deter shape: torch.Size([16, 128])
train_step: Post-imagine_trajectory: Imagined features shape: torch.Size([16, 15, 1152])
train_step: Post-imagine_trajectory: Imagined actions shape: torch.Size([16, 15, 2])
train_step: Post-imagine_trajectory: Imagined action indices shape: torch.Size([16, 15])
train_step: Post-imagine_trajectory: Imagined state deter shape: torch.Size([16, 15, 128])
train_step: Post-imagine_trajectory: Imagined state stoch shape: torch.Size([16, 15, 1024])
Reward shape: torch.Size([16, 15, 1]), Value shape: torch.Size([16, 15, 1]), Slow Value shape: torch.Size([16, 15, 1]), Discount shape: torch.Size([16, 15, 1, 1])
Return targets length: 15, First target shape: torch.Size([16, 16, 1])
train_step: Actor distribution shape: torch.Size([16, 15, 2])
train_step: Action log probabilities shape: torch.Size([16, 15])
train_step: Action log probabilities sample: tensor([[-1.2120, -0.2280],
        [-0.5549, -0.0896]], grad_fn=<SliceBackward0>)
train_step: Advantages shape: torch.Size([16, 15, 16, 15])
train_step: Advantages sample: tensor([[[[-9.3686, -9.3686, -9.3687, -9.3687, -9.3687, -9.3687, -9.3687,
           -9.3687, -9.3686, -9.3687, -9.3687, -9.3687, -9.3686, -9.3687,
           -9.3686],
          [-9.3686, -9.3686, -9.3687, -9.3687, -9.3687, -9.3687, -9.3687,
           -9.3687, -9.3686, -9.3687, -9.3687, -9.3687, -9.3686, -9.3687,
           -9.3686],
          [-9.3686, -9.3686, -9.3687, -9.3687, -9.3687, -9.3687, -9.3687,
           -9.3687, -9.3686, -9.3687, -9.3687, -9.3687, -9.3686, -9.3687,
           -9.3686],
          [-9.3686, -9.3686, -9.3687, -9.3687, -9.3687, -9.3687, -9.3687,
           -9.3687, -9.3686, -9.3687, -9.3687, -9.3687, -9.3686, -9.3687,
           -9.3686],
          [-9.3686, -9.3686, -9.3687, -9.3687, -9.3687, -9.3687, -9.3687,
           -9.3687, -9.3686, -9.3687, -9.3687, -9.3687, -9.3686, -9.3687,
           -9.3686],
          [-9.3686, -9.3686, -9.3687, -9.3687, -9.3687, -9.3687, -9.3687,
           -9.3687, -9.3686, -9.3687, -9.3687, -9.3687, -9.3686, -9.3687,
           -9.3686],
          [-9.3686, -9.3686, -9.3687, -9.3687, -9.3687, -9.3687, -9.3687,
           -9.3687, -9.3686, -9.3687, -9.3687, -9.3687, -9.3686, -9.3687,
           -9.3686],
          [-9.3686, -9.3686, -9.3687, -9.3687, -9.3687, -9.3687, -9.3687,
           -9.3687, -9.3686, -9.3687, -9.3687, -9.3687, -9.3686, -9.3687,
           -9.3686],
          [-9.3686, -9.3686, -9.3687, -9.3687, -9.3687, -9.3687, -9.3687,
           -9.3687, -9.3686, -9.3687, -9.3687, -9.3687, -9.3686, -9.3687,
           -9.3686],
          [-9.3686, -9.3686, -9.3687, -9.3687, -9.3687, -9.3687, -9.3687,
           -9.3687, -9.3686, -9.3687, -9.3687, -9.3687, -9.3686, -9.3687,
           -9.3686],
          [-9.3686, -9.3686, -9.3687, -9.3687, -9.3687, -9.3687, -9.3687,
           -9.3687, -9.3686, -9.3687, -9.3687, -9.3687, -9.3686, -9.3687,
           -9.3686],
          [-9.3686, -9.3686, -9.3687, -9.3687, -9.3687, -9.3687, -9.3687,
           -9.3687, -9.3686, -9.3687, -9.3687, -9.3687, -9.3686, -9.3687,
           -9.3686],
          [-9.3686, -9.3686, -9.3687, -9.3687, -9.3687, -9.3687, -9.3687,
           -9.3687, -9.3686, -9.3687, -9.3687, -9.3687, -9.3686, -9.3687,
           -9.3686],
          [-9.3686, -9.3686, -9.3687, -9.3687, -9.3687, -9.3687, -9.3687,
           -9.3687, -9.3686, -9.3687, -9.3687, -9.3687, -9.3686, -9.3687,
           -9.3686],
          [-0.8794, -0.8794, -0.8795, -0.8795, -0.8795, -0.8795, -0.8795,
           -0.8795, -0.8794, -0.8795, -0.8795, -0.8795, -0.8795, -0.8795,
           -0.8794],
          [-9.3686, -9.3686, -9.3687, -9.3687, -9.3687, -9.3687, -9.3687,
           -9.3687, -9.3686, -9.3687, -9.3687, -9.3687, -9.3686, -9.3687,
           -9.3686]],

         [[-8.9625, -8.9626, -8.9625, -8.9625, -8.9625, -8.9626, -8.9625,
           -8.9625, -8.9626, -8.9625, -8.9626, -8.9626, -8.9625, -8.9626,
           -8.9625],
          [-8.9625, -8.9626, -8.9625, -8.9625, -8.9625, -8.9626, -8.9625,
           -8.9625, -8.9626, -8.9625, -8.9626, -8.9626, -8.9625, -8.9626,
           -8.9625],
          [-8.9625, -8.9626, -8.9625, -8.9625, -8.9625, -8.9626, -8.9625,
           -8.9625, -8.9626, -8.9625, -8.9626, -8.9626, -8.9625, -8.9626,
           -8.9625],
          [-8.9625, -8.9626, -8.9625, -8.9625, -8.9625, -8.9626, -8.9625,
           -8.9625, -8.9626, -8.9625, -8.9626, -8.9626, -8.9625, -8.9626,
           -8.9625],
          [-8.9625, -8.9626, -8.9625, -8.9625, -8.9625, -8.9626, -8.9625,
           -8.9625, -8.9626, -8.9625, -8.9626, -8.9626, -8.9625, -8.9626,
           -8.9625],
          [-8.9625, -8.9626, -8.9625, -8.9625, -8.9625, -8.9626, -8.9625,
           -8.9625, -8.9626, -8.9625, -8.9626, -8.9626, -8.9625, -8.9626,
           -8.9625],
          [-8.9625, -8.9626, -8.9625, -8.9625, -8.9625, -8.9626, -8.9625,
           -8.9625, -8.9626, -8.9625, -8.9626, -8.9626, -8.9625, -8.9626,
           -8.9625],
          [-8.9625, -8.9626, -8.9625, -8.9625, -8.9625, -8.9626, -8.9625,
           -8.9625, -8.9626, -8.9625, -8.9626, -8.9626, -8.9625, -8.9626,
           -8.9625],
          [-8.9625, -8.9626, -8.9625, -8.9625, -8.9625, -8.9626, -8.9625,
           -8.9625, -8.9626, -8.9625, -8.9626, -8.9626, -8.9625, -8.9626,
           -8.9625],
          [-8.9625, -8.9626, -8.9625, -8.9625, -8.9625, -8.9626, -8.9625,
           -8.9625, -8.9626, -8.9625, -8.9626, -8.9626, -8.9625, -8.9626,
           -8.9625],
          [-8.9625, -8.9626, -8.9625, -8.9625, -8.9625, -8.9626, -8.9625,
           -8.9625, -8.9626, -8.9625, -8.9626, -8.9626, -8.9625, -8.9626,
           -8.9625],
          [-8.9625, -8.9626, -8.9625, -8.9625, -8.9625, -8.9626, -8.9625,
           -8.9625, -8.9626, -8.9625, -8.9626, -8.9626, -8.9625, -8.9626,
           -8.9625],
          [-8.9625, -8.9626, -8.9625, -8.9625, -8.9625, -8.9626, -8.9625,
           -8.9625, -8.9626, -8.9625, -8.9626, -8.9626, -8.9625, -8.9626,
           -8.9625],
          [-8.9625, -8.9626, -8.9625, -8.9625, -8.9625, -8.9626, -8.9625,
           -8.9625, -8.9626, -8.9625, -8.9626, -8.9626, -8.9625, -8.9626,
           -8.9625],
          [-8.9625, -8.9626, -8.9625, -8.9625, -8.9625, -8.9626, -8.9625,
           -8.9625, -8.9626, -8.9625, -8.9626, -8.9626, -8.9625, -8.9626,
           -8.9625],
          [-8.9625, -8.9626, -8.9625, -8.9625, -8.9625, -8.9626, -8.9625,
           -8.9625, -8.9626, -8.9625, -8.9626, -8.9626, -8.9625, -8.9626,
           -8.9625]]],


        [[[-7.4423, -7.4423, -7.4423, -7.4423, -7.4423, -7.4424, -7.4423,
           -7.4423, -7.4423, -7.4423, -7.4423, -7.4423, -7.4423, -7.4423,
           -7.4423],
          [-7.4423, -7.4423, -7.4423, -7.4423, -7.4423, -7.4424, -7.4423,
           -7.4423, -7.4423, -7.4423, -7.4423, -7.4423, -7.4423, -7.4423,
           -7.4423],
          [-7.4423, -7.4423, -7.4423, -7.4423, -7.4423, -7.4424, -7.4423,
           -7.4423, -7.4423, -7.4423, -7.4423, -7.4423, -7.4423, -7.4423,
           -7.4423],
          [-7.4423, -7.4423, -7.4423, -7.4423, -7.4423, -7.4424, -7.4423,
           -7.4423, -7.4423, -7.4423, -7.4423, -7.4423, -7.4423, -7.4423,
           -7.4423],
          [-7.4423, -7.4423, -7.4423, -7.4423, -7.4423, -7.4424, -7.4423,
           -7.4423, -7.4423, -7.4423, -7.4423, -7.4423, -7.4423, -7.4423,
           -7.4423],
          [-7.4423, -7.4423, -7.4423, -7.4423, -7.4423, -7.4424, -7.4423,
           -7.4423, -7.4423, -7.4423, -7.4423, -7.4423, -7.4423, -7.4423,
           -7.4423],
          [-7.4423, -7.4423, -7.4423, -7.4423, -7.4423, -7.4424, -7.4423,
           -7.4423, -7.4423, -7.4423, -7.4423, -7.4423, -7.4423, -7.4423,
           -7.4423],
          [-7.4423, -7.4423, -7.4423, -7.4423, -7.4423, -7.4424, -7.4423,
           -7.4423, -7.4423, -7.4423, -7.4423, -7.4423, -7.4423, -7.4423,
           -7.4423],
          [-7.4423, -7.4423, -7.4423, -7.4423, -7.4423, -7.4424, -7.4423,
           -7.4423, -7.4423, -7.4423, -7.4423, -7.4423, -7.4423, -7.4423,
           -7.4423],
          [-7.4423, -7.4423, -7.4423, -7.4423, -7.4423, -7.4424, -7.4423,
           -7.4423, -7.4423, -7.4423, -7.4423, -7.4423, -7.4423, -7.4423,
           -7.4423],
          [-7.4423, -7.4423, -7.4423, -7.4423, -7.4423, -7.4424, -7.4423,
           -7.4423, -7.4423, -7.4423, -7.4423, -7.4423, -7.4423, -7.4423,
           -7.4423],
          [-7.4423, -7.4423, -7.4423, -7.4423, -7.4423, -7.4424, -7.4423,
           -7.4423, -7.4423, -7.4423, -7.4423, -7.4423, -7.4423, -7.4423,
           -7.4423],
          [-7.4423, -7.4423, -7.4423, -7.4423, -7.4423, -7.4424, -7.4423,
           -7.4423, -7.4423, -7.4423, -7.4423, -7.4423, -7.4423, -7.4423,
           -7.4423],
          [-7.4423, -7.4423, -7.4423, -7.4423, -7.4423, -7.4424, -7.4423,
           -7.4423, -7.4423, -7.4423, -7.4423, -7.4423, -7.4423, -7.4423,
           -7.4423],
          [-0.3076, -0.3076, -0.3077, -0.3077, -0.3077, -0.3077, -0.3077,
           -0.3077, -0.3076, -0.3077, -0.3077, -0.3077, -0.3076, -0.3077,
           -0.3076],
          [-7.4423, -7.4423, -7.4423, -7.4423, -7.4423, -7.4424, -7.4423,
           -7.4423, -7.4423, -7.4423, -7.4423, -7.4423, -7.4423, -7.4423,
           -7.4423]],

         [[-7.5324, -7.5324, -7.5324, -7.5324, -7.5324, -7.5324, -7.5324,
           -7.5324, -7.5324, -7.5324, -7.5325, -7.5324, -7.5324, -7.5324,
           -7.5324],
          [-7.5324, -7.5324, -7.5324, -7.5324, -7.5324, -7.5324, -7.5324,
           -7.5324, -7.5324, -7.5324, -7.5325, -7.5324, -7.5324, -7.5324,
           -7.5324],
          [-7.5324, -7.5324, -7.5324, -7.5324, -7.5324, -7.5324, -7.5324,
           -7.5324, -7.5324, -7.5324, -7.5325, -7.5324, -7.5324, -7.5324,
           -7.5324],
          [-7.5324, -7.5324, -7.5324, -7.5324, -7.5324, -7.5324, -7.5324,
           -7.5324, -7.5324, -7.5324, -7.5325, -7.5324, -7.5324, -7.5324,
           -7.5324],
          [-7.5324, -7.5324, -7.5324, -7.5324, -7.5324, -7.5324, -7.5324,
           -7.5324, -7.5324, -7.5324, -7.5325, -7.5324, -7.5324, -7.5324,
           -7.5324],
          [-7.5324, -7.5324, -7.5324, -7.5324, -7.5324, -7.5324, -7.5324,
           -7.5324, -7.5324, -7.5324, -7.5325, -7.5324, -7.5324, -7.5324,
           -7.5324],
          [-7.5324, -7.5324, -7.5324, -7.5324, -7.5324, -7.5324, -7.5324,
           -7.5324, -7.5324, -7.5324, -7.5325, -7.5324, -7.5324, -7.5324,
           -7.5324],
          [-7.5324, -7.5324, -7.5324, -7.5324, -7.5324, -7.5324, -7.5324,
           -7.5324, -7.5324, -7.5324, -7.5325, -7.5324, -7.5324, -7.5324,
           -7.5324],
          [-7.5324, -7.5324, -7.5324, -7.5324, -7.5324, -7.5324, -7.5324,
           -7.5324, -7.5324, -7.5324, -7.5325, -7.5324, -7.5324, -7.5324,
           -7.5324],
          [-7.5324, -7.5324, -7.5324, -7.5324, -7.5324, -7.5324, -7.5324,
           -7.5324, -7.5324, -7.5324, -7.5325, -7.5324, -7.5324, -7.5324,
           -7.5324],
          [-7.5324, -7.5324, -7.5324, -7.5324, -7.5324, -7.5324, -7.5324,
           -7.5324, -7.5324, -7.5324, -7.5325, -7.5324, -7.5324, -7.5324,
           -7.5324],
          [-7.5324, -7.5324, -7.5324, -7.5324, -7.5324, -7.5324, -7.5324,
           -7.5324, -7.5324, -7.5324, -7.5325, -7.5324, -7.5324, -7.5324,
           -7.5324],
          [-7.5324, -7.5324, -7.5324, -7.5324, -7.5324, -7.5324, -7.5324,
           -7.5324, -7.5324, -7.5324, -7.5325, -7.5324, -7.5324, -7.5324,
           -7.5324],
          [-7.5324, -7.5324, -7.5324, -7.5324, -7.5324, -7.5324, -7.5324,
           -7.5324, -7.5324, -7.5324, -7.5325, -7.5324, -7.5324, -7.5324,
           -7.5324],
          [-7.5324, -7.5324, -7.5324, -7.5324, -7.5324, -7.5324, -7.5324,
           -7.5324, -7.5324, -7.5324, -7.5325, -7.5324, -7.5324, -7.5324,
           -7.5324],
          [-7.5324, -7.5324, -7.5324, -7.5324, -7.5324, -7.5324, -7.5324,
           -7.5324, -7.5324, -7.5324, -7.5325, -7.5324, -7.5324, -7.5324,
           -7.5324]]]], grad_fn=<SliceBackward0>)
train_step: Return scale: 1.7785387009812874
train_step: Scaled advantages shape: torch.Size([16, 15, 16, 15])
train_step: Scaled advantages sample: tensor([[[[-5.2676, -5.2676, -5.2676, -5.2676, -5.2676, -5.2676, -5.2676,
           -5.2676, -5.2676, -5.2676, -5.2676, -5.2676, -5.2676, -5.2676,
           -5.2676],
          [-5.2676, -5.2676, -5.2676, -5.2676, -5.2676, -5.2676, -5.2676,
           -5.2676, -5.2676, -5.2676, -5.2676, -5.2676, -5.2676, -5.2676,
           -5.2676],
          [-5.2676, -5.2676, -5.2676, -5.2676, -5.2676, -5.2676, -5.2676,
           -5.2676, -5.2676, -5.2676, -5.2676, -5.2676, -5.2676, -5.2676,
           -5.2676],
          [-5.2676, -5.2676, -5.2676, -5.2676, -5.2676, -5.2676, -5.2676,
           -5.2676, -5.2676, -5.2676, -5.2676, -5.2676, -5.2676, -5.2676,
           -5.2676],
          [-5.2676, -5.2676, -5.2676, -5.2676, -5.2676, -5.2676, -5.2676,
           -5.2676, -5.2676, -5.2676, -5.2676, -5.2676, -5.2676, -5.2676,
           -5.2676],
          [-5.2676, -5.2676, -5.2676, -5.2676, -5.2676, -5.2676, -5.2676,
           -5.2676, -5.2676, -5.2676, -5.2676, -5.2676, -5.2676, -5.2676,
           -5.2676],
          [-5.2676, -5.2676, -5.2676, -5.2676, -5.2676, -5.2676, -5.2676,
           -5.2676, -5.2676, -5.2676, -5.2676, -5.2676, -5.2676, -5.2676,
           -5.2676],
          [-5.2676, -5.2676, -5.2676, -5.2676, -5.2676, -5.2676, -5.2676,
           -5.2676, -5.2676, -5.2676, -5.2676, -5.2676, -5.2676, -5.2676,
           -5.2676],
          [-5.2676, -5.2676, -5.2676, -5.2676, -5.2676, -5.2676, -5.2676,
           -5.2676, -5.2676, -5.2676, -5.2676, -5.2676, -5.2676, -5.2676,
           -5.2676],
          [-5.2676, -5.2676, -5.2676, -5.2676, -5.2676, -5.2676, -5.2676,
           -5.2676, -5.2676, -5.2676, -5.2676, -5.2676, -5.2676, -5.2676,
           -5.2676],
          [-5.2676, -5.2676, -5.2676, -5.2676, -5.2676, -5.2676, -5.2676,
           -5.2676, -5.2676, -5.2676, -5.2676, -5.2676, -5.2676, -5.2676,
           -5.2676],
          [-5.2676, -5.2676, -5.2676, -5.2676, -5.2676, -5.2676, -5.2676,
           -5.2676, -5.2676, -5.2676, -5.2676, -5.2676, -5.2676, -5.2676,
           -5.2676],
          [-5.2676, -5.2676, -5.2676, -5.2676, -5.2676, -5.2676, -5.2676,
           -5.2676, -5.2676, -5.2676, -5.2676, -5.2676, -5.2676, -5.2676,
           -5.2676],
          [-5.2676, -5.2676, -5.2676, -5.2676, -5.2676, -5.2676, -5.2676,
           -5.2676, -5.2676, -5.2676, -5.2676, -5.2676, -5.2676, -5.2676,
           -5.2676],
          [-0.8794, -0.8794, -0.8795, -0.8795, -0.8795, -0.8795, -0.8795,
           -0.8795, -0.8794, -0.8795, -0.8795, -0.8795, -0.8795, -0.8795,
           -0.8794],
          [-5.2676, -5.2676, -5.2676, -5.2676, -5.2676, -5.2676, -5.2676,
           -5.2676, -5.2676, -5.2676, -5.2676, -5.2676, -5.2676, -5.2676,
           -5.2676]],

         [[-5.0393, -5.0393, -5.0393, -5.0393, -5.0393, -5.0393, -5.0392,
           -5.0393, -5.0393, -5.0393, -5.0393, -5.0393, -5.0393, -5.0393,
           -5.0393],
          [-5.0393, -5.0393, -5.0393, -5.0393, -5.0393, -5.0393, -5.0392,
           -5.0393, -5.0393, -5.0393, -5.0393, -5.0393, -5.0393, -5.0393,
           -5.0393],
          [-5.0393, -5.0393, -5.0393, -5.0393, -5.0393, -5.0393, -5.0392,
           -5.0393, -5.0393, -5.0393, -5.0393, -5.0393, -5.0393, -5.0393,
           -5.0393],
          [-5.0393, -5.0393, -5.0393, -5.0393, -5.0393, -5.0393, -5.0392,
           -5.0393, -5.0393, -5.0393, -5.0393, -5.0393, -5.0393, -5.0393,
           -5.0393],
          [-5.0393, -5.0393, -5.0393, -5.0393, -5.0393, -5.0393, -5.0392,
           -5.0393, -5.0393, -5.0393, -5.0393, -5.0393, -5.0393, -5.0393,
           -5.0393],
          [-5.0393, -5.0393, -5.0393, -5.0393, -5.0393, -5.0393, -5.0392,
           -5.0393, -5.0393, -5.0393, -5.0393, -5.0393, -5.0393, -5.0393,
           -5.0393],
          [-5.0393, -5.0393, -5.0393, -5.0393, -5.0393, -5.0393, -5.0392,
           -5.0393, -5.0393, -5.0393, -5.0393, -5.0393, -5.0393, -5.0393,
           -5.0393],
          [-5.0393, -5.0393, -5.0393, -5.0393, -5.0393, -5.0393, -5.0392,
           -5.0393, -5.0393, -5.0393, -5.0393, -5.0393, -5.0393, -5.0393,
           -5.0393],
          [-5.0393, -5.0393, -5.0393, -5.0393, -5.0393, -5.0393, -5.0392,
           -5.0393, -5.0393, -5.0393, -5.0393, -5.0393, -5.0393, -5.0393,
           -5.0393],
          [-5.0393, -5.0393, -5.0393, -5.0393, -5.0393, -5.0393, -5.0392,
           -5.0393, -5.0393, -5.0393, -5.0393, -5.0393, -5.0393, -5.0393,
           -5.0393],
          [-5.0393, -5.0393, -5.0393, -5.0393, -5.0393, -5.0393, -5.0392,
           -5.0393, -5.0393, -5.0393, -5.0393, -5.0393, -5.0393, -5.0393,
           -5.0393],
          [-5.0393, -5.0393, -5.0393, -5.0393, -5.0393, -5.0393, -5.0392,
           -5.0393, -5.0393, -5.0393, -5.0393, -5.0393, -5.0393, -5.0393,
           -5.0393],
          [-5.0393, -5.0393, -5.0393, -5.0393, -5.0393, -5.0393, -5.0392,
           -5.0393, -5.0393, -5.0393, -5.0393, -5.0393, -5.0393, -5.0393,
           -5.0393],
          [-5.0393, -5.0393, -5.0393, -5.0393, -5.0393, -5.0393, -5.0392,
           -5.0393, -5.0393, -5.0393, -5.0393, -5.0393, -5.0393, -5.0393,
           -5.0393],
          [-5.0393, -5.0393, -5.0393, -5.0393, -5.0393, -5.0393, -5.0392,
           -5.0393, -5.0393, -5.0393, -5.0393, -5.0393, -5.0393, -5.0393,
           -5.0393],
          [-5.0393, -5.0393, -5.0393, -5.0393, -5.0393, -5.0393, -5.0392,
           -5.0393, -5.0393, -5.0393, -5.0393, -5.0393, -5.0393, -5.0393,
           -5.0393]]],


        [[[-4.1845, -4.1845, -4.1845, -4.1845, -4.1845, -4.1845, -4.1845,
           -4.1845, -4.1845, -4.1845, -4.1845, -4.1845, -4.1845, -4.1845,
           -4.1845],
          [-4.1845, -4.1845, -4.1845, -4.1845, -4.1845, -4.1845, -4.1845,
           -4.1845, -4.1845, -4.1845, -4.1845, -4.1845, -4.1845, -4.1845,
           -4.1845],
          [-4.1845, -4.1845, -4.1845, -4.1845, -4.1845, -4.1845, -4.1845,
           -4.1845, -4.1845, -4.1845, -4.1845, -4.1845, -4.1845, -4.1845,
           -4.1845],
          [-4.1845, -4.1845, -4.1845, -4.1845, -4.1845, -4.1845, -4.1845,
           -4.1845, -4.1845, -4.1845, -4.1845, -4.1845, -4.1845, -4.1845,
           -4.1845],
          [-4.1845, -4.1845, -4.1845, -4.1845, -4.1845, -4.1845, -4.1845,
           -4.1845, -4.1845, -4.1845, -4.1845, -4.1845, -4.1845, -4.1845,
           -4.1845],
          [-4.1845, -4.1845, -4.1845, -4.1845, -4.1845, -4.1845, -4.1845,
           -4.1845, -4.1845, -4.1845, -4.1845, -4.1845, -4.1845, -4.1845,
           -4.1845],
          [-4.1845, -4.1845, -4.1845, -4.1845, -4.1845, -4.1845, -4.1845,
           -4.1845, -4.1845, -4.1845, -4.1845, -4.1845, -4.1845, -4.1845,
           -4.1845],
          [-4.1845, -4.1845, -4.1845, -4.1845, -4.1845, -4.1845, -4.1845,
           -4.1845, -4.1845, -4.1845, -4.1845, -4.1845, -4.1845, -4.1845,
           -4.1845],
          [-4.1845, -4.1845, -4.1845, -4.1845, -4.1845, -4.1845, -4.1845,
           -4.1845, -4.1845, -4.1845, -4.1845, -4.1845, -4.1845, -4.1845,
           -4.1845],
          [-4.1845, -4.1845, -4.1845, -4.1845, -4.1845, -4.1845, -4.1845,
           -4.1845, -4.1845, -4.1845, -4.1845, -4.1845, -4.1845, -4.1845,
           -4.1845],
          [-4.1845, -4.1845, -4.1845, -4.1845, -4.1845, -4.1845, -4.1845,
           -4.1845, -4.1845, -4.1845, -4.1845, -4.1845, -4.1845, -4.1845,
           -4.1845],
          [-4.1845, -4.1845, -4.1845, -4.1845, -4.1845, -4.1845, -4.1845,
           -4.1845, -4.1845, -4.1845, -4.1845, -4.1845, -4.1845, -4.1845,
           -4.1845],
          [-4.1845, -4.1845, -4.1845, -4.1845, -4.1845, -4.1845, -4.1845,
           -4.1845, -4.1845, -4.1845, -4.1845, -4.1845, -4.1845, -4.1845,
           -4.1845],
          [-4.1845, -4.1845, -4.1845, -4.1845, -4.1845, -4.1845, -4.1845,
           -4.1845, -4.1845, -4.1845, -4.1845, -4.1845, -4.1845, -4.1845,
           -4.1845],
          [-0.3076, -0.3076, -0.3077, -0.3077, -0.3077, -0.3077, -0.3077,
           -0.3077, -0.3076, -0.3077, -0.3077, -0.3077, -0.3076, -0.3077,
           -0.3076],
          [-4.1845, -4.1845, -4.1845, -4.1845, -4.1845, -4.1845, -4.1845,
           -4.1845, -4.1845, -4.1845, -4.1845, -4.1845, -4.1845, -4.1845,
           -4.1845]],

         [[-4.2352, -4.2352, -4.2352, -4.2352, -4.2352, -4.2352, -4.2351,
           -4.2352, -4.2352, -4.2352, -4.2352, -4.2352, -4.2352, -4.2352,
           -4.2352],
          [-4.2352, -4.2352, -4.2352, -4.2352, -4.2352, -4.2352, -4.2351,
           -4.2352, -4.2352, -4.2352, -4.2352, -4.2352, -4.2352, -4.2352,
           -4.2352],
          [-4.2352, -4.2352, -4.2352, -4.2352, -4.2352, -4.2352, -4.2351,
           -4.2352, -4.2352, -4.2352, -4.2352, -4.2352, -4.2352, -4.2352,
           -4.2352],
          [-4.2352, -4.2352, -4.2352, -4.2352, -4.2352, -4.2352, -4.2351,
           -4.2352, -4.2352, -4.2352, -4.2352, -4.2352, -4.2352, -4.2352,
           -4.2352],
          [-4.2352, -4.2352, -4.2352, -4.2352, -4.2352, -4.2352, -4.2351,
           -4.2352, -4.2352, -4.2352, -4.2352, -4.2352, -4.2352, -4.2352,
           -4.2352],
          [-4.2352, -4.2352, -4.2352, -4.2352, -4.2352, -4.2352, -4.2351,
           -4.2352, -4.2352, -4.2352, -4.2352, -4.2352, -4.2352, -4.2352,
           -4.2352],
          [-4.2352, -4.2352, -4.2352, -4.2352, -4.2352, -4.2352, -4.2351,
           -4.2352, -4.2352, -4.2352, -4.2352, -4.2352, -4.2352, -4.2352,
           -4.2352],
          [-4.2352, -4.2352, -4.2352, -4.2352, -4.2352, -4.2352, -4.2351,
           -4.2352, -4.2352, -4.2352, -4.2352, -4.2352, -4.2352, -4.2352,
           -4.2352],
          [-4.2352, -4.2352, -4.2352, -4.2352, -4.2352, -4.2352, -4.2351,
           -4.2352, -4.2352, -4.2352, -4.2352, -4.2352, -4.2352, -4.2352,
           -4.2352],
          [-4.2352, -4.2352, -4.2352, -4.2352, -4.2352, -4.2352, -4.2351,
           -4.2352, -4.2352, -4.2352, -4.2352, -4.2352, -4.2352, -4.2352,
           -4.2352],
          [-4.2352, -4.2352, -4.2352, -4.2352, -4.2352, -4.2352, -4.2351,
           -4.2352, -4.2352, -4.2352, -4.2352, -4.2352, -4.2352, -4.2352,
           -4.2352],
          [-4.2352, -4.2352, -4.2352, -4.2352, -4.2352, -4.2352, -4.2351,
           -4.2352, -4.2352, -4.2352, -4.2352, -4.2352, -4.2352, -4.2352,
           -4.2352],
          [-4.2352, -4.2352, -4.2352, -4.2352, -4.2352, -4.2352, -4.2351,
           -4.2352, -4.2352, -4.2352, -4.2352, -4.2352, -4.2352, -4.2352,
           -4.2352],
          [-4.2352, -4.2352, -4.2352, -4.2352, -4.2352, -4.2352, -4.2351,
           -4.2352, -4.2352, -4.2352, -4.2352, -4.2352, -4.2352, -4.2352,
           -4.2352],
          [-4.2352, -4.2352, -4.2352, -4.2352, -4.2352, -4.2352, -4.2351,
           -4.2352, -4.2352, -4.2352, -4.2352, -4.2352, -4.2352, -4.2352,
           -4.2352],
          [-4.2352, -4.2352, -4.2352, -4.2352, -4.2352, -4.2352, -4.2351,
           -4.2352, -4.2352, -4.2352, -4.2352, -4.2352, -4.2352, -4.2352,
           -4.2352]]]], grad_fn=<SliceBackward0>)
train_step: Entropy shape: torch.Size([16, 15])
train_step: Entropy sample: tensor([[0.6088, 0.5057],
        [0.6821, 0.2924]], grad_fn=<SliceBackward0>)
train_step: Entropy coefficient: 0.01
train_step: Actor loss: -1.4028054475784302
train_step: returns shape after mean: torch.Size([16, 15])
train_step: target_indices shape: torch.Size([16, 15])
train_step: value_logits shape: torch.Size([16, 15, 255])
train_step: target_twohot shape: torch.Size([16, 15, 255])
--- Starting train_step at 2025-04-01 01:54:28 ---
Full starting_state: {'deter': tensor([[[ 2.2765e-02, -6.0451e-03, -5.8070e-02,  ..., -1.2495e-01,
           2.8125e-02, -2.8187e-02],
         [ 1.2225e-01, -7.9446e-02,  4.0193e-03,  ..., -1.0078e-01,
           1.4412e-01, -1.1799e-01],
         [-1.0135e-01,  1.4037e-01,  4.9358e-02,  ..., -1.4253e-01,
          -1.0130e-02, -6.1239e-02],
         ...,
         [ 8.9544e-02, -1.0649e-01,  9.4132e-02,  ..., -7.5454e-02,
          -6.5685e-02, -2.6819e-02],
         [-9.6738e-02, -1.3833e-01, -3.4262e-02,  ...,  2.0887e-02,
          -1.7392e-02, -1.3268e-01],
         [-4.5288e-02, -8.1931e-02, -1.4523e-01,  ...,  8.3590e-02,
           2.3329e-02, -1.0223e-01]],

        [[-5.5743e-02,  6.7801e-02, -1.3823e-01,  ...,  7.2796e-02,
           5.2593e-02, -1.0554e-02],
         [-3.1286e-02, -1.2294e-01,  6.2299e-02,  ...,  1.0142e-02,
           6.8430e-02,  9.0455e-03],
         [-1.9509e-02, -1.5568e-01, -1.3421e-01,  ...,  1.1189e-02,
          -1.1859e-03, -1.0216e-01],
         ...,
         [-1.1615e-01,  1.7990e-02, -1.6798e-01,  ...,  1.1886e-01,
           2.2275e-01, -1.1356e-01],
         [-2.2567e-02, -1.7102e-02, -8.2339e-02,  ...,  1.0681e-01,
           2.0484e-02, -1.6198e-01],
         [-1.0272e-01,  1.2356e-02, -1.5829e-01,  ...,  8.5099e-03,
           1.9127e-02, -1.0925e-01]],

        [[-7.3366e-02, -9.7986e-02, -1.4531e-01,  ..., -2.3466e-02,
           5.3317e-02, -3.4531e-02],
         [-9.6810e-02, -1.8927e-01, -2.4306e-02,  ..., -5.9507e-02,
          -4.8587e-02,  1.1250e-02],
         [-1.0511e-01, -6.7166e-02, -1.1626e-02,  ...,  6.8524e-02,
           1.0766e-01, -3.0298e-02],
         ...,
         [ 1.2507e-01,  9.8061e-02,  3.9773e-02,  ...,  1.8794e-02,
          -4.0659e-03,  1.7279e-02],
         [-8.3131e-02,  3.6931e-02,  1.0258e-01,  ..., -7.8146e-03,
           4.9657e-02,  1.0664e-02],
         [-1.3639e-01, -8.1355e-02,  3.7017e-03,  ..., -1.1203e-01,
          -8.9357e-02, -6.4915e-02]],

        ...,

        [[-8.4812e-03, -3.1208e-02,  1.0866e-01,  ..., -1.0475e-02,
          -4.5935e-04, -1.6273e-01],
         [ 5.0582e-02,  1.3167e-01,  6.1322e-02,  ...,  9.5146e-02,
           3.1989e-03,  9.3519e-02],
         [-1.5269e-01, -1.2468e-01, -1.9453e-01,  ...,  3.3683e-02,
           1.8886e-01,  1.8206e-02],
         ...,
         [-2.9022e-02, -8.3785e-02, -1.9123e-01,  ...,  2.4752e-02,
           3.4443e-02, -9.9990e-02],
         [-1.7768e-01,  6.5203e-02, -9.2816e-02,  ...,  1.5289e-01,
          -1.4820e-01, -1.9557e-01],
         [-1.1986e-02,  7.7407e-02, -3.0730e-02,  ...,  1.1695e-01,
          -2.8460e-02, -9.2901e-02]],

        [[ 7.2765e-03, -8.3443e-05,  7.2218e-02,  ...,  4.2145e-02,
          -2.5311e-02, -3.3953e-02],
         [-2.3479e-01, -1.2197e-01, -1.0382e-01,  ..., -4.9947e-02,
           1.3622e-01, -4.4274e-02],
         [-5.8790e-02,  5.7605e-02, -8.1760e-02,  ...,  9.9919e-03,
           4.8505e-02, -6.9567e-02],
         ...,
         [-3.5480e-02, -7.8262e-02, -2.2224e-01,  ..., -1.6947e-01,
          -6.6419e-03, -9.2865e-02],
         [ 8.8907e-03, -1.1699e-01, -3.5668e-02,  ..., -3.7346e-02,
          -2.0312e-03, -4.4657e-02],
         [-1.1449e-01,  2.2721e-02, -7.4698e-02,  ..., -3.8140e-02,
          -6.4126e-02, -2.3409e-01]],

        [[-7.6219e-02, -9.5551e-02, -2.3472e-01,  ...,  5.7393e-02,
           6.1578e-02, -8.5672e-02],
         [-4.6194e-02, -5.6908e-02, -7.0239e-02,  ...,  1.7855e-02,
          -2.0612e-02,  6.1410e-03],
         [-1.2236e-02,  7.6018e-02, -7.8087e-02,  ..., -2.8217e-02,
          -6.7671e-02, -7.3899e-02],
         ...,
         [ 2.2245e-02,  8.9287e-02, -1.5933e-01,  ..., -1.4816e-02,
           6.2567e-02, -9.3264e-02],
         [-2.0642e-01, -3.8419e-03, -1.1596e-01,  ..., -1.6101e-01,
          -6.8666e-02,  1.3509e-01],
         [-6.9353e-03,  6.4814e-02, -1.9964e-01,  ...,  3.8524e-02,
           1.0267e-01,  4.5279e-02]]], grad_fn=<StackBackward0>), 'stoch': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 1.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 1., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 1., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]])}
train_step: Starting state deter shape: torch.Size([16, 50, 128])
train_step: Starting state stoch shape: torch.Size([16, 50, 1024])
After ensuring logits/stoch: {'deter': tensor([[[ 2.2765e-02, -6.0451e-03, -5.8070e-02,  ..., -1.2495e-01,
           2.8125e-02, -2.8187e-02],
         [ 1.2225e-01, -7.9446e-02,  4.0193e-03,  ..., -1.0078e-01,
           1.4412e-01, -1.1799e-01],
         [-1.0135e-01,  1.4037e-01,  4.9358e-02,  ..., -1.4253e-01,
          -1.0130e-02, -6.1239e-02],
         ...,
         [ 8.9544e-02, -1.0649e-01,  9.4132e-02,  ..., -7.5454e-02,
          -6.5685e-02, -2.6819e-02],
         [-9.6738e-02, -1.3833e-01, -3.4262e-02,  ...,  2.0887e-02,
          -1.7392e-02, -1.3268e-01],
         [-4.5288e-02, -8.1931e-02, -1.4523e-01,  ...,  8.3590e-02,
           2.3329e-02, -1.0223e-01]],

        [[-5.5743e-02,  6.7801e-02, -1.3823e-01,  ...,  7.2796e-02,
           5.2593e-02, -1.0554e-02],
         [-3.1286e-02, -1.2294e-01,  6.2299e-02,  ...,  1.0142e-02,
           6.8430e-02,  9.0455e-03],
         [-1.9509e-02, -1.5568e-01, -1.3421e-01,  ...,  1.1189e-02,
          -1.1859e-03, -1.0216e-01],
         ...,
         [-1.1615e-01,  1.7990e-02, -1.6798e-01,  ...,  1.1886e-01,
           2.2275e-01, -1.1356e-01],
         [-2.2567e-02, -1.7102e-02, -8.2339e-02,  ...,  1.0681e-01,
           2.0484e-02, -1.6198e-01],
         [-1.0272e-01,  1.2356e-02, -1.5829e-01,  ...,  8.5099e-03,
           1.9127e-02, -1.0925e-01]],

        [[-7.3366e-02, -9.7986e-02, -1.4531e-01,  ..., -2.3466e-02,
           5.3317e-02, -3.4531e-02],
         [-9.6810e-02, -1.8927e-01, -2.4306e-02,  ..., -5.9507e-02,
          -4.8587e-02,  1.1250e-02],
         [-1.0511e-01, -6.7166e-02, -1.1626e-02,  ...,  6.8524e-02,
           1.0766e-01, -3.0298e-02],
         ...,
         [ 1.2507e-01,  9.8061e-02,  3.9773e-02,  ...,  1.8794e-02,
          -4.0659e-03,  1.7279e-02],
         [-8.3131e-02,  3.6931e-02,  1.0258e-01,  ..., -7.8146e-03,
           4.9657e-02,  1.0664e-02],
         [-1.3639e-01, -8.1355e-02,  3.7017e-03,  ..., -1.1203e-01,
          -8.9357e-02, -6.4915e-02]],

        ...,

        [[-8.4812e-03, -3.1208e-02,  1.0866e-01,  ..., -1.0475e-02,
          -4.5935e-04, -1.6273e-01],
         [ 5.0582e-02,  1.3167e-01,  6.1322e-02,  ...,  9.5146e-02,
           3.1989e-03,  9.3519e-02],
         [-1.5269e-01, -1.2468e-01, -1.9453e-01,  ...,  3.3683e-02,
           1.8886e-01,  1.8206e-02],
         ...,
         [-2.9022e-02, -8.3785e-02, -1.9123e-01,  ...,  2.4752e-02,
           3.4443e-02, -9.9990e-02],
         [-1.7768e-01,  6.5203e-02, -9.2816e-02,  ...,  1.5289e-01,
          -1.4820e-01, -1.9557e-01],
         [-1.1986e-02,  7.7407e-02, -3.0730e-02,  ...,  1.1695e-01,
          -2.8460e-02, -9.2901e-02]],

        [[ 7.2765e-03, -8.3443e-05,  7.2218e-02,  ...,  4.2145e-02,
          -2.5311e-02, -3.3953e-02],
         [-2.3479e-01, -1.2197e-01, -1.0382e-01,  ..., -4.9947e-02,
           1.3622e-01, -4.4274e-02],
         [-5.8790e-02,  5.7605e-02, -8.1760e-02,  ...,  9.9919e-03,
           4.8505e-02, -6.9567e-02],
         ...,
         [-3.5480e-02, -7.8262e-02, -2.2224e-01,  ..., -1.6947e-01,
          -6.6419e-03, -9.2865e-02],
         [ 8.8907e-03, -1.1699e-01, -3.5668e-02,  ..., -3.7346e-02,
          -2.0312e-03, -4.4657e-02],
         [-1.1449e-01,  2.2721e-02, -7.4698e-02,  ..., -3.8140e-02,
          -6.4126e-02, -2.3409e-01]],

        [[-7.6219e-02, -9.5551e-02, -2.3472e-01,  ...,  5.7393e-02,
           6.1578e-02, -8.5672e-02],
         [-4.6194e-02, -5.6908e-02, -7.0239e-02,  ...,  1.7855e-02,
          -2.0612e-02,  6.1410e-03],
         [-1.2236e-02,  7.6018e-02, -7.8087e-02,  ..., -2.8217e-02,
          -6.7671e-02, -7.3899e-02],
         ...,
         [ 2.2245e-02,  8.9287e-02, -1.5933e-01,  ..., -1.4816e-02,
           6.2567e-02, -9.3264e-02],
         [-2.0642e-01, -3.8419e-03, -1.1596e-01,  ..., -1.6101e-01,
          -6.8666e-02,  1.3509e-01],
         [-6.9353e-03,  6.4814e-02, -1.9964e-01,  ...,  3.8524e-02,
           1.0267e-01,  4.5279e-02]]], grad_fn=<StackBackward0>), 'stoch': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 1.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 1., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 1., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]]), 'logits': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]])}
train_step: Normalized hidden_state shape: torch.Size([1, 16, 128])
train_step: Normalized stoch shape: torch.Size([16, 1024])
train_step: Normalized deter shape: torch.Size([16, 128])
train_step: Post-imagine_trajectory: Imagined features shape: torch.Size([16, 15, 1152])
train_step: Post-imagine_trajectory: Imagined actions shape: torch.Size([16, 15, 2])
train_step: Post-imagine_trajectory: Imagined action indices shape: torch.Size([16, 15])
train_step: Post-imagine_trajectory: Imagined state deter shape: torch.Size([16, 15, 128])
train_step: Post-imagine_trajectory: Imagined state stoch shape: torch.Size([16, 15, 1024])
Reward shape: torch.Size([16, 15, 1]), Value shape: torch.Size([16, 15, 1]), Slow Value shape: torch.Size([16, 15, 1]), Discount shape: torch.Size([16, 15, 1, 1])
Return targets length: 15, First target shape: torch.Size([16, 16, 1])
train_step: Actor distribution shape: torch.Size([16, 15, 2])
train_step: Action log probabilities shape: torch.Size([16, 15])
train_step: Action log probabilities sample: tensor([[-0.3831, -0.0631],
        [-0.1853, -0.7148]], grad_fn=<SliceBackward0>)
train_step: Advantages shape: torch.Size([16, 15, 16, 15])
train_step: Advantages sample: tensor([[[[-5.9860, -5.9859, -5.9859, -5.9859, -5.9859, -5.9859, -5.9860,
           -5.9859, -5.9859, -5.9859, -5.9859, -5.9859, -5.9860, -5.9859,
           -5.9859],
          [-5.9860, -5.9859, -5.9859, -5.9859, -5.9859, -5.9859, -5.9860,
           -5.9859, -5.9859, -5.9859, -5.9859, -5.9859, -5.9860, -5.9859,
           -5.9859],
          [-3.6179, -3.6178, -3.6179, -3.6178, -3.6179, -3.6178, -3.6179,
           -3.6178, -3.6178, -3.6178, -3.6178, -3.6178, -3.6179, -3.6178,
           -3.6178],
          [-5.9860, -5.9859, -5.9859, -5.9859, -5.9859, -5.9859, -5.9860,
           -5.9859, -5.9859, -5.9859, -5.9859, -5.9859, -5.9860, -5.9859,
           -5.9859],
          [-5.9860, -5.9859, -5.9859, -5.9859, -5.9859, -5.9859, -5.9860,
           -5.9859, -5.9859, -5.9859, -5.9859, -5.9859, -5.9860, -5.9859,
           -5.9859],
          [-5.9858, -5.9857, -5.9858, -5.9857, -5.9858, -5.9857, -5.9858,
           -5.9857, -5.9857, -5.9857, -5.9857, -5.9857, -5.9858, -5.9857,
           -5.9857],
          [-5.9860, -5.9859, -5.9859, -5.9859, -5.9859, -5.9859, -5.9860,
           -5.9859, -5.9859, -5.9859, -5.9859, -5.9859, -5.9860, -5.9859,
           -5.9859],
          [-3.6150, -3.6149, -3.6149, -3.6149, -3.6149, -3.6149, -3.6150,
           -3.6149, -3.6149, -3.6149, -3.6149, -3.6149, -3.6150, -3.6149,
           -3.6149],
          [-5.9860, -5.9859, -5.9859, -5.9859, -5.9859, -5.9859, -5.9860,
           -5.9859, -5.9859, -5.9859, -5.9859, -5.9859, -5.9860, -5.9859,
           -5.9859],
          [-5.9860, -5.9859, -5.9859, -5.9859, -5.9859, -5.9859, -5.9860,
           -5.9859, -5.9859, -5.9859, -5.9859, -5.9859, -5.9860, -5.9859,
           -5.9859],
          [-5.9860, -5.9859, -5.9859, -5.9859, -5.9859, -5.9859, -5.9860,
           -5.9859, -5.9859, -5.9859, -5.9859, -5.9859, -5.9860, -5.9859,
           -5.9859],
          [-5.9860, -5.9859, -5.9859, -5.9859, -5.9859, -5.9859, -5.9860,
           -5.9859, -5.9859, -5.9859, -5.9859, -5.9859, -5.9860, -5.9859,
           -5.9859],
          [-5.9860, -5.9859, -5.9859, -5.9859, -5.9859, -5.9859, -5.9860,
           -5.9859, -5.9859, -5.9859, -5.9859, -5.9859, -5.9860, -5.9859,
           -5.9859],
          [-5.9860, -5.9859, -5.9859, -5.9859, -5.9859, -5.9859, -5.9860,
           -5.9859, -5.9859, -5.9859, -5.9859, -5.9859, -5.9860, -5.9859,
           -5.9859],
          [-5.9860, -5.9859, -5.9859, -5.9859, -5.9859, -5.9859, -5.9860,
           -5.9859, -5.9859, -5.9859, -5.9859, -5.9859, -5.9860, -5.9859,
           -5.9859],
          [-5.9860, -5.9859, -5.9859, -5.9859, -5.9859, -5.9859, -5.9860,
           -5.9859, -5.9859, -5.9859, -5.9859, -5.9859, -5.9860, -5.9859,
           -5.9859]],

         [[-5.8392, -5.8392, -5.8392, -5.8392, -5.8392, -5.8392, -5.8392,
           -5.8392, -5.8392, -5.8392, -5.8392, -5.8392, -5.8392, -5.8392,
           -5.8392],
          [-5.8392, -5.8392, -5.8392, -5.8392, -5.8392, -5.8392, -5.8392,
           -5.8392, -5.8392, -5.8392, -5.8392, -5.8392, -5.8392, -5.8392,
           -5.8392],
          [-3.3390, -3.3390, -3.3390, -3.3390, -3.3390, -3.3390, -3.3390,
           -3.3390, -3.3389, -3.3390, -3.3390, -3.3390, -3.3390, -3.3389,
           -3.3390],
          [-5.8392, -5.8392, -5.8392, -5.8392, -5.8392, -5.8392, -5.8392,
           -5.8392, -5.8392, -5.8392, -5.8392, -5.8392, -5.8392, -5.8392,
           -5.8392],
          [-5.8392, -5.8392, -5.8392, -5.8392, -5.8392, -5.8392, -5.8392,
           -5.8392, -5.8392, -5.8392, -5.8392, -5.8392, -5.8392, -5.8392,
           -5.8392],
          [-5.8390, -5.8390, -5.8390, -5.8390, -5.8390, -5.8390, -5.8390,
           -5.8390, -5.8390, -5.8390, -5.8390, -5.8390, -5.8390, -5.8390,
           -5.8390],
          [-5.8392, -5.8392, -5.8392, -5.8392, -5.8392, -5.8392, -5.8392,
           -5.8392, -5.8392, -5.8392, -5.8392, -5.8392, -5.8392, -5.8392,
           -5.8392],
          [-3.3359, -3.3359, -3.3359, -3.3359, -3.3359, -3.3359, -3.3359,
           -3.3359, -3.3359, -3.3359, -3.3359, -3.3359, -3.3359, -3.3359,
           -3.3359],
          [-5.8392, -5.8392, -5.8392, -5.8392, -5.8392, -5.8392, -5.8392,
           -5.8392, -5.8392, -5.8392, -5.8392, -5.8392, -5.8392, -5.8392,
           -5.8392],
          [-5.8392, -5.8392, -5.8392, -5.8392, -5.8392, -5.8392, -5.8392,
           -5.8392, -5.8392, -5.8392, -5.8392, -5.8392, -5.8392, -5.8392,
           -5.8392],
          [-5.8392, -5.8392, -5.8392, -5.8392, -5.8392, -5.8392, -5.8392,
           -5.8392, -5.8392, -5.8392, -5.8392, -5.8392, -5.8392, -5.8392,
           -5.8392],
          [-5.8392, -5.8392, -5.8392, -5.8392, -5.8392, -5.8392, -5.8392,
           -5.8392, -5.8392, -5.8392, -5.8392, -5.8392, -5.8392, -5.8392,
           -5.8392],
          [-5.8392, -5.8392, -5.8392, -5.8392, -5.8392, -5.8392, -5.8392,
           -5.8392, -5.8392, -5.8392, -5.8392, -5.8392, -5.8392, -5.8392,
           -5.8392],
          [-5.8392, -5.8392, -5.8392, -5.8392, -5.8392, -5.8392, -5.8392,
           -5.8392, -5.8392, -5.8392, -5.8392, -5.8392, -5.8392, -5.8392,
           -5.8392],
          [-5.8392, -5.8392, -5.8392, -5.8392, -5.8392, -5.8392, -5.8392,
           -5.8392, -5.8392, -5.8392, -5.8392, -5.8392, -5.8392, -5.8392,
           -5.8392],
          [-5.8392, -5.8392, -5.8392, -5.8392, -5.8392, -5.8392, -5.8392,
           -5.8392, -5.8392, -5.8392, -5.8392, -5.8392, -5.8392, -5.8392,
           -5.8392]]],


        [[[-6.4607, -6.4606, -6.4607, -6.4607, -6.4607, -6.4606, -6.4607,
           -6.4606, -6.4607, -6.4606, -6.4607, -6.4606, -6.4607, -6.4606,
           -6.4606],
          [-6.4607, -6.4606, -6.4607, -6.4607, -6.4607, -6.4606, -6.4607,
           -6.4606, -6.4607, -6.4606, -6.4607, -6.4606, -6.4607, -6.4606,
           -6.4606],
          [-4.8733, -4.8732, -4.8733, -4.8733, -4.8733, -4.8732, -4.8733,
           -4.8732, -4.8733, -4.8732, -4.8733, -4.8733, -4.8733, -4.8732,
           -4.8732],
          [-6.4607, -6.4606, -6.4607, -6.4607, -6.4607, -6.4606, -6.4607,
           -6.4606, -6.4607, -6.4606, -6.4607, -6.4606, -6.4607, -6.4606,
           -6.4606],
          [-6.4607, -6.4606, -6.4607, -6.4607, -6.4607, -6.4606, -6.4607,
           -6.4606, -6.4607, -6.4606, -6.4607, -6.4606, -6.4607, -6.4606,
           -6.4606],
          [-6.4605, -6.4604, -6.4605, -6.4605, -6.4605, -6.4604, -6.4605,
           -6.4604, -6.4605, -6.4604, -6.4605, -6.4605, -6.4605, -6.4604,
           -6.4604],
          [-6.4607, -6.4606, -6.4607, -6.4607, -6.4607, -6.4606, -6.4607,
           -6.4606, -6.4607, -6.4606, -6.4607, -6.4606, -6.4607, -6.4606,
           -6.4606],
          [-4.7550, -4.7550, -4.7550, -4.7550, -4.7550, -4.7549, -4.7551,
           -4.7550, -4.7550, -4.7550, -4.7550, -4.7550, -4.7551, -4.7550,
           -4.7550],
          [-6.4607, -6.4606, -6.4607, -6.4607, -6.4607, -6.4606, -6.4607,
           -6.4606, -6.4607, -6.4606, -6.4607, -6.4606, -6.4607, -6.4606,
           -6.4606],
          [-6.4607, -6.4606, -6.4607, -6.4607, -6.4607, -6.4606, -6.4607,
           -6.4606, -6.4607, -6.4606, -6.4607, -6.4606, -6.4607, -6.4606,
           -6.4606],
          [-6.4607, -6.4606, -6.4607, -6.4607, -6.4607, -6.4606, -6.4607,
           -6.4606, -6.4607, -6.4606, -6.4607, -6.4606, -6.4607, -6.4606,
           -6.4606],
          [-6.4607, -6.4606, -6.4607, -6.4607, -6.4607, -6.4606, -6.4607,
           -6.4606, -6.4607, -6.4606, -6.4607, -6.4606, -6.4607, -6.4606,
           -6.4606],
          [-6.4607, -6.4606, -6.4607, -6.4607, -6.4607, -6.4606, -6.4607,
           -6.4606, -6.4607, -6.4606, -6.4607, -6.4606, -6.4607, -6.4606,
           -6.4606],
          [-6.4607, -6.4606, -6.4607, -6.4607, -6.4607, -6.4606, -6.4607,
           -6.4606, -6.4607, -6.4606, -6.4607, -6.4606, -6.4607, -6.4606,
           -6.4606],
          [-6.4607, -6.4606, -6.4607, -6.4607, -6.4607, -6.4606, -6.4607,
           -6.4606, -6.4607, -6.4606, -6.4607, -6.4606, -6.4607, -6.4606,
           -6.4606],
          [-6.4607, -6.4606, -6.4607, -6.4607, -6.4607, -6.4606, -6.4607,
           -6.4606, -6.4607, -6.4606, -6.4607, -6.4606, -6.4607, -6.4606,
           -6.4606]],

         [[-6.2547, -6.2547, -6.2547, -6.2547, -6.2547, -6.2547, -6.2547,
           -6.2547, -6.2547, -6.2547, -6.2547, -6.2547, -6.2547, -6.2547,
           -6.2547],
          [-6.2547, -6.2547, -6.2547, -6.2547, -6.2547, -6.2547, -6.2547,
           -6.2547, -6.2547, -6.2547, -6.2547, -6.2547, -6.2547, -6.2547,
           -6.2547],
          [-4.5788, -4.5787, -4.5787, -4.5787, -4.5788, -4.5787, -4.5787,
           -4.5788, -4.5787, -4.5788, -4.5788, -4.5788, -4.5787, -4.5787,
           -4.5787],
          [-6.2547, -6.2547, -6.2547, -6.2547, -6.2547, -6.2547, -6.2547,
           -6.2547, -6.2547, -6.2547, -6.2547, -6.2547, -6.2547, -6.2547,
           -6.2547],
          [-6.2547, -6.2547, -6.2547, -6.2547, -6.2547, -6.2547, -6.2547,
           -6.2547, -6.2547, -6.2547, -6.2547, -6.2547, -6.2547, -6.2547,
           -6.2547],
          [-6.2545, -6.2545, -6.2545, -6.2545, -6.2545, -6.2545, -6.2545,
           -6.2545, -6.2545, -6.2545, -6.2545, -6.2545, -6.2545, -6.2545,
           -6.2545],
          [-6.2547, -6.2547, -6.2547, -6.2547, -6.2547, -6.2547, -6.2547,
           -6.2547, -6.2547, -6.2547, -6.2547, -6.2547, -6.2547, -6.2547,
           -6.2547],
          [-4.4539, -4.4539, -4.4539, -4.4539, -4.4539, -4.4539, -4.4539,
           -4.4539, -4.4538, -4.4539, -4.4539, -4.4539, -4.4539, -4.4538,
           -4.4539],
          [-6.2547, -6.2547, -6.2547, -6.2547, -6.2547, -6.2547, -6.2547,
           -6.2547, -6.2547, -6.2547, -6.2547, -6.2547, -6.2547, -6.2547,
           -6.2547],
          [-6.2547, -6.2547, -6.2547, -6.2547, -6.2547, -6.2547, -6.2547,
           -6.2547, -6.2547, -6.2547, -6.2547, -6.2547, -6.2547, -6.2547,
           -6.2547],
          [-6.2547, -6.2547, -6.2547, -6.2547, -6.2547, -6.2547, -6.2547,
           -6.2547, -6.2547, -6.2547, -6.2547, -6.2547, -6.2547, -6.2547,
           -6.2547],
          [-6.2547, -6.2547, -6.2547, -6.2547, -6.2547, -6.2547, -6.2547,
           -6.2547, -6.2547, -6.2547, -6.2547, -6.2547, -6.2547, -6.2547,
           -6.2547],
          [-6.2547, -6.2547, -6.2547, -6.2547, -6.2547, -6.2547, -6.2547,
           -6.2547, -6.2547, -6.2547, -6.2547, -6.2547, -6.2547, -6.2547,
           -6.2547],
          [-6.2547, -6.2547, -6.2547, -6.2547, -6.2547, -6.2547, -6.2547,
           -6.2547, -6.2547, -6.2547, -6.2547, -6.2547, -6.2547, -6.2547,
           -6.2547],
          [-6.2547, -6.2547, -6.2547, -6.2547, -6.2547, -6.2547, -6.2547,
           -6.2547, -6.2547, -6.2547, -6.2547, -6.2547, -6.2547, -6.2547,
           -6.2547],
          [-6.2547, -6.2547, -6.2547, -6.2547, -6.2547, -6.2547, -6.2547,
           -6.2547, -6.2547, -6.2547, -6.2547, -6.2547, -6.2547, -6.2547,
           -6.2547]]]], grad_fn=<SliceBackward0>)
train_step: Return scale: 1.8280789668092279
train_step: Scaled advantages shape: torch.Size([16, 15, 16, 15])
train_step: Scaled advantages sample: tensor([[[[-3.2745, -3.2744, -3.2744, -3.2744, -3.2744, -3.2744, -3.2745,
           -3.2744, -3.2744, -3.2744, -3.2744, -3.2744, -3.2745, -3.2744,
           -3.2744],
          [-3.2745, -3.2744, -3.2744, -3.2744, -3.2744, -3.2744, -3.2745,
           -3.2744, -3.2744, -3.2744, -3.2744, -3.2744, -3.2745, -3.2744,
           -3.2744],
          [-1.9791, -1.9790, -1.9790, -1.9790, -1.9790, -1.9790, -1.9791,
           -1.9790, -1.9790, -1.9790, -1.9790, -1.9790, -1.9791, -1.9790,
           -1.9790],
          [-3.2745, -3.2744, -3.2744, -3.2744, -3.2744, -3.2744, -3.2745,
           -3.2744, -3.2744, -3.2744, -3.2744, -3.2744, -3.2745, -3.2744,
           -3.2744],
          [-3.2745, -3.2744, -3.2744, -3.2744, -3.2744, -3.2744, -3.2745,
           -3.2744, -3.2744, -3.2744, -3.2744, -3.2744, -3.2745, -3.2744,
           -3.2744],
          [-3.2743, -3.2743, -3.2743, -3.2743, -3.2743, -3.2743, -3.2744,
           -3.2743, -3.2743, -3.2743, -3.2743, -3.2743, -3.2744, -3.2743,
           -3.2743],
          [-3.2745, -3.2744, -3.2744, -3.2744, -3.2744, -3.2744, -3.2745,
           -3.2744, -3.2744, -3.2744, -3.2744, -3.2744, -3.2745, -3.2744,
           -3.2744],
          [-1.9775, -1.9774, -1.9775, -1.9774, -1.9775, -1.9774, -1.9775,
           -1.9774, -1.9774, -1.9774, -1.9774, -1.9774, -1.9775, -1.9774,
           -1.9774],
          [-3.2745, -3.2744, -3.2744, -3.2744, -3.2744, -3.2744, -3.2745,
           -3.2744, -3.2744, -3.2744, -3.2744, -3.2744, -3.2745, -3.2744,
           -3.2744],
          [-3.2745, -3.2744, -3.2744, -3.2744, -3.2744, -3.2744, -3.2745,
           -3.2744, -3.2744, -3.2744, -3.2744, -3.2744, -3.2745, -3.2744,
           -3.2744],
          [-3.2745, -3.2744, -3.2744, -3.2744, -3.2744, -3.2744, -3.2745,
           -3.2744, -3.2744, -3.2744, -3.2744, -3.2744, -3.2745, -3.2744,
           -3.2744],
          [-3.2745, -3.2744, -3.2744, -3.2744, -3.2744, -3.2744, -3.2745,
           -3.2744, -3.2744, -3.2744, -3.2744, -3.2744, -3.2745, -3.2744,
           -3.2744],
          [-3.2745, -3.2744, -3.2744, -3.2744, -3.2744, -3.2744, -3.2745,
           -3.2744, -3.2744, -3.2744, -3.2744, -3.2744, -3.2745, -3.2744,
           -3.2744],
          [-3.2745, -3.2744, -3.2744, -3.2744, -3.2744, -3.2744, -3.2745,
           -3.2744, -3.2744, -3.2744, -3.2744, -3.2744, -3.2745, -3.2744,
           -3.2744],
          [-3.2745, -3.2744, -3.2744, -3.2744, -3.2744, -3.2744, -3.2745,
           -3.2744, -3.2744, -3.2744, -3.2744, -3.2744, -3.2745, -3.2744,
           -3.2744],
          [-3.2745, -3.2744, -3.2744, -3.2744, -3.2744, -3.2744, -3.2745,
           -3.2744, -3.2744, -3.2744, -3.2744, -3.2744, -3.2745, -3.2744,
           -3.2744]],

         [[-3.1942, -3.1942, -3.1942, -3.1942, -3.1942, -3.1942, -3.1942,
           -3.1942, -3.1942, -3.1942, -3.1942, -3.1942, -3.1942, -3.1942,
           -3.1942],
          [-3.1942, -3.1942, -3.1942, -3.1942, -3.1942, -3.1942, -3.1942,
           -3.1942, -3.1942, -3.1942, -3.1942, -3.1942, -3.1942, -3.1942,
           -3.1942],
          [-1.8265, -1.8265, -1.8265, -1.8265, -1.8265, -1.8265, -1.8265,
           -1.8265, -1.8265, -1.8265, -1.8265, -1.8265, -1.8265, -1.8265,
           -1.8265],
          [-3.1942, -3.1942, -3.1942, -3.1942, -3.1942, -3.1942, -3.1942,
           -3.1942, -3.1942, -3.1942, -3.1942, -3.1942, -3.1942, -3.1942,
           -3.1942],
          [-3.1942, -3.1942, -3.1942, -3.1942, -3.1942, -3.1942, -3.1942,
           -3.1942, -3.1942, -3.1942, -3.1942, -3.1942, -3.1942, -3.1942,
           -3.1942],
          [-3.1941, -3.1941, -3.1941, -3.1941, -3.1941, -3.1941, -3.1940,
           -3.1941, -3.1940, -3.1941, -3.1941, -3.1941, -3.1941, -3.1940,
           -3.1941],
          [-3.1942, -3.1942, -3.1942, -3.1942, -3.1942, -3.1942, -3.1942,
           -3.1942, -3.1942, -3.1942, -3.1942, -3.1942, -3.1942, -3.1942,
           -3.1942],
          [-1.8248, -1.8248, -1.8248, -1.8248, -1.8248, -1.8248, -1.8248,
           -1.8248, -1.8248, -1.8248, -1.8248, -1.8248, -1.8248, -1.8248,
           -1.8248],
          [-3.1942, -3.1942, -3.1942, -3.1942, -3.1942, -3.1942, -3.1942,
           -3.1942, -3.1942, -3.1942, -3.1942, -3.1942, -3.1942, -3.1942,
           -3.1942],
          [-3.1942, -3.1942, -3.1942, -3.1942, -3.1942, -3.1942, -3.1942,
           -3.1942, -3.1942, -3.1942, -3.1942, -3.1942, -3.1942, -3.1942,
           -3.1942],
          [-3.1942, -3.1942, -3.1942, -3.1942, -3.1942, -3.1942, -3.1942,
           -3.1942, -3.1942, -3.1942, -3.1942, -3.1942, -3.1942, -3.1942,
           -3.1942],
          [-3.1942, -3.1942, -3.1942, -3.1942, -3.1942, -3.1942, -3.1942,
           -3.1942, -3.1942, -3.1942, -3.1942, -3.1942, -3.1942, -3.1942,
           -3.1942],
          [-3.1942, -3.1942, -3.1942, -3.1942, -3.1942, -3.1942, -3.1942,
           -3.1942, -3.1942, -3.1942, -3.1942, -3.1942, -3.1942, -3.1942,
           -3.1942],
          [-3.1942, -3.1942, -3.1942, -3.1942, -3.1942, -3.1942, -3.1942,
           -3.1942, -3.1942, -3.1942, -3.1942, -3.1942, -3.1942, -3.1942,
           -3.1942],
          [-3.1942, -3.1942, -3.1942, -3.1942, -3.1942, -3.1942, -3.1942,
           -3.1942, -3.1942, -3.1942, -3.1942, -3.1942, -3.1942, -3.1942,
           -3.1942],
          [-3.1942, -3.1942, -3.1942, -3.1942, -3.1942, -3.1942, -3.1942,
           -3.1942, -3.1942, -3.1942, -3.1942, -3.1942, -3.1942, -3.1942,
           -3.1942]]],


        [[[-3.5341, -3.5341, -3.5341, -3.5341, -3.5341, -3.5341, -3.5341,
           -3.5341, -3.5341, -3.5341, -3.5341, -3.5341, -3.5341, -3.5341,
           -3.5341],
          [-3.5341, -3.5341, -3.5341, -3.5341, -3.5341, -3.5341, -3.5341,
           -3.5341, -3.5341, -3.5341, -3.5341, -3.5341, -3.5341, -3.5341,
           -3.5341],
          [-2.6658, -2.6658, -2.6658, -2.6658, -2.6658, -2.6658, -2.6658,
           -2.6658, -2.6658, -2.6658, -2.6658, -2.6658, -2.6658, -2.6658,
           -2.6658],
          [-3.5341, -3.5341, -3.5341, -3.5341, -3.5341, -3.5341, -3.5341,
           -3.5341, -3.5341, -3.5341, -3.5341, -3.5341, -3.5341, -3.5341,
           -3.5341],
          [-3.5341, -3.5341, -3.5341, -3.5341, -3.5341, -3.5341, -3.5341,
           -3.5341, -3.5341, -3.5341, -3.5341, -3.5341, -3.5341, -3.5341,
           -3.5341],
          [-3.5340, -3.5340, -3.5340, -3.5340, -3.5340, -3.5340, -3.5340,
           -3.5340, -3.5340, -3.5340, -3.5340, -3.5340, -3.5340, -3.5340,
           -3.5340],
          [-3.5341, -3.5341, -3.5341, -3.5341, -3.5341, -3.5341, -3.5341,
           -3.5341, -3.5341, -3.5341, -3.5341, -3.5341, -3.5341, -3.5341,
           -3.5341],
          [-2.6011, -2.6011, -2.6011, -2.6011, -2.6011, -2.6011, -2.6011,
           -2.6011, -2.6011, -2.6011, -2.6011, -2.6011, -2.6011, -2.6011,
           -2.6011],
          [-3.5341, -3.5341, -3.5341, -3.5341, -3.5341, -3.5341, -3.5341,
           -3.5341, -3.5341, -3.5341, -3.5341, -3.5341, -3.5341, -3.5341,
           -3.5341],
          [-3.5341, -3.5341, -3.5341, -3.5341, -3.5341, -3.5341, -3.5341,
           -3.5341, -3.5341, -3.5341, -3.5341, -3.5341, -3.5341, -3.5341,
           -3.5341],
          [-3.5341, -3.5341, -3.5341, -3.5341, -3.5341, -3.5341, -3.5341,
           -3.5341, -3.5341, -3.5341, -3.5341, -3.5341, -3.5341, -3.5341,
           -3.5341],
          [-3.5341, -3.5341, -3.5341, -3.5341, -3.5341, -3.5341, -3.5341,
           -3.5341, -3.5341, -3.5341, -3.5341, -3.5341, -3.5341, -3.5341,
           -3.5341],
          [-3.5341, -3.5341, -3.5341, -3.5341, -3.5341, -3.5341, -3.5341,
           -3.5341, -3.5341, -3.5341, -3.5341, -3.5341, -3.5341, -3.5341,
           -3.5341],
          [-3.5341, -3.5341, -3.5341, -3.5341, -3.5341, -3.5341, -3.5341,
           -3.5341, -3.5341, -3.5341, -3.5341, -3.5341, -3.5341, -3.5341,
           -3.5341],
          [-3.5341, -3.5341, -3.5341, -3.5341, -3.5341, -3.5341, -3.5341,
           -3.5341, -3.5341, -3.5341, -3.5341, -3.5341, -3.5341, -3.5341,
           -3.5341],
          [-3.5341, -3.5341, -3.5341, -3.5341, -3.5341, -3.5341, -3.5341,
           -3.5341, -3.5341, -3.5341, -3.5341, -3.5341, -3.5341, -3.5341,
           -3.5341]],

         [[-3.4215, -3.4215, -3.4215, -3.4215, -3.4215, -3.4215, -3.4214,
           -3.4215, -3.4214, -3.4215, -3.4215, -3.4215, -3.4215, -3.4214,
           -3.4215],
          [-3.4215, -3.4215, -3.4215, -3.4215, -3.4215, -3.4215, -3.4214,
           -3.4215, -3.4214, -3.4215, -3.4215, -3.4215, -3.4215, -3.4214,
           -3.4215],
          [-2.5047, -2.5047, -2.5047, -2.5047, -2.5047, -2.5047, -2.5047,
           -2.5047, -2.5047, -2.5047, -2.5047, -2.5047, -2.5047, -2.5047,
           -2.5047],
          [-3.4215, -3.4215, -3.4215, -3.4215, -3.4215, -3.4215, -3.4214,
           -3.4215, -3.4214, -3.4215, -3.4215, -3.4215, -3.4215, -3.4214,
           -3.4215],
          [-3.4215, -3.4215, -3.4215, -3.4215, -3.4215, -3.4215, -3.4214,
           -3.4215, -3.4214, -3.4215, -3.4215, -3.4215, -3.4215, -3.4214,
           -3.4215],
          [-3.4214, -3.4214, -3.4213, -3.4214, -3.4214, -3.4213, -3.4213,
           -3.4214, -3.4213, -3.4214, -3.4214, -3.4214, -3.4213, -3.4213,
           -3.4213],
          [-3.4215, -3.4215, -3.4215, -3.4215, -3.4215, -3.4215, -3.4214,
           -3.4215, -3.4214, -3.4215, -3.4215, -3.4215, -3.4215, -3.4214,
           -3.4215],
          [-2.4364, -2.4364, -2.4364, -2.4364, -2.4364, -2.4364, -2.4364,
           -2.4364, -2.4364, -2.4364, -2.4364, -2.4364, -2.4364, -2.4364,
           -2.4364],
          [-3.4215, -3.4215, -3.4215, -3.4215, -3.4215, -3.4215, -3.4214,
           -3.4215, -3.4214, -3.4215, -3.4215, -3.4215, -3.4215, -3.4214,
           -3.4215],
          [-3.4215, -3.4215, -3.4215, -3.4215, -3.4215, -3.4215, -3.4214,
           -3.4215, -3.4214, -3.4215, -3.4215, -3.4215, -3.4215, -3.4214,
           -3.4215],
          [-3.4215, -3.4215, -3.4215, -3.4215, -3.4215, -3.4215, -3.4214,
           -3.4215, -3.4214, -3.4215, -3.4215, -3.4215, -3.4215, -3.4214,
           -3.4215],
          [-3.4215, -3.4215, -3.4215, -3.4215, -3.4215, -3.4215, -3.4214,
           -3.4215, -3.4214, -3.4215, -3.4215, -3.4215, -3.4215, -3.4214,
           -3.4215],
          [-3.4215, -3.4215, -3.4215, -3.4215, -3.4215, -3.4215, -3.4214,
           -3.4215, -3.4214, -3.4215, -3.4215, -3.4215, -3.4215, -3.4214,
           -3.4215],
          [-3.4215, -3.4215, -3.4215, -3.4215, -3.4215, -3.4215, -3.4214,
           -3.4215, -3.4214, -3.4215, -3.4215, -3.4215, -3.4215, -3.4214,
           -3.4215],
          [-3.4215, -3.4215, -3.4215, -3.4215, -3.4215, -3.4215, -3.4214,
           -3.4215, -3.4214, -3.4215, -3.4215, -3.4215, -3.4215, -3.4214,
           -3.4215],
          [-3.4215, -3.4215, -3.4215, -3.4215, -3.4215, -3.4215, -3.4214,
           -3.4215, -3.4214, -3.4215, -3.4215, -3.4215, -3.4215, -3.4214,
           -3.4215]]]], grad_fn=<SliceBackward0>)
train_step: Entropy shape: torch.Size([16, 15])
train_step: Entropy sample: tensor([[0.6255, 0.2302],
        [0.4545, 0.6929]], grad_fn=<SliceBackward0>)
train_step: Entropy coefficient: 0.01
train_step: Actor loss: -1.1132909059524536
train_step: returns shape after mean: torch.Size([16, 15])
train_step: target_indices shape: torch.Size([16, 15])
train_step: value_logits shape: torch.Size([16, 15, 255])
train_step: target_twohot shape: torch.Size([16, 15, 255])
--- Starting train_step at 2025-04-01 01:54:45 ---
Full starting_state: {'deter': tensor([[[-0.0121, -0.0250,  0.0452,  ...,  0.0260,  0.0285, -0.0768],
         [ 0.0506,  0.0471, -0.0141,  ..., -0.0501, -0.0301, -0.0620],
         [-0.0476,  0.1289, -0.1900,  ..., -0.0440,  0.0746, -0.0077],
         ...,
         [ 0.0082, -0.0041, -0.1589,  ..., -0.1308,  0.0259, -0.1601],
         [-0.1326,  0.0877, -0.1817,  ..., -0.0163,  0.1028, -0.0558],
         [-0.0526,  0.0502,  0.1310,  ..., -0.0486,  0.0512, -0.0224]],

        [[ 0.0357,  0.0806, -0.0077,  ..., -0.0632, -0.0864, -0.0008],
         [-0.0100, -0.0855, -0.1667,  ...,  0.0460, -0.0650, -0.0371],
         [-0.0304, -0.0089, -0.1105,  ..., -0.0164,  0.0634,  0.1231],
         ...,
         [-0.0279,  0.0836, -0.1808,  ..., -0.0005,  0.0076, -0.1796],
         [-0.1349,  0.0219,  0.0320,  ..., -0.2119,  0.0923,  0.0513],
         [-0.1958,  0.1011, -0.0532,  ...,  0.0910, -0.0020, -0.1142]],

        [[-0.0548, -0.0102, -0.1371,  ...,  0.0004,  0.1344,  0.0062],
         [-0.1047,  0.1021, -0.0317,  ..., -0.0037, -0.1123, -0.0673],
         [-0.0262,  0.0287,  0.0480,  ...,  0.0249, -0.0418, -0.0514],
         ...,
         [-0.1162, -0.0389, -0.0010,  ...,  0.0816, -0.0112,  0.0299],
         [-0.0939, -0.0166, -0.1790,  ...,  0.0870, -0.0470,  0.0842],
         [ 0.0417, -0.0542, -0.0787,  ...,  0.0968,  0.0859, -0.1268]],

        ...,

        [[-0.1319, -0.0462,  0.0682,  ...,  0.0932,  0.0025, -0.1560],
         [ 0.0439,  0.1324, -0.0640,  ...,  0.1748,  0.0542, -0.0247],
         [ 0.0063, -0.0761, -0.1662,  ...,  0.1837, -0.1607, -0.0179],
         ...,
         [-0.0062, -0.0984, -0.0122,  ...,  0.1573,  0.0857,  0.1234],
         [-0.1288,  0.0792, -0.0848,  ...,  0.1225, -0.0101, -0.0765],
         [-0.1350,  0.0067,  0.0654,  ...,  0.0619,  0.0619, -0.2114]],

        [[-0.0479, -0.0047,  0.0234,  ..., -0.0142,  0.0586, -0.0884],
         [-0.1031,  0.1134, -0.2032,  ..., -0.0196,  0.0874,  0.0532],
         [-0.0292,  0.0675, -0.0016,  ...,  0.1015,  0.0265, -0.1184],
         ...,
         [-0.1880, -0.0724,  0.0343,  ...,  0.0876, -0.0197,  0.0217],
         [-0.0089, -0.0265,  0.0741,  ...,  0.0583, -0.0773,  0.0544],
         [-0.0615,  0.0333, -0.0221,  ...,  0.1568,  0.0403,  0.0318]],

        [[-0.1495, -0.1006,  0.0126,  ...,  0.1390,  0.0566, -0.0153],
         [ 0.0115,  0.1380,  0.0434,  ...,  0.0698,  0.1023, -0.0483],
         [-0.0125,  0.1538, -0.1039,  ...,  0.1036,  0.0119, -0.0861],
         ...,
         [-0.0712, -0.0708, -0.0086,  ...,  0.0260, -0.0251, -0.0592],
         [-0.1044, -0.1078, -0.0169,  ..., -0.0360, -0.0544, -0.1038],
         [ 0.0488,  0.0088,  0.0552,  ...,  0.0161,  0.1810, -0.1369]]],
       grad_fn=<StackBackward0>), 'stoch': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [1., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 1., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 1., 0.,  ..., 0., 0., 1.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 1.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]])}
train_step: Starting state deter shape: torch.Size([16, 50, 128])
train_step: Starting state stoch shape: torch.Size([16, 50, 1024])
After ensuring logits/stoch: {'deter': tensor([[[-0.0121, -0.0250,  0.0452,  ...,  0.0260,  0.0285, -0.0768],
         [ 0.0506,  0.0471, -0.0141,  ..., -0.0501, -0.0301, -0.0620],
         [-0.0476,  0.1289, -0.1900,  ..., -0.0440,  0.0746, -0.0077],
         ...,
         [ 0.0082, -0.0041, -0.1589,  ..., -0.1308,  0.0259, -0.1601],
         [-0.1326,  0.0877, -0.1817,  ..., -0.0163,  0.1028, -0.0558],
         [-0.0526,  0.0502,  0.1310,  ..., -0.0486,  0.0512, -0.0224]],

        [[ 0.0357,  0.0806, -0.0077,  ..., -0.0632, -0.0864, -0.0008],
         [-0.0100, -0.0855, -0.1667,  ...,  0.0460, -0.0650, -0.0371],
         [-0.0304, -0.0089, -0.1105,  ..., -0.0164,  0.0634,  0.1231],
         ...,
         [-0.0279,  0.0836, -0.1808,  ..., -0.0005,  0.0076, -0.1796],
         [-0.1349,  0.0219,  0.0320,  ..., -0.2119,  0.0923,  0.0513],
         [-0.1958,  0.1011, -0.0532,  ...,  0.0910, -0.0020, -0.1142]],

        [[-0.0548, -0.0102, -0.1371,  ...,  0.0004,  0.1344,  0.0062],
         [-0.1047,  0.1021, -0.0317,  ..., -0.0037, -0.1123, -0.0673],
         [-0.0262,  0.0287,  0.0480,  ...,  0.0249, -0.0418, -0.0514],
         ...,
         [-0.1162, -0.0389, -0.0010,  ...,  0.0816, -0.0112,  0.0299],
         [-0.0939, -0.0166, -0.1790,  ...,  0.0870, -0.0470,  0.0842],
         [ 0.0417, -0.0542, -0.0787,  ...,  0.0968,  0.0859, -0.1268]],

        ...,

        [[-0.1319, -0.0462,  0.0682,  ...,  0.0932,  0.0025, -0.1560],
         [ 0.0439,  0.1324, -0.0640,  ...,  0.1748,  0.0542, -0.0247],
         [ 0.0063, -0.0761, -0.1662,  ...,  0.1837, -0.1607, -0.0179],
         ...,
         [-0.0062, -0.0984, -0.0122,  ...,  0.1573,  0.0857,  0.1234],
         [-0.1288,  0.0792, -0.0848,  ...,  0.1225, -0.0101, -0.0765],
         [-0.1350,  0.0067,  0.0654,  ...,  0.0619,  0.0619, -0.2114]],

        [[-0.0479, -0.0047,  0.0234,  ..., -0.0142,  0.0586, -0.0884],
         [-0.1031,  0.1134, -0.2032,  ..., -0.0196,  0.0874,  0.0532],
         [-0.0292,  0.0675, -0.0016,  ...,  0.1015,  0.0265, -0.1184],
         ...,
         [-0.1880, -0.0724,  0.0343,  ...,  0.0876, -0.0197,  0.0217],
         [-0.0089, -0.0265,  0.0741,  ...,  0.0583, -0.0773,  0.0544],
         [-0.0615,  0.0333, -0.0221,  ...,  0.1568,  0.0403,  0.0318]],

        [[-0.1495, -0.1006,  0.0126,  ...,  0.1390,  0.0566, -0.0153],
         [ 0.0115,  0.1380,  0.0434,  ...,  0.0698,  0.1023, -0.0483],
         [-0.0125,  0.1538, -0.1039,  ...,  0.1036,  0.0119, -0.0861],
         ...,
         [-0.0712, -0.0708, -0.0086,  ...,  0.0260, -0.0251, -0.0592],
         [-0.1044, -0.1078, -0.0169,  ..., -0.0360, -0.0544, -0.1038],
         [ 0.0488,  0.0088,  0.0552,  ...,  0.0161,  0.1810, -0.1369]]],
       grad_fn=<StackBackward0>), 'stoch': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [1., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 1., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 1., 0.,  ..., 0., 0., 1.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 1.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]]), 'logits': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]])}
train_step: Normalized hidden_state shape: torch.Size([1, 16, 128])
train_step: Normalized stoch shape: torch.Size([16, 1024])
train_step: Normalized deter shape: torch.Size([16, 128])
train_step: Post-imagine_trajectory: Imagined features shape: torch.Size([16, 15, 1152])
train_step: Post-imagine_trajectory: Imagined actions shape: torch.Size([16, 15, 2])
train_step: Post-imagine_trajectory: Imagined action indices shape: torch.Size([16, 15])
train_step: Post-imagine_trajectory: Imagined state deter shape: torch.Size([16, 15, 128])
train_step: Post-imagine_trajectory: Imagined state stoch shape: torch.Size([16, 15, 1024])
Reward shape: torch.Size([16, 15, 1]), Value shape: torch.Size([16, 15, 1]), Slow Value shape: torch.Size([16, 15, 1]), Discount shape: torch.Size([16, 15, 1, 1])
Return targets length: 15, First target shape: torch.Size([16, 16, 1])
train_step: Actor distribution shape: torch.Size([16, 15, 2])
train_step: Action log probabilities shape: torch.Size([16, 15])
train_step: Action log probabilities sample: tensor([[-0.1652, -0.3950],
        [-1.5975, -0.4776]], grad_fn=<SliceBackward0>)
train_step: Advantages shape: torch.Size([16, 15, 16, 15])
train_step: Advantages sample: tensor([[[[-5.7503, -5.7504, -5.7503, -5.7503, -5.7503, -5.7504, -5.7503,
           -5.7503, -5.7503, -5.7503, -5.7504, -5.7503, -5.7503, -5.7503,
           -5.7503],
          [-5.7503, -5.7504, -5.7503, -5.7503, -5.7503, -5.7504, -5.7503,
           -5.7503, -5.7503, -5.7503, -5.7504, -5.7503, -5.7503, -5.7503,
           -5.7503],
          [-5.7503, -5.7504, -5.7503, -5.7503, -5.7503, -5.7504, -5.7503,
           -5.7503, -5.7503, -5.7503, -5.7504, -5.7503, -5.7503, -5.7503,
           -5.7503],
          [-3.0211, -3.0211, -3.0211, -3.0211, -3.0211, -3.0211, -3.0211,
           -3.0211, -3.0211, -3.0211, -3.0212, -3.0211, -3.0211, -3.0211,
           -3.0211],
          [-5.7503, -5.7504, -5.7503, -5.7503, -5.7503, -5.7504, -5.7503,
           -5.7503, -5.7503, -5.7503, -5.7504, -5.7503, -5.7503, -5.7503,
           -5.7503],
          [-5.7503, -5.7504, -5.7503, -5.7503, -5.7503, -5.7504, -5.7503,
           -5.7503, -5.7503, -5.7503, -5.7504, -5.7503, -5.7503, -5.7503,
           -5.7503],
          [-5.7503, -5.7504, -5.7503, -5.7503, -5.7503, -5.7504, -5.7503,
           -5.7503, -5.7503, -5.7503, -5.7504, -5.7503, -5.7503, -5.7503,
           -5.7503],
          [-5.7503, -5.7504, -5.7503, -5.7503, -5.7503, -5.7504, -5.7503,
           -5.7503, -5.7503, -5.7503, -5.7504, -5.7503, -5.7503, -5.7503,
           -5.7503],
          [-5.7503, -5.7504, -5.7503, -5.7503, -5.7503, -5.7504, -5.7503,
           -5.7503, -5.7503, -5.7503, -5.7504, -5.7503, -5.7503, -5.7503,
           -5.7503],
          [-5.7503, -5.7504, -5.7503, -5.7503, -5.7503, -5.7504, -5.7503,
           -5.7503, -5.7503, -5.7503, -5.7504, -5.7503, -5.7503, -5.7503,
           -5.7503],
          [-3.5309, -3.5310, -3.5310, -3.5310, -3.5310, -3.5310, -3.5310,
           -3.5309, -3.5309, -3.5310, -3.5310, -3.5310, -3.5310, -3.5309,
           -3.5309],
          [-5.7503, -5.7504, -5.7503, -5.7503, -5.7503, -5.7504, -5.7503,
           -5.7503, -5.7503, -5.7503, -5.7504, -5.7503, -5.7503, -5.7503,
           -5.7503],
          [-5.7503, -5.7504, -5.7503, -5.7503, -5.7503, -5.7504, -5.7503,
           -5.7503, -5.7503, -5.7503, -5.7504, -5.7503, -5.7503, -5.7503,
           -5.7503],
          [-3.0211, -3.0211, -3.0211, -3.0211, -3.0211, -3.0211, -3.0211,
           -3.0211, -3.0211, -3.0211, -3.0212, -3.0211, -3.0211, -3.0211,
           -3.0211],
          [-5.7503, -5.7504, -5.7503, -5.7503, -5.7503, -5.7504, -5.7503,
           -5.7503, -5.7503, -5.7503, -5.7504, -5.7503, -5.7503, -5.7503,
           -5.7503],
          [-5.7503, -5.7504, -5.7503, -5.7503, -5.7503, -5.7504, -5.7503,
           -5.7503, -5.7503, -5.7503, -5.7504, -5.7503, -5.7503, -5.7503,
           -5.7503]],

         [[-4.6135, -4.6134, -4.6135, -4.6134, -4.6135, -4.6135, -4.6135,
           -4.6135, -4.6135, -4.6135, -4.6135, -4.6135, -4.6135, -4.6135,
           -4.6135],
          [-4.6135, -4.6134, -4.6135, -4.6134, -4.6135, -4.6135, -4.6135,
           -4.6135, -4.6135, -4.6135, -4.6135, -4.6135, -4.6135, -4.6135,
           -4.6135],
          [-4.6135, -4.6134, -4.6135, -4.6134, -4.6135, -4.6135, -4.6135,
           -4.6135, -4.6135, -4.6135, -4.6135, -4.6135, -4.6135, -4.6135,
           -4.6135],
          [-1.7320, -1.7319, -1.7320, -1.7319, -1.7320, -1.7320, -1.7320,
           -1.7320, -1.7321, -1.7320, -1.7320, -1.7320, -1.7320, -1.7320,
           -1.7320],
          [-4.6135, -4.6134, -4.6135, -4.6134, -4.6135, -4.6135, -4.6135,
           -4.6135, -4.6135, -4.6135, -4.6135, -4.6135, -4.6135, -4.6135,
           -4.6135],
          [-4.6135, -4.6134, -4.6135, -4.6134, -4.6135, -4.6135, -4.6135,
           -4.6135, -4.6135, -4.6135, -4.6135, -4.6135, -4.6135, -4.6135,
           -4.6135],
          [-4.6135, -4.6134, -4.6135, -4.6134, -4.6135, -4.6135, -4.6135,
           -4.6135, -4.6135, -4.6135, -4.6135, -4.6135, -4.6135, -4.6135,
           -4.6135],
          [-4.6135, -4.6134, -4.6135, -4.6134, -4.6135, -4.6135, -4.6135,
           -4.6135, -4.6135, -4.6135, -4.6135, -4.6135, -4.6135, -4.6135,
           -4.6135],
          [-4.6135, -4.6134, -4.6135, -4.6134, -4.6135, -4.6135, -4.6135,
           -4.6135, -4.6135, -4.6135, -4.6135, -4.6135, -4.6135, -4.6135,
           -4.6135],
          [-4.6135, -4.6134, -4.6135, -4.6134, -4.6135, -4.6135, -4.6135,
           -4.6135, -4.6135, -4.6135, -4.6135, -4.6135, -4.6135, -4.6135,
           -4.6135],
          [-2.2703, -2.2702, -2.2703, -2.2702, -2.2703, -2.2703, -2.2703,
           -2.2703, -2.2703, -2.2703, -2.2702, -2.2703, -2.2703, -2.2703,
           -2.2703],
          [-4.6135, -4.6134, -4.6135, -4.6134, -4.6135, -4.6135, -4.6135,
           -4.6135, -4.6135, -4.6135, -4.6135, -4.6135, -4.6135, -4.6135,
           -4.6135],
          [-4.6135, -4.6134, -4.6135, -4.6134, -4.6135, -4.6135, -4.6135,
           -4.6135, -4.6135, -4.6135, -4.6135, -4.6135, -4.6135, -4.6135,
           -4.6135],
          [-1.7320, -1.7319, -1.7320, -1.7319, -1.7320, -1.7320, -1.7320,
           -1.7320, -1.7321, -1.7320, -1.7320, -1.7320, -1.7320, -1.7320,
           -1.7320],
          [-4.6135, -4.6134, -4.6135, -4.6134, -4.6135, -4.6135, -4.6135,
           -4.6135, -4.6135, -4.6135, -4.6135, -4.6135, -4.6135, -4.6135,
           -4.6135],
          [-4.6135, -4.6134, -4.6135, -4.6134, -4.6135, -4.6135, -4.6135,
           -4.6135, -4.6135, -4.6135, -4.6135, -4.6135, -4.6135, -4.6135,
           -4.6135]]],


        [[[-4.4276, -4.4276, -4.4276, -4.4276, -4.4276, -4.4276, -4.4276,
           -4.4276, -4.4276, -4.4276, -4.4277, -4.4276, -4.4276, -4.4276,
           -4.4276],
          [-4.4276, -4.4276, -4.4276, -4.4276, -4.4276, -4.4276, -4.4276,
           -4.4276, -4.4276, -4.4276, -4.4277, -4.4276, -4.4276, -4.4276,
           -4.4276],
          [-4.4276, -4.4276, -4.4276, -4.4276, -4.4276, -4.4276, -4.4276,
           -4.4276, -4.4276, -4.4276, -4.4277, -4.4276, -4.4276, -4.4276,
           -4.4276],
          [-1.9073, -1.9074, -1.9074, -1.9073, -1.9073, -1.9074, -1.9073,
           -1.9073, -1.9073, -1.9073, -1.9074, -1.9073, -1.9073, -1.9073,
           -1.9073],
          [-4.4276, -4.4276, -4.4276, -4.4276, -4.4276, -4.4276, -4.4276,
           -4.4276, -4.4276, -4.4276, -4.4277, -4.4276, -4.4276, -4.4276,
           -4.4276],
          [-4.4276, -4.4276, -4.4276, -4.4276, -4.4276, -4.4276, -4.4276,
           -4.4276, -4.4276, -4.4276, -4.4277, -4.4276, -4.4276, -4.4276,
           -4.4276],
          [-4.4276, -4.4276, -4.4276, -4.4276, -4.4276, -4.4276, -4.4276,
           -4.4276, -4.4276, -4.4276, -4.4277, -4.4276, -4.4276, -4.4276,
           -4.4276],
          [-4.4276, -4.4276, -4.4276, -4.4276, -4.4276, -4.4276, -4.4276,
           -4.4276, -4.4276, -4.4276, -4.4277, -4.4276, -4.4276, -4.4276,
           -4.4276],
          [-4.4276, -4.4276, -4.4276, -4.4276, -4.4276, -4.4276, -4.4276,
           -4.4276, -4.4276, -4.4276, -4.4277, -4.4276, -4.4276, -4.4276,
           -4.4276],
          [-4.4276, -4.4276, -4.4276, -4.4276, -4.4276, -4.4276, -4.4276,
           -4.4276, -4.4276, -4.4276, -4.4277, -4.4276, -4.4276, -4.4276,
           -4.4276],
          [-2.0514, -2.0514, -2.0514, -2.0514, -2.0514, -2.0514, -2.0514,
           -2.0513, -2.0514, -2.0514, -2.0515, -2.0514, -2.0514, -2.0514,
           -2.0514],
          [-4.4276, -4.4276, -4.4276, -4.4276, -4.4276, -4.4276, -4.4276,
           -4.4276, -4.4276, -4.4276, -4.4277, -4.4276, -4.4276, -4.4276,
           -4.4276],
          [-4.4276, -4.4276, -4.4276, -4.4276, -4.4276, -4.4276, -4.4276,
           -4.4276, -4.4276, -4.4276, -4.4277, -4.4276, -4.4276, -4.4276,
           -4.4276],
          [-1.9073, -1.9074, -1.9074, -1.9073, -1.9073, -1.9074, -1.9073,
           -1.9073, -1.9073, -1.9073, -1.9074, -1.9073, -1.9073, -1.9073,
           -1.9073],
          [-4.4276, -4.4276, -4.4276, -4.4276, -4.4276, -4.4276, -4.4276,
           -4.4276, -4.4276, -4.4276, -4.4277, -4.4276, -4.4276, -4.4276,
           -4.4276],
          [-4.4276, -4.4276, -4.4276, -4.4276, -4.4276, -4.4276, -4.4276,
           -4.4276, -4.4276, -4.4276, -4.4277, -4.4276, -4.4276, -4.4276,
           -4.4276]],

         [[-4.1786, -4.1786, -4.1786, -4.1786, -4.1786, -4.1786, -4.1786,
           -4.1786, -4.1787, -4.1786, -4.1786, -4.1786, -4.1786, -4.1786,
           -4.1786],
          [-4.1786, -4.1786, -4.1786, -4.1786, -4.1786, -4.1786, -4.1786,
           -4.1786, -4.1787, -4.1786, -4.1786, -4.1786, -4.1786, -4.1786,
           -4.1786],
          [-4.1786, -4.1786, -4.1786, -4.1786, -4.1786, -4.1786, -4.1786,
           -4.1786, -4.1787, -4.1786, -4.1786, -4.1786, -4.1786, -4.1786,
           -4.1786],
          [-1.5177, -1.5177, -1.5177, -1.5177, -1.5177, -1.5177, -1.5177,
           -1.5177, -1.5178, -1.5177, -1.5177, -1.5177, -1.5177, -1.5177,
           -1.5177],
          [-4.1786, -4.1786, -4.1786, -4.1786, -4.1786, -4.1786, -4.1786,
           -4.1786, -4.1787, -4.1786, -4.1786, -4.1786, -4.1786, -4.1786,
           -4.1786],
          [-4.1786, -4.1786, -4.1786, -4.1786, -4.1786, -4.1786, -4.1786,
           -4.1786, -4.1787, -4.1786, -4.1786, -4.1786, -4.1786, -4.1786,
           -4.1786],
          [-4.1786, -4.1786, -4.1786, -4.1786, -4.1786, -4.1786, -4.1786,
           -4.1786, -4.1787, -4.1786, -4.1786, -4.1786, -4.1786, -4.1786,
           -4.1786],
          [-4.1786, -4.1786, -4.1786, -4.1786, -4.1786, -4.1786, -4.1786,
           -4.1786, -4.1787, -4.1786, -4.1786, -4.1786, -4.1786, -4.1786,
           -4.1786],
          [-4.1786, -4.1786, -4.1786, -4.1786, -4.1786, -4.1786, -4.1786,
           -4.1786, -4.1787, -4.1786, -4.1786, -4.1786, -4.1786, -4.1786,
           -4.1786],
          [-4.1786, -4.1786, -4.1786, -4.1786, -4.1786, -4.1786, -4.1786,
           -4.1786, -4.1787, -4.1786, -4.1786, -4.1786, -4.1786, -4.1786,
           -4.1786],
          [-1.6698, -1.6698, -1.6698, -1.6698, -1.6698, -1.6698, -1.6698,
           -1.6698, -1.6699, -1.6698, -1.6698, -1.6698, -1.6698, -1.6698,
           -1.6698],
          [-4.1786, -4.1786, -4.1786, -4.1786, -4.1786, -4.1786, -4.1786,
           -4.1786, -4.1787, -4.1786, -4.1786, -4.1786, -4.1786, -4.1786,
           -4.1786],
          [-4.1786, -4.1786, -4.1786, -4.1786, -4.1786, -4.1786, -4.1786,
           -4.1786, -4.1787, -4.1786, -4.1786, -4.1786, -4.1786, -4.1786,
           -4.1786],
          [-1.5177, -1.5177, -1.5177, -1.5177, -1.5177, -1.5177, -1.5177,
           -1.5177, -1.5178, -1.5177, -1.5177, -1.5177, -1.5177, -1.5177,
           -1.5177],
          [-4.1786, -4.1786, -4.1786, -4.1786, -4.1786, -4.1786, -4.1786,
           -4.1786, -4.1787, -4.1786, -4.1786, -4.1786, -4.1786, -4.1786,
           -4.1786],
          [-4.1786, -4.1786, -4.1786, -4.1786, -4.1786, -4.1786, -4.1786,
           -4.1786, -4.1787, -4.1786, -4.1786, -4.1786, -4.1786, -4.1786,
           -4.1786]]]], grad_fn=<SliceBackward0>)
train_step: Return scale: 1.8730782219352182
train_step: Scaled advantages shape: torch.Size([16, 15, 16, 15])
train_step: Scaled advantages sample: tensor([[[[-3.0700, -3.0700, -3.0700, -3.0700, -3.0700, -3.0700, -3.0700,
           -3.0700, -3.0700, -3.0700, -3.0700, -3.0700, -3.0700, -3.0700,
           -3.0700],
          [-3.0700, -3.0700, -3.0700, -3.0700, -3.0700, -3.0700, -3.0700,
           -3.0700, -3.0700, -3.0700, -3.0700, -3.0700, -3.0700, -3.0700,
           -3.0700],
          [-3.0700, -3.0700, -3.0700, -3.0700, -3.0700, -3.0700, -3.0700,
           -3.0700, -3.0700, -3.0700, -3.0700, -3.0700, -3.0700, -3.0700,
           -3.0700],
          [-1.6129, -1.6129, -1.6129, -1.6129, -1.6129, -1.6129, -1.6129,
           -1.6129, -1.6129, -1.6129, -1.6130, -1.6129, -1.6129, -1.6129,
           -1.6129],
          [-3.0700, -3.0700, -3.0700, -3.0700, -3.0700, -3.0700, -3.0700,
           -3.0700, -3.0700, -3.0700, -3.0700, -3.0700, -3.0700, -3.0700,
           -3.0700],
          [-3.0700, -3.0700, -3.0700, -3.0700, -3.0700, -3.0700, -3.0700,
           -3.0700, -3.0700, -3.0700, -3.0700, -3.0700, -3.0700, -3.0700,
           -3.0700],
          [-3.0700, -3.0700, -3.0700, -3.0700, -3.0700, -3.0700, -3.0700,
           -3.0700, -3.0700, -3.0700, -3.0700, -3.0700, -3.0700, -3.0700,
           -3.0700],
          [-3.0700, -3.0700, -3.0700, -3.0700, -3.0700, -3.0700, -3.0700,
           -3.0700, -3.0700, -3.0700, -3.0700, -3.0700, -3.0700, -3.0700,
           -3.0700],
          [-3.0700, -3.0700, -3.0700, -3.0700, -3.0700, -3.0700, -3.0700,
           -3.0700, -3.0700, -3.0700, -3.0700, -3.0700, -3.0700, -3.0700,
           -3.0700],
          [-3.0700, -3.0700, -3.0700, -3.0700, -3.0700, -3.0700, -3.0700,
           -3.0700, -3.0700, -3.0700, -3.0700, -3.0700, -3.0700, -3.0700,
           -3.0700],
          [-1.8851, -1.8851, -1.8851, -1.8851, -1.8851, -1.8851, -1.8851,
           -1.8851, -1.8851, -1.8851, -1.8851, -1.8851, -1.8851, -1.8851,
           -1.8851],
          [-3.0700, -3.0700, -3.0700, -3.0700, -3.0700, -3.0700, -3.0700,
           -3.0700, -3.0700, -3.0700, -3.0700, -3.0700, -3.0700, -3.0700,
           -3.0700],
          [-3.0700, -3.0700, -3.0700, -3.0700, -3.0700, -3.0700, -3.0700,
           -3.0700, -3.0700, -3.0700, -3.0700, -3.0700, -3.0700, -3.0700,
           -3.0700],
          [-1.6129, -1.6129, -1.6129, -1.6129, -1.6129, -1.6129, -1.6129,
           -1.6129, -1.6129, -1.6129, -1.6130, -1.6129, -1.6129, -1.6129,
           -1.6129],
          [-3.0700, -3.0700, -3.0700, -3.0700, -3.0700, -3.0700, -3.0700,
           -3.0700, -3.0700, -3.0700, -3.0700, -3.0700, -3.0700, -3.0700,
           -3.0700],
          [-3.0700, -3.0700, -3.0700, -3.0700, -3.0700, -3.0700, -3.0700,
           -3.0700, -3.0700, -3.0700, -3.0700, -3.0700, -3.0700, -3.0700,
           -3.0700]],

         [[-2.4631, -2.4630, -2.4631, -2.4630, -2.4630, -2.4631, -2.4630,
           -2.4630, -2.4631, -2.4631, -2.4630, -2.4631, -2.4630, -2.4631,
           -2.4631],
          [-2.4631, -2.4630, -2.4631, -2.4630, -2.4630, -2.4631, -2.4630,
           -2.4630, -2.4631, -2.4631, -2.4630, -2.4631, -2.4630, -2.4631,
           -2.4631],
          [-2.4631, -2.4630, -2.4631, -2.4630, -2.4630, -2.4631, -2.4630,
           -2.4630, -2.4631, -2.4631, -2.4630, -2.4631, -2.4630, -2.4631,
           -2.4631],
          [-0.9247, -0.9246, -0.9247, -0.9246, -0.9247, -0.9247, -0.9247,
           -0.9247, -0.9247, -0.9247, -0.9247, -0.9247, -0.9247, -0.9247,
           -0.9247],
          [-2.4631, -2.4630, -2.4631, -2.4630, -2.4630, -2.4631, -2.4630,
           -2.4630, -2.4631, -2.4631, -2.4630, -2.4631, -2.4630, -2.4631,
           -2.4631],
          [-2.4631, -2.4630, -2.4631, -2.4630, -2.4630, -2.4631, -2.4630,
           -2.4630, -2.4631, -2.4631, -2.4630, -2.4631, -2.4630, -2.4631,
           -2.4631],
          [-2.4631, -2.4630, -2.4631, -2.4630, -2.4630, -2.4631, -2.4630,
           -2.4630, -2.4631, -2.4631, -2.4630, -2.4631, -2.4630, -2.4631,
           -2.4631],
          [-2.4631, -2.4630, -2.4631, -2.4630, -2.4630, -2.4631, -2.4630,
           -2.4630, -2.4631, -2.4631, -2.4630, -2.4631, -2.4630, -2.4631,
           -2.4631],
          [-2.4631, -2.4630, -2.4631, -2.4630, -2.4630, -2.4631, -2.4630,
           -2.4630, -2.4631, -2.4631, -2.4630, -2.4631, -2.4630, -2.4631,
           -2.4631],
          [-2.4631, -2.4630, -2.4631, -2.4630, -2.4630, -2.4631, -2.4630,
           -2.4630, -2.4631, -2.4631, -2.4630, -2.4631, -2.4630, -2.4631,
           -2.4631],
          [-1.2121, -1.2120, -1.2121, -1.2120, -1.2121, -1.2121, -1.2121,
           -1.2121, -1.2121, -1.2121, -1.2120, -1.2121, -1.2120, -1.2121,
           -1.2121],
          [-2.4631, -2.4630, -2.4631, -2.4630, -2.4630, -2.4631, -2.4630,
           -2.4630, -2.4631, -2.4631, -2.4630, -2.4631, -2.4630, -2.4631,
           -2.4631],
          [-2.4631, -2.4630, -2.4631, -2.4630, -2.4630, -2.4631, -2.4630,
           -2.4630, -2.4631, -2.4631, -2.4630, -2.4631, -2.4630, -2.4631,
           -2.4631],
          [-0.9247, -0.9246, -0.9247, -0.9246, -0.9247, -0.9247, -0.9247,
           -0.9247, -0.9247, -0.9247, -0.9247, -0.9247, -0.9247, -0.9247,
           -0.9247],
          [-2.4631, -2.4630, -2.4631, -2.4630, -2.4630, -2.4631, -2.4630,
           -2.4630, -2.4631, -2.4631, -2.4630, -2.4631, -2.4630, -2.4631,
           -2.4631],
          [-2.4631, -2.4630, -2.4631, -2.4630, -2.4630, -2.4631, -2.4630,
           -2.4630, -2.4631, -2.4631, -2.4630, -2.4631, -2.4630, -2.4631,
           -2.4631]]],


        [[[-2.3638, -2.3638, -2.3638, -2.3638, -2.3638, -2.3638, -2.3638,
           -2.3638, -2.3638, -2.3638, -2.3639, -2.3638, -2.3638, -2.3638,
           -2.3638],
          [-2.3638, -2.3638, -2.3638, -2.3638, -2.3638, -2.3638, -2.3638,
           -2.3638, -2.3638, -2.3638, -2.3639, -2.3638, -2.3638, -2.3638,
           -2.3638],
          [-2.3638, -2.3638, -2.3638, -2.3638, -2.3638, -2.3638, -2.3638,
           -2.3638, -2.3638, -2.3638, -2.3639, -2.3638, -2.3638, -2.3638,
           -2.3638],
          [-1.0183, -1.0183, -1.0183, -1.0183, -1.0183, -1.0183, -1.0183,
           -1.0183, -1.0183, -1.0183, -1.0183, -1.0183, -1.0183, -1.0183,
           -1.0183],
          [-2.3638, -2.3638, -2.3638, -2.3638, -2.3638, -2.3638, -2.3638,
           -2.3638, -2.3638, -2.3638, -2.3639, -2.3638, -2.3638, -2.3638,
           -2.3638],
          [-2.3638, -2.3638, -2.3638, -2.3638, -2.3638, -2.3638, -2.3638,
           -2.3638, -2.3638, -2.3638, -2.3639, -2.3638, -2.3638, -2.3638,
           -2.3638],
          [-2.3638, -2.3638, -2.3638, -2.3638, -2.3638, -2.3638, -2.3638,
           -2.3638, -2.3638, -2.3638, -2.3639, -2.3638, -2.3638, -2.3638,
           -2.3638],
          [-2.3638, -2.3638, -2.3638, -2.3638, -2.3638, -2.3638, -2.3638,
           -2.3638, -2.3638, -2.3638, -2.3639, -2.3638, -2.3638, -2.3638,
           -2.3638],
          [-2.3638, -2.3638, -2.3638, -2.3638, -2.3638, -2.3638, -2.3638,
           -2.3638, -2.3638, -2.3638, -2.3639, -2.3638, -2.3638, -2.3638,
           -2.3638],
          [-2.3638, -2.3638, -2.3638, -2.3638, -2.3638, -2.3638, -2.3638,
           -2.3638, -2.3638, -2.3638, -2.3639, -2.3638, -2.3638, -2.3638,
           -2.3638],
          [-1.0952, -1.0952, -1.0952, -1.0952, -1.0952, -1.0952, -1.0952,
           -1.0952, -1.0952, -1.0952, -1.0952, -1.0952, -1.0952, -1.0952,
           -1.0952],
          [-2.3638, -2.3638, -2.3638, -2.3638, -2.3638, -2.3638, -2.3638,
           -2.3638, -2.3638, -2.3638, -2.3639, -2.3638, -2.3638, -2.3638,
           -2.3638],
          [-2.3638, -2.3638, -2.3638, -2.3638, -2.3638, -2.3638, -2.3638,
           -2.3638, -2.3638, -2.3638, -2.3639, -2.3638, -2.3638, -2.3638,
           -2.3638],
          [-1.0183, -1.0183, -1.0183, -1.0183, -1.0183, -1.0183, -1.0183,
           -1.0183, -1.0183, -1.0183, -1.0183, -1.0183, -1.0183, -1.0183,
           -1.0183],
          [-2.3638, -2.3638, -2.3638, -2.3638, -2.3638, -2.3638, -2.3638,
           -2.3638, -2.3638, -2.3638, -2.3639, -2.3638, -2.3638, -2.3638,
           -2.3638],
          [-2.3638, -2.3638, -2.3638, -2.3638, -2.3638, -2.3638, -2.3638,
           -2.3638, -2.3638, -2.3638, -2.3639, -2.3638, -2.3638, -2.3638,
           -2.3638]],

         [[-2.2309, -2.2309, -2.2309, -2.2309, -2.2309, -2.2309, -2.2309,
           -2.2309, -2.2309, -2.2309, -2.2309, -2.2309, -2.2309, -2.2309,
           -2.2309],
          [-2.2309, -2.2309, -2.2309, -2.2309, -2.2309, -2.2309, -2.2309,
           -2.2309, -2.2309, -2.2309, -2.2309, -2.2309, -2.2309, -2.2309,
           -2.2309],
          [-2.2309, -2.2309, -2.2309, -2.2309, -2.2309, -2.2309, -2.2309,
           -2.2309, -2.2309, -2.2309, -2.2309, -2.2309, -2.2309, -2.2309,
           -2.2309],
          [-0.8103, -0.8102, -0.8103, -0.8103, -0.8103, -0.8103, -0.8103,
           -0.8103, -0.8103, -0.8103, -0.8103, -0.8103, -0.8103, -0.8103,
           -0.8103],
          [-2.2309, -2.2309, -2.2309, -2.2309, -2.2309, -2.2309, -2.2309,
           -2.2309, -2.2309, -2.2309, -2.2309, -2.2309, -2.2309, -2.2309,
           -2.2309],
          [-2.2309, -2.2309, -2.2309, -2.2309, -2.2309, -2.2309, -2.2309,
           -2.2309, -2.2309, -2.2309, -2.2309, -2.2309, -2.2309, -2.2309,
           -2.2309],
          [-2.2309, -2.2309, -2.2309, -2.2309, -2.2309, -2.2309, -2.2309,
           -2.2309, -2.2309, -2.2309, -2.2309, -2.2309, -2.2309, -2.2309,
           -2.2309],
          [-2.2309, -2.2309, -2.2309, -2.2309, -2.2309, -2.2309, -2.2309,
           -2.2309, -2.2309, -2.2309, -2.2309, -2.2309, -2.2309, -2.2309,
           -2.2309],
          [-2.2309, -2.2309, -2.2309, -2.2309, -2.2309, -2.2309, -2.2309,
           -2.2309, -2.2309, -2.2309, -2.2309, -2.2309, -2.2309, -2.2309,
           -2.2309],
          [-2.2309, -2.2309, -2.2309, -2.2309, -2.2309, -2.2309, -2.2309,
           -2.2309, -2.2309, -2.2309, -2.2309, -2.2309, -2.2309, -2.2309,
           -2.2309],
          [-0.8915, -0.8915, -0.8915, -0.8915, -0.8915, -0.8915, -0.8915,
           -0.8915, -0.8915, -0.8915, -0.8915, -0.8915, -0.8915, -0.8915,
           -0.8915],
          [-2.2309, -2.2309, -2.2309, -2.2309, -2.2309, -2.2309, -2.2309,
           -2.2309, -2.2309, -2.2309, -2.2309, -2.2309, -2.2309, -2.2309,
           -2.2309],
          [-2.2309, -2.2309, -2.2309, -2.2309, -2.2309, -2.2309, -2.2309,
           -2.2309, -2.2309, -2.2309, -2.2309, -2.2309, -2.2309, -2.2309,
           -2.2309],
          [-0.8103, -0.8102, -0.8103, -0.8103, -0.8103, -0.8103, -0.8103,
           -0.8103, -0.8103, -0.8103, -0.8103, -0.8103, -0.8103, -0.8103,
           -0.8103],
          [-2.2309, -2.2309, -2.2309, -2.2309, -2.2309, -2.2309, -2.2309,
           -2.2309, -2.2309, -2.2309, -2.2309, -2.2309, -2.2309, -2.2309,
           -2.2309],
          [-2.2309, -2.2309, -2.2309, -2.2309, -2.2309, -2.2309, -2.2309,
           -2.2309, -2.2309, -2.2309, -2.2309, -2.2309, -2.2309, -2.2309,
           -2.2309]]]], grad_fn=<SliceBackward0>)
train_step: Entropy shape: torch.Size([16, 15])
train_step: Entropy sample: tensor([[0.4266, 0.6316],
        [0.5037, 0.6639]], grad_fn=<SliceBackward0>)
train_step: Entropy coefficient: 0.01
train_step: Actor loss: -1.0731550455093384
train_step: returns shape after mean: torch.Size([16, 15])
train_step: target_indices shape: torch.Size([16, 15])
train_step: value_logits shape: torch.Size([16, 15, 255])
train_step: target_twohot shape: torch.Size([16, 15, 255])
--- Starting train_step at 2025-04-01 01:55:03 ---
Full starting_state: {'deter': tensor([[[-0.0082,  0.0796, -0.0342,  ...,  0.0156,  0.0499, -0.1027],
         [-0.0043,  0.0037, -0.0935,  ..., -0.0764,  0.0617,  0.0794],
         [-0.0304,  0.0566,  0.0242,  ..., -0.0056,  0.0380, -0.0215],
         ...,
         [-0.0075, -0.0018,  0.0524,  ..., -0.0897,  0.0810, -0.1446],
         [-0.1367, -0.1058, -0.0440,  ..., -0.0807,  0.1346, -0.0280],
         [-0.0318,  0.1145, -0.1471,  ...,  0.0552,  0.0921, -0.1246]],

        [[-0.0205, -0.1049, -0.0977,  ...,  0.0856,  0.0446, -0.0254],
         [-0.0405,  0.0521, -0.1613,  ...,  0.1446,  0.0005, -0.0205],
         [-0.0619,  0.2291, -0.0659,  ...,  0.0227, -0.0343, -0.0851],
         ...,
         [-0.0360, -0.1438, -0.1543,  ...,  0.1361, -0.0290, -0.0467],
         [-0.1111,  0.0311,  0.1977,  ...,  0.0801,  0.1194, -0.1275],
         [-0.0996, -0.0275, -0.0686,  ...,  0.0400,  0.0073, -0.1234]],

        [[-0.1212,  0.0163, -0.0253,  ...,  0.0427, -0.0601, -0.0822],
         [-0.0422,  0.0295, -0.1482,  ...,  0.0397, -0.2056,  0.1985],
         [-0.0687,  0.0246,  0.0656,  ..., -0.1453, -0.0131,  0.0346],
         ...,
         [-0.0652,  0.0013, -0.0268,  ...,  0.0687,  0.0543,  0.0570],
         [-0.0399,  0.0237, -0.0359,  ..., -0.0925, -0.0325, -0.0080],
         [ 0.0723,  0.0286, -0.0169,  ..., -0.0701, -0.0391, -0.0903]],

        ...,

        [[-0.2560,  0.0343,  0.0198,  ...,  0.0235, -0.1294, -0.1122],
         [-0.1168, -0.0134,  0.0013,  ..., -0.1594, -0.0681,  0.0166],
         [-0.1366, -0.0065,  0.1101,  ...,  0.0647,  0.0332,  0.0900],
         ...,
         [-0.0386,  0.0044, -0.0181,  ..., -0.0179,  0.0197, -0.0183],
         [-0.0944,  0.0044,  0.0425,  ..., -0.0581, -0.0138, -0.0370],
         [-0.1762, -0.0132, -0.1563,  ...,  0.0021,  0.0080,  0.1578]],

        [[-0.0636, -0.0319,  0.0238,  ..., -0.0226, -0.0668,  0.1363],
         [-0.0010,  0.1299, -0.0585,  ...,  0.0913,  0.0424,  0.0119],
         [-0.0549,  0.1239, -0.0887,  ...,  0.2059,  0.1081, -0.0314],
         ...,
         [-0.1810,  0.0728, -0.0564,  ...,  0.0258,  0.0494,  0.1025],
         [-0.0484,  0.0967, -0.0358,  ..., -0.0453, -0.1152, -0.2767],
         [-0.0448,  0.0187, -0.2066,  ...,  0.1324, -0.1930,  0.1942]],

        [[-0.1027, -0.0213, -0.1386,  ..., -0.0042,  0.0113, -0.1417],
         [ 0.0537,  0.0707, -0.1861,  ..., -0.0186,  0.0360, -0.0045],
         [-0.1148,  0.0645, -0.0655,  ..., -0.1318,  0.0558, -0.0885],
         ...,
         [-0.0933,  0.1551, -0.0183,  ...,  0.1530, -0.1379,  0.0547],
         [ 0.0604,  0.0082, -0.0835,  ...,  0.1885, -0.0456, -0.1020],
         [ 0.0083, -0.0573, -0.0734,  ...,  0.1250,  0.0183,  0.1465]]],
       grad_fn=<StackBackward0>), 'stoch': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 1.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 1., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 1.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [1., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 1., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]])}
train_step: Starting state deter shape: torch.Size([16, 50, 128])
train_step: Starting state stoch shape: torch.Size([16, 50, 1024])
After ensuring logits/stoch: {'deter': tensor([[[-0.0082,  0.0796, -0.0342,  ...,  0.0156,  0.0499, -0.1027],
         [-0.0043,  0.0037, -0.0935,  ..., -0.0764,  0.0617,  0.0794],
         [-0.0304,  0.0566,  0.0242,  ..., -0.0056,  0.0380, -0.0215],
         ...,
         [-0.0075, -0.0018,  0.0524,  ..., -0.0897,  0.0810, -0.1446],
         [-0.1367, -0.1058, -0.0440,  ..., -0.0807,  0.1346, -0.0280],
         [-0.0318,  0.1145, -0.1471,  ...,  0.0552,  0.0921, -0.1246]],

        [[-0.0205, -0.1049, -0.0977,  ...,  0.0856,  0.0446, -0.0254],
         [-0.0405,  0.0521, -0.1613,  ...,  0.1446,  0.0005, -0.0205],
         [-0.0619,  0.2291, -0.0659,  ...,  0.0227, -0.0343, -0.0851],
         ...,
         [-0.0360, -0.1438, -0.1543,  ...,  0.1361, -0.0290, -0.0467],
         [-0.1111,  0.0311,  0.1977,  ...,  0.0801,  0.1194, -0.1275],
         [-0.0996, -0.0275, -0.0686,  ...,  0.0400,  0.0073, -0.1234]],

        [[-0.1212,  0.0163, -0.0253,  ...,  0.0427, -0.0601, -0.0822],
         [-0.0422,  0.0295, -0.1482,  ...,  0.0397, -0.2056,  0.1985],
         [-0.0687,  0.0246,  0.0656,  ..., -0.1453, -0.0131,  0.0346],
         ...,
         [-0.0652,  0.0013, -0.0268,  ...,  0.0687,  0.0543,  0.0570],
         [-0.0399,  0.0237, -0.0359,  ..., -0.0925, -0.0325, -0.0080],
         [ 0.0723,  0.0286, -0.0169,  ..., -0.0701, -0.0391, -0.0903]],

        ...,

        [[-0.2560,  0.0343,  0.0198,  ...,  0.0235, -0.1294, -0.1122],
         [-0.1168, -0.0134,  0.0013,  ..., -0.1594, -0.0681,  0.0166],
         [-0.1366, -0.0065,  0.1101,  ...,  0.0647,  0.0332,  0.0900],
         ...,
         [-0.0386,  0.0044, -0.0181,  ..., -0.0179,  0.0197, -0.0183],
         [-0.0944,  0.0044,  0.0425,  ..., -0.0581, -0.0138, -0.0370],
         [-0.1762, -0.0132, -0.1563,  ...,  0.0021,  0.0080,  0.1578]],

        [[-0.0636, -0.0319,  0.0238,  ..., -0.0226, -0.0668,  0.1363],
         [-0.0010,  0.1299, -0.0585,  ...,  0.0913,  0.0424,  0.0119],
         [-0.0549,  0.1239, -0.0887,  ...,  0.2059,  0.1081, -0.0314],
         ...,
         [-0.1810,  0.0728, -0.0564,  ...,  0.0258,  0.0494,  0.1025],
         [-0.0484,  0.0967, -0.0358,  ..., -0.0453, -0.1152, -0.2767],
         [-0.0448,  0.0187, -0.2066,  ...,  0.1324, -0.1930,  0.1942]],

        [[-0.1027, -0.0213, -0.1386,  ..., -0.0042,  0.0113, -0.1417],
         [ 0.0537,  0.0707, -0.1861,  ..., -0.0186,  0.0360, -0.0045],
         [-0.1148,  0.0645, -0.0655,  ..., -0.1318,  0.0558, -0.0885],
         ...,
         [-0.0933,  0.1551, -0.0183,  ...,  0.1530, -0.1379,  0.0547],
         [ 0.0604,  0.0082, -0.0835,  ...,  0.1885, -0.0456, -0.1020],
         [ 0.0083, -0.0573, -0.0734,  ...,  0.1250,  0.0183,  0.1465]]],
       grad_fn=<StackBackward0>), 'stoch': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 1.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 1., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 1.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [1., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 1., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]]), 'logits': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]])}
train_step: Normalized hidden_state shape: torch.Size([1, 16, 128])
train_step: Normalized stoch shape: torch.Size([16, 1024])
train_step: Normalized deter shape: torch.Size([16, 128])
train_step: Post-imagine_trajectory: Imagined features shape: torch.Size([16, 15, 1152])
train_step: Post-imagine_trajectory: Imagined actions shape: torch.Size([16, 15, 2])
train_step: Post-imagine_trajectory: Imagined action indices shape: torch.Size([16, 15])
train_step: Post-imagine_trajectory: Imagined state deter shape: torch.Size([16, 15, 128])
train_step: Post-imagine_trajectory: Imagined state stoch shape: torch.Size([16, 15, 1024])
Reward shape: torch.Size([16, 15, 1]), Value shape: torch.Size([16, 15, 1]), Slow Value shape: torch.Size([16, 15, 1]), Discount shape: torch.Size([16, 15, 1, 1])
Return targets length: 15, First target shape: torch.Size([16, 16, 1])
train_step: Actor distribution shape: torch.Size([16, 15, 2])
train_step: Action log probabilities shape: torch.Size([16, 15])
train_step: Action log probabilities sample: tensor([[-0.5209, -0.8531],
        [-0.1862, -0.1939]], grad_fn=<SliceBackward0>)
train_step: Advantages shape: torch.Size([16, 15, 16, 15])
train_step: Advantages sample: tensor([[[[-5.7471, -5.7471, -5.7472, -5.7471, -5.7472, -5.7471, -5.7472,
           -5.7471, -5.7471, -5.7471, -5.7471, -5.7472, -5.7472, -5.7472,
           -5.7472],
          [-5.7471, -5.7471, -5.7472, -5.7471, -5.7472, -5.7471, -5.7472,
           -5.7471, -5.7471, -5.7471, -5.7471, -5.7472, -5.7472, -5.7472,
           -5.7472],
          [-5.7471, -5.7471, -5.7472, -5.7471, -5.7472, -5.7471, -5.7472,
           -5.7471, -5.7471, -5.7471, -5.7471, -5.7472, -5.7472, -5.7472,
           -5.7472],
          [-5.7471, -5.7471, -5.7472, -5.7471, -5.7472, -5.7471, -5.7472,
           -5.7471, -5.7471, -5.7471, -5.7471, -5.7472, -5.7472, -5.7472,
           -5.7472],
          [-5.7471, -5.7471, -5.7472, -5.7471, -5.7472, -5.7471, -5.7472,
           -5.7471, -5.7471, -5.7471, -5.7471, -5.7472, -5.7472, -5.7472,
           -5.7472],
          [-5.7471, -5.7471, -5.7472, -5.7471, -5.7472, -5.7471, -5.7472,
           -5.7471, -5.7471, -5.7471, -5.7471, -5.7472, -5.7472, -5.7472,
           -5.7472],
          [-5.7471, -5.7471, -5.7472, -5.7471, -5.7472, -5.7471, -5.7472,
           -5.7471, -5.7471, -5.7471, -5.7471, -5.7472, -5.7472, -5.7472,
           -5.7472],
          [-5.7471, -5.7471, -5.7472, -5.7471, -5.7472, -5.7471, -5.7472,
           -5.7471, -5.7471, -5.7471, -5.7471, -5.7472, -5.7472, -5.7472,
           -5.7472],
          [-5.7471, -5.7471, -5.7472, -5.7471, -5.7472, -5.7471, -5.7472,
           -5.7471, -5.7471, -5.7471, -5.7471, -5.7472, -5.7472, -5.7472,
           -5.7472],
          [-5.7471, -5.7471, -5.7472, -5.7471, -5.7472, -5.7471, -5.7472,
           -5.7471, -5.7471, -5.7471, -5.7471, -5.7472, -5.7472, -5.7472,
           -5.7472],
          [-5.2691, -5.2690, -5.2691, -5.2690, -5.2691, -5.2691, -5.2691,
           -5.2690, -5.2690, -5.2691, -5.2690, -5.2691, -5.2691, -5.2691,
           -5.2691],
          [-5.7471, -5.7471, -5.7472, -5.7471, -5.7472, -5.7471, -5.7472,
           -5.7471, -5.7471, -5.7471, -5.7471, -5.7472, -5.7472, -5.7472,
           -5.7472],
          [-5.7471, -5.7471, -5.7472, -5.7471, -5.7472, -5.7471, -5.7472,
           -5.7471, -5.7471, -5.7471, -5.7471, -5.7472, -5.7472, -5.7472,
           -5.7472],
          [-5.7471, -5.7471, -5.7472, -5.7471, -5.7472, -5.7471, -5.7472,
           -5.7471, -5.7471, -5.7471, -5.7471, -5.7472, -5.7472, -5.7472,
           -5.7472],
          [-5.7471, -5.7471, -5.7472, -5.7471, -5.7472, -5.7471, -5.7472,
           -5.7471, -5.7471, -5.7471, -5.7471, -5.7472, -5.7472, -5.7472,
           -5.7472],
          [-5.7471, -5.7471, -5.7472, -5.7471, -5.7472, -5.7471, -5.7472,
           -5.7471, -5.7471, -5.7471, -5.7471, -5.7472, -5.7472, -5.7472,
           -5.7472]],

         [[-5.1712, -5.1712, -5.1712, -5.1712, -5.1713, -5.1711, -5.1711,
           -5.1712, -5.1712, -5.1712, -5.1712, -5.1712, -5.1711, -5.1711,
           -5.1712],
          [-5.1712, -5.1712, -5.1712, -5.1712, -5.1713, -5.1711, -5.1711,
           -5.1712, -5.1712, -5.1712, -5.1712, -5.1712, -5.1711, -5.1711,
           -5.1712],
          [-5.1712, -5.1712, -5.1712, -5.1712, -5.1713, -5.1711, -5.1711,
           -5.1712, -5.1712, -5.1712, -5.1712, -5.1712, -5.1711, -5.1711,
           -5.1712],
          [-5.1712, -5.1712, -5.1712, -5.1712, -5.1713, -5.1711, -5.1711,
           -5.1712, -5.1712, -5.1712, -5.1712, -5.1712, -5.1711, -5.1711,
           -5.1712],
          [-5.1712, -5.1712, -5.1712, -5.1712, -5.1713, -5.1711, -5.1711,
           -5.1712, -5.1712, -5.1712, -5.1712, -5.1712, -5.1711, -5.1711,
           -5.1712],
          [-5.1712, -5.1712, -5.1712, -5.1712, -5.1713, -5.1711, -5.1711,
           -5.1712, -5.1712, -5.1712, -5.1712, -5.1712, -5.1711, -5.1711,
           -5.1712],
          [-5.1712, -5.1712, -5.1712, -5.1712, -5.1713, -5.1711, -5.1711,
           -5.1712, -5.1712, -5.1712, -5.1712, -5.1712, -5.1711, -5.1711,
           -5.1712],
          [-5.1712, -5.1712, -5.1712, -5.1712, -5.1713, -5.1711, -5.1711,
           -5.1712, -5.1712, -5.1712, -5.1712, -5.1712, -5.1711, -5.1711,
           -5.1712],
          [-5.1712, -5.1712, -5.1712, -5.1712, -5.1713, -5.1711, -5.1711,
           -5.1712, -5.1712, -5.1712, -5.1712, -5.1712, -5.1711, -5.1711,
           -5.1712],
          [-5.1712, -5.1712, -5.1712, -5.1712, -5.1713, -5.1711, -5.1711,
           -5.1712, -5.1712, -5.1712, -5.1712, -5.1712, -5.1711, -5.1711,
           -5.1712],
          [-4.6665, -4.6665, -4.6665, -4.6664, -4.6665, -4.6664, -4.6664,
           -4.6664, -4.6665, -4.6664, -4.6665, -4.6664, -4.6664, -4.6664,
           -4.6665],
          [-5.1712, -5.1712, -5.1712, -5.1712, -5.1713, -5.1711, -5.1711,
           -5.1712, -5.1712, -5.1712, -5.1712, -5.1712, -5.1711, -5.1711,
           -5.1712],
          [-5.1712, -5.1712, -5.1712, -5.1712, -5.1713, -5.1711, -5.1711,
           -5.1712, -5.1712, -5.1712, -5.1712, -5.1712, -5.1711, -5.1711,
           -5.1712],
          [-5.1712, -5.1712, -5.1712, -5.1712, -5.1713, -5.1711, -5.1711,
           -5.1712, -5.1712, -5.1712, -5.1712, -5.1712, -5.1711, -5.1711,
           -5.1712],
          [-5.1712, -5.1712, -5.1712, -5.1712, -5.1713, -5.1711, -5.1711,
           -5.1712, -5.1712, -5.1712, -5.1712, -5.1712, -5.1711, -5.1711,
           -5.1712],
          [-5.1712, -5.1712, -5.1712, -5.1712, -5.1713, -5.1711, -5.1711,
           -5.1712, -5.1712, -5.1712, -5.1712, -5.1712, -5.1711, -5.1711,
           -5.1712]]],


        [[[-7.7959, -7.7959, -7.7959, -7.7959, -7.7959, -7.7959, -7.7959,
           -7.7959, -7.7959, -7.7959, -7.7958, -7.7960, -7.7959, -7.7959,
           -7.7959],
          [-7.7959, -7.7959, -7.7959, -7.7959, -7.7959, -7.7959, -7.7959,
           -7.7959, -7.7959, -7.7959, -7.7958, -7.7960, -7.7959, -7.7959,
           -7.7959],
          [-7.7959, -7.7959, -7.7959, -7.7959, -7.7959, -7.7959, -7.7959,
           -7.7959, -7.7959, -7.7959, -7.7958, -7.7960, -7.7959, -7.7959,
           -7.7959],
          [-7.7959, -7.7959, -7.7959, -7.7959, -7.7959, -7.7959, -7.7959,
           -7.7959, -7.7959, -7.7959, -7.7958, -7.7960, -7.7959, -7.7959,
           -7.7959],
          [-7.7959, -7.7959, -7.7959, -7.7959, -7.7959, -7.7959, -7.7959,
           -7.7959, -7.7959, -7.7959, -7.7958, -7.7960, -7.7959, -7.7959,
           -7.7959],
          [-7.7959, -7.7959, -7.7959, -7.7959, -7.7959, -7.7959, -7.7959,
           -7.7959, -7.7959, -7.7959, -7.7958, -7.7960, -7.7959, -7.7959,
           -7.7959],
          [-7.7959, -7.7959, -7.7959, -7.7959, -7.7959, -7.7959, -7.7959,
           -7.7959, -7.7959, -7.7959, -7.7958, -7.7960, -7.7959, -7.7959,
           -7.7959],
          [-7.7959, -7.7959, -7.7959, -7.7959, -7.7959, -7.7959, -7.7959,
           -7.7959, -7.7959, -7.7959, -7.7958, -7.7960, -7.7959, -7.7959,
           -7.7959],
          [-7.7959, -7.7959, -7.7959, -7.7959, -7.7959, -7.7959, -7.7959,
           -7.7959, -7.7959, -7.7959, -7.7958, -7.7960, -7.7959, -7.7959,
           -7.7959],
          [-7.7959, -7.7959, -7.7959, -7.7959, -7.7959, -7.7959, -7.7959,
           -7.7959, -7.7959, -7.7959, -7.7958, -7.7960, -7.7959, -7.7959,
           -7.7959],
          [-7.5463, -7.5463, -7.5464, -7.5463, -7.5464, -7.5463, -7.5464,
           -7.5463, -7.5463, -7.5463, -7.5463, -7.5464, -7.5464, -7.5464,
           -7.5464],
          [-7.7959, -7.7959, -7.7959, -7.7959, -7.7959, -7.7959, -7.7959,
           -7.7959, -7.7959, -7.7959, -7.7958, -7.7960, -7.7959, -7.7959,
           -7.7959],
          [-7.7959, -7.7959, -7.7959, -7.7959, -7.7959, -7.7959, -7.7959,
           -7.7959, -7.7959, -7.7959, -7.7958, -7.7960, -7.7959, -7.7959,
           -7.7959],
          [-7.7959, -7.7959, -7.7959, -7.7959, -7.7959, -7.7959, -7.7959,
           -7.7959, -7.7959, -7.7959, -7.7958, -7.7960, -7.7959, -7.7959,
           -7.7959],
          [-7.7959, -7.7959, -7.7959, -7.7959, -7.7959, -7.7959, -7.7959,
           -7.7959, -7.7959, -7.7959, -7.7958, -7.7960, -7.7959, -7.7959,
           -7.7959],
          [-7.7959, -7.7959, -7.7959, -7.7959, -7.7959, -7.7959, -7.7959,
           -7.7959, -7.7959, -7.7959, -7.7958, -7.7960, -7.7959, -7.7959,
           -7.7959]],

         [[-7.5667, -7.5667, -7.5667, -7.5667, -7.5667, -7.5666, -7.5666,
           -7.5666, -7.5667, -7.5666, -7.5667, -7.5666, -7.5666, -7.5666,
           -7.5667],
          [-7.5667, -7.5667, -7.5667, -7.5667, -7.5667, -7.5666, -7.5666,
           -7.5666, -7.5667, -7.5666, -7.5667, -7.5666, -7.5666, -7.5666,
           -7.5667],
          [-7.5667, -7.5667, -7.5667, -7.5667, -7.5667, -7.5666, -7.5666,
           -7.5666, -7.5667, -7.5666, -7.5667, -7.5666, -7.5666, -7.5666,
           -7.5667],
          [-7.5667, -7.5667, -7.5667, -7.5667, -7.5667, -7.5666, -7.5666,
           -7.5666, -7.5667, -7.5666, -7.5667, -7.5666, -7.5666, -7.5666,
           -7.5667],
          [-7.5667, -7.5667, -7.5667, -7.5667, -7.5667, -7.5666, -7.5666,
           -7.5666, -7.5667, -7.5666, -7.5667, -7.5666, -7.5666, -7.5666,
           -7.5667],
          [-7.5667, -7.5667, -7.5667, -7.5667, -7.5667, -7.5666, -7.5666,
           -7.5666, -7.5667, -7.5666, -7.5667, -7.5666, -7.5666, -7.5666,
           -7.5667],
          [-7.5667, -7.5667, -7.5667, -7.5667, -7.5667, -7.5666, -7.5666,
           -7.5666, -7.5667, -7.5666, -7.5667, -7.5666, -7.5666, -7.5666,
           -7.5667],
          [-7.5667, -7.5667, -7.5667, -7.5667, -7.5667, -7.5666, -7.5666,
           -7.5666, -7.5667, -7.5666, -7.5667, -7.5666, -7.5666, -7.5666,
           -7.5667],
          [-7.5667, -7.5667, -7.5667, -7.5667, -7.5667, -7.5666, -7.5666,
           -7.5666, -7.5667, -7.5666, -7.5667, -7.5666, -7.5666, -7.5666,
           -7.5667],
          [-7.5667, -7.5667, -7.5667, -7.5667, -7.5667, -7.5666, -7.5666,
           -7.5666, -7.5667, -7.5666, -7.5667, -7.5666, -7.5666, -7.5666,
           -7.5667],
          [-7.3032, -7.3032, -7.3032, -7.3032, -7.3032, -7.3031, -7.3031,
           -7.3032, -7.3032, -7.3031, -7.3032, -7.3032, -7.3031, -7.3031,
           -7.3032],
          [-7.5667, -7.5667, -7.5667, -7.5667, -7.5667, -7.5666, -7.5666,
           -7.5666, -7.5667, -7.5666, -7.5667, -7.5666, -7.5666, -7.5666,
           -7.5667],
          [-7.5667, -7.5667, -7.5667, -7.5667, -7.5667, -7.5666, -7.5666,
           -7.5666, -7.5667, -7.5666, -7.5667, -7.5666, -7.5666, -7.5666,
           -7.5667],
          [-7.5667, -7.5667, -7.5667, -7.5667, -7.5667, -7.5666, -7.5666,
           -7.5666, -7.5667, -7.5666, -7.5667, -7.5666, -7.5666, -7.5666,
           -7.5667],
          [-7.5667, -7.5667, -7.5667, -7.5667, -7.5667, -7.5666, -7.5666,
           -7.5666, -7.5667, -7.5666, -7.5667, -7.5666, -7.5666, -7.5666,
           -7.5667],
          [-7.5667, -7.5667, -7.5667, -7.5667, -7.5667, -7.5666, -7.5666,
           -7.5666, -7.5667, -7.5666, -7.5667, -7.5666, -7.5666, -7.5666,
           -7.5667]]]], grad_fn=<SliceBackward0>)
train_step: Return scale: 1.9241426029896775
train_step: Scaled advantages shape: torch.Size([16, 15, 16, 15])
train_step: Scaled advantages sample: tensor([[[[-2.9869, -2.9869, -2.9869, -2.9868, -2.9869, -2.9869, -2.9869,
           -2.9868, -2.9868, -2.9869, -2.9868, -2.9869, -2.9869, -2.9869,
           -2.9869],
          [-2.9869, -2.9869, -2.9869, -2.9868, -2.9869, -2.9869, -2.9869,
           -2.9868, -2.9868, -2.9869, -2.9868, -2.9869, -2.9869, -2.9869,
           -2.9869],
          [-2.9869, -2.9869, -2.9869, -2.9868, -2.9869, -2.9869, -2.9869,
           -2.9868, -2.9868, -2.9869, -2.9868, -2.9869, -2.9869, -2.9869,
           -2.9869],
          [-2.9869, -2.9869, -2.9869, -2.9868, -2.9869, -2.9869, -2.9869,
           -2.9868, -2.9868, -2.9869, -2.9868, -2.9869, -2.9869, -2.9869,
           -2.9869],
          [-2.9869, -2.9869, -2.9869, -2.9868, -2.9869, -2.9869, -2.9869,
           -2.9868, -2.9868, -2.9869, -2.9868, -2.9869, -2.9869, -2.9869,
           -2.9869],
          [-2.9869, -2.9869, -2.9869, -2.9868, -2.9869, -2.9869, -2.9869,
           -2.9868, -2.9868, -2.9869, -2.9868, -2.9869, -2.9869, -2.9869,
           -2.9869],
          [-2.9869, -2.9869, -2.9869, -2.9868, -2.9869, -2.9869, -2.9869,
           -2.9868, -2.9868, -2.9869, -2.9868, -2.9869, -2.9869, -2.9869,
           -2.9869],
          [-2.9869, -2.9869, -2.9869, -2.9868, -2.9869, -2.9869, -2.9869,
           -2.9868, -2.9868, -2.9869, -2.9868, -2.9869, -2.9869, -2.9869,
           -2.9869],
          [-2.9869, -2.9869, -2.9869, -2.9868, -2.9869, -2.9869, -2.9869,
           -2.9868, -2.9868, -2.9869, -2.9868, -2.9869, -2.9869, -2.9869,
           -2.9869],
          [-2.9869, -2.9869, -2.9869, -2.9868, -2.9869, -2.9869, -2.9869,
           -2.9868, -2.9868, -2.9869, -2.9868, -2.9869, -2.9869, -2.9869,
           -2.9869],
          [-2.7384, -2.7384, -2.7384, -2.7384, -2.7384, -2.7384, -2.7384,
           -2.7384, -2.7384, -2.7384, -2.7384, -2.7384, -2.7384, -2.7384,
           -2.7384],
          [-2.9869, -2.9869, -2.9869, -2.9868, -2.9869, -2.9869, -2.9869,
           -2.9868, -2.9868, -2.9869, -2.9868, -2.9869, -2.9869, -2.9869,
           -2.9869],
          [-2.9869, -2.9869, -2.9869, -2.9868, -2.9869, -2.9869, -2.9869,
           -2.9868, -2.9868, -2.9869, -2.9868, -2.9869, -2.9869, -2.9869,
           -2.9869],
          [-2.9869, -2.9869, -2.9869, -2.9868, -2.9869, -2.9869, -2.9869,
           -2.9868, -2.9868, -2.9869, -2.9868, -2.9869, -2.9869, -2.9869,
           -2.9869],
          [-2.9869, -2.9869, -2.9869, -2.9868, -2.9869, -2.9869, -2.9869,
           -2.9868, -2.9868, -2.9869, -2.9868, -2.9869, -2.9869, -2.9869,
           -2.9869],
          [-2.9869, -2.9869, -2.9869, -2.9868, -2.9869, -2.9869, -2.9869,
           -2.9868, -2.9868, -2.9869, -2.9868, -2.9869, -2.9869, -2.9869,
           -2.9869]],

         [[-2.6875, -2.6875, -2.6875, -2.6875, -2.6876, -2.6875, -2.6875,
           -2.6875, -2.6875, -2.6875, -2.6876, -2.6875, -2.6875, -2.6875,
           -2.6875],
          [-2.6875, -2.6875, -2.6875, -2.6875, -2.6876, -2.6875, -2.6875,
           -2.6875, -2.6875, -2.6875, -2.6876, -2.6875, -2.6875, -2.6875,
           -2.6875],
          [-2.6875, -2.6875, -2.6875, -2.6875, -2.6876, -2.6875, -2.6875,
           -2.6875, -2.6875, -2.6875, -2.6876, -2.6875, -2.6875, -2.6875,
           -2.6875],
          [-2.6875, -2.6875, -2.6875, -2.6875, -2.6876, -2.6875, -2.6875,
           -2.6875, -2.6875, -2.6875, -2.6876, -2.6875, -2.6875, -2.6875,
           -2.6875],
          [-2.6875, -2.6875, -2.6875, -2.6875, -2.6876, -2.6875, -2.6875,
           -2.6875, -2.6875, -2.6875, -2.6876, -2.6875, -2.6875, -2.6875,
           -2.6875],
          [-2.6875, -2.6875, -2.6875, -2.6875, -2.6876, -2.6875, -2.6875,
           -2.6875, -2.6875, -2.6875, -2.6876, -2.6875, -2.6875, -2.6875,
           -2.6875],
          [-2.6875, -2.6875, -2.6875, -2.6875, -2.6876, -2.6875, -2.6875,
           -2.6875, -2.6875, -2.6875, -2.6876, -2.6875, -2.6875, -2.6875,
           -2.6875],
          [-2.6875, -2.6875, -2.6875, -2.6875, -2.6876, -2.6875, -2.6875,
           -2.6875, -2.6875, -2.6875, -2.6876, -2.6875, -2.6875, -2.6875,
           -2.6875],
          [-2.6875, -2.6875, -2.6875, -2.6875, -2.6876, -2.6875, -2.6875,
           -2.6875, -2.6875, -2.6875, -2.6876, -2.6875, -2.6875, -2.6875,
           -2.6875],
          [-2.6875, -2.6875, -2.6875, -2.6875, -2.6876, -2.6875, -2.6875,
           -2.6875, -2.6875, -2.6875, -2.6876, -2.6875, -2.6875, -2.6875,
           -2.6875],
          [-2.4252, -2.4252, -2.4252, -2.4252, -2.4252, -2.4252, -2.4252,
           -2.4252, -2.4252, -2.4252, -2.4252, -2.4252, -2.4252, -2.4252,
           -2.4252],
          [-2.6875, -2.6875, -2.6875, -2.6875, -2.6876, -2.6875, -2.6875,
           -2.6875, -2.6875, -2.6875, -2.6876, -2.6875, -2.6875, -2.6875,
           -2.6875],
          [-2.6875, -2.6875, -2.6875, -2.6875, -2.6876, -2.6875, -2.6875,
           -2.6875, -2.6875, -2.6875, -2.6876, -2.6875, -2.6875, -2.6875,
           -2.6875],
          [-2.6875, -2.6875, -2.6875, -2.6875, -2.6876, -2.6875, -2.6875,
           -2.6875, -2.6875, -2.6875, -2.6876, -2.6875, -2.6875, -2.6875,
           -2.6875],
          [-2.6875, -2.6875, -2.6875, -2.6875, -2.6876, -2.6875, -2.6875,
           -2.6875, -2.6875, -2.6875, -2.6876, -2.6875, -2.6875, -2.6875,
           -2.6875],
          [-2.6875, -2.6875, -2.6875, -2.6875, -2.6876, -2.6875, -2.6875,
           -2.6875, -2.6875, -2.6875, -2.6876, -2.6875, -2.6875, -2.6875,
           -2.6875]]],


        [[[-4.0516, -4.0516, -4.0516, -4.0516, -4.0516, -4.0516, -4.0516,
           -4.0516, -4.0516, -4.0516, -4.0516, -4.0517, -4.0516, -4.0516,
           -4.0516],
          [-4.0516, -4.0516, -4.0516, -4.0516, -4.0516, -4.0516, -4.0516,
           -4.0516, -4.0516, -4.0516, -4.0516, -4.0517, -4.0516, -4.0516,
           -4.0516],
          [-4.0516, -4.0516, -4.0516, -4.0516, -4.0516, -4.0516, -4.0516,
           -4.0516, -4.0516, -4.0516, -4.0516, -4.0517, -4.0516, -4.0516,
           -4.0516],
          [-4.0516, -4.0516, -4.0516, -4.0516, -4.0516, -4.0516, -4.0516,
           -4.0516, -4.0516, -4.0516, -4.0516, -4.0517, -4.0516, -4.0516,
           -4.0516],
          [-4.0516, -4.0516, -4.0516, -4.0516, -4.0516, -4.0516, -4.0516,
           -4.0516, -4.0516, -4.0516, -4.0516, -4.0517, -4.0516, -4.0516,
           -4.0516],
          [-4.0516, -4.0516, -4.0516, -4.0516, -4.0516, -4.0516, -4.0516,
           -4.0516, -4.0516, -4.0516, -4.0516, -4.0517, -4.0516, -4.0516,
           -4.0516],
          [-4.0516, -4.0516, -4.0516, -4.0516, -4.0516, -4.0516, -4.0516,
           -4.0516, -4.0516, -4.0516, -4.0516, -4.0517, -4.0516, -4.0516,
           -4.0516],
          [-4.0516, -4.0516, -4.0516, -4.0516, -4.0516, -4.0516, -4.0516,
           -4.0516, -4.0516, -4.0516, -4.0516, -4.0517, -4.0516, -4.0516,
           -4.0516],
          [-4.0516, -4.0516, -4.0516, -4.0516, -4.0516, -4.0516, -4.0516,
           -4.0516, -4.0516, -4.0516, -4.0516, -4.0517, -4.0516, -4.0516,
           -4.0516],
          [-4.0516, -4.0516, -4.0516, -4.0516, -4.0516, -4.0516, -4.0516,
           -4.0516, -4.0516, -4.0516, -4.0516, -4.0517, -4.0516, -4.0516,
           -4.0516],
          [-3.9219, -3.9219, -3.9219, -3.9219, -3.9219, -3.9219, -3.9219,
           -3.9219, -3.9219, -3.9219, -3.9219, -3.9220, -3.9219, -3.9219,
           -3.9219],
          [-4.0516, -4.0516, -4.0516, -4.0516, -4.0516, -4.0516, -4.0516,
           -4.0516, -4.0516, -4.0516, -4.0516, -4.0517, -4.0516, -4.0516,
           -4.0516],
          [-4.0516, -4.0516, -4.0516, -4.0516, -4.0516, -4.0516, -4.0516,
           -4.0516, -4.0516, -4.0516, -4.0516, -4.0517, -4.0516, -4.0516,
           -4.0516],
          [-4.0516, -4.0516, -4.0516, -4.0516, -4.0516, -4.0516, -4.0516,
           -4.0516, -4.0516, -4.0516, -4.0516, -4.0517, -4.0516, -4.0516,
           -4.0516],
          [-4.0516, -4.0516, -4.0516, -4.0516, -4.0516, -4.0516, -4.0516,
           -4.0516, -4.0516, -4.0516, -4.0516, -4.0517, -4.0516, -4.0516,
           -4.0516],
          [-4.0516, -4.0516, -4.0516, -4.0516, -4.0516, -4.0516, -4.0516,
           -4.0516, -4.0516, -4.0516, -4.0516, -4.0517, -4.0516, -4.0516,
           -4.0516]],

         [[-3.9325, -3.9325, -3.9325, -3.9325, -3.9325, -3.9325, -3.9325,
           -3.9325, -3.9325, -3.9325, -3.9325, -3.9325, -3.9324, -3.9324,
           -3.9325],
          [-3.9325, -3.9325, -3.9325, -3.9325, -3.9325, -3.9325, -3.9325,
           -3.9325, -3.9325, -3.9325, -3.9325, -3.9325, -3.9324, -3.9324,
           -3.9325],
          [-3.9325, -3.9325, -3.9325, -3.9325, -3.9325, -3.9325, -3.9325,
           -3.9325, -3.9325, -3.9325, -3.9325, -3.9325, -3.9324, -3.9324,
           -3.9325],
          [-3.9325, -3.9325, -3.9325, -3.9325, -3.9325, -3.9325, -3.9325,
           -3.9325, -3.9325, -3.9325, -3.9325, -3.9325, -3.9324, -3.9324,
           -3.9325],
          [-3.9325, -3.9325, -3.9325, -3.9325, -3.9325, -3.9325, -3.9325,
           -3.9325, -3.9325, -3.9325, -3.9325, -3.9325, -3.9324, -3.9324,
           -3.9325],
          [-3.9325, -3.9325, -3.9325, -3.9325, -3.9325, -3.9325, -3.9325,
           -3.9325, -3.9325, -3.9325, -3.9325, -3.9325, -3.9324, -3.9324,
           -3.9325],
          [-3.9325, -3.9325, -3.9325, -3.9325, -3.9325, -3.9325, -3.9325,
           -3.9325, -3.9325, -3.9325, -3.9325, -3.9325, -3.9324, -3.9324,
           -3.9325],
          [-3.9325, -3.9325, -3.9325, -3.9325, -3.9325, -3.9325, -3.9325,
           -3.9325, -3.9325, -3.9325, -3.9325, -3.9325, -3.9324, -3.9324,
           -3.9325],
          [-3.9325, -3.9325, -3.9325, -3.9325, -3.9325, -3.9325, -3.9325,
           -3.9325, -3.9325, -3.9325, -3.9325, -3.9325, -3.9324, -3.9324,
           -3.9325],
          [-3.9325, -3.9325, -3.9325, -3.9325, -3.9325, -3.9325, -3.9325,
           -3.9325, -3.9325, -3.9325, -3.9325, -3.9325, -3.9324, -3.9324,
           -3.9325],
          [-3.7956, -3.7956, -3.7956, -3.7956, -3.7956, -3.7955, -3.7955,
           -3.7955, -3.7956, -3.7955, -3.7956, -3.7955, -3.7955, -3.7955,
           -3.7956],
          [-3.9325, -3.9325, -3.9325, -3.9325, -3.9325, -3.9325, -3.9325,
           -3.9325, -3.9325, -3.9325, -3.9325, -3.9325, -3.9324, -3.9324,
           -3.9325],
          [-3.9325, -3.9325, -3.9325, -3.9325, -3.9325, -3.9325, -3.9325,
           -3.9325, -3.9325, -3.9325, -3.9325, -3.9325, -3.9324, -3.9324,
           -3.9325],
          [-3.9325, -3.9325, -3.9325, -3.9325, -3.9325, -3.9325, -3.9325,
           -3.9325, -3.9325, -3.9325, -3.9325, -3.9325, -3.9324, -3.9324,
           -3.9325],
          [-3.9325, -3.9325, -3.9325, -3.9325, -3.9325, -3.9325, -3.9325,
           -3.9325, -3.9325, -3.9325, -3.9325, -3.9325, -3.9324, -3.9324,
           -3.9325],
          [-3.9325, -3.9325, -3.9325, -3.9325, -3.9325, -3.9325, -3.9325,
           -3.9325, -3.9325, -3.9325, -3.9325, -3.9325, -3.9324, -3.9324,
           -3.9325]]]], grad_fn=<SliceBackward0>)
train_step: Entropy shape: torch.Size([16, 15])
train_step: Entropy sample: tensor([[0.6754, 0.6822],
        [0.4557, 0.4656]], grad_fn=<SliceBackward0>)
train_step: Entropy coefficient: 0.01
train_step: Actor loss: -1.2437770366668701
train_step: returns shape after mean: torch.Size([16, 15])
train_step: target_indices shape: torch.Size([16, 15])
train_step: value_logits shape: torch.Size([16, 15, 255])
train_step: target_twohot shape: torch.Size([16, 15, 255])
--- Starting train_step at 2025-04-01 01:56:35 ---
Full starting_state: {'deter': tensor([[[-0.0039, -0.1355, -0.0593,  ...,  0.1176, -0.0932, -0.0429],
         [-0.1858, -0.0039, -0.0308,  ..., -0.1345, -0.0028,  0.0662],
         [-0.1519, -0.0294, -0.2057,  ...,  0.0083,  0.0492, -0.1230],
         ...,
         [-0.1019,  0.0447, -0.1887,  ...,  0.1648, -0.1114,  0.0037],
         [ 0.0705,  0.0494, -0.0833,  ...,  0.0270, -0.0792, -0.0699],
         [-0.0800,  0.0950, -0.1782,  ...,  0.2066,  0.0383,  0.0898]],

        [[-0.1193,  0.0781,  0.0755,  ..., -0.0521, -0.0478, -0.0493],
         [-0.1518, -0.0055, -0.0227,  ...,  0.0241, -0.0119,  0.0891],
         [ 0.1641, -0.0080, -0.0688,  ...,  0.0912, -0.0209,  0.1191],
         ...,
         [ 0.1287,  0.0143,  0.0422,  ...,  0.0005, -0.0317,  0.0818],
         [ 0.0347,  0.0980, -0.1235,  ...,  0.0384,  0.0495, -0.1766],
         [-0.1736, -0.0885, -0.0620,  ...,  0.0178,  0.2085, -0.1336]],

        [[-0.0836,  0.0063, -0.0038,  ...,  0.0291, -0.0323,  0.0595],
         [ 0.0130, -0.0037, -0.0827,  ..., -0.0239, -0.0521,  0.0976],
         [ 0.0420, -0.0962, -0.1339,  ..., -0.0845, -0.1098,  0.0603],
         ...,
         [ 0.1485,  0.0642, -0.0454,  ...,  0.0269, -0.1065,  0.0327],
         [ 0.0832,  0.0807,  0.0111,  ...,  0.0236, -0.1262, -0.0673],
         [-0.0560, -0.0950, -0.0237,  ...,  0.0092,  0.0604, -0.0150]],

        [[-0.0908, -0.0436, -0.0531,  ...,  0.0054,  0.0605,  0.1046],
         [-0.0017,  0.0815,  0.0708,  ..., -0.1126, -0.0165, -0.0733],
         [-0.1917,  0.0344, -0.1410,  ...,  0.1509, -0.0688, -0.0428],
         ...,
         [-0.0479, -0.0295, -0.1710,  ...,  0.0288,  0.0515, -0.0791],
         [-0.2185, -0.0564, -0.1565,  ...,  0.0060,  0.0438, -0.0135],
         [ 0.0365,  0.0898, -0.0749,  ..., -0.0287, -0.0667,  0.0468]]],
       grad_fn=<StackBackward0>), 'stoch': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 1.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 1., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]])}
train_step: Starting state deter shape: torch.Size([4, 10, 128])
train_step: Starting state stoch shape: torch.Size([4, 10, 1024])
After ensuring logits/stoch: {'deter': tensor([[[-0.0039, -0.1355, -0.0593,  ...,  0.1176, -0.0932, -0.0429],
         [-0.1858, -0.0039, -0.0308,  ..., -0.1345, -0.0028,  0.0662],
         [-0.1519, -0.0294, -0.2057,  ...,  0.0083,  0.0492, -0.1230],
         ...,
         [-0.1019,  0.0447, -0.1887,  ...,  0.1648, -0.1114,  0.0037],
         [ 0.0705,  0.0494, -0.0833,  ...,  0.0270, -0.0792, -0.0699],
         [-0.0800,  0.0950, -0.1782,  ...,  0.2066,  0.0383,  0.0898]],

        [[-0.1193,  0.0781,  0.0755,  ..., -0.0521, -0.0478, -0.0493],
         [-0.1518, -0.0055, -0.0227,  ...,  0.0241, -0.0119,  0.0891],
         [ 0.1641, -0.0080, -0.0688,  ...,  0.0912, -0.0209,  0.1191],
         ...,
         [ 0.1287,  0.0143,  0.0422,  ...,  0.0005, -0.0317,  0.0818],
         [ 0.0347,  0.0980, -0.1235,  ...,  0.0384,  0.0495, -0.1766],
         [-0.1736, -0.0885, -0.0620,  ...,  0.0178,  0.2085, -0.1336]],

        [[-0.0836,  0.0063, -0.0038,  ...,  0.0291, -0.0323,  0.0595],
         [ 0.0130, -0.0037, -0.0827,  ..., -0.0239, -0.0521,  0.0976],
         [ 0.0420, -0.0962, -0.1339,  ..., -0.0845, -0.1098,  0.0603],
         ...,
         [ 0.1485,  0.0642, -0.0454,  ...,  0.0269, -0.1065,  0.0327],
         [ 0.0832,  0.0807,  0.0111,  ...,  0.0236, -0.1262, -0.0673],
         [-0.0560, -0.0950, -0.0237,  ...,  0.0092,  0.0604, -0.0150]],

        [[-0.0908, -0.0436, -0.0531,  ...,  0.0054,  0.0605,  0.1046],
         [-0.0017,  0.0815,  0.0708,  ..., -0.1126, -0.0165, -0.0733],
         [-0.1917,  0.0344, -0.1410,  ...,  0.1509, -0.0688, -0.0428],
         ...,
         [-0.0479, -0.0295, -0.1710,  ...,  0.0288,  0.0515, -0.0791],
         [-0.2185, -0.0564, -0.1565,  ...,  0.0060,  0.0438, -0.0135],
         [ 0.0365,  0.0898, -0.0749,  ..., -0.0287, -0.0667,  0.0468]]],
       grad_fn=<StackBackward0>), 'stoch': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 1.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 1., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]]), 'logits': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]])}
train_step: Normalized hidden_state shape: torch.Size([1, 4, 128])
train_step: Normalized stoch shape: torch.Size([4, 1024])
train_step: Normalized deter shape: torch.Size([4, 128])
train_step: Post-imagine_trajectory: Imagined features shape: torch.Size([4, 15, 1152])
train_step: Post-imagine_trajectory: Imagined actions shape: torch.Size([4, 15, 2])
train_step: Post-imagine_trajectory: Imagined action indices shape: torch.Size([4, 15])
train_step: Post-imagine_trajectory: Imagined state deter shape: torch.Size([4, 15, 128])
train_step: Post-imagine_trajectory: Imagined state stoch shape: torch.Size([4, 15, 1024])
Reward shape: torch.Size([4, 15, 1]), Value shape: torch.Size([4, 15, 1]), Slow Value shape: torch.Size([4, 15, 1]), Discount shape: torch.Size([4, 15, 1, 1])
Return targets length: 15, First target shape: torch.Size([4, 4, 1])
train_step: Actor distribution shape: torch.Size([4, 15, 2])
train_step: Action log probabilities shape: torch.Size([4, 15])
train_step: Action log probabilities sample: tensor([[-0.3614, -0.8731],
        [-0.2569, -0.3510]], grad_fn=<SliceBackward0>)
train_step: Advantages shape: torch.Size([4, 4, 4, 15])
train_step: Advantages sample: tensor([[[[-1.0768, -1.0768, -1.0768, -1.0768, -1.0768, -1.0768, -1.0768,
           -1.0768, -1.0768, -1.0768, -1.0768, -1.0768, -1.0768, -1.0768,
           -1.0768],
          [-1.0768, -1.0768, -1.0768, -1.0768, -1.0768, -1.0768, -1.0768,
           -1.0768, -1.0768, -1.0768, -1.0768, -1.0768, -1.0768, -1.0768,
           -1.0768],
          [-4.5833, -4.5833, -4.5833, -4.5833, -4.5833, -4.5833, -4.5833,
           -4.5833, -4.5833, -4.5833, -4.5833, -4.5833, -4.5833, -4.5833,
           -4.5833],
          [-2.4251, -2.4251, -2.4251, -2.4251, -2.4251, -2.4251, -2.4251,
           -2.4251, -2.4251, -2.4251, -2.4251, -2.4251, -2.4251, -2.4251,
           -2.4251]],

         [[-0.7569, -0.7569, -0.7569, -0.7569, -0.7569, -0.7569, -0.7569,
           -0.7569, -0.7569, -0.7569, -0.7569, -0.7569, -0.7569, -0.7569,
           -0.7569],
          [-5.0805, -5.0805, -5.0805, -5.0805, -5.0805, -5.0805, -5.0805,
           -5.0805, -5.0805, -5.0805, -5.0805, -5.0805, -5.0805, -5.0805,
           -5.0805],
          [-3.7022, -3.7022, -3.7022, -3.7022, -3.7022, -3.7022, -3.7022,
           -3.7022, -3.7022, -3.7022, -3.7022, -3.7022, -3.7022, -3.7022,
           -3.7022],
          [-1.4235, -1.4235, -1.4235, -1.4235, -1.4235, -1.4235, -1.4235,
           -1.4235, -1.4235, -1.4235, -1.4235, -1.4235, -1.4235, -1.4235,
           -1.4235]]],


        [[[-0.6835, -0.6835, -0.6835, -0.6835, -0.6835, -0.6835, -0.6835,
           -0.6835, -0.6835, -0.6835, -0.6835, -0.6835, -0.6835, -0.6835,
           -0.6835],
          [-0.6835, -0.6835, -0.6835, -0.6835, -0.6835, -0.6835, -0.6835,
           -0.6835, -0.6835, -0.6835, -0.6835, -0.6835, -0.6835, -0.6835,
           -0.6835],
          [-2.5903, -2.5903, -2.5903, -2.5903, -2.5903, -2.5903, -2.5903,
           -2.5903, -2.5903, -2.5903, -2.5903, -2.5903, -2.5903, -2.5903,
           -2.5903],
          [-1.6041, -1.6041, -1.6041, -1.6041, -1.6041, -1.6041, -1.6041,
           -1.6041, -1.6041, -1.6041, -1.6041, -1.6041, -1.6041, -1.6041,
           -1.6041]],

         [[-0.2349, -0.2349, -0.2349, -0.2349, -0.2349, -0.2349, -0.2349,
           -0.2349, -0.2349, -0.2349, -0.2349, -0.2349, -0.2349, -0.2349,
           -0.2349],
          [-3.0873, -3.0873, -3.0873, -3.0873, -3.0873, -3.0873, -3.0873,
           -3.0873, -3.0873, -3.0873, -3.0873, -3.0873, -3.0873, -3.0873,
           -3.0873],
          [-2.0132, -2.0132, -2.0132, -2.0132, -2.0132, -2.0132, -2.0132,
           -2.0132, -2.0132, -2.0132, -2.0132, -2.0132, -2.0132, -2.0132,
           -2.0132],
          [-0.9720, -0.9720, -0.9720, -0.9720, -0.9720, -0.9720, -0.9720,
           -0.9720, -0.9720, -0.9720, -0.9720, -0.9720, -0.9720, -0.9720,
           -0.9720]]]], grad_fn=<SliceBackward0>)
train_step: Return scale: 1.033979158550501
train_step: Scaled advantages shape: torch.Size([4, 4, 4, 15])
train_step: Scaled advantages sample: tensor([[[[-1.0414, -1.0414, -1.0414, -1.0414, -1.0414, -1.0414, -1.0414,
           -1.0414, -1.0414, -1.0414, -1.0414, -1.0414, -1.0414, -1.0414,
           -1.0414],
          [-1.0414, -1.0414, -1.0414, -1.0414, -1.0414, -1.0414, -1.0414,
           -1.0414, -1.0414, -1.0414, -1.0414, -1.0414, -1.0414, -1.0414,
           -1.0414],
          [-4.4327, -4.4327, -4.4327, -4.4327, -4.4327, -4.4327, -4.4327,
           -4.4327, -4.4327, -4.4327, -4.4327, -4.4327, -4.4327, -4.4327,
           -4.4327],
          [-2.3454, -2.3454, -2.3454, -2.3454, -2.3454, -2.3454, -2.3454,
           -2.3454, -2.3454, -2.3454, -2.3454, -2.3454, -2.3454, -2.3454,
           -2.3454]],

         [[-0.7569, -0.7569, -0.7569, -0.7569, -0.7569, -0.7569, -0.7569,
           -0.7569, -0.7569, -0.7569, -0.7569, -0.7569, -0.7569, -0.7569,
           -0.7569],
          [-4.9136, -4.9136, -4.9136, -4.9136, -4.9136, -4.9136, -4.9136,
           -4.9136, -4.9136, -4.9136, -4.9136, -4.9136, -4.9136, -4.9136,
           -4.9136],
          [-3.5805, -3.5805, -3.5805, -3.5805, -3.5805, -3.5805, -3.5805,
           -3.5805, -3.5805, -3.5805, -3.5805, -3.5805, -3.5805, -3.5805,
           -3.5805],
          [-1.3767, -1.3767, -1.3767, -1.3767, -1.3767, -1.3767, -1.3767,
           -1.3767, -1.3767, -1.3767, -1.3767, -1.3767, -1.3767, -1.3767,
           -1.3767]]],


        [[[-0.6835, -0.6835, -0.6835, -0.6835, -0.6835, -0.6835, -0.6835,
           -0.6835, -0.6835, -0.6835, -0.6835, -0.6835, -0.6835, -0.6835,
           -0.6835],
          [-0.6835, -0.6835, -0.6835, -0.6835, -0.6835, -0.6835, -0.6835,
           -0.6835, -0.6835, -0.6835, -0.6835, -0.6835, -0.6835, -0.6835,
           -0.6835],
          [-2.5051, -2.5051, -2.5051, -2.5051, -2.5051, -2.5051, -2.5051,
           -2.5051, -2.5051, -2.5051, -2.5051, -2.5051, -2.5051, -2.5051,
           -2.5051],
          [-1.5514, -1.5514, -1.5514, -1.5514, -1.5514, -1.5514, -1.5514,
           -1.5514, -1.5514, -1.5514, -1.5514, -1.5514, -1.5514, -1.5514,
           -1.5514]],

         [[-0.2349, -0.2349, -0.2349, -0.2349, -0.2349, -0.2349, -0.2349,
           -0.2349, -0.2349, -0.2349, -0.2349, -0.2349, -0.2349, -0.2349,
           -0.2349],
          [-2.9859, -2.9859, -2.9859, -2.9859, -2.9859, -2.9859, -2.9859,
           -2.9859, -2.9859, -2.9859, -2.9859, -2.9859, -2.9859, -2.9859,
           -2.9859],
          [-1.9470, -1.9470, -1.9470, -1.9470, -1.9470, -1.9470, -1.9470,
           -1.9470, -1.9470, -1.9470, -1.9470, -1.9470, -1.9470, -1.9470,
           -1.9470],
          [-0.9720, -0.9720, -0.9720, -0.9720, -0.9720, -0.9720, -0.9720,
           -0.9720, -0.9720, -0.9720, -0.9720, -0.9720, -0.9720, -0.9720,
           -0.9720]]]], grad_fn=<SliceBackward0>)
train_step: Entropy shape: torch.Size([4, 15])
train_step: Entropy sample: tensor([[0.6136, 0.6795],
        [0.5351, 0.6075]], grad_fn=<SliceBackward0>)
train_step: Entropy coefficient: 0.01
train_step: Actor loss: -1.2170108556747437
train_step: returns shape after mean: torch.Size([4, 15])
train_step: target_indices shape: torch.Size([4, 15])
train_step: value_logits shape: torch.Size([4, 15, 255])
train_step: target_twohot shape: torch.Size([4, 15, 255])
--- Starting train_step at 2025-04-01 01:56:35 ---
Full starting_state: {'deter': tensor([[[ 1.5481e-01,  9.7870e-02, -3.6855e-02,  ..., -6.1023e-02,
           1.2957e-02, -1.3702e-01],
         [-5.4251e-02,  7.8578e-02, -1.0353e-01,  ..., -1.3036e-01,
          -6.6195e-02,  3.2296e-02],
         [ 1.3054e-01,  2.0749e-01,  3.9367e-02,  ...,  2.8365e-03,
          -1.0631e-01,  5.5598e-02],
         ...,
         [ 1.0183e-01,  1.4874e-02, -1.7200e-01,  ..., -2.8608e-02,
           1.7293e-02, -5.5043e-02],
         [-1.9109e-01,  1.9585e-01, -1.7575e-01,  ...,  4.8762e-02,
           1.2087e-01, -3.4920e-02],
         [-9.1593e-02,  8.9367e-06,  6.5423e-02,  ..., -3.2170e-02,
          -5.3791e-02, -4.1740e-02]],

        [[-2.7081e-02,  1.2911e-01, -7.7289e-03,  ..., -1.9401e-02,
           9.1739e-02, -2.3813e-02],
         [-6.5232e-03,  1.3659e-02, -7.8875e-02,  ..., -1.5674e-01,
          -1.7864e-02, -6.9542e-02],
         [ 5.9531e-02, -1.1535e-02,  1.6737e-01,  ...,  1.3096e-01,
          -5.9244e-03,  3.2770e-02],
         ...,
         [-2.0493e-01, -6.6447e-03,  9.2717e-04,  ...,  1.8365e-02,
          -3.7084e-02, -4.7850e-02],
         [ 7.6707e-02,  3.1250e-02,  1.2069e-01,  ...,  3.7137e-02,
          -6.3433e-02,  6.6500e-02],
         [-1.0231e-04, -5.8219e-02, -8.3265e-02,  ..., -7.6276e-02,
          -6.9949e-02,  9.9713e-02]],

        [[-3.0011e-02,  3.8612e-02, -4.2530e-02,  ...,  8.5219e-02,
           6.8311e-02, -2.2981e-02],
         [-7.6258e-02,  3.7699e-02, -4.1274e-02,  ..., -1.1260e-01,
          -1.6906e-01,  1.1579e-01],
         [-3.0532e-02,  7.9512e-02,  1.2161e-03,  ...,  2.3763e-02,
          -2.1581e-02, -1.2797e-01],
         ...,
         [-4.2695e-02,  7.3476e-03,  1.6109e-01,  ...,  1.4757e-01,
           6.6846e-03,  1.1564e-02],
         [-2.7618e-02,  6.6421e-02, -6.5992e-02,  ...,  5.7826e-02,
           1.8811e-02, -4.4617e-02],
         [-6.9162e-02, -4.7060e-03,  3.4228e-02,  ..., -4.1331e-02,
           8.3096e-03,  6.6972e-02]],

        [[ 8.8544e-02,  1.4929e-02,  1.0989e-01,  ...,  1.5671e-02,
           7.2294e-02,  1.2976e-02],
         [ 6.2212e-02, -7.8619e-02, -3.5201e-03,  ..., -9.4244e-02,
          -3.9950e-03, -8.4480e-02],
         [-3.5664e-01,  9.7348e-03, -3.4094e-02,  ..., -2.2708e-01,
          -9.1862e-02,  2.3209e-02],
         ...,
         [-1.5907e-01, -1.2464e-02,  1.1951e-01,  ...,  2.5076e-02,
           4.3637e-02,  4.7834e-02],
         [ 1.4748e-02,  1.3585e-01, -2.4797e-01,  ..., -7.2696e-02,
          -1.3034e-02, -7.8452e-02],
         [-4.2705e-02, -8.4851e-02, -7.7180e-02,  ..., -1.3413e-01,
           1.3501e-01,  1.2112e-01]]], grad_fn=<StackBackward0>), 'stoch': tensor([[[0., 0., 0.,  ..., 0., 0., 1.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 1., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 1., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 1.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]])}
train_step: Starting state deter shape: torch.Size([4, 10, 128])
train_step: Starting state stoch shape: torch.Size([4, 10, 1024])
After ensuring logits/stoch: {'deter': tensor([[[ 1.5481e-01,  9.7870e-02, -3.6855e-02,  ..., -6.1023e-02,
           1.2957e-02, -1.3702e-01],
         [-5.4251e-02,  7.8578e-02, -1.0353e-01,  ..., -1.3036e-01,
          -6.6195e-02,  3.2296e-02],
         [ 1.3054e-01,  2.0749e-01,  3.9367e-02,  ...,  2.8365e-03,
          -1.0631e-01,  5.5598e-02],
         ...,
         [ 1.0183e-01,  1.4874e-02, -1.7200e-01,  ..., -2.8608e-02,
           1.7293e-02, -5.5043e-02],
         [-1.9109e-01,  1.9585e-01, -1.7575e-01,  ...,  4.8762e-02,
           1.2087e-01, -3.4920e-02],
         [-9.1593e-02,  8.9367e-06,  6.5423e-02,  ..., -3.2170e-02,
          -5.3791e-02, -4.1740e-02]],

        [[-2.7081e-02,  1.2911e-01, -7.7289e-03,  ..., -1.9401e-02,
           9.1739e-02, -2.3813e-02],
         [-6.5232e-03,  1.3659e-02, -7.8875e-02,  ..., -1.5674e-01,
          -1.7864e-02, -6.9542e-02],
         [ 5.9531e-02, -1.1535e-02,  1.6737e-01,  ...,  1.3096e-01,
          -5.9244e-03,  3.2770e-02],
         ...,
         [-2.0493e-01, -6.6447e-03,  9.2717e-04,  ...,  1.8365e-02,
          -3.7084e-02, -4.7850e-02],
         [ 7.6707e-02,  3.1250e-02,  1.2069e-01,  ...,  3.7137e-02,
          -6.3433e-02,  6.6500e-02],
         [-1.0231e-04, -5.8219e-02, -8.3265e-02,  ..., -7.6276e-02,
          -6.9949e-02,  9.9713e-02]],

        [[-3.0011e-02,  3.8612e-02, -4.2530e-02,  ...,  8.5219e-02,
           6.8311e-02, -2.2981e-02],
         [-7.6258e-02,  3.7699e-02, -4.1274e-02,  ..., -1.1260e-01,
          -1.6906e-01,  1.1579e-01],
         [-3.0532e-02,  7.9512e-02,  1.2161e-03,  ...,  2.3763e-02,
          -2.1581e-02, -1.2797e-01],
         ...,
         [-4.2695e-02,  7.3476e-03,  1.6109e-01,  ...,  1.4757e-01,
           6.6846e-03,  1.1564e-02],
         [-2.7618e-02,  6.6421e-02, -6.5992e-02,  ...,  5.7826e-02,
           1.8811e-02, -4.4617e-02],
         [-6.9162e-02, -4.7060e-03,  3.4228e-02,  ..., -4.1331e-02,
           8.3096e-03,  6.6972e-02]],

        [[ 8.8544e-02,  1.4929e-02,  1.0989e-01,  ...,  1.5671e-02,
           7.2294e-02,  1.2976e-02],
         [ 6.2212e-02, -7.8619e-02, -3.5201e-03,  ..., -9.4244e-02,
          -3.9950e-03, -8.4480e-02],
         [-3.5664e-01,  9.7348e-03, -3.4094e-02,  ..., -2.2708e-01,
          -9.1862e-02,  2.3209e-02],
         ...,
         [-1.5907e-01, -1.2464e-02,  1.1951e-01,  ...,  2.5076e-02,
           4.3637e-02,  4.7834e-02],
         [ 1.4748e-02,  1.3585e-01, -2.4797e-01,  ..., -7.2696e-02,
          -1.3034e-02, -7.8452e-02],
         [-4.2705e-02, -8.4851e-02, -7.7180e-02,  ..., -1.3413e-01,
           1.3501e-01,  1.2112e-01]]], grad_fn=<StackBackward0>), 'stoch': tensor([[[0., 0., 0.,  ..., 0., 0., 1.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 1., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 1., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 1.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]]), 'logits': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]])}
train_step: Normalized hidden_state shape: torch.Size([1, 4, 128])
train_step: Normalized stoch shape: torch.Size([4, 1024])
train_step: Normalized deter shape: torch.Size([4, 128])
train_step: Post-imagine_trajectory: Imagined features shape: torch.Size([4, 15, 1152])
train_step: Post-imagine_trajectory: Imagined actions shape: torch.Size([4, 15, 2])
train_step: Post-imagine_trajectory: Imagined action indices shape: torch.Size([4, 15])
train_step: Post-imagine_trajectory: Imagined state deter shape: torch.Size([4, 15, 128])
train_step: Post-imagine_trajectory: Imagined state stoch shape: torch.Size([4, 15, 1024])
Reward shape: torch.Size([4, 15, 1]), Value shape: torch.Size([4, 15, 1]), Slow Value shape: torch.Size([4, 15, 1]), Discount shape: torch.Size([4, 15, 1, 1])
Return targets length: 15, First target shape: torch.Size([4, 4, 1])
train_step: Actor distribution shape: torch.Size([4, 15, 2])
train_step: Action log probabilities shape: torch.Size([4, 15])
train_step: Action log probabilities sample: tensor([[-0.1145, -0.3142],
        [-0.1769, -0.4081]], grad_fn=<SliceBackward0>)
train_step: Advantages shape: torch.Size([4, 4, 4, 15])
train_step: Advantages sample: tensor([[[[-2.8700, -2.8700, -2.8700, -2.8700, -2.8700, -2.8700, -2.8700,
           -2.8700, -2.8700, -2.8700, -2.8700, -2.8700, -2.8700, -2.8700,
           -2.8700],
          [-4.7517, -4.7517, -4.7517, -4.7517, -4.7517, -4.7517, -4.7517,
           -4.7517, -4.7517, -4.7517, -4.7517, -4.7517, -4.7517, -4.7517,
           -4.7517],
          [-7.7636, -7.7636, -7.7636, -7.7636, -7.7636, -7.7636, -7.7636,
           -7.7636, -7.7636, -7.7636, -7.7636, -7.7636, -7.7636, -7.7636,
           -7.7636],
          [-2.0688, -2.0688, -2.0688, -2.0688, -2.0688, -2.0688, -2.0688,
           -2.0688, -2.0688, -2.0688, -2.0688, -2.0688, -2.0688, -2.0688,
           -2.0688]],

         [[-1.7380, -1.7380, -1.7380, -1.7380, -1.7380, -1.7380, -1.7380,
           -1.7380, -1.7380, -1.7380, -1.7380, -1.7380, -1.7380, -1.7380,
           -1.7380],
          [-3.7248, -3.7248, -3.7248, -3.7248, -3.7248, -3.7248, -3.7248,
           -3.7248, -3.7248, -3.7248, -3.7248, -3.7248, -3.7248, -3.7248,
           -3.7248],
          [-6.9047, -6.9047, -6.9047, -6.9047, -6.9047, -6.9047, -6.9047,
           -6.9047, -6.9047, -6.9047, -6.9047, -6.9047, -6.9047, -6.9047,
           -6.9047],
          [-0.8921, -0.8921, -0.8921, -0.8921, -0.8921, -0.8921, -0.8921,
           -0.8921, -0.8921, -0.8921, -0.8921, -0.8921, -0.8921, -0.8921,
           -0.8921]]],


        [[[-4.7525, -4.7525, -4.7525, -4.7525, -4.7525, -4.7525, -4.7525,
           -4.7525, -4.7525, -4.7525, -4.7525, -4.7525, -4.7525, -4.7525,
           -4.7525],
          [-7.0401, -7.0401, -7.0401, -7.0401, -7.0401, -7.0401, -7.0401,
           -7.0401, -7.0401, -7.0401, -7.0401, -7.0401, -7.0401, -7.0401,
           -7.0401],
          [-9.9675, -9.9675, -9.9675, -9.9675, -9.9675, -9.9675, -9.9675,
           -9.9675, -9.9675, -9.9675, -9.9675, -9.9675, -9.9675, -9.9675,
           -9.9675],
          [-1.3846, -1.3846, -1.3846, -1.3846, -1.3846, -1.3846, -1.3846,
           -1.3846, -1.3846, -1.3846, -1.3846, -1.3846, -1.3846, -1.3846,
           -1.3846]],

         [[-4.3112, -4.3112, -4.3112, -4.3112, -4.3112, -4.3112, -4.3112,
           -4.3112, -4.3112, -4.3112, -4.3112, -4.3112, -4.3112, -4.3112,
           -4.3112],
          [-6.7264, -6.7264, -6.7264, -6.7264, -6.7264, -6.7264, -6.7264,
           -6.7264, -6.7264, -6.7264, -6.7264, -6.7264, -6.7264, -6.7264,
           -6.7264],
          [-9.8172, -9.8172, -9.8172, -9.8172, -9.8172, -9.8172, -9.8172,
           -9.8172, -9.8172, -9.8172, -9.8172, -9.8172, -9.8172, -9.8172,
           -9.8172],
          [-0.7553, -0.7553, -0.7553, -0.7553, -0.7553, -0.7553, -0.7553,
           -0.7553, -0.7553, -0.7553, -0.7553, -0.7553, -0.7553, -0.7553,
           -0.7553]]]], grad_fn=<SliceBackward0>)
train_step: Return scale: 1.112879593114555
train_step: Scaled advantages shape: torch.Size([4, 4, 4, 15])
train_step: Scaled advantages sample: tensor([[[[-2.5789, -2.5789, -2.5789, -2.5789, -2.5789, -2.5789, -2.5789,
           -2.5789, -2.5789, -2.5789, -2.5789, -2.5789, -2.5789, -2.5789,
           -2.5789],
          [-4.2698, -4.2698, -4.2698, -4.2698, -4.2698, -4.2698, -4.2698,
           -4.2698, -4.2698, -4.2698, -4.2698, -4.2698, -4.2698, -4.2698,
           -4.2698],
          [-6.9761, -6.9761, -6.9761, -6.9761, -6.9761, -6.9761, -6.9761,
           -6.9761, -6.9761, -6.9761, -6.9761, -6.9761, -6.9761, -6.9761,
           -6.9761],
          [-1.8589, -1.8589, -1.8589, -1.8589, -1.8589, -1.8589, -1.8589,
           -1.8589, -1.8589, -1.8589, -1.8589, -1.8589, -1.8589, -1.8589,
           -1.8589]],

         [[-1.5617, -1.5617, -1.5617, -1.5617, -1.5617, -1.5617, -1.5617,
           -1.5617, -1.5617, -1.5617, -1.5617, -1.5617, -1.5617, -1.5617,
           -1.5617],
          [-3.3470, -3.3470, -3.3470, -3.3470, -3.3470, -3.3470, -3.3470,
           -3.3470, -3.3470, -3.3470, -3.3470, -3.3470, -3.3470, -3.3470,
           -3.3470],
          [-6.2044, -6.2044, -6.2044, -6.2044, -6.2044, -6.2044, -6.2044,
           -6.2044, -6.2044, -6.2044, -6.2044, -6.2044, -6.2044, -6.2044,
           -6.2044],
          [-0.8921, -0.8921, -0.8921, -0.8921, -0.8921, -0.8921, -0.8921,
           -0.8921, -0.8921, -0.8921, -0.8921, -0.8921, -0.8921, -0.8921,
           -0.8921]]],


        [[[-4.2705, -4.2705, -4.2705, -4.2705, -4.2705, -4.2705, -4.2705,
           -4.2705, -4.2705, -4.2705, -4.2705, -4.2705, -4.2705, -4.2705,
           -4.2705],
          [-6.3260, -6.3260, -6.3260, -6.3260, -6.3260, -6.3260, -6.3260,
           -6.3260, -6.3260, -6.3260, -6.3260, -6.3260, -6.3260, -6.3260,
           -6.3260],
          [-8.9565, -8.9565, -8.9565, -8.9565, -8.9565, -8.9565, -8.9565,
           -8.9565, -8.9565, -8.9565, -8.9565, -8.9565, -8.9565, -8.9565,
           -8.9565],
          [-1.2441, -1.2441, -1.2441, -1.2441, -1.2441, -1.2441, -1.2441,
           -1.2441, -1.2441, -1.2441, -1.2441, -1.2441, -1.2441, -1.2441,
           -1.2441]],

         [[-3.8739, -3.8739, -3.8739, -3.8739, -3.8739, -3.8739, -3.8739,
           -3.8739, -3.8739, -3.8739, -3.8739, -3.8739, -3.8739, -3.8739,
           -3.8739],
          [-6.0441, -6.0441, -6.0441, -6.0441, -6.0441, -6.0441, -6.0441,
           -6.0441, -6.0441, -6.0441, -6.0441, -6.0441, -6.0441, -6.0441,
           -6.0441],
          [-8.8214, -8.8214, -8.8214, -8.8214, -8.8214, -8.8214, -8.8214,
           -8.8214, -8.8214, -8.8214, -8.8214, -8.8214, -8.8214, -8.8214,
           -8.8214],
          [-0.7553, -0.7553, -0.7553, -0.7553, -0.7553, -0.7553, -0.7553,
           -0.7553, -0.7553, -0.7553, -0.7553, -0.7553, -0.7553, -0.7553,
           -0.7553]]]], grad_fn=<SliceBackward0>)
train_step: Entropy shape: torch.Size([4, 15])
train_step: Entropy sample: tensor([[0.3427, 0.5829],
        [0.4433, 0.6377]], grad_fn=<SliceBackward0>)
train_step: Entropy coefficient: 0.01
train_step: Actor loss: -2.763500928878784
train_step: returns shape after mean: torch.Size([4, 15])
train_step: target_indices shape: torch.Size([4, 15])
train_step: value_logits shape: torch.Size([4, 15, 255])
train_step: target_twohot shape: torch.Size([4, 15, 255])
--- Starting train_step at 2025-04-01 01:56:47 ---
Full starting_state: {'deter': tensor([[[-0.0021,  0.0092, -0.1091,  ...,  0.1558, -0.2149, -0.0853],
         [-0.0480, -0.1523, -0.1395,  ...,  0.2106,  0.1105,  0.0811],
         [-0.0676, -0.1295, -0.0432,  ...,  0.0038,  0.1244, -0.1575],
         ...,
         [-0.0076, -0.0551,  0.0608,  ...,  0.0522,  0.0302,  0.0220],
         [ 0.0442,  0.0854, -0.2224,  ..., -0.0993, -0.0116, -0.0201],
         [-0.0363,  0.0575, -0.0538,  ...,  0.0203, -0.0220,  0.0699]],

        [[ 0.0748,  0.0216, -0.1179,  ..., -0.0635, -0.0088,  0.0088],
         [-0.1011, -0.0729, -0.1424,  ..., -0.0836,  0.1089, -0.0594],
         [-0.1076,  0.0673, -0.1139,  ..., -0.0616, -0.0742, -0.0460],
         ...,
         [-0.0707, -0.0348, -0.0041,  ..., -0.1112, -0.0619,  0.0301],
         [-0.0989,  0.1522, -0.0801,  ...,  0.0570, -0.0291,  0.0155],
         [ 0.0209,  0.0726, -0.0879,  ...,  0.1143,  0.1335,  0.0789]],

        [[ 0.1241, -0.0298, -0.0797,  ...,  0.0753,  0.1452, -0.1011],
         [ 0.0559, -0.0962, -0.0251,  ...,  0.0804,  0.0211, -0.0062],
         [-0.1003, -0.0894,  0.2144,  ...,  0.0868, -0.0583, -0.0816],
         ...,
         [-0.0150, -0.0968, -0.0182,  ...,  0.0117, -0.0488, -0.0129],
         [ 0.0135, -0.1296, -0.1430,  ...,  0.0931, -0.0394, -0.0643],
         [-0.0583,  0.1907, -0.0680,  ...,  0.0067, -0.0284,  0.1183]],

        ...,

        [[ 0.0448, -0.0208, -0.0541,  ...,  0.0388,  0.1115, -0.0124],
         [-0.0989, -0.0209, -0.0434,  ...,  0.0458,  0.1482,  0.0115],
         [-0.0580,  0.0043, -0.1223,  ..., -0.0691, -0.0104, -0.0945],
         ...,
         [-0.1219,  0.0379,  0.0058,  ...,  0.0125,  0.0342, -0.0839],
         [-0.0611,  0.0368,  0.0218,  ..., -0.0089,  0.1042, -0.1132],
         [-0.0187, -0.0313, -0.0419,  ...,  0.0089, -0.0470,  0.0120]],

        [[-0.1586, -0.0338, -0.0069,  ..., -0.0844,  0.0717,  0.0270],
         [-0.0603,  0.0016, -0.0504,  ...,  0.1148, -0.0564, -0.1678],
         [-0.0262,  0.0591, -0.1180,  ..., -0.0489,  0.0974, -0.1585],
         ...,
         [-0.1125, -0.0356, -0.0267,  ..., -0.0469,  0.0545, -0.0483],
         [ 0.0443, -0.1388, -0.0563,  ...,  0.1863, -0.0060,  0.0109],
         [-0.0108, -0.1179,  0.0737,  ..., -0.0388,  0.0282,  0.0803]],

        [[-0.0155,  0.1538, -0.0681,  ...,  0.0476, -0.0699, -0.0885],
         [ 0.0226, -0.0831, -0.0063,  ..., -0.0105,  0.0496,  0.2102],
         [ 0.0808,  0.1698,  0.0247,  ...,  0.1041, -0.0419,  0.1045],
         ...,
         [-0.0410,  0.1469, -0.1012,  ...,  0.0555,  0.0236,  0.0530],
         [ 0.0660,  0.1382, -0.2359,  ..., -0.1038, -0.0558, -0.1269],
         [-0.1518,  0.0598, -0.0860,  ..., -0.0708,  0.0537,  0.1031]]],
       grad_fn=<StackBackward0>), 'stoch': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 1., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [1., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 1., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[1., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 1.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [1., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]])}
train_step: Starting state deter shape: torch.Size([16, 50, 128])
train_step: Starting state stoch shape: torch.Size([16, 50, 1024])
After ensuring logits/stoch: {'deter': tensor([[[-0.0021,  0.0092, -0.1091,  ...,  0.1558, -0.2149, -0.0853],
         [-0.0480, -0.1523, -0.1395,  ...,  0.2106,  0.1105,  0.0811],
         [-0.0676, -0.1295, -0.0432,  ...,  0.0038,  0.1244, -0.1575],
         ...,
         [-0.0076, -0.0551,  0.0608,  ...,  0.0522,  0.0302,  0.0220],
         [ 0.0442,  0.0854, -0.2224,  ..., -0.0993, -0.0116, -0.0201],
         [-0.0363,  0.0575, -0.0538,  ...,  0.0203, -0.0220,  0.0699]],

        [[ 0.0748,  0.0216, -0.1179,  ..., -0.0635, -0.0088,  0.0088],
         [-0.1011, -0.0729, -0.1424,  ..., -0.0836,  0.1089, -0.0594],
         [-0.1076,  0.0673, -0.1139,  ..., -0.0616, -0.0742, -0.0460],
         ...,
         [-0.0707, -0.0348, -0.0041,  ..., -0.1112, -0.0619,  0.0301],
         [-0.0989,  0.1522, -0.0801,  ...,  0.0570, -0.0291,  0.0155],
         [ 0.0209,  0.0726, -0.0879,  ...,  0.1143,  0.1335,  0.0789]],

        [[ 0.1241, -0.0298, -0.0797,  ...,  0.0753,  0.1452, -0.1011],
         [ 0.0559, -0.0962, -0.0251,  ...,  0.0804,  0.0211, -0.0062],
         [-0.1003, -0.0894,  0.2144,  ...,  0.0868, -0.0583, -0.0816],
         ...,
         [-0.0150, -0.0968, -0.0182,  ...,  0.0117, -0.0488, -0.0129],
         [ 0.0135, -0.1296, -0.1430,  ...,  0.0931, -0.0394, -0.0643],
         [-0.0583,  0.1907, -0.0680,  ...,  0.0067, -0.0284,  0.1183]],

        ...,

        [[ 0.0448, -0.0208, -0.0541,  ...,  0.0388,  0.1115, -0.0124],
         [-0.0989, -0.0209, -0.0434,  ...,  0.0458,  0.1482,  0.0115],
         [-0.0580,  0.0043, -0.1223,  ..., -0.0691, -0.0104, -0.0945],
         ...,
         [-0.1219,  0.0379,  0.0058,  ...,  0.0125,  0.0342, -0.0839],
         [-0.0611,  0.0368,  0.0218,  ..., -0.0089,  0.1042, -0.1132],
         [-0.0187, -0.0313, -0.0419,  ...,  0.0089, -0.0470,  0.0120]],

        [[-0.1586, -0.0338, -0.0069,  ..., -0.0844,  0.0717,  0.0270],
         [-0.0603,  0.0016, -0.0504,  ...,  0.1148, -0.0564, -0.1678],
         [-0.0262,  0.0591, -0.1180,  ..., -0.0489,  0.0974, -0.1585],
         ...,
         [-0.1125, -0.0356, -0.0267,  ..., -0.0469,  0.0545, -0.0483],
         [ 0.0443, -0.1388, -0.0563,  ...,  0.1863, -0.0060,  0.0109],
         [-0.0108, -0.1179,  0.0737,  ..., -0.0388,  0.0282,  0.0803]],

        [[-0.0155,  0.1538, -0.0681,  ...,  0.0476, -0.0699, -0.0885],
         [ 0.0226, -0.0831, -0.0063,  ..., -0.0105,  0.0496,  0.2102],
         [ 0.0808,  0.1698,  0.0247,  ...,  0.1041, -0.0419,  0.1045],
         ...,
         [-0.0410,  0.1469, -0.1012,  ...,  0.0555,  0.0236,  0.0530],
         [ 0.0660,  0.1382, -0.2359,  ..., -0.1038, -0.0558, -0.1269],
         [-0.1518,  0.0598, -0.0860,  ..., -0.0708,  0.0537,  0.1031]]],
       grad_fn=<StackBackward0>), 'stoch': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 1., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [1., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 1., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[1., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 1.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [1., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]]), 'logits': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]])}
train_step: Normalized hidden_state shape: torch.Size([1, 16, 128])
train_step: Normalized stoch shape: torch.Size([16, 1024])
train_step: Normalized deter shape: torch.Size([16, 128])
train_step: Post-imagine_trajectory: Imagined features shape: torch.Size([16, 15, 1152])
train_step: Post-imagine_trajectory: Imagined actions shape: torch.Size([16, 15, 2])
train_step: Post-imagine_trajectory: Imagined action indices shape: torch.Size([16, 15])
train_step: Post-imagine_trajectory: Imagined state deter shape: torch.Size([16, 15, 128])
train_step: Post-imagine_trajectory: Imagined state stoch shape: torch.Size([16, 15, 1024])
Reward shape: torch.Size([16, 15, 1]), Value shape: torch.Size([16, 15, 1]), Slow Value shape: torch.Size([16, 15, 1]), Discount shape: torch.Size([16, 15, 1, 1])
Return targets length: 15, First target shape: torch.Size([16, 16, 1])
train_step: Actor distribution shape: torch.Size([16, 15, 2])
train_step: Action log probabilities shape: torch.Size([16, 15])
train_step: Action log probabilities sample: tensor([[-1.2277, -0.5567],
        [-0.7178, -1.2949]], grad_fn=<SliceBackward0>)
train_step: Advantages shape: torch.Size([16, 15, 16, 15])
train_step: Advantages sample: tensor([[[[-0.8752, -0.8752, -0.8752, -0.8752, -0.8752, -0.8752, -0.8752,
           -0.8752, -0.8752, -0.8752, -0.8752, -0.8752, -0.8752, -0.8752,
           -0.8752],
          [-7.0123, -7.0123, -7.0123, -7.0123, -7.0123, -7.0123, -7.0123,
           -7.0123, -7.0123, -7.0123, -7.0123, -7.0123, -7.0123, -7.0123,
           -7.0123],
          [-5.3735, -5.3735, -5.3735, -5.3735, -5.3735, -5.3735, -5.3735,
           -5.3735, -5.3735, -5.3735, -5.3735, -5.3735, -5.3735, -5.3735,
           -5.3735],
          [-4.6557, -4.6557, -4.6557, -4.6557, -4.6557, -4.6557, -4.6557,
           -4.6557, -4.6557, -4.6557, -4.6557, -4.6557, -4.6557, -4.6557,
           -4.6557],
          [-6.5570, -6.5570, -6.5570, -6.5570, -6.5570, -6.5570, -6.5570,
           -6.5570, -6.5570, -6.5570, -6.5570, -6.5570, -6.5570, -6.5570,
           -6.5570],
          [-7.0123, -7.0123, -7.0123, -7.0123, -7.0123, -7.0123, -7.0123,
           -7.0123, -7.0123, -7.0123, -7.0123, -7.0123, -7.0123, -7.0123,
           -7.0123],
          [-4.7803, -4.7803, -4.7803, -4.7803, -4.7803, -4.7803, -4.7803,
           -4.7803, -4.7803, -4.7803, -4.7803, -4.7803, -4.7803, -4.7803,
           -4.7803],
          [-0.7062, -0.7062, -0.7062, -0.7062, -0.7062, -0.7062, -0.7062,
           -0.7062, -0.7062, -0.7062, -0.7062, -0.7062, -0.7062, -0.7062,
           -0.7062],
          [-5.9780, -5.9780, -5.9780, -5.9780, -5.9780, -5.9780, -5.9780,
           -5.9780, -5.9780, -5.9780, -5.9780, -5.9780, -5.9780, -5.9780,
           -5.9780],
          [-7.0123, -7.0123, -7.0123, -7.0123, -7.0123, -7.0123, -7.0123,
           -7.0123, -7.0123, -7.0123, -7.0123, -7.0123, -7.0123, -7.0123,
           -7.0123],
          [-2.0958, -2.0958, -2.0958, -2.0958, -2.0958, -2.0958, -2.0958,
           -2.0958, -2.0958, -2.0958, -2.0958, -2.0958, -2.0958, -2.0958,
           -2.0958],
          [-6.3294, -6.3294, -6.3294, -6.3294, -6.3294, -6.3294, -6.3294,
           -6.3294, -6.3294, -6.3294, -6.3294, -6.3294, -6.3294, -6.3294,
           -6.3294],
          [-5.6350, -5.6350, -5.6350, -5.6350, -5.6350, -5.6350, -5.6350,
           -5.6350, -5.6350, -5.6350, -5.6350, -5.6350, -5.6350, -5.6350,
           -5.6350],
          [-3.8618, -3.8618, -3.8618, -3.8618, -3.8618, -3.8618, -3.8618,
           -3.8618, -3.8618, -3.8618, -3.8618, -3.8618, -3.8618, -3.8618,
           -3.8618],
          [-0.8752, -0.8752, -0.8752, -0.8752, -0.8752, -0.8752, -0.8752,
           -0.8752, -0.8752, -0.8752, -0.8752, -0.8752, -0.8752, -0.8752,
           -0.8752],
          [-0.7062, -0.7062, -0.7062, -0.7062, -0.7062, -0.7062, -0.7062,
           -0.7062, -0.7062, -0.7062, -0.7062, -0.7062, -0.7062, -0.7062,
           -0.7062]],

         [[-0.1784, -0.1784, -0.1784, -0.1784, -0.1784, -0.1784, -0.1784,
           -0.1784, -0.1784, -0.1784, -0.1784, -0.1784, -0.1784, -0.1784,
           -0.1784],
          [-6.6579, -6.6579, -6.6579, -6.6579, -6.6579, -6.6579, -6.6579,
           -6.6579, -6.6579, -6.6579, -6.6579, -6.6579, -6.6579, -6.6579,
           -6.6579],
          [-4.9277, -4.9277, -4.9277, -4.9277, -4.9277, -4.9277, -4.9277,
           -4.9277, -4.9277, -4.9277, -4.9277, -4.9277, -4.9277, -4.9277,
           -4.9277],
          [-4.1699, -4.1699, -4.1699, -4.1699, -4.1699, -4.1699, -4.1699,
           -4.1699, -4.1699, -4.1699, -4.1699, -4.1699, -4.1699, -4.1699,
           -4.1699],
          [-6.1772, -6.1772, -6.1772, -6.1772, -6.1772, -6.1772, -6.1772,
           -6.1772, -6.1772, -6.1772, -6.1772, -6.1772, -6.1772, -6.1772,
           -6.1772],
          [-6.6579, -6.6579, -6.6579, -6.6579, -6.6579, -6.6579, -6.6579,
           -6.6579, -6.6579, -6.6579, -6.6579, -6.6579, -6.6579, -6.6579,
           -6.6579],
          [-4.3014, -4.3014, -4.3014, -4.3014, -4.3014, -4.3014, -4.3014,
           -4.3014, -4.3014, -4.3014, -4.3014, -4.3014, -4.3014, -4.3014,
           -4.3014],
          [-5.2038, -5.2038, -5.2038, -5.2038, -5.2038, -5.2038, -5.2038,
           -5.2038, -5.2038, -5.2038, -5.2038, -5.2038, -5.2038, -5.2038,
           -5.2038],
          [-5.5659, -5.5659, -5.5659, -5.5659, -5.5659, -5.5659, -5.5659,
           -5.5659, -5.5659, -5.5659, -5.5659, -5.5659, -5.5659, -5.5659,
           -5.5659],
          [-6.6579, -6.6579, -6.6579, -6.6579, -6.6579, -6.6579, -6.6579,
           -6.6579, -6.6579, -6.6579, -6.6579, -6.6579, -6.6579, -6.6579,
           -6.6579],
          [-1.4671, -1.4671, -1.4671, -1.4671, -1.4671, -1.4671, -1.4671,
           -1.4671, -1.4671, -1.4671, -1.4671, -1.4671, -1.4671, -1.4671,
           -1.4671],
          [-5.9369, -5.9369, -5.9369, -5.9369, -5.9369, -5.9369, -5.9369,
           -5.9369, -5.9369, -5.9369, -5.9369, -5.9369, -5.9369, -5.9369,
           -5.9369],
          [-5.2038, -5.2038, -5.2038, -5.2038, -5.2038, -5.2038, -5.2038,
           -5.2038, -5.2038, -5.2038, -5.2038, -5.2038, -5.2038, -5.2038,
           -5.2038],
          [-3.3316, -3.3316, -3.3316, -3.3316, -3.3316, -3.3316, -3.3316,
           -3.3316, -3.3316, -3.3316, -3.3316, -3.3316, -3.3316, -3.3316,
           -3.3316],
          [-0.1784, -0.1784, -0.1784, -0.1784, -0.1784, -0.1784, -0.1784,
           -0.1784, -0.1784, -0.1784, -0.1784, -0.1784, -0.1784, -0.1784,
           -0.1784],
          [-1.4671, -1.4671, -1.4671, -1.4671, -1.4671, -1.4671, -1.4671,
           -1.4671, -1.4671, -1.4671, -1.4671, -1.4671, -1.4671, -1.4671,
           -1.4671]]],


        [[[-1.0975, -1.0975, -1.0975, -1.0975, -1.0975, -1.0975, -1.0975,
           -1.0975, -1.0975, -1.0975, -1.0975, -1.0975, -1.0975, -1.0975,
           -1.0975],
          [-8.0901, -8.0901, -8.0901, -8.0901, -8.0901, -8.0901, -8.0901,
           -8.0901, -8.0901, -8.0901, -8.0901, -8.0901, -8.0901, -8.0901,
           -8.0901],
          [-6.6006, -6.6006, -6.6006, -6.6006, -6.6006, -6.6006, -6.6006,
           -6.6006, -6.6006, -6.6006, -6.6006, -6.6006, -6.6006, -6.6006,
           -6.6006],
          [-5.5158, -5.5158, -5.5158, -5.5158, -5.5158, -5.5158, -5.5158,
           -5.5158, -5.5158, -5.5158, -5.5158, -5.5158, -5.5158, -5.5158,
           -5.5158],
          [-7.6372, -7.6372, -7.6372, -7.6372, -7.6372, -7.6372, -7.6372,
           -7.6372, -7.6372, -7.6372, -7.6372, -7.6372, -7.6372, -7.6372,
           -7.6372],
          [-8.0901, -8.0901, -8.0901, -8.0901, -8.0901, -8.0901, -8.0901,
           -8.0901, -8.0901, -8.0901, -8.0901, -8.0901, -8.0901, -8.0901,
           -8.0901],
          [-6.1886, -6.1886, -6.1886, -6.1886, -6.1886, -6.1886, -6.1886,
           -6.1886, -6.1886, -6.1886, -6.1886, -6.1886, -6.1886, -6.1886,
           -6.1886],
          [-0.6067, -0.6067, -0.6067, -0.6067, -0.6067, -0.6067, -0.6067,
           -0.6067, -0.6067, -0.6067, -0.6067, -0.6067, -0.6067, -0.6067,
           -0.6067],
          [-7.2717, -7.2717, -7.2717, -7.2717, -7.2717, -7.2717, -7.2717,
           -7.2717, -7.2717, -7.2717, -7.2717, -7.2717, -7.2717, -7.2717,
           -7.2717],
          [-8.0901, -8.0901, -8.0901, -8.0901, -8.0901, -8.0901, -8.0901,
           -8.0901, -8.0901, -8.0901, -8.0901, -8.0901, -8.0901, -8.0901,
           -8.0901],
          [-2.4916, -2.4916, -2.4916, -2.4916, -2.4916, -2.4916, -2.4916,
           -2.4916, -2.4916, -2.4916, -2.4916, -2.4916, -2.4916, -2.4916,
           -2.4916],
          [-7.2661, -7.2661, -7.2661, -7.2661, -7.2661, -7.2661, -7.2661,
           -7.2661, -7.2661, -7.2661, -7.2661, -7.2661, -7.2661, -7.2661,
           -7.2661],
          [-7.0919, -7.0919, -7.0919, -7.0919, -7.0919, -7.0919, -7.0919,
           -7.0919, -7.0919, -7.0919, -7.0919, -7.0919, -7.0919, -7.0919,
           -7.0919],
          [-4.9354, -4.9354, -4.9354, -4.9354, -4.9354, -4.9354, -4.9354,
           -4.9354, -4.9354, -4.9354, -4.9354, -4.9354, -4.9354, -4.9354,
           -4.9354],
          [-1.0975, -1.0975, -1.0975, -1.0975, -1.0975, -1.0975, -1.0975,
           -1.0975, -1.0975, -1.0975, -1.0975, -1.0975, -1.0975, -1.0975,
           -1.0975],
          [-0.6067, -0.6067, -0.6067, -0.6067, -0.6067, -0.6067, -0.6067,
           -0.6067, -0.6067, -0.6067, -0.6067, -0.6067, -0.6067, -0.6067,
           -0.6067]],

         [[-0.5182, -0.5182, -0.5182, -0.5182, -0.5182, -0.5182, -0.5182,
           -0.5182, -0.5182, -0.5182, -0.5182, -0.5182, -0.5182, -0.5182,
           -0.5182],
          [-7.9009, -7.9009, -7.9009, -7.9009, -7.9009, -7.9009, -7.9009,
           -7.9009, -7.9009, -7.9009, -7.9009, -7.9009, -7.9009, -7.9009,
           -7.9009],
          [-6.3283, -6.3283, -6.3283, -6.3283, -6.3283, -6.3283, -6.3283,
           -6.3283, -6.3283, -6.3283, -6.3283, -6.3283, -6.3283, -6.3283,
           -6.3283],
          [-5.1829, -5.1829, -5.1829, -5.1829, -5.1829, -5.1829, -5.1829,
           -5.1829, -5.1829, -5.1829, -5.1829, -5.1829, -5.1829, -5.1829,
           -5.1829],
          [-7.4227, -7.4227, -7.4227, -7.4227, -7.4227, -7.4227, -7.4227,
           -7.4227, -7.4227, -7.4227, -7.4227, -7.4227, -7.4227, -7.4227,
           -7.4227],
          [-7.9009, -7.9009, -7.9009, -7.9009, -7.9009, -7.9009, -7.9009,
           -7.9009, -7.9009, -7.9009, -7.9009, -7.9009, -7.9009, -7.9009,
           -7.9009],
          [-5.8933, -5.8933, -5.8933, -5.8933, -5.8933, -5.8933, -5.8933,
           -5.8933, -5.8933, -5.8933, -5.8933, -5.8933, -5.8933, -5.8933,
           -5.8933],
          [-6.8470, -6.8470, -6.8470, -6.8470, -6.8470, -6.8470, -6.8470,
           -6.8470, -6.8470, -6.8470, -6.8470, -6.8470, -6.8470, -6.8470,
           -6.8470],
          [-7.0368, -7.0368, -7.0368, -7.0368, -7.0368, -7.0368, -7.0368,
           -7.0368, -7.0368, -7.0368, -7.0368, -7.0368, -7.0368, -7.0368,
           -7.0368],
          [-7.9009, -7.9009, -7.9009, -7.9009, -7.9009, -7.9009, -7.9009,
           -7.9009, -7.9009, -7.9009, -7.9009, -7.9009, -7.9009, -7.9009,
           -7.9009],
          [-1.9900, -1.9900, -1.9900, -1.9900, -1.9900, -1.9900, -1.9900,
           -1.9900, -1.9900, -1.9900, -1.9900, -1.9900, -1.9900, -1.9900,
           -1.9900],
          [-7.0309, -7.0309, -7.0309, -7.0309, -7.0309, -7.0309, -7.0309,
           -7.0309, -7.0309, -7.0309, -7.0309, -7.0309, -7.0309, -7.0309,
           -7.0309],
          [-6.8470, -6.8470, -6.8470, -6.8470, -6.8470, -6.8470, -6.8470,
           -6.8470, -6.8470, -6.8470, -6.8470, -6.8470, -6.8470, -6.8470,
           -6.8470],
          [-4.5702, -4.5702, -4.5702, -4.5702, -4.5702, -4.5702, -4.5702,
           -4.5702, -4.5702, -4.5702, -4.5702, -4.5702, -4.5702, -4.5702,
           -4.5702],
          [-0.5182, -0.5182, -0.5182, -0.5182, -0.5182, -0.5182, -0.5182,
           -0.5182, -0.5182, -0.5182, -0.5182, -0.5182, -0.5182, -0.5182,
           -0.5182],
          [-1.9900, -1.9900, -1.9900, -1.9900, -1.9900, -1.9900, -1.9900,
           -1.9900, -1.9900, -1.9900, -1.9900, -1.9900, -1.9900, -1.9900,
           -1.9900]]]], grad_fn=<SliceBackward0>)
train_step: Return scale: 1.1638448371004018
train_step: Scaled advantages shape: torch.Size([16, 15, 16, 15])
train_step: Scaled advantages sample: tensor([[[[-0.8752, -0.8752, -0.8752, -0.8752, -0.8752, -0.8752, -0.8752,
           -0.8752, -0.8752, -0.8752, -0.8752, -0.8752, -0.8752, -0.8752,
           -0.8752],
          [-6.0251, -6.0251, -6.0251, -6.0251, -6.0251, -6.0251, -6.0251,
           -6.0251, -6.0251, -6.0251, -6.0251, -6.0251, -6.0251, -6.0251,
           -6.0251],
          [-4.6171, -4.6171, -4.6171, -4.6171, -4.6171, -4.6171, -4.6171,
           -4.6171, -4.6171, -4.6171, -4.6171, -4.6171, -4.6171, -4.6171,
           -4.6171],
          [-4.0003, -4.0003, -4.0003, -4.0003, -4.0003, -4.0003, -4.0003,
           -4.0003, -4.0003, -4.0003, -4.0003, -4.0003, -4.0003, -4.0003,
           -4.0003],
          [-5.6339, -5.6339, -5.6339, -5.6339, -5.6339, -5.6339, -5.6339,
           -5.6339, -5.6339, -5.6339, -5.6339, -5.6339, -5.6339, -5.6339,
           -5.6339],
          [-6.0251, -6.0251, -6.0251, -6.0251, -6.0251, -6.0251, -6.0251,
           -6.0251, -6.0251, -6.0251, -6.0251, -6.0251, -6.0251, -6.0251,
           -6.0251],
          [-4.1073, -4.1073, -4.1073, -4.1073, -4.1073, -4.1073, -4.1073,
           -4.1073, -4.1073, -4.1073, -4.1073, -4.1073, -4.1073, -4.1073,
           -4.1073],
          [-0.7062, -0.7062, -0.7062, -0.7062, -0.7062, -0.7062, -0.7062,
           -0.7062, -0.7062, -0.7062, -0.7062, -0.7062, -0.7062, -0.7062,
           -0.7062],
          [-5.1364, -5.1364, -5.1364, -5.1364, -5.1364, -5.1364, -5.1364,
           -5.1364, -5.1364, -5.1364, -5.1364, -5.1364, -5.1364, -5.1364,
           -5.1364],
          [-6.0251, -6.0251, -6.0251, -6.0251, -6.0251, -6.0251, -6.0251,
           -6.0251, -6.0251, -6.0251, -6.0251, -6.0251, -6.0251, -6.0251,
           -6.0251],
          [-1.8008, -1.8008, -1.8008, -1.8008, -1.8008, -1.8008, -1.8008,
           -1.8008, -1.8008, -1.8008, -1.8008, -1.8008, -1.8008, -1.8008,
           -1.8008],
          [-5.4384, -5.4384, -5.4384, -5.4384, -5.4384, -5.4384, -5.4384,
           -5.4384, -5.4384, -5.4384, -5.4384, -5.4384, -5.4384, -5.4384,
           -5.4384],
          [-4.8417, -4.8417, -4.8417, -4.8417, -4.8417, -4.8417, -4.8417,
           -4.8417, -4.8417, -4.8417, -4.8417, -4.8417, -4.8417, -4.8417,
           -4.8417],
          [-3.3181, -3.3181, -3.3181, -3.3181, -3.3181, -3.3181, -3.3181,
           -3.3181, -3.3181, -3.3181, -3.3181, -3.3181, -3.3181, -3.3181,
           -3.3181],
          [-0.8752, -0.8752, -0.8752, -0.8752, -0.8752, -0.8752, -0.8752,
           -0.8752, -0.8752, -0.8752, -0.8752, -0.8752, -0.8752, -0.8752,
           -0.8752],
          [-0.7062, -0.7062, -0.7062, -0.7062, -0.7062, -0.7062, -0.7062,
           -0.7062, -0.7062, -0.7062, -0.7062, -0.7062, -0.7062, -0.7062,
           -0.7062]],

         [[-0.1784, -0.1784, -0.1784, -0.1784, -0.1784, -0.1784, -0.1784,
           -0.1784, -0.1784, -0.1784, -0.1784, -0.1784, -0.1784, -0.1784,
           -0.1784],
          [-5.7206, -5.7206, -5.7206, -5.7206, -5.7206, -5.7206, -5.7206,
           -5.7206, -5.7206, -5.7206, -5.7206, -5.7206, -5.7206, -5.7206,
           -5.7206],
          [-4.2340, -4.2340, -4.2340, -4.2340, -4.2340, -4.2340, -4.2340,
           -4.2340, -4.2340, -4.2340, -4.2340, -4.2340, -4.2340, -4.2340,
           -4.2340],
          [-3.5828, -3.5828, -3.5828, -3.5828, -3.5828, -3.5828, -3.5828,
           -3.5828, -3.5828, -3.5828, -3.5828, -3.5828, -3.5828, -3.5828,
           -3.5828],
          [-5.3076, -5.3076, -5.3076, -5.3076, -5.3076, -5.3076, -5.3076,
           -5.3076, -5.3076, -5.3076, -5.3076, -5.3076, -5.3076, -5.3076,
           -5.3076],
          [-5.7206, -5.7206, -5.7206, -5.7206, -5.7206, -5.7206, -5.7206,
           -5.7206, -5.7206, -5.7206, -5.7206, -5.7206, -5.7206, -5.7206,
           -5.7206],
          [-3.6958, -3.6958, -3.6958, -3.6958, -3.6958, -3.6958, -3.6958,
           -3.6958, -3.6958, -3.6958, -3.6958, -3.6958, -3.6958, -3.6958,
           -3.6958],
          [-4.4712, -4.4712, -4.4712, -4.4712, -4.4712, -4.4712, -4.4712,
           -4.4712, -4.4712, -4.4712, -4.4712, -4.4712, -4.4712, -4.4712,
           -4.4712],
          [-4.7824, -4.7824, -4.7824, -4.7824, -4.7824, -4.7824, -4.7824,
           -4.7824, -4.7824, -4.7824, -4.7824, -4.7824, -4.7824, -4.7824,
           -4.7824],
          [-5.7206, -5.7206, -5.7206, -5.7206, -5.7206, -5.7206, -5.7206,
           -5.7206, -5.7206, -5.7206, -5.7206, -5.7206, -5.7206, -5.7206,
           -5.7206],
          [-1.2606, -1.2606, -1.2606, -1.2606, -1.2606, -1.2606, -1.2606,
           -1.2606, -1.2606, -1.2606, -1.2606, -1.2606, -1.2606, -1.2606,
           -1.2606],
          [-5.1011, -5.1011, -5.1011, -5.1011, -5.1011, -5.1011, -5.1011,
           -5.1011, -5.1011, -5.1011, -5.1011, -5.1011, -5.1011, -5.1011,
           -5.1011],
          [-4.4712, -4.4712, -4.4712, -4.4712, -4.4712, -4.4712, -4.4712,
           -4.4712, -4.4712, -4.4712, -4.4712, -4.4712, -4.4712, -4.4712,
           -4.4712],
          [-2.8626, -2.8626, -2.8626, -2.8626, -2.8626, -2.8626, -2.8626,
           -2.8626, -2.8626, -2.8626, -2.8626, -2.8626, -2.8626, -2.8626,
           -2.8626],
          [-0.1784, -0.1784, -0.1784, -0.1784, -0.1784, -0.1784, -0.1784,
           -0.1784, -0.1784, -0.1784, -0.1784, -0.1784, -0.1784, -0.1784,
           -0.1784],
          [-1.2606, -1.2606, -1.2606, -1.2606, -1.2606, -1.2606, -1.2606,
           -1.2606, -1.2606, -1.2606, -1.2606, -1.2606, -1.2606, -1.2606,
           -1.2606]]],


        [[[-0.9430, -0.9430, -0.9430, -0.9430, -0.9430, -0.9430, -0.9430,
           -0.9430, -0.9430, -0.9430, -0.9430, -0.9430, -0.9430, -0.9430,
           -0.9430],
          [-6.9512, -6.9512, -6.9512, -6.9512, -6.9512, -6.9512, -6.9512,
           -6.9512, -6.9512, -6.9512, -6.9512, -6.9512, -6.9512, -6.9512,
           -6.9512],
          [-5.6714, -5.6714, -5.6714, -5.6714, -5.6714, -5.6714, -5.6714,
           -5.6714, -5.6714, -5.6714, -5.6714, -5.6714, -5.6714, -5.6714,
           -5.6714],
          [-4.7393, -4.7393, -4.7393, -4.7393, -4.7393, -4.7393, -4.7393,
           -4.7393, -4.7393, -4.7393, -4.7393, -4.7393, -4.7393, -4.7393,
           -4.7393],
          [-6.5620, -6.5620, -6.5620, -6.5620, -6.5620, -6.5620, -6.5620,
           -6.5620, -6.5620, -6.5620, -6.5620, -6.5620, -6.5620, -6.5620,
           -6.5620],
          [-6.9512, -6.9512, -6.9512, -6.9512, -6.9512, -6.9512, -6.9512,
           -6.9512, -6.9512, -6.9512, -6.9512, -6.9512, -6.9512, -6.9512,
           -6.9512],
          [-5.3174, -5.3174, -5.3174, -5.3174, -5.3174, -5.3174, -5.3174,
           -5.3174, -5.3174, -5.3174, -5.3174, -5.3174, -5.3174, -5.3174,
           -5.3174],
          [-0.6067, -0.6067, -0.6067, -0.6067, -0.6067, -0.6067, -0.6067,
           -0.6067, -0.6067, -0.6067, -0.6067, -0.6067, -0.6067, -0.6067,
           -0.6067],
          [-6.2480, -6.2480, -6.2480, -6.2480, -6.2480, -6.2480, -6.2480,
           -6.2480, -6.2480, -6.2480, -6.2480, -6.2480, -6.2480, -6.2480,
           -6.2480],
          [-6.9512, -6.9512, -6.9512, -6.9512, -6.9512, -6.9512, -6.9512,
           -6.9512, -6.9512, -6.9512, -6.9512, -6.9512, -6.9512, -6.9512,
           -6.9512],
          [-2.1408, -2.1408, -2.1408, -2.1408, -2.1408, -2.1408, -2.1408,
           -2.1408, -2.1408, -2.1408, -2.1408, -2.1408, -2.1408, -2.1408,
           -2.1408],
          [-6.2432, -6.2432, -6.2432, -6.2432, -6.2432, -6.2432, -6.2432,
           -6.2432, -6.2432, -6.2432, -6.2432, -6.2432, -6.2432, -6.2432,
           -6.2432],
          [-6.0935, -6.0935, -6.0935, -6.0935, -6.0935, -6.0935, -6.0935,
           -6.0935, -6.0935, -6.0935, -6.0935, -6.0935, -6.0935, -6.0935,
           -6.0935],
          [-4.2406, -4.2406, -4.2406, -4.2406, -4.2406, -4.2406, -4.2406,
           -4.2406, -4.2406, -4.2406, -4.2406, -4.2406, -4.2406, -4.2406,
           -4.2406],
          [-0.9430, -0.9430, -0.9430, -0.9430, -0.9430, -0.9430, -0.9430,
           -0.9430, -0.9430, -0.9430, -0.9430, -0.9430, -0.9430, -0.9430,
           -0.9430],
          [-0.6067, -0.6067, -0.6067, -0.6067, -0.6067, -0.6067, -0.6067,
           -0.6067, -0.6067, -0.6067, -0.6067, -0.6067, -0.6067, -0.6067,
           -0.6067]],

         [[-0.5182, -0.5182, -0.5182, -0.5182, -0.5182, -0.5182, -0.5182,
           -0.5182, -0.5182, -0.5182, -0.5182, -0.5182, -0.5182, -0.5182,
           -0.5182],
          [-6.7886, -6.7886, -6.7886, -6.7886, -6.7886, -6.7886, -6.7886,
           -6.7886, -6.7886, -6.7886, -6.7886, -6.7886, -6.7886, -6.7886,
           -6.7886],
          [-5.4374, -5.4374, -5.4374, -5.4374, -5.4374, -5.4374, -5.4374,
           -5.4374, -5.4374, -5.4374, -5.4374, -5.4374, -5.4374, -5.4374,
           -5.4374],
          [-4.4533, -4.4533, -4.4533, -4.4533, -4.4533, -4.4533, -4.4533,
           -4.4533, -4.4533, -4.4533, -4.4533, -4.4533, -4.4533, -4.4533,
           -4.4533],
          [-6.3777, -6.3777, -6.3777, -6.3777, -6.3777, -6.3777, -6.3777,
           -6.3777, -6.3777, -6.3777, -6.3777, -6.3777, -6.3777, -6.3777,
           -6.3777],
          [-6.7886, -6.7886, -6.7886, -6.7886, -6.7886, -6.7886, -6.7886,
           -6.7886, -6.7886, -6.7886, -6.7886, -6.7886, -6.7886, -6.7886,
           -6.7886],
          [-5.0637, -5.0637, -5.0637, -5.0637, -5.0637, -5.0637, -5.0637,
           -5.0637, -5.0637, -5.0637, -5.0637, -5.0637, -5.0637, -5.0637,
           -5.0637],
          [-5.8831, -5.8831, -5.8831, -5.8831, -5.8831, -5.8831, -5.8831,
           -5.8831, -5.8831, -5.8831, -5.8831, -5.8831, -5.8831, -5.8831,
           -5.8831],
          [-6.0462, -6.0462, -6.0462, -6.0462, -6.0462, -6.0462, -6.0462,
           -6.0462, -6.0462, -6.0462, -6.0462, -6.0462, -6.0462, -6.0462,
           -6.0462],
          [-6.7886, -6.7886, -6.7886, -6.7886, -6.7886, -6.7886, -6.7886,
           -6.7886, -6.7886, -6.7886, -6.7886, -6.7886, -6.7886, -6.7886,
           -6.7886],
          [-1.7098, -1.7098, -1.7098, -1.7098, -1.7098, -1.7098, -1.7098,
           -1.7098, -1.7098, -1.7098, -1.7098, -1.7098, -1.7098, -1.7098,
           -1.7098],
          [-6.0411, -6.0411, -6.0411, -6.0411, -6.0411, -6.0411, -6.0411,
           -6.0411, -6.0411, -6.0411, -6.0411, -6.0411, -6.0411, -6.0411,
           -6.0411],
          [-5.8831, -5.8831, -5.8831, -5.8831, -5.8831, -5.8831, -5.8831,
           -5.8831, -5.8831, -5.8831, -5.8831, -5.8831, -5.8831, -5.8831,
           -5.8831],
          [-3.9268, -3.9268, -3.9268, -3.9268, -3.9268, -3.9268, -3.9268,
           -3.9268, -3.9268, -3.9268, -3.9268, -3.9268, -3.9268, -3.9268,
           -3.9268],
          [-0.5182, -0.5182, -0.5182, -0.5182, -0.5182, -0.5182, -0.5182,
           -0.5182, -0.5182, -0.5182, -0.5182, -0.5182, -0.5182, -0.5182,
           -0.5182],
          [-1.7098, -1.7098, -1.7098, -1.7098, -1.7098, -1.7098, -1.7098,
           -1.7098, -1.7098, -1.7098, -1.7098, -1.7098, -1.7098, -1.7098,
           -1.7098]]]], grad_fn=<SliceBackward0>)
train_step: Entropy shape: torch.Size([16, 15])
train_step: Entropy sample: tensor([[0.6048, 0.6824],
        [0.6929, 0.5871]], grad_fn=<SliceBackward0>)
train_step: Entropy coefficient: 0.01
train_step: Actor loss: -1.5915192365646362
train_step: returns shape after mean: torch.Size([16, 15])
train_step: target_indices shape: torch.Size([16, 15])
train_step: value_logits shape: torch.Size([16, 15, 255])
train_step: target_twohot shape: torch.Size([16, 15, 255])
--- Starting train_step at 2025-04-01 01:57:03 ---
Full starting_state: {'deter': tensor([[[-1.9430e-01,  1.2784e-02,  4.9213e-02,  ..., -2.6033e-01,
          -8.6620e-04,  1.3641e-02],
         [-5.9548e-02,  1.7962e-01, -9.6700e-02,  ...,  3.3203e-02,
           1.2352e-03, -1.8958e-01],
         [ 1.2626e-01,  7.1493e-02, -1.9601e-01,  ..., -8.9210e-03,
           5.2888e-02, -3.7028e-02],
         ...,
         [ 4.0414e-02,  1.4702e-01,  1.4031e-01,  ..., -2.4655e-02,
           8.3074e-02,  3.5532e-02],
         [-8.4260e-02,  3.2356e-02,  4.6352e-02,  ..., -4.0868e-02,
          -6.0803e-02,  6.9715e-02],
         [ 5.4995e-03,  5.5179e-03, -1.1775e-01,  ..., -7.0008e-03,
          -9.4119e-02, -1.3511e-01]],

        [[ 7.9106e-02, -1.5230e-01, -5.8302e-03,  ..., -9.6042e-02,
           2.4404e-02, -1.0574e-01],
         [-1.4359e-01,  1.5723e-01,  8.1088e-03,  ..., -1.5076e-01,
          -1.1510e-02,  7.1351e-02],
         [-9.8167e-02,  5.3494e-02, -7.7597e-02,  ..., -3.1716e-02,
           6.6933e-03,  3.5435e-02],
         ...,
         [-6.1944e-02, -1.1778e-01,  1.1236e-01,  ..., -2.9888e-02,
          -3.2255e-02, -1.3991e-01],
         [ 2.9825e-02, -6.7707e-02,  1.1211e-01,  ..., -3.6610e-02,
          -9.5019e-02,  8.8986e-02],
         [-1.4389e-01, -5.4214e-02, -6.9896e-02,  ...,  1.7420e-01,
          -3.0449e-02,  8.3501e-02]],

        [[ 1.4554e-02, -4.9307e-02, -7.1979e-02,  ...,  3.5737e-02,
          -1.8022e-02, -9.5269e-02],
         [-2.0588e-01,  1.6301e-02,  1.1436e-01,  ..., -7.3025e-02,
           9.6318e-02, -1.2189e-01],
         [-1.7873e-02, -7.2435e-02, -2.4695e-01,  ..., -9.2241e-03,
           1.7173e-02, -8.1552e-02],
         ...,
         [-3.5603e-02, -6.1901e-03, -2.6555e-02,  ..., -8.4496e-02,
           2.7859e-02,  1.6347e-01],
         [ 1.7837e-02,  2.4094e-02,  1.2219e-01,  ...,  1.3842e-02,
           1.4737e-01,  8.8993e-02],
         [-9.1375e-03,  3.0882e-03, -9.3483e-02,  ...,  1.2104e-01,
           5.2932e-02, -3.7818e-02]],

        ...,

        [[ 1.2066e-01,  5.0053e-02, -5.2348e-02,  ..., -8.9141e-02,
          -4.6710e-02,  1.6354e-01],
         [-1.1872e-01, -4.3517e-02, -6.5859e-02,  ..., -1.9379e-02,
           1.1550e-01,  6.0222e-02],
         [ 8.2519e-03,  8.5140e-02, -4.5242e-02,  ...,  5.2674e-02,
          -1.4790e-02,  3.2233e-02],
         ...,
         [-2.1102e-02,  5.4475e-02, -2.2661e-01,  ..., -1.6586e-01,
          -8.0008e-03,  2.7554e-02],
         [ 6.7107e-02,  3.3704e-02,  1.2352e-02,  ...,  6.5225e-02,
           7.3213e-02, -1.2633e-01],
         [ 5.1103e-02, -3.6340e-02, -1.1645e-02,  ..., -7.2274e-02,
           4.2514e-02,  2.9461e-03]],

        [[-1.1449e-01, -6.0837e-02, -1.2584e-01,  ..., -2.8799e-02,
           1.0391e-01, -1.6462e-01],
         [-2.8616e-03,  3.7162e-02, -3.3191e-02,  ..., -5.5675e-02,
           4.8843e-02,  3.0928e-02],
         [-1.2944e-01, -6.8116e-02,  5.4720e-02,  ..., -1.3574e-02,
          -2.6165e-02,  1.3340e-01],
         ...,
         [-1.3182e-01,  1.1250e-02, -5.4956e-02,  ..., -1.2997e-01,
          -1.2169e-02, -1.2688e-01],
         [-8.2818e-02, -2.5249e-02,  1.1024e-02,  ...,  3.0752e-02,
          -1.2878e-04,  1.0787e-02],
         [-1.0977e-01,  5.3796e-02, -3.1280e-02,  ...,  5.1841e-02,
          -8.9409e-03,  3.1585e-02]],

        [[-9.7635e-02, -2.9915e-02,  5.0495e-02,  ..., -6.2936e-02,
           9.2599e-02,  1.3429e-01],
         [ 9.7249e-02, -1.5897e-02,  1.0695e-02,  ...,  3.6928e-02,
           2.2490e-01,  1.1493e-03],
         [-9.8817e-02,  3.4978e-02, -1.8742e-03,  ..., -6.8301e-02,
          -2.6203e-02, -1.7983e-01],
         ...,
         [-1.7446e-01,  8.5989e-02,  9.9798e-02,  ..., -1.2597e-03,
          -2.6003e-02,  6.5877e-02],
         [ 1.8169e-02, -7.4638e-02, -1.3917e-02,  ...,  9.1432e-02,
          -9.4654e-03, -2.7116e-02],
         [-4.4243e-02, -2.4471e-01, -4.9051e-02,  ..., -2.4346e-02,
          -4.9701e-02, -2.2671e-02]]], grad_fn=<StackBackward0>), 'stoch': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [1., 0., 0.,  ..., 0., 0., 0.],
         [1., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 1.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 1., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 1., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]])}
train_step: Starting state deter shape: torch.Size([16, 50, 128])
train_step: Starting state stoch shape: torch.Size([16, 50, 1024])
After ensuring logits/stoch: {'deter': tensor([[[-1.9430e-01,  1.2784e-02,  4.9213e-02,  ..., -2.6033e-01,
          -8.6620e-04,  1.3641e-02],
         [-5.9548e-02,  1.7962e-01, -9.6700e-02,  ...,  3.3203e-02,
           1.2352e-03, -1.8958e-01],
         [ 1.2626e-01,  7.1493e-02, -1.9601e-01,  ..., -8.9210e-03,
           5.2888e-02, -3.7028e-02],
         ...,
         [ 4.0414e-02,  1.4702e-01,  1.4031e-01,  ..., -2.4655e-02,
           8.3074e-02,  3.5532e-02],
         [-8.4260e-02,  3.2356e-02,  4.6352e-02,  ..., -4.0868e-02,
          -6.0803e-02,  6.9715e-02],
         [ 5.4995e-03,  5.5179e-03, -1.1775e-01,  ..., -7.0008e-03,
          -9.4119e-02, -1.3511e-01]],

        [[ 7.9106e-02, -1.5230e-01, -5.8302e-03,  ..., -9.6042e-02,
           2.4404e-02, -1.0574e-01],
         [-1.4359e-01,  1.5723e-01,  8.1088e-03,  ..., -1.5076e-01,
          -1.1510e-02,  7.1351e-02],
         [-9.8167e-02,  5.3494e-02, -7.7597e-02,  ..., -3.1716e-02,
           6.6933e-03,  3.5435e-02],
         ...,
         [-6.1944e-02, -1.1778e-01,  1.1236e-01,  ..., -2.9888e-02,
          -3.2255e-02, -1.3991e-01],
         [ 2.9825e-02, -6.7707e-02,  1.1211e-01,  ..., -3.6610e-02,
          -9.5019e-02,  8.8986e-02],
         [-1.4389e-01, -5.4214e-02, -6.9896e-02,  ...,  1.7420e-01,
          -3.0449e-02,  8.3501e-02]],

        [[ 1.4554e-02, -4.9307e-02, -7.1979e-02,  ...,  3.5737e-02,
          -1.8022e-02, -9.5269e-02],
         [-2.0588e-01,  1.6301e-02,  1.1436e-01,  ..., -7.3025e-02,
           9.6318e-02, -1.2189e-01],
         [-1.7873e-02, -7.2435e-02, -2.4695e-01,  ..., -9.2241e-03,
           1.7173e-02, -8.1552e-02],
         ...,
         [-3.5603e-02, -6.1901e-03, -2.6555e-02,  ..., -8.4496e-02,
           2.7859e-02,  1.6347e-01],
         [ 1.7837e-02,  2.4094e-02,  1.2219e-01,  ...,  1.3842e-02,
           1.4737e-01,  8.8993e-02],
         [-9.1375e-03,  3.0882e-03, -9.3483e-02,  ...,  1.2104e-01,
           5.2932e-02, -3.7818e-02]],

        ...,

        [[ 1.2066e-01,  5.0053e-02, -5.2348e-02,  ..., -8.9141e-02,
          -4.6710e-02,  1.6354e-01],
         [-1.1872e-01, -4.3517e-02, -6.5859e-02,  ..., -1.9379e-02,
           1.1550e-01,  6.0222e-02],
         [ 8.2519e-03,  8.5140e-02, -4.5242e-02,  ...,  5.2674e-02,
          -1.4790e-02,  3.2233e-02],
         ...,
         [-2.1102e-02,  5.4475e-02, -2.2661e-01,  ..., -1.6586e-01,
          -8.0008e-03,  2.7554e-02],
         [ 6.7107e-02,  3.3704e-02,  1.2352e-02,  ...,  6.5225e-02,
           7.3213e-02, -1.2633e-01],
         [ 5.1103e-02, -3.6340e-02, -1.1645e-02,  ..., -7.2274e-02,
           4.2514e-02,  2.9461e-03]],

        [[-1.1449e-01, -6.0837e-02, -1.2584e-01,  ..., -2.8799e-02,
           1.0391e-01, -1.6462e-01],
         [-2.8616e-03,  3.7162e-02, -3.3191e-02,  ..., -5.5675e-02,
           4.8843e-02,  3.0928e-02],
         [-1.2944e-01, -6.8116e-02,  5.4720e-02,  ..., -1.3574e-02,
          -2.6165e-02,  1.3340e-01],
         ...,
         [-1.3182e-01,  1.1250e-02, -5.4956e-02,  ..., -1.2997e-01,
          -1.2169e-02, -1.2688e-01],
         [-8.2818e-02, -2.5249e-02,  1.1024e-02,  ...,  3.0752e-02,
          -1.2878e-04,  1.0787e-02],
         [-1.0977e-01,  5.3796e-02, -3.1280e-02,  ...,  5.1841e-02,
          -8.9409e-03,  3.1585e-02]],

        [[-9.7635e-02, -2.9915e-02,  5.0495e-02,  ..., -6.2936e-02,
           9.2599e-02,  1.3429e-01],
         [ 9.7249e-02, -1.5897e-02,  1.0695e-02,  ...,  3.6928e-02,
           2.2490e-01,  1.1493e-03],
         [-9.8817e-02,  3.4978e-02, -1.8742e-03,  ..., -6.8301e-02,
          -2.6203e-02, -1.7983e-01],
         ...,
         [-1.7446e-01,  8.5989e-02,  9.9798e-02,  ..., -1.2597e-03,
          -2.6003e-02,  6.5877e-02],
         [ 1.8169e-02, -7.4638e-02, -1.3917e-02,  ...,  9.1432e-02,
          -9.4654e-03, -2.7116e-02],
         [-4.4243e-02, -2.4471e-01, -4.9051e-02,  ..., -2.4346e-02,
          -4.9701e-02, -2.2671e-02]]], grad_fn=<StackBackward0>), 'stoch': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [1., 0., 0.,  ..., 0., 0., 0.],
         [1., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 1.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 1., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 1., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]]), 'logits': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]])}
train_step: Normalized hidden_state shape: torch.Size([1, 16, 128])
train_step: Normalized stoch shape: torch.Size([16, 1024])
train_step: Normalized deter shape: torch.Size([16, 128])
train_step: Post-imagine_trajectory: Imagined features shape: torch.Size([16, 15, 1152])
train_step: Post-imagine_trajectory: Imagined actions shape: torch.Size([16, 15, 2])
train_step: Post-imagine_trajectory: Imagined action indices shape: torch.Size([16, 15])
train_step: Post-imagine_trajectory: Imagined state deter shape: torch.Size([16, 15, 128])
train_step: Post-imagine_trajectory: Imagined state stoch shape: torch.Size([16, 15, 1024])
Reward shape: torch.Size([16, 15, 1]), Value shape: torch.Size([16, 15, 1]), Slow Value shape: torch.Size([16, 15, 1]), Discount shape: torch.Size([16, 15, 1, 1])
Return targets length: 15, First target shape: torch.Size([16, 16, 1])
train_step: Actor distribution shape: torch.Size([16, 15, 2])
train_step: Action log probabilities shape: torch.Size([16, 15])
train_step: Action log probabilities sample: tensor([[-0.2525, -0.2029],
        [-0.7546, -0.1680]], grad_fn=<SliceBackward0>)
train_step: Advantages shape: torch.Size([16, 15, 16, 15])
train_step: Advantages sample: tensor([[[[-5.4274, -5.4274, -5.4274, -5.4274, -5.4274, -5.4274, -5.4274,
           -5.4274, -5.4274, -5.4274, -5.4274, -5.4274, -5.4274, -5.4274,
           -5.4274],
          [-1.2308, -1.2308, -1.2308, -1.2308, -1.2308, -1.2308, -1.2308,
           -1.2308, -1.2308, -1.2308, -1.2308, -1.2308, -1.2308, -1.2308,
           -1.2308],
          [-4.5005, -4.5005, -4.5005, -4.5005, -4.5005, -4.5005, -4.5005,
           -4.5005, -4.5005, -4.5005, -4.5005, -4.5005, -4.5005, -4.5005,
           -4.5005],
          [-1.2308, -1.2308, -1.2308, -1.2308, -1.2308, -1.2308, -1.2308,
           -1.2308, -1.2308, -1.2308, -1.2308, -1.2308, -1.2308, -1.2308,
           -1.2308],
          [-0.8296, -0.8296, -0.8296, -0.8296, -0.8296, -0.8296, -0.8296,
           -0.8296, -0.8296, -0.8296, -0.8296, -0.8296, -0.8296, -0.8296,
           -0.8296],
          [-3.0430, -3.0430, -3.0430, -3.0430, -3.0430, -3.0430, -3.0430,
           -3.0430, -3.0430, -3.0430, -3.0430, -3.0430, -3.0430, -3.0430,
           -3.0430],
          [-5.5431, -5.5431, -5.5431, -5.5431, -5.5431, -5.5431, -5.5431,
           -5.5431, -5.5431, -5.5431, -5.5431, -5.5431, -5.5431, -5.5431,
           -5.5431],
          [-0.8296, -0.8296, -0.8296, -0.8296, -0.8296, -0.8296, -0.8296,
           -0.8296, -0.8296, -0.8296, -0.8296, -0.8296, -0.8296, -0.8296,
           -0.8296],
          [-6.0767, -6.0767, -6.0767, -6.0767, -6.0767, -6.0767, -6.0767,
           -6.0767, -6.0767, -6.0767, -6.0767, -6.0767, -6.0767, -6.0767,
           -6.0767],
          [-1.8370, -1.8370, -1.8370, -1.8370, -1.8370, -1.8370, -1.8370,
           -1.8370, -1.8370, -1.8370, -1.8370, -1.8370, -1.8370, -1.8370,
           -1.8370],
          [-6.0767, -6.0767, -6.0767, -6.0767, -6.0767, -6.0767, -6.0767,
           -6.0767, -6.0767, -6.0767, -6.0767, -6.0767, -6.0767, -6.0767,
           -6.0767],
          [-6.0767, -6.0767, -6.0767, -6.0767, -6.0767, -6.0767, -6.0767,
           -6.0767, -6.0767, -6.0767, -6.0767, -6.0767, -6.0767, -6.0767,
           -6.0767],
          [-0.8296, -0.8296, -0.8296, -0.8296, -0.8296, -0.8296, -0.8296,
           -0.8296, -0.8296, -0.8296, -0.8296, -0.8296, -0.8296, -0.8296,
           -0.8296],
          [-4.5005, -4.5005, -4.5005, -4.5005, -4.5005, -4.5005, -4.5005,
           -4.5005, -4.5005, -4.5005, -4.5005, -4.5005, -4.5005, -4.5005,
           -4.5005],
          [-6.0767, -6.0767, -6.0767, -6.0767, -6.0767, -6.0767, -6.0767,
           -6.0767, -6.0767, -6.0767, -6.0767, -6.0767, -6.0767, -6.0767,
           -6.0767],
          [-6.0767, -6.0767, -6.0767, -6.0767, -6.0767, -6.0767, -6.0767,
           -6.0767, -6.0767, -6.0767, -6.0767, -6.0767, -6.0767, -6.0767,
           -6.0767]],

         [[-5.2876, -5.2876, -5.2876, -5.2876, -5.2876, -5.2876, -5.2876,
           -5.2876, -5.2876, -5.2876, -5.2876, -5.2876, -5.2876, -5.2876,
           -5.2876],
          [-0.8569, -0.8569, -0.8569, -0.8569, -0.8569, -0.8569, -0.8569,
           -0.8569, -0.8569, -0.8569, -0.8569, -0.8569, -0.8569, -0.8569,
           -0.8569],
          [-4.3090, -4.3090, -4.3090, -4.3090, -4.3090, -4.3090, -4.3090,
           -4.3090, -4.3090, -4.3090, -4.3090, -4.3090, -4.3090, -4.3090,
           -4.3090],
          [-0.8569, -0.8569, -0.8569, -0.8569, -0.8569, -0.8569, -0.8569,
           -0.8569, -0.8569, -0.8569, -0.8569, -0.8569, -0.8569, -0.8569,
           -0.8569],
          [-0.4332, -0.4332, -0.4332, -0.4332, -0.4332, -0.4332, -0.4332,
           -0.4332, -0.4332, -0.4332, -0.4332, -0.4332, -0.4332, -0.4332,
           -0.4332],
          [-2.7701, -2.7701, -2.7701, -2.7701, -2.7701, -2.7701, -2.7701,
           -2.7701, -2.7701, -2.7701, -2.7701, -2.7701, -2.7701, -2.7701,
           -2.7701],
          [-5.4098, -5.4098, -5.4098, -5.4098, -5.4098, -5.4098, -5.4098,
           -5.4098, -5.4098, -5.4098, -5.4098, -5.4098, -5.4098, -5.4098,
           -5.4098],
          [-0.4332, -0.4332, -0.4332, -0.4332, -0.4332, -0.4332, -0.4332,
           -0.4332, -0.4332, -0.4332, -0.4332, -0.4332, -0.4332, -0.4332,
           -0.4332],
          [-5.9732, -5.9732, -5.9732, -5.9732, -5.9732, -5.9732, -5.9732,
           -5.9732, -5.9732, -5.9732, -5.9732, -5.9732, -5.9732, -5.9732,
           -5.9732],
          [-1.4969, -1.4969, -1.4969, -1.4969, -1.4969, -1.4969, -1.4969,
           -1.4969, -1.4969, -1.4969, -1.4969, -1.4969, -1.4969, -1.4969,
           -1.4969],
          [-5.9732, -5.9732, -5.9732, -5.9732, -5.9732, -5.9732, -5.9732,
           -5.9732, -5.9732, -5.9732, -5.9732, -5.9732, -5.9732, -5.9732,
           -5.9732],
          [-5.9732, -5.9732, -5.9732, -5.9732, -5.9732, -5.9732, -5.9732,
           -5.9732, -5.9732, -5.9732, -5.9732, -5.9732, -5.9732, -5.9732,
           -5.9732],
          [-0.4332, -0.4332, -0.4332, -0.4332, -0.4332, -0.4332, -0.4332,
           -0.4332, -0.4332, -0.4332, -0.4332, -0.4332, -0.4332, -0.4332,
           -0.4332],
          [-4.3090, -4.3090, -4.3090, -4.3090, -4.3090, -4.3090, -4.3090,
           -4.3090, -4.3090, -4.3090, -4.3090, -4.3090, -4.3090, -4.3090,
           -4.3090],
          [-5.9732, -5.9732, -5.9732, -5.9732, -5.9732, -5.9732, -5.9732,
           -5.9732, -5.9732, -5.9732, -5.9732, -5.9732, -5.9732, -5.9732,
           -5.9732],
          [-5.9732, -5.9732, -5.9732, -5.9732, -5.9732, -5.9732, -5.9732,
           -5.9732, -5.9732, -5.9732, -5.9732, -5.9732, -5.9732, -5.9732,
           -5.9732]]],


        [[[-8.3866, -8.3866, -8.3866, -8.3866, -8.3866, -8.3866, -8.3866,
           -8.3866, -8.3866, -8.3866, -8.3866, -8.3866, -8.3866, -8.3866,
           -8.3866],
          [-2.2278, -2.2278, -2.2278, -2.2278, -2.2278, -2.2278, -2.2278,
           -2.2278, -2.2278, -2.2278, -2.2278, -2.2278, -2.2278, -2.2278,
           -2.2278],
          [-7.3921, -7.3921, -7.3921, -7.3921, -7.3921, -7.3921, -7.3921,
           -7.3921, -7.3921, -7.3921, -7.3921, -7.3921, -7.3921, -7.3921,
           -7.3921],
          [-2.2278, -2.2278, -2.2278, -2.2278, -2.2278, -2.2278, -2.2278,
           -2.2278, -2.2278, -2.2278, -2.2278, -2.2278, -2.2278, -2.2278,
           -2.2278],
          [-1.8204, -1.8204, -1.8204, -1.8204, -1.8204, -1.8204, -1.8204,
           -1.8204, -1.8204, -1.8204, -1.8204, -1.8204, -1.8204, -1.8204,
           -1.8204],
          [-7.0726, -7.0726, -7.0725, -7.0726, -7.0726, -7.0726, -7.0726,
           -7.0726, -7.0726, -7.0726, -7.0726, -7.0726, -7.0726, -7.0726,
           -7.0726],
          [-8.8194, -8.8194, -8.8194, -8.8194, -8.8194, -8.8194, -8.8194,
           -8.8194, -8.8194, -8.8194, -8.8194, -8.8194, -8.8194, -8.8194,
           -8.8194],
          [-1.8204, -1.8204, -1.8204, -1.8204, -1.8204, -1.8204, -1.8204,
           -1.8204, -1.8204, -1.8204, -1.8204, -1.8204, -1.8204, -1.8204,
           -1.8204],
          [-9.8007, -9.8007, -9.8007, -9.8007, -9.8007, -9.8007, -9.8007,
           -9.8007, -9.8007, -9.8007, -9.8007, -9.8007, -9.8007, -9.8007,
           -9.8007],
          [-3.1125, -3.1125, -3.1125, -3.1125, -3.1125, -3.1125, -3.1125,
           -3.1125, -3.1125, -3.1125, -3.1125, -3.1125, -3.1125, -3.1125,
           -3.1125],
          [-9.8007, -9.8007, -9.8007, -9.8007, -9.8007, -9.8007, -9.8007,
           -9.8007, -9.8007, -9.8007, -9.8007, -9.8007, -9.8007, -9.8007,
           -9.8007],
          [-9.8007, -9.8007, -9.8007, -9.8007, -9.8007, -9.8007, -9.8007,
           -9.8007, -9.8007, -9.8007, -9.8007, -9.8007, -9.8007, -9.8007,
           -9.8007],
          [-1.8204, -1.8204, -1.8204, -1.8204, -1.8204, -1.8204, -1.8204,
           -1.8204, -1.8204, -1.8204, -1.8204, -1.8204, -1.8204, -1.8204,
           -1.8204],
          [-7.3921, -7.3921, -7.3921, -7.3921, -7.3921, -7.3921, -7.3921,
           -7.3921, -7.3921, -7.3921, -7.3921, -7.3921, -7.3921, -7.3921,
           -7.3921],
          [-9.8007, -9.8007, -9.8007, -9.8007, -9.8007, -9.8007, -9.8007,
           -9.8007, -9.8007, -9.8007, -9.8007, -9.8007, -9.8007, -9.8007,
           -9.8007],
          [-9.8007, -9.8007, -9.8007, -9.8007, -9.8007, -9.8007, -9.8007,
           -9.8007, -9.8007, -9.8007, -9.8007, -9.8007, -9.8007, -9.8007,
           -9.8007]],

         [[-8.2555, -8.2555, -8.2555, -8.2555, -8.2555, -8.2555, -8.2555,
           -8.2555, -8.2555, -8.2555, -8.2555, -8.2555, -8.2555, -8.2555,
           -8.2555],
          [-1.7530, -1.7530, -1.7530, -1.7530, -1.7530, -1.7530, -1.7530,
           -1.7530, -1.7530, -1.7530, -1.7530, -1.7530, -1.7530, -1.7530,
           -1.7530],
          [-7.2055, -7.2055, -7.2055, -7.2055, -7.2055, -7.2055, -7.2055,
           -7.2055, -7.2055, -7.2055, -7.2055, -7.2055, -7.2055, -7.2055,
           -7.2055],
          [-1.7530, -1.7530, -1.7530, -1.7530, -1.7530, -1.7530, -1.7530,
           -1.7530, -1.7530, -1.7530, -1.7530, -1.7530, -1.7530, -1.7530,
           -1.7530],
          [-1.3229, -1.3229, -1.3229, -1.3229, -1.3229, -1.3229, -1.3229,
           -1.3229, -1.3229, -1.3229, -1.3229, -1.3229, -1.3229, -1.3229,
           -1.3229],
          [-6.8681, -6.8681, -6.8681, -6.8681, -6.8681, -6.8681, -6.8681,
           -6.8681, -6.8681, -6.8681, -6.8681, -6.8681, -6.8681, -6.8681,
           -6.8681],
          [-8.7124, -8.7124, -8.7124, -8.7124, -8.7124, -8.7124, -8.7124,
           -8.7124, -8.7124, -8.7124, -8.7124, -8.7124, -8.7124, -8.7124,
           -8.7124],
          [-1.3229, -1.3229, -1.3229, -1.3229, -1.3229, -1.3229, -1.3229,
           -1.3229, -1.3229, -1.3229, -1.3229, -1.3229, -1.3229, -1.3229,
           -1.3229],
          [-9.7485, -9.7485, -9.7485, -9.7485, -9.7485, -9.7485, -9.7485,
           -9.7485, -9.7485, -9.7485, -9.7485, -9.7485, -9.7485, -9.7485,
           -9.7485],
          [-2.6870, -2.6870, -2.6870, -2.6870, -2.6870, -2.6870, -2.6870,
           -2.6870, -2.6870, -2.6870, -2.6870, -2.6870, -2.6870, -2.6870,
           -2.6870],
          [-9.7485, -9.7485, -9.7485, -9.7485, -9.7485, -9.7485, -9.7485,
           -9.7485, -9.7485, -9.7485, -9.7485, -9.7485, -9.7485, -9.7485,
           -9.7485],
          [-9.7485, -9.7485, -9.7485, -9.7485, -9.7485, -9.7485, -9.7485,
           -9.7485, -9.7485, -9.7485, -9.7485, -9.7485, -9.7485, -9.7485,
           -9.7485],
          [-1.3229, -1.3229, -1.3229, -1.3229, -1.3229, -1.3229, -1.3229,
           -1.3229, -1.3229, -1.3229, -1.3229, -1.3229, -1.3229, -1.3229,
           -1.3229],
          [-7.2055, -7.2055, -7.2055, -7.2055, -7.2055, -7.2055, -7.2055,
           -7.2055, -7.2055, -7.2055, -7.2055, -7.2055, -7.2055, -7.2055,
           -7.2055],
          [-9.7485, -9.7485, -9.7485, -9.7485, -9.7485, -9.7485, -9.7485,
           -9.7485, -9.7485, -9.7485, -9.7485, -9.7485, -9.7485, -9.7485,
           -9.7485],
          [-9.7485, -9.7485, -9.7485, -9.7485, -9.7485, -9.7485, -9.7485,
           -9.7485, -9.7485, -9.7485, -9.7485, -9.7485, -9.7485, -9.7485,
           -9.7485]]]], grad_fn=<SliceBackward0>)
train_step: Return scale: 1.2249530983145878
train_step: Scaled advantages shape: torch.Size([16, 15, 16, 15])
train_step: Scaled advantages sample: tensor([[[[-4.4307, -4.4307, -4.4307, -4.4307, -4.4307, -4.4307, -4.4307,
           -4.4307, -4.4307, -4.4307, -4.4307, -4.4307, -4.4307, -4.4307,
           -4.4307],
          [-1.0048, -1.0048, -1.0048, -1.0048, -1.0048, -1.0048, -1.0048,
           -1.0048, -1.0048, -1.0048, -1.0048, -1.0048, -1.0048, -1.0048,
           -1.0048],
          [-3.6740, -3.6740, -3.6740, -3.6740, -3.6740, -3.6740, -3.6740,
           -3.6740, -3.6740, -3.6740, -3.6740, -3.6740, -3.6740, -3.6740,
           -3.6740],
          [-1.0048, -1.0048, -1.0048, -1.0048, -1.0048, -1.0048, -1.0048,
           -1.0048, -1.0048, -1.0048, -1.0048, -1.0048, -1.0048, -1.0048,
           -1.0048],
          [-0.8296, -0.8296, -0.8296, -0.8296, -0.8296, -0.8296, -0.8296,
           -0.8296, -0.8296, -0.8296, -0.8296, -0.8296, -0.8296, -0.8296,
           -0.8296],
          [-2.4842, -2.4842, -2.4842, -2.4842, -2.4842, -2.4842, -2.4842,
           -2.4842, -2.4842, -2.4842, -2.4842, -2.4842, -2.4842, -2.4842,
           -2.4842],
          [-4.5252, -4.5252, -4.5252, -4.5252, -4.5252, -4.5252, -4.5252,
           -4.5252, -4.5252, -4.5252, -4.5252, -4.5252, -4.5252, -4.5252,
           -4.5252],
          [-0.8296, -0.8296, -0.8296, -0.8296, -0.8296, -0.8296, -0.8296,
           -0.8296, -0.8296, -0.8296, -0.8296, -0.8296, -0.8296, -0.8296,
           -0.8296],
          [-4.9608, -4.9608, -4.9608, -4.9608, -4.9608, -4.9608, -4.9608,
           -4.9608, -4.9608, -4.9608, -4.9608, -4.9608, -4.9608, -4.9608,
           -4.9608],
          [-1.4997, -1.4997, -1.4997, -1.4997, -1.4997, -1.4997, -1.4997,
           -1.4997, -1.4997, -1.4997, -1.4997, -1.4997, -1.4997, -1.4997,
           -1.4997],
          [-4.9608, -4.9608, -4.9608, -4.9608, -4.9608, -4.9608, -4.9608,
           -4.9608, -4.9608, -4.9608, -4.9608, -4.9608, -4.9608, -4.9608,
           -4.9608],
          [-4.9608, -4.9608, -4.9608, -4.9608, -4.9608, -4.9608, -4.9608,
           -4.9608, -4.9608, -4.9608, -4.9608, -4.9608, -4.9608, -4.9608,
           -4.9608],
          [-0.8296, -0.8296, -0.8296, -0.8296, -0.8296, -0.8296, -0.8296,
           -0.8296, -0.8296, -0.8296, -0.8296, -0.8296, -0.8296, -0.8296,
           -0.8296],
          [-3.6740, -3.6740, -3.6740, -3.6740, -3.6740, -3.6740, -3.6740,
           -3.6740, -3.6740, -3.6740, -3.6740, -3.6740, -3.6740, -3.6740,
           -3.6740],
          [-4.9608, -4.9608, -4.9608, -4.9608, -4.9608, -4.9608, -4.9608,
           -4.9608, -4.9608, -4.9608, -4.9608, -4.9608, -4.9608, -4.9608,
           -4.9608],
          [-4.9608, -4.9608, -4.9608, -4.9608, -4.9608, -4.9608, -4.9608,
           -4.9608, -4.9608, -4.9608, -4.9608, -4.9608, -4.9608, -4.9608,
           -4.9608]],

         [[-4.3166, -4.3166, -4.3166, -4.3166, -4.3166, -4.3166, -4.3166,
           -4.3166, -4.3166, -4.3166, -4.3166, -4.3166, -4.3166, -4.3166,
           -4.3166],
          [-0.8569, -0.8569, -0.8569, -0.8569, -0.8569, -0.8569, -0.8569,
           -0.8569, -0.8569, -0.8569, -0.8569, -0.8569, -0.8569, -0.8569,
           -0.8569],
          [-3.5177, -3.5177, -3.5177, -3.5177, -3.5177, -3.5177, -3.5177,
           -3.5177, -3.5177, -3.5177, -3.5177, -3.5177, -3.5177, -3.5177,
           -3.5177],
          [-0.8569, -0.8569, -0.8569, -0.8569, -0.8569, -0.8569, -0.8569,
           -0.8569, -0.8569, -0.8569, -0.8569, -0.8569, -0.8569, -0.8569,
           -0.8569],
          [-0.4332, -0.4332, -0.4332, -0.4332, -0.4332, -0.4332, -0.4332,
           -0.4332, -0.4332, -0.4332, -0.4332, -0.4332, -0.4332, -0.4332,
           -0.4332],
          [-2.2614, -2.2614, -2.2614, -2.2614, -2.2614, -2.2614, -2.2614,
           -2.2614, -2.2614, -2.2614, -2.2614, -2.2614, -2.2614, -2.2614,
           -2.2614],
          [-4.4163, -4.4163, -4.4163, -4.4163, -4.4163, -4.4163, -4.4163,
           -4.4163, -4.4163, -4.4163, -4.4163, -4.4163, -4.4163, -4.4163,
           -4.4163],
          [-0.4332, -0.4332, -0.4332, -0.4332, -0.4332, -0.4332, -0.4332,
           -0.4332, -0.4332, -0.4332, -0.4332, -0.4332, -0.4332, -0.4332,
           -0.4332],
          [-4.8762, -4.8762, -4.8762, -4.8762, -4.8762, -4.8762, -4.8762,
           -4.8762, -4.8762, -4.8762, -4.8762, -4.8762, -4.8762, -4.8762,
           -4.8762],
          [-1.2220, -1.2220, -1.2220, -1.2220, -1.2220, -1.2220, -1.2220,
           -1.2220, -1.2220, -1.2220, -1.2220, -1.2220, -1.2220, -1.2220,
           -1.2220],
          [-4.8762, -4.8762, -4.8762, -4.8762, -4.8762, -4.8762, -4.8762,
           -4.8762, -4.8762, -4.8762, -4.8762, -4.8762, -4.8762, -4.8762,
           -4.8762],
          [-4.8762, -4.8762, -4.8762, -4.8762, -4.8762, -4.8762, -4.8762,
           -4.8762, -4.8762, -4.8762, -4.8762, -4.8762, -4.8762, -4.8762,
           -4.8762],
          [-0.4332, -0.4332, -0.4332, -0.4332, -0.4332, -0.4332, -0.4332,
           -0.4332, -0.4332, -0.4332, -0.4332, -0.4332, -0.4332, -0.4332,
           -0.4332],
          [-3.5177, -3.5177, -3.5177, -3.5177, -3.5177, -3.5177, -3.5177,
           -3.5177, -3.5177, -3.5177, -3.5177, -3.5177, -3.5177, -3.5177,
           -3.5177],
          [-4.8762, -4.8762, -4.8762, -4.8762, -4.8762, -4.8762, -4.8762,
           -4.8762, -4.8762, -4.8762, -4.8762, -4.8762, -4.8762, -4.8762,
           -4.8762],
          [-4.8762, -4.8762, -4.8762, -4.8762, -4.8762, -4.8762, -4.8762,
           -4.8762, -4.8762, -4.8762, -4.8762, -4.8762, -4.8762, -4.8762,
           -4.8762]]],


        [[[-6.8465, -6.8465, -6.8465, -6.8465, -6.8465, -6.8465, -6.8465,
           -6.8465, -6.8465, -6.8465, -6.8465, -6.8465, -6.8465, -6.8465,
           -6.8465],
          [-1.8187, -1.8187, -1.8187, -1.8187, -1.8187, -1.8187, -1.8187,
           -1.8187, -1.8187, -1.8187, -1.8187, -1.8187, -1.8187, -1.8187,
           -1.8187],
          [-6.0346, -6.0346, -6.0346, -6.0346, -6.0346, -6.0346, -6.0346,
           -6.0346, -6.0346, -6.0346, -6.0346, -6.0346, -6.0346, -6.0346,
           -6.0346],
          [-1.8187, -1.8187, -1.8187, -1.8187, -1.8187, -1.8187, -1.8187,
           -1.8187, -1.8187, -1.8187, -1.8187, -1.8187, -1.8187, -1.8187,
           -1.8187],
          [-1.4861, -1.4861, -1.4861, -1.4861, -1.4861, -1.4861, -1.4861,
           -1.4861, -1.4861, -1.4861, -1.4861, -1.4861, -1.4861, -1.4861,
           -1.4861],
          [-5.7737, -5.7737, -5.7737, -5.7737, -5.7737, -5.7737, -5.7737,
           -5.7737, -5.7737, -5.7737, -5.7737, -5.7737, -5.7737, -5.7737,
           -5.7737],
          [-7.1998, -7.1998, -7.1998, -7.1998, -7.1998, -7.1998, -7.1998,
           -7.1998, -7.1998, -7.1998, -7.1998, -7.1998, -7.1998, -7.1998,
           -7.1998],
          [-1.4861, -1.4861, -1.4861, -1.4861, -1.4861, -1.4861, -1.4861,
           -1.4861, -1.4861, -1.4861, -1.4861, -1.4861, -1.4861, -1.4861,
           -1.4861],
          [-8.0009, -8.0009, -8.0009, -8.0009, -8.0009, -8.0009, -8.0009,
           -8.0009, -8.0009, -8.0009, -8.0009, -8.0009, -8.0009, -8.0009,
           -8.0009],
          [-2.5409, -2.5409, -2.5409, -2.5409, -2.5409, -2.5409, -2.5409,
           -2.5409, -2.5409, -2.5409, -2.5409, -2.5409, -2.5409, -2.5409,
           -2.5409],
          [-8.0009, -8.0009, -8.0009, -8.0009, -8.0009, -8.0009, -8.0009,
           -8.0009, -8.0009, -8.0009, -8.0009, -8.0009, -8.0009, -8.0009,
           -8.0009],
          [-8.0009, -8.0009, -8.0009, -8.0009, -8.0009, -8.0009, -8.0009,
           -8.0009, -8.0009, -8.0009, -8.0009, -8.0009, -8.0009, -8.0009,
           -8.0009],
          [-1.4861, -1.4861, -1.4861, -1.4861, -1.4861, -1.4861, -1.4861,
           -1.4861, -1.4861, -1.4861, -1.4861, -1.4861, -1.4861, -1.4861,
           -1.4861],
          [-6.0346, -6.0346, -6.0346, -6.0346, -6.0346, -6.0346, -6.0346,
           -6.0346, -6.0346, -6.0346, -6.0346, -6.0346, -6.0346, -6.0346,
           -6.0346],
          [-8.0009, -8.0009, -8.0009, -8.0009, -8.0009, -8.0009, -8.0009,
           -8.0009, -8.0009, -8.0009, -8.0009, -8.0009, -8.0009, -8.0009,
           -8.0009],
          [-8.0009, -8.0009, -8.0009, -8.0009, -8.0009, -8.0009, -8.0009,
           -8.0009, -8.0009, -8.0009, -8.0009, -8.0009, -8.0009, -8.0009,
           -8.0009]],

         [[-6.7394, -6.7394, -6.7394, -6.7394, -6.7394, -6.7394, -6.7394,
           -6.7394, -6.7394, -6.7394, -6.7394, -6.7394, -6.7394, -6.7394,
           -6.7394],
          [-1.4311, -1.4311, -1.4311, -1.4311, -1.4311, -1.4311, -1.4311,
           -1.4311, -1.4311, -1.4311, -1.4311, -1.4311, -1.4311, -1.4311,
           -1.4311],
          [-5.8823, -5.8823, -5.8823, -5.8823, -5.8823, -5.8823, -5.8823,
           -5.8823, -5.8823, -5.8823, -5.8823, -5.8823, -5.8823, -5.8823,
           -5.8823],
          [-1.4311, -1.4311, -1.4311, -1.4311, -1.4311, -1.4311, -1.4311,
           -1.4311, -1.4311, -1.4311, -1.4311, -1.4311, -1.4311, -1.4311,
           -1.4311],
          [-1.0799, -1.0799, -1.0799, -1.0799, -1.0799, -1.0799, -1.0799,
           -1.0799, -1.0799, -1.0799, -1.0799, -1.0799, -1.0799, -1.0799,
           -1.0799],
          [-5.6068, -5.6068, -5.6068, -5.6068, -5.6068, -5.6068, -5.6068,
           -5.6068, -5.6068, -5.6068, -5.6068, -5.6068, -5.6068, -5.6068,
           -5.6068],
          [-7.1124, -7.1124, -7.1124, -7.1124, -7.1124, -7.1124, -7.1124,
           -7.1124, -7.1124, -7.1124, -7.1124, -7.1124, -7.1124, -7.1124,
           -7.1124],
          [-1.0799, -1.0799, -1.0799, -1.0799, -1.0799, -1.0799, -1.0799,
           -1.0799, -1.0799, -1.0799, -1.0799, -1.0799, -1.0799, -1.0799,
           -1.0799],
          [-7.9582, -7.9582, -7.9582, -7.9582, -7.9582, -7.9582, -7.9582,
           -7.9582, -7.9582, -7.9582, -7.9582, -7.9582, -7.9582, -7.9582,
           -7.9582],
          [-2.1936, -2.1936, -2.1936, -2.1936, -2.1936, -2.1936, -2.1936,
           -2.1936, -2.1936, -2.1936, -2.1936, -2.1936, -2.1936, -2.1936,
           -2.1936],
          [-7.9582, -7.9582, -7.9582, -7.9582, -7.9582, -7.9582, -7.9582,
           -7.9582, -7.9582, -7.9582, -7.9582, -7.9582, -7.9582, -7.9582,
           -7.9582],
          [-7.9582, -7.9582, -7.9582, -7.9582, -7.9582, -7.9582, -7.9582,
           -7.9582, -7.9582, -7.9582, -7.9582, -7.9582, -7.9582, -7.9582,
           -7.9582],
          [-1.0799, -1.0799, -1.0799, -1.0799, -1.0799, -1.0799, -1.0799,
           -1.0799, -1.0799, -1.0799, -1.0799, -1.0799, -1.0799, -1.0799,
           -1.0799],
          [-5.8823, -5.8823, -5.8823, -5.8823, -5.8823, -5.8823, -5.8823,
           -5.8823, -5.8823, -5.8823, -5.8823, -5.8823, -5.8823, -5.8823,
           -5.8823],
          [-7.9582, -7.9582, -7.9582, -7.9582, -7.9582, -7.9582, -7.9582,
           -7.9582, -7.9582, -7.9582, -7.9582, -7.9582, -7.9582, -7.9582,
           -7.9582],
          [-7.9582, -7.9582, -7.9582, -7.9582, -7.9582, -7.9582, -7.9582,
           -7.9582, -7.9582, -7.9582, -7.9582, -7.9582, -7.9582, -7.9582,
           -7.9582]]]], grad_fn=<SliceBackward0>)
train_step: Entropy shape: torch.Size([16, 15])
train_step: Entropy sample: tensor([[0.5309, 0.4769],
        [0.6914, 0.4306]], grad_fn=<SliceBackward0>)
train_step: Entropy coefficient: 0.01
train_step: Actor loss: -1.7928636074066162
train_step: returns shape after mean: torch.Size([16, 15])
train_step: target_indices shape: torch.Size([16, 15])
train_step: value_logits shape: torch.Size([16, 15, 255])
train_step: target_twohot shape: torch.Size([16, 15, 255])
--- Starting train_step at 2025-04-01 01:57:19 ---
Full starting_state: {'deter': tensor([[[-0.0405,  0.0123,  0.0312,  ...,  0.0649, -0.1653,  0.0268],
         [-0.0791, -0.0940, -0.2081,  ...,  0.0447,  0.0315,  0.0174],
         [-0.0104, -0.0057, -0.0159,  ..., -0.0038,  0.0122, -0.0723],
         ...,
         [-0.2116,  0.0753, -0.0966,  ...,  0.0432,  0.0099, -0.1083],
         [-0.0675,  0.0309, -0.0506,  ..., -0.1461, -0.0840, -0.0324],
         [-0.0615,  0.0284, -0.0222,  ...,  0.0364,  0.1996, -0.0081]],

        [[-0.0700, -0.0848, -0.1797,  ..., -0.0084, -0.0570,  0.0099],
         [-0.0029,  0.0695, -0.0926,  ...,  0.1413,  0.0985,  0.0969],
         [ 0.0054, -0.0610, -0.2277,  ...,  0.0657, -0.0079,  0.0608],
         ...,
         [-0.1616, -0.1232, -0.0083,  ..., -0.1541,  0.1798, -0.0145],
         [-0.1441, -0.0874, -0.1725,  ..., -0.0125, -0.0372, -0.0425],
         [ 0.1288, -0.0094,  0.0193,  ...,  0.1033,  0.1898,  0.0151]],

        [[ 0.0370,  0.1202, -0.1596,  ..., -0.1243, -0.0976,  0.1047],
         [-0.0075,  0.1026,  0.2122,  ..., -0.0436, -0.0305,  0.0624],
         [ 0.0094,  0.0058, -0.0332,  ...,  0.1103,  0.0260, -0.1251],
         ...,
         [-0.0346, -0.0273,  0.0756,  ..., -0.0228, -0.0538,  0.1117],
         [-0.0023,  0.0492, -0.0465,  ..., -0.0403,  0.0257,  0.0419],
         [-0.0754,  0.0645, -0.0744,  ...,  0.0741, -0.0591, -0.0133]],

        ...,

        [[-0.0906, -0.2409, -0.0028,  ...,  0.0665, -0.0233, -0.2019],
         [-0.0687, -0.0825,  0.0099,  ..., -0.0920,  0.0625, -0.0988],
         [-0.0734, -0.0643,  0.1147,  ...,  0.0518, -0.0102,  0.1371],
         ...,
         [-0.0192,  0.0020,  0.0285,  ..., -0.1722, -0.0396,  0.0082],
         [-0.1151,  0.0563, -0.0875,  ..., -0.1921, -0.0551,  0.0391],
         [-0.0601, -0.0520,  0.0294,  ..., -0.0619, -0.0321, -0.0107]],

        [[-0.0442,  0.1784,  0.0466,  ..., -0.0765, -0.1366, -0.0567],
         [-0.0196,  0.1522,  0.1790,  ..., -0.1095, -0.0109,  0.0572],
         [ 0.0386, -0.0430,  0.0978,  ...,  0.0938,  0.0549, -0.1519],
         ...,
         [-0.0396, -0.0616, -0.0234,  ..., -0.1171,  0.0760, -0.1129],
         [-0.1489, -0.0613, -0.0650,  ...,  0.0648,  0.0986, -0.0916],
         [ 0.0317, -0.0314, -0.0428,  ...,  0.0914, -0.0111, -0.0307]],

        [[-0.0568, -0.0348, -0.0781,  ...,  0.0472,  0.1273,  0.1764],
         [ 0.0248,  0.0005, -0.1940,  ..., -0.0020, -0.0450,  0.0442],
         [-0.1820, -0.1689,  0.1309,  ..., -0.0327,  0.0246, -0.0136],
         ...,
         [ 0.1464,  0.0012,  0.0645,  ...,  0.0609, -0.0539,  0.0546],
         [ 0.1865, -0.0226,  0.0511,  ...,  0.0105,  0.0317,  0.0384],
         [-0.0130,  0.1291, -0.0174,  ..., -0.0197,  0.0814, -0.0050]]],
       grad_fn=<StackBackward0>), 'stoch': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [1., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 1., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 1.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [1., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 1., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 1., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]])}
train_step: Starting state deter shape: torch.Size([16, 50, 128])
train_step: Starting state stoch shape: torch.Size([16, 50, 1024])
After ensuring logits/stoch: {'deter': tensor([[[-0.0405,  0.0123,  0.0312,  ...,  0.0649, -0.1653,  0.0268],
         [-0.0791, -0.0940, -0.2081,  ...,  0.0447,  0.0315,  0.0174],
         [-0.0104, -0.0057, -0.0159,  ..., -0.0038,  0.0122, -0.0723],
         ...,
         [-0.2116,  0.0753, -0.0966,  ...,  0.0432,  0.0099, -0.1083],
         [-0.0675,  0.0309, -0.0506,  ..., -0.1461, -0.0840, -0.0324],
         [-0.0615,  0.0284, -0.0222,  ...,  0.0364,  0.1996, -0.0081]],

        [[-0.0700, -0.0848, -0.1797,  ..., -0.0084, -0.0570,  0.0099],
         [-0.0029,  0.0695, -0.0926,  ...,  0.1413,  0.0985,  0.0969],
         [ 0.0054, -0.0610, -0.2277,  ...,  0.0657, -0.0079,  0.0608],
         ...,
         [-0.1616, -0.1232, -0.0083,  ..., -0.1541,  0.1798, -0.0145],
         [-0.1441, -0.0874, -0.1725,  ..., -0.0125, -0.0372, -0.0425],
         [ 0.1288, -0.0094,  0.0193,  ...,  0.1033,  0.1898,  0.0151]],

        [[ 0.0370,  0.1202, -0.1596,  ..., -0.1243, -0.0976,  0.1047],
         [-0.0075,  0.1026,  0.2122,  ..., -0.0436, -0.0305,  0.0624],
         [ 0.0094,  0.0058, -0.0332,  ...,  0.1103,  0.0260, -0.1251],
         ...,
         [-0.0346, -0.0273,  0.0756,  ..., -0.0228, -0.0538,  0.1117],
         [-0.0023,  0.0492, -0.0465,  ..., -0.0403,  0.0257,  0.0419],
         [-0.0754,  0.0645, -0.0744,  ...,  0.0741, -0.0591, -0.0133]],

        ...,

        [[-0.0906, -0.2409, -0.0028,  ...,  0.0665, -0.0233, -0.2019],
         [-0.0687, -0.0825,  0.0099,  ..., -0.0920,  0.0625, -0.0988],
         [-0.0734, -0.0643,  0.1147,  ...,  0.0518, -0.0102,  0.1371],
         ...,
         [-0.0192,  0.0020,  0.0285,  ..., -0.1722, -0.0396,  0.0082],
         [-0.1151,  0.0563, -0.0875,  ..., -0.1921, -0.0551,  0.0391],
         [-0.0601, -0.0520,  0.0294,  ..., -0.0619, -0.0321, -0.0107]],

        [[-0.0442,  0.1784,  0.0466,  ..., -0.0765, -0.1366, -0.0567],
         [-0.0196,  0.1522,  0.1790,  ..., -0.1095, -0.0109,  0.0572],
         [ 0.0386, -0.0430,  0.0978,  ...,  0.0938,  0.0549, -0.1519],
         ...,
         [-0.0396, -0.0616, -0.0234,  ..., -0.1171,  0.0760, -0.1129],
         [-0.1489, -0.0613, -0.0650,  ...,  0.0648,  0.0986, -0.0916],
         [ 0.0317, -0.0314, -0.0428,  ...,  0.0914, -0.0111, -0.0307]],

        [[-0.0568, -0.0348, -0.0781,  ...,  0.0472,  0.1273,  0.1764],
         [ 0.0248,  0.0005, -0.1940,  ..., -0.0020, -0.0450,  0.0442],
         [-0.1820, -0.1689,  0.1309,  ..., -0.0327,  0.0246, -0.0136],
         ...,
         [ 0.1464,  0.0012,  0.0645,  ...,  0.0609, -0.0539,  0.0546],
         [ 0.1865, -0.0226,  0.0511,  ...,  0.0105,  0.0317,  0.0384],
         [-0.0130,  0.1291, -0.0174,  ..., -0.0197,  0.0814, -0.0050]]],
       grad_fn=<StackBackward0>), 'stoch': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [1., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 1., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 1.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [1., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 1., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 1., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]]), 'logits': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]])}
train_step: Normalized hidden_state shape: torch.Size([1, 16, 128])
train_step: Normalized stoch shape: torch.Size([16, 1024])
train_step: Normalized deter shape: torch.Size([16, 128])
train_step: Post-imagine_trajectory: Imagined features shape: torch.Size([16, 15, 1152])
train_step: Post-imagine_trajectory: Imagined actions shape: torch.Size([16, 15, 2])
train_step: Post-imagine_trajectory: Imagined action indices shape: torch.Size([16, 15])
train_step: Post-imagine_trajectory: Imagined state deter shape: torch.Size([16, 15, 128])
train_step: Post-imagine_trajectory: Imagined state stoch shape: torch.Size([16, 15, 1024])
Reward shape: torch.Size([16, 15, 1]), Value shape: torch.Size([16, 15, 1]), Slow Value shape: torch.Size([16, 15, 1]), Discount shape: torch.Size([16, 15, 1, 1])
Return targets length: 15, First target shape: torch.Size([16, 16, 1])
train_step: Actor distribution shape: torch.Size([16, 15, 2])
train_step: Action log probabilities shape: torch.Size([16, 15])
train_step: Action log probabilities sample: tensor([[-0.3042, -0.2938],
        [-0.5241, -0.6789]], grad_fn=<SliceBackward0>)
train_step: Advantages shape: torch.Size([16, 15, 16, 15])
train_step: Advantages sample: tensor([[[[-6.8625, -6.8625, -6.8625, -6.8625, -6.8625, -6.8625, -6.8625,
           -6.8625, -6.8625, -6.8625, -6.8625, -6.8625, -6.8625, -6.8625,
           -6.8625],
          [-6.8625, -6.8625, -6.8625, -6.8625, -6.8625, -6.8625, -6.8625,
           -6.8625, -6.8625, -6.8625, -6.8625, -6.8625, -6.8625, -6.8625,
           -6.8625],
          [-2.7273, -2.7273, -2.7273, -2.7273, -2.7273, -2.7273, -2.7273,
           -2.7273, -2.7273, -2.7273, -2.7273, -2.7273, -2.7273, -2.7273,
           -2.7273],
          [-6.1333, -6.1333, -6.1333, -6.1333, -6.1333, -6.1333, -6.1333,
           -6.1333, -6.1333, -6.1333, -6.1333, -6.1333, -6.1333, -6.1333,
           -6.1333],
          [-6.8625, -6.8625, -6.8625, -6.8625, -6.8625, -6.8625, -6.8625,
           -6.8625, -6.8625, -6.8625, -6.8625, -6.8625, -6.8625, -6.8625,
           -6.8625],
          [-6.8625, -6.8625, -6.8625, -6.8625, -6.8625, -6.8625, -6.8625,
           -6.8625, -6.8625, -6.8625, -6.8625, -6.8625, -6.8625, -6.8625,
           -6.8625],
          [-6.8625, -6.8625, -6.8625, -6.8625, -6.8625, -6.8625, -6.8625,
           -6.8625, -6.8625, -6.8625, -6.8625, -6.8625, -6.8625, -6.8625,
           -6.8625],
          [-6.8625, -6.8625, -6.8625, -6.8625, -6.8625, -6.8625, -6.8625,
           -6.8625, -6.8625, -6.8625, -6.8625, -6.8625, -6.8625, -6.8625,
           -6.8625],
          [-2.2115, -2.2115, -2.2115, -2.2115, -2.2115, -2.2115, -2.2115,
           -2.2115, -2.2115, -2.2115, -2.2115, -2.2115, -2.2115, -2.2115,
           -2.2115],
          [-6.8625, -6.8625, -6.8625, -6.8625, -6.8625, -6.8625, -6.8625,
           -6.8625, -6.8625, -6.8625, -6.8625, -6.8625, -6.8625, -6.8625,
           -6.8625],
          [-5.8939, -5.8939, -5.8939, -5.8939, -5.8939, -5.8939, -5.8939,
           -5.8939, -5.8939, -5.8939, -5.8939, -5.8939, -5.8939, -5.8939,
           -5.8939],
          [-6.8625, -6.8625, -6.8625, -6.8625, -6.8625, -6.8625, -6.8625,
           -6.8625, -6.8625, -6.8625, -6.8625, -6.8625, -6.8625, -6.8625,
           -6.8625],
          [-2.2115, -2.2115, -2.2115, -2.2115, -2.2115, -2.2115, -2.2115,
           -2.2115, -2.2115, -2.2115, -2.2115, -2.2115, -2.2115, -2.2115,
           -2.2115],
          [-6.8625, -6.8625, -6.8625, -6.8625, -6.8625, -6.8625, -6.8625,
           -6.8625, -6.8625, -6.8625, -6.8625, -6.8625, -6.8625, -6.8625,
           -6.8625],
          [-6.8625, -6.8625, -6.8625, -6.8625, -6.8625, -6.8625, -6.8625,
           -6.8625, -6.8625, -6.8625, -6.8625, -6.8625, -6.8625, -6.8625,
           -6.8625],
          [-1.9639, -1.9639, -1.9639, -1.9639, -1.9639, -1.9639, -1.9639,
           -1.9639, -1.9639, -1.9639, -1.9639, -1.9639, -1.9639, -1.9639,
           -1.9639]],

         [[-5.9696, -5.9696, -5.9696, -5.9696, -5.9696, -5.9696, -5.9696,
           -5.9696, -5.9696, -5.9696, -5.9696, -5.9696, -5.9696, -5.9696,
           -5.9696],
          [-5.9696, -5.9696, -5.9696, -5.9696, -5.9696, -5.9696, -5.9696,
           -5.9696, -5.9696, -5.9696, -5.9696, -5.9696, -5.9696, -5.9696,
           -5.9696],
          [-1.6036, -1.6036, -1.6036, -1.6036, -1.6036, -1.6036, -1.6036,
           -1.6036, -1.6036, -1.6036, -1.6036, -1.6036, -1.6036, -1.6036,
           -1.6036],
          [-5.1997, -5.1997, -5.1997, -5.1997, -5.1997, -5.1997, -5.1997,
           -5.1997, -5.1997, -5.1997, -5.1997, -5.1997, -5.1997, -5.1997,
           -5.1997],
          [-5.9696, -5.9696, -5.9696, -5.9696, -5.9696, -5.9696, -5.9696,
           -5.9696, -5.9696, -5.9696, -5.9696, -5.9696, -5.9696, -5.9696,
           -5.9696],
          [-5.9696, -5.9696, -5.9696, -5.9696, -5.9696, -5.9696, -5.9696,
           -5.9696, -5.9696, -5.9696, -5.9696, -5.9696, -5.9696, -5.9696,
           -5.9696],
          [-5.9696, -5.9696, -5.9696, -5.9696, -5.9696, -5.9696, -5.9696,
           -5.9696, -5.9696, -5.9696, -5.9696, -5.9696, -5.9696, -5.9696,
           -5.9696],
          [-5.9696, -5.9696, -5.9696, -5.9696, -5.9696, -5.9696, -5.9696,
           -5.9696, -5.9696, -5.9696, -5.9696, -5.9696, -5.9696, -5.9696,
           -5.9696],
          [-1.0591, -1.0591, -1.0591, -1.0591, -1.0591, -1.0591, -1.0591,
           -1.0591, -1.0591, -1.0591, -1.0591, -1.0591, -1.0591, -1.0591,
           -1.0591],
          [-5.9696, -5.9696, -5.9696, -5.9696, -5.9696, -5.9696, -5.9696,
           -5.9696, -5.9696, -5.9696, -5.9696, -5.9696, -5.9696, -5.9696,
           -5.9696],
          [-4.9469, -4.9469, -4.9469, -4.9469, -4.9469, -4.9469, -4.9469,
           -4.9469, -4.9469, -4.9469, -4.9469, -4.9469, -4.9469, -4.9469,
           -4.9469],
          [-5.9696, -5.9696, -5.9696, -5.9696, -5.9696, -5.9696, -5.9696,
           -5.9696, -5.9696, -5.9696, -5.9696, -5.9696, -5.9696, -5.9696,
           -5.9696],
          [-1.0591, -1.0591, -1.0591, -1.0591, -1.0591, -1.0591, -1.0591,
           -1.0591, -1.0591, -1.0591, -1.0591, -1.0591, -1.0591, -1.0591,
           -1.0591],
          [-5.9696, -5.9696, -5.9696, -5.9696, -5.9696, -5.9696, -5.9696,
           -5.9696, -5.9696, -5.9696, -5.9696, -5.9696, -5.9696, -5.9696,
           -5.9696],
          [-5.9696, -5.9696, -5.9696, -5.9696, -5.9696, -5.9696, -5.9696,
           -5.9696, -5.9696, -5.9696, -5.9696, -5.9696, -5.9696, -5.9696,
           -5.9696],
          [-0.7977, -0.7977, -0.7977, -0.7977, -0.7977, -0.7977, -0.7977,
           -0.7977, -0.7977, -0.7977, -0.7977, -0.7977, -0.7977, -0.7977,
           -0.7977]]],


        [[[-6.3742, -6.3742, -6.3742, -6.3742, -6.3742, -6.3742, -6.3742,
           -6.3742, -6.3742, -6.3742, -6.3742, -6.3742, -6.3742, -6.3742,
           -6.3742],
          [-6.3742, -6.3742, -6.3742, -6.3742, -6.3742, -6.3742, -6.3742,
           -6.3742, -6.3742, -6.3742, -6.3742, -6.3742, -6.3742, -6.3742,
           -6.3742],
          [-2.4104, -2.4104, -2.4104, -2.4104, -2.4104, -2.4104, -2.4104,
           -2.4104, -2.4104, -2.4104, -2.4104, -2.4104, -2.4104, -2.4104,
           -2.4104],
          [-5.5379, -5.5379, -5.5379, -5.5379, -5.5379, -5.5379, -5.5379,
           -5.5379, -5.5379, -5.5379, -5.5379, -5.5379, -5.5379, -5.5379,
           -5.5379],
          [-6.3742, -6.3742, -6.3742, -6.3742, -6.3742, -6.3742, -6.3742,
           -6.3742, -6.3742, -6.3742, -6.3742, -6.3742, -6.3742, -6.3742,
           -6.3742],
          [-6.3742, -6.3742, -6.3742, -6.3742, -6.3742, -6.3742, -6.3742,
           -6.3742, -6.3742, -6.3742, -6.3742, -6.3742, -6.3742, -6.3742,
           -6.3742],
          [-6.3742, -6.3742, -6.3742, -6.3742, -6.3742, -6.3742, -6.3742,
           -6.3742, -6.3742, -6.3742, -6.3742, -6.3742, -6.3742, -6.3742,
           -6.3742],
          [-6.3742, -6.3742, -6.3742, -6.3742, -6.3742, -6.3742, -6.3742,
           -6.3742, -6.3742, -6.3742, -6.3742, -6.3742, -6.3742, -6.3742,
           -6.3742],
          [-1.7695, -1.7695, -1.7695, -1.7695, -1.7695, -1.7695, -1.7695,
           -1.7695, -1.7695, -1.7695, -1.7695, -1.7695, -1.7695, -1.7695,
           -1.7695],
          [-6.3742, -6.3742, -6.3742, -6.3742, -6.3742, -6.3742, -6.3742,
           -6.3742, -6.3742, -6.3742, -6.3742, -6.3742, -6.3742, -6.3742,
           -6.3742],
          [-5.3773, -5.3773, -5.3774, -5.3773, -5.3774, -5.3774, -5.3774,
           -5.3774, -5.3774, -5.3774, -5.3774, -5.3774, -5.3773, -5.3773,
           -5.3773],
          [-6.3742, -6.3742, -6.3742, -6.3742, -6.3742, -6.3742, -6.3742,
           -6.3742, -6.3742, -6.3742, -6.3742, -6.3742, -6.3742, -6.3742,
           -6.3742],
          [-1.7695, -1.7695, -1.7695, -1.7695, -1.7695, -1.7695, -1.7695,
           -1.7695, -1.7695, -1.7695, -1.7695, -1.7695, -1.7695, -1.7695,
           -1.7695],
          [-6.3742, -6.3742, -6.3742, -6.3742, -6.3742, -6.3742, -6.3742,
           -6.3742, -6.3742, -6.3742, -6.3742, -6.3742, -6.3742, -6.3742,
           -6.3742],
          [-6.3742, -6.3742, -6.3742, -6.3742, -6.3742, -6.3742, -6.3742,
           -6.3742, -6.3742, -6.3742, -6.3742, -6.3742, -6.3742, -6.3742,
           -6.3742],
          [-1.1105, -1.1105, -1.1105, -1.1105, -1.1105, -1.1105, -1.1105,
           -1.1105, -1.1105, -1.1105, -1.1105, -1.1105, -1.1105, -1.1105,
           -1.1105]],

         [[-6.1081, -6.1081, -6.1081, -6.1081, -6.1081, -6.1081, -6.1081,
           -6.1081, -6.1081, -6.1081, -6.1081, -6.1081, -6.1081, -6.1081,
           -6.1081],
          [-6.1081, -6.1081, -6.1081, -6.1081, -6.1081, -6.1081, -6.1081,
           -6.1081, -6.1081, -6.1081, -6.1081, -6.1081, -6.1081, -6.1081,
           -6.1081],
          [-1.9232, -1.9232, -1.9232, -1.9232, -1.9232, -1.9232, -1.9232,
           -1.9232, -1.9232, -1.9232, -1.9232, -1.9232, -1.9232, -1.9232,
           -1.9232],
          [-5.2252, -5.2252, -5.2252, -5.2252, -5.2252, -5.2252, -5.2252,
           -5.2252, -5.2252, -5.2252, -5.2252, -5.2252, -5.2252, -5.2252,
           -5.2252],
          [-6.1081, -6.1081, -6.1081, -6.1081, -6.1081, -6.1081, -6.1081,
           -6.1081, -6.1081, -6.1081, -6.1081, -6.1081, -6.1081, -6.1081,
           -6.1081],
          [-6.1081, -6.1081, -6.1081, -6.1081, -6.1081, -6.1081, -6.1081,
           -6.1081, -6.1081, -6.1081, -6.1081, -6.1081, -6.1081, -6.1081,
           -6.1081],
          [-6.1081, -6.1081, -6.1081, -6.1081, -6.1081, -6.1081, -6.1081,
           -6.1081, -6.1081, -6.1081, -6.1081, -6.1081, -6.1081, -6.1081,
           -6.1081],
          [-6.1081, -6.1081, -6.1081, -6.1081, -6.1081, -6.1081, -6.1081,
           -6.1081, -6.1081, -6.1081, -6.1081, -6.1081, -6.1081, -6.1081,
           -6.1081],
          [-1.2465, -1.2465, -1.2465, -1.2465, -1.2465, -1.2465, -1.2465,
           -1.2465, -1.2465, -1.2465, -1.2465, -1.2465, -1.2465, -1.2465,
           -1.2465],
          [-6.1081, -6.1081, -6.1081, -6.1081, -6.1081, -6.1081, -6.1081,
           -6.1081, -6.1081, -6.1081, -6.1081, -6.1081, -6.1081, -6.1081,
           -6.1081],
          [-5.0557, -5.0557, -5.0557, -5.0557, -5.0557, -5.0557, -5.0557,
           -5.0557, -5.0557, -5.0557, -5.0557, -5.0557, -5.0557, -5.0557,
           -5.0557],
          [-6.1081, -6.1081, -6.1081, -6.1081, -6.1081, -6.1081, -6.1081,
           -6.1081, -6.1081, -6.1081, -6.1081, -6.1081, -6.1081, -6.1081,
           -6.1081],
          [-1.2465, -1.2465, -1.2465, -1.2465, -1.2465, -1.2465, -1.2465,
           -1.2465, -1.2465, -1.2465, -1.2465, -1.2465, -1.2465, -1.2465,
           -1.2465],
          [-6.1081, -6.1081, -6.1081, -6.1081, -6.1081, -6.1081, -6.1081,
           -6.1081, -6.1081, -6.1081, -6.1081, -6.1081, -6.1081, -6.1081,
           -6.1081],
          [-6.1081, -6.1081, -6.1081, -6.1081, -6.1081, -6.1081, -6.1081,
           -6.1081, -6.1081, -6.1081, -6.1081, -6.1081, -6.1081, -6.1081,
           -6.1081],
          [-0.5508, -0.5508, -0.5508, -0.5508, -0.5508, -0.5508, -0.5508,
           -0.5508, -0.5508, -0.5508, -0.5508, -0.5508, -0.5508, -0.5508,
           -0.5508]]]], grad_fn=<SliceBackward0>)
train_step: Return scale: 1.2831216673904744
train_step: Scaled advantages shape: torch.Size([16, 15, 16, 15])
train_step: Scaled advantages sample: tensor([[[[-5.3483, -5.3483, -5.3483, -5.3483, -5.3483, -5.3483, -5.3483,
           -5.3483, -5.3483, -5.3483, -5.3483, -5.3483, -5.3483, -5.3483,
           -5.3483],
          [-5.3483, -5.3483, -5.3483, -5.3483, -5.3483, -5.3483, -5.3483,
           -5.3483, -5.3483, -5.3483, -5.3483, -5.3483, -5.3483, -5.3483,
           -5.3483],
          [-2.1255, -2.1255, -2.1255, -2.1255, -2.1255, -2.1255, -2.1255,
           -2.1255, -2.1255, -2.1255, -2.1255, -2.1255, -2.1255, -2.1255,
           -2.1255],
          [-4.7800, -4.7800, -4.7800, -4.7800, -4.7800, -4.7800, -4.7800,
           -4.7800, -4.7800, -4.7800, -4.7800, -4.7800, -4.7800, -4.7800,
           -4.7800],
          [-5.3483, -5.3483, -5.3483, -5.3483, -5.3483, -5.3483, -5.3483,
           -5.3483, -5.3483, -5.3483, -5.3483, -5.3483, -5.3483, -5.3483,
           -5.3483],
          [-5.3483, -5.3483, -5.3483, -5.3483, -5.3483, -5.3483, -5.3483,
           -5.3483, -5.3483, -5.3483, -5.3483, -5.3483, -5.3483, -5.3483,
           -5.3483],
          [-5.3483, -5.3483, -5.3483, -5.3483, -5.3483, -5.3483, -5.3483,
           -5.3483, -5.3483, -5.3483, -5.3483, -5.3483, -5.3483, -5.3483,
           -5.3483],
          [-5.3483, -5.3483, -5.3483, -5.3483, -5.3483, -5.3483, -5.3483,
           -5.3483, -5.3483, -5.3483, -5.3483, -5.3483, -5.3483, -5.3483,
           -5.3483],
          [-1.7235, -1.7235, -1.7235, -1.7235, -1.7235, -1.7235, -1.7235,
           -1.7235, -1.7235, -1.7235, -1.7235, -1.7235, -1.7235, -1.7235,
           -1.7235],
          [-5.3483, -5.3483, -5.3483, -5.3483, -5.3483, -5.3483, -5.3483,
           -5.3483, -5.3483, -5.3483, -5.3483, -5.3483, -5.3483, -5.3483,
           -5.3483],
          [-4.5934, -4.5934, -4.5934, -4.5934, -4.5934, -4.5934, -4.5934,
           -4.5934, -4.5934, -4.5934, -4.5934, -4.5934, -4.5934, -4.5934,
           -4.5934],
          [-5.3483, -5.3483, -5.3483, -5.3483, -5.3483, -5.3483, -5.3483,
           -5.3483, -5.3483, -5.3483, -5.3483, -5.3483, -5.3483, -5.3483,
           -5.3483],
          [-1.7235, -1.7235, -1.7235, -1.7235, -1.7235, -1.7235, -1.7235,
           -1.7235, -1.7235, -1.7235, -1.7235, -1.7235, -1.7235, -1.7235,
           -1.7235],
          [-5.3483, -5.3483, -5.3483, -5.3483, -5.3483, -5.3483, -5.3483,
           -5.3483, -5.3483, -5.3483, -5.3483, -5.3483, -5.3483, -5.3483,
           -5.3483],
          [-5.3483, -5.3483, -5.3483, -5.3483, -5.3483, -5.3483, -5.3483,
           -5.3483, -5.3483, -5.3483, -5.3483, -5.3483, -5.3483, -5.3483,
           -5.3483],
          [-1.5306, -1.5306, -1.5306, -1.5306, -1.5306, -1.5306, -1.5306,
           -1.5306, -1.5306, -1.5306, -1.5306, -1.5306, -1.5306, -1.5306,
           -1.5306]],

         [[-4.6524, -4.6524, -4.6524, -4.6524, -4.6524, -4.6524, -4.6524,
           -4.6524, -4.6524, -4.6524, -4.6524, -4.6524, -4.6524, -4.6524,
           -4.6524],
          [-4.6524, -4.6524, -4.6524, -4.6524, -4.6524, -4.6524, -4.6524,
           -4.6524, -4.6524, -4.6524, -4.6524, -4.6524, -4.6524, -4.6524,
           -4.6524],
          [-1.2498, -1.2498, -1.2498, -1.2498, -1.2498, -1.2498, -1.2498,
           -1.2498, -1.2498, -1.2498, -1.2498, -1.2498, -1.2498, -1.2498,
           -1.2498],
          [-4.0524, -4.0524, -4.0524, -4.0524, -4.0524, -4.0524, -4.0524,
           -4.0524, -4.0524, -4.0524, -4.0524, -4.0524, -4.0524, -4.0524,
           -4.0524],
          [-4.6524, -4.6524, -4.6524, -4.6524, -4.6524, -4.6524, -4.6524,
           -4.6524, -4.6524, -4.6524, -4.6524, -4.6524, -4.6524, -4.6524,
           -4.6524],
          [-4.6524, -4.6524, -4.6524, -4.6524, -4.6524, -4.6524, -4.6524,
           -4.6524, -4.6524, -4.6524, -4.6524, -4.6524, -4.6524, -4.6524,
           -4.6524],
          [-4.6524, -4.6524, -4.6524, -4.6524, -4.6524, -4.6524, -4.6524,
           -4.6524, -4.6524, -4.6524, -4.6524, -4.6524, -4.6524, -4.6524,
           -4.6524],
          [-4.6524, -4.6524, -4.6524, -4.6524, -4.6524, -4.6524, -4.6524,
           -4.6524, -4.6524, -4.6524, -4.6524, -4.6524, -4.6524, -4.6524,
           -4.6524],
          [-0.8254, -0.8254, -0.8254, -0.8254, -0.8254, -0.8254, -0.8254,
           -0.8254, -0.8254, -0.8254, -0.8254, -0.8254, -0.8254, -0.8254,
           -0.8254],
          [-4.6524, -4.6524, -4.6524, -4.6524, -4.6524, -4.6524, -4.6524,
           -4.6524, -4.6524, -4.6524, -4.6524, -4.6524, -4.6524, -4.6524,
           -4.6524],
          [-3.8554, -3.8554, -3.8554, -3.8554, -3.8554, -3.8554, -3.8554,
           -3.8554, -3.8554, -3.8554, -3.8554, -3.8554, -3.8554, -3.8554,
           -3.8554],
          [-4.6524, -4.6524, -4.6524, -4.6524, -4.6524, -4.6524, -4.6524,
           -4.6524, -4.6524, -4.6524, -4.6524, -4.6524, -4.6524, -4.6524,
           -4.6524],
          [-0.8254, -0.8254, -0.8254, -0.8254, -0.8254, -0.8254, -0.8254,
           -0.8254, -0.8254, -0.8254, -0.8254, -0.8254, -0.8254, -0.8254,
           -0.8254],
          [-4.6524, -4.6524, -4.6524, -4.6524, -4.6524, -4.6524, -4.6524,
           -4.6524, -4.6524, -4.6524, -4.6524, -4.6524, -4.6524, -4.6524,
           -4.6524],
          [-4.6524, -4.6524, -4.6524, -4.6524, -4.6524, -4.6524, -4.6524,
           -4.6524, -4.6524, -4.6524, -4.6524, -4.6524, -4.6524, -4.6524,
           -4.6524],
          [-0.7977, -0.7977, -0.7977, -0.7977, -0.7977, -0.7977, -0.7977,
           -0.7977, -0.7977, -0.7977, -0.7977, -0.7977, -0.7977, -0.7977,
           -0.7977]]],


        [[[-4.9677, -4.9677, -4.9677, -4.9677, -4.9677, -4.9677, -4.9677,
           -4.9677, -4.9677, -4.9677, -4.9677, -4.9677, -4.9677, -4.9677,
           -4.9677],
          [-4.9677, -4.9677, -4.9677, -4.9677, -4.9677, -4.9677, -4.9677,
           -4.9677, -4.9677, -4.9677, -4.9677, -4.9677, -4.9677, -4.9677,
           -4.9677],
          [-1.8785, -1.8785, -1.8785, -1.8785, -1.8785, -1.8785, -1.8785,
           -1.8785, -1.8785, -1.8785, -1.8785, -1.8785, -1.8785, -1.8785,
           -1.8785],
          [-4.3160, -4.3160, -4.3160, -4.3160, -4.3160, -4.3160, -4.3160,
           -4.3160, -4.3160, -4.3160, -4.3160, -4.3160, -4.3160, -4.3160,
           -4.3160],
          [-4.9677, -4.9677, -4.9677, -4.9677, -4.9677, -4.9677, -4.9677,
           -4.9677, -4.9677, -4.9677, -4.9677, -4.9677, -4.9677, -4.9677,
           -4.9677],
          [-4.9677, -4.9677, -4.9677, -4.9677, -4.9677, -4.9677, -4.9677,
           -4.9677, -4.9677, -4.9677, -4.9677, -4.9677, -4.9677, -4.9677,
           -4.9677],
          [-4.9677, -4.9677, -4.9677, -4.9677, -4.9677, -4.9677, -4.9677,
           -4.9677, -4.9677, -4.9677, -4.9677, -4.9677, -4.9677, -4.9677,
           -4.9677],
          [-4.9677, -4.9677, -4.9677, -4.9677, -4.9677, -4.9677, -4.9677,
           -4.9677, -4.9677, -4.9677, -4.9677, -4.9677, -4.9677, -4.9677,
           -4.9677],
          [-1.3791, -1.3791, -1.3791, -1.3791, -1.3791, -1.3791, -1.3791,
           -1.3791, -1.3791, -1.3791, -1.3791, -1.3791, -1.3791, -1.3791,
           -1.3791],
          [-4.9677, -4.9677, -4.9677, -4.9677, -4.9677, -4.9677, -4.9677,
           -4.9677, -4.9677, -4.9677, -4.9677, -4.9677, -4.9677, -4.9677,
           -4.9677],
          [-4.1908, -4.1908, -4.1908, -4.1908, -4.1908, -4.1908, -4.1908,
           -4.1908, -4.1908, -4.1908, -4.1908, -4.1908, -4.1908, -4.1908,
           -4.1908],
          [-4.9677, -4.9677, -4.9677, -4.9677, -4.9677, -4.9677, -4.9677,
           -4.9677, -4.9677, -4.9677, -4.9677, -4.9677, -4.9677, -4.9677,
           -4.9677],
          [-1.3791, -1.3791, -1.3791, -1.3791, -1.3791, -1.3791, -1.3791,
           -1.3791, -1.3791, -1.3791, -1.3791, -1.3791, -1.3791, -1.3791,
           -1.3791],
          [-4.9677, -4.9677, -4.9677, -4.9677, -4.9677, -4.9677, -4.9677,
           -4.9677, -4.9677, -4.9677, -4.9677, -4.9677, -4.9677, -4.9677,
           -4.9677],
          [-4.9677, -4.9677, -4.9677, -4.9677, -4.9677, -4.9677, -4.9677,
           -4.9677, -4.9677, -4.9677, -4.9677, -4.9677, -4.9677, -4.9677,
           -4.9677],
          [-0.8655, -0.8655, -0.8655, -0.8655, -0.8655, -0.8655, -0.8655,
           -0.8655, -0.8655, -0.8655, -0.8655, -0.8655, -0.8655, -0.8655,
           -0.8655]],

         [[-4.7604, -4.7604, -4.7604, -4.7604, -4.7604, -4.7604, -4.7604,
           -4.7604, -4.7604, -4.7604, -4.7604, -4.7604, -4.7604, -4.7604,
           -4.7604],
          [-4.7604, -4.7604, -4.7604, -4.7604, -4.7604, -4.7604, -4.7604,
           -4.7604, -4.7604, -4.7604, -4.7604, -4.7604, -4.7604, -4.7604,
           -4.7604],
          [-1.4988, -1.4988, -1.4988, -1.4988, -1.4988, -1.4988, -1.4988,
           -1.4988, -1.4988, -1.4988, -1.4988, -1.4988, -1.4988, -1.4988,
           -1.4988],
          [-4.0723, -4.0723, -4.0723, -4.0723, -4.0723, -4.0723, -4.0723,
           -4.0723, -4.0723, -4.0723, -4.0723, -4.0723, -4.0723, -4.0723,
           -4.0723],
          [-4.7604, -4.7604, -4.7604, -4.7604, -4.7604, -4.7604, -4.7604,
           -4.7604, -4.7604, -4.7604, -4.7604, -4.7604, -4.7604, -4.7604,
           -4.7604],
          [-4.7604, -4.7604, -4.7604, -4.7604, -4.7604, -4.7604, -4.7604,
           -4.7604, -4.7604, -4.7604, -4.7604, -4.7604, -4.7604, -4.7604,
           -4.7604],
          [-4.7604, -4.7604, -4.7604, -4.7604, -4.7604, -4.7604, -4.7604,
           -4.7604, -4.7604, -4.7604, -4.7604, -4.7604, -4.7604, -4.7604,
           -4.7604],
          [-4.7604, -4.7604, -4.7604, -4.7604, -4.7604, -4.7604, -4.7604,
           -4.7604, -4.7604, -4.7604, -4.7604, -4.7604, -4.7604, -4.7604,
           -4.7604],
          [-0.9715, -0.9715, -0.9715, -0.9715, -0.9715, -0.9715, -0.9715,
           -0.9715, -0.9715, -0.9715, -0.9715, -0.9715, -0.9715, -0.9715,
           -0.9715],
          [-4.7604, -4.7604, -4.7604, -4.7604, -4.7604, -4.7604, -4.7604,
           -4.7604, -4.7604, -4.7604, -4.7604, -4.7604, -4.7604, -4.7604,
           -4.7604],
          [-3.9401, -3.9401, -3.9401, -3.9401, -3.9401, -3.9401, -3.9401,
           -3.9401, -3.9401, -3.9401, -3.9401, -3.9401, -3.9401, -3.9401,
           -3.9401],
          [-4.7604, -4.7604, -4.7604, -4.7604, -4.7604, -4.7604, -4.7604,
           -4.7604, -4.7604, -4.7604, -4.7604, -4.7604, -4.7604, -4.7604,
           -4.7604],
          [-0.9715, -0.9715, -0.9715, -0.9715, -0.9715, -0.9715, -0.9715,
           -0.9715, -0.9715, -0.9715, -0.9715, -0.9715, -0.9715, -0.9715,
           -0.9715],
          [-4.7604, -4.7604, -4.7604, -4.7604, -4.7604, -4.7604, -4.7604,
           -4.7604, -4.7604, -4.7604, -4.7604, -4.7604, -4.7604, -4.7604,
           -4.7604],
          [-4.7604, -4.7604, -4.7604, -4.7604, -4.7604, -4.7604, -4.7604,
           -4.7604, -4.7604, -4.7604, -4.7604, -4.7604, -4.7604, -4.7604,
           -4.7604],
          [-0.5508, -0.5508, -0.5508, -0.5508, -0.5508, -0.5508, -0.5508,
           -0.5508, -0.5508, -0.5508, -0.5508, -0.5508, -0.5508, -0.5508,
           -0.5508]]]], grad_fn=<SliceBackward0>)
train_step: Entropy shape: torch.Size([16, 15])
train_step: Entropy sample: tensor([[0.5754, 0.5673],
        [0.6761, 0.6930]], grad_fn=<SliceBackward0>)
train_step: Entropy coefficient: 0.01
train_step: Actor loss: -1.5533387660980225
train_step: returns shape after mean: torch.Size([16, 15])
train_step: target_indices shape: torch.Size([16, 15])
train_step: value_logits shape: torch.Size([16, 15, 255])
train_step: target_twohot shape: torch.Size([16, 15, 255])
--- Starting train_step at 2025-04-01 01:57:34 ---
Full starting_state: {'deter': tensor([[[-6.6949e-02, -1.0147e-01, -8.4348e-02,  ..., -8.4080e-03,
           3.3955e-02, -1.0932e-01],
         [ 8.1011e-03, -2.3589e-02,  5.9346e-02,  ..., -1.8255e-01,
           4.0068e-02,  3.7156e-02],
         [-1.2137e-01, -2.6239e-02,  5.8589e-02,  ..., -3.8982e-02,
          -1.0226e-02, -7.5544e-02],
         ...,
         [-2.4110e-02,  7.9202e-02, -5.7118e-02,  ..., -9.2764e-02,
           1.2977e-02, -9.6744e-02],
         [-7.9048e-03,  7.3407e-02, -1.6405e-02,  ..., -4.5094e-02,
          -9.2610e-04, -9.9754e-03],
         [ 1.6461e-01,  1.3171e-01, -5.9368e-02,  ...,  3.6986e-02,
           1.1400e-01, -1.7692e-02]],

        [[ 7.5682e-03,  1.0467e-01, -1.7761e-01,  ...,  3.9953e-02,
           5.8375e-02, -1.6229e-01],
         [ 9.1839e-02, -5.1087e-02, -1.5305e-01,  ...,  2.4818e-02,
          -1.5682e-01,  3.8404e-02],
         [ 1.7027e-01, -2.2130e-02, -2.8232e-02,  ...,  4.7767e-02,
          -2.2780e-02,  9.0693e-05],
         ...,
         [-1.0986e-01,  1.9251e-01, -9.8373e-02,  ...,  2.8286e-02,
          -5.8555e-02, -8.5629e-02],
         [-4.9954e-02,  6.0322e-02, -2.7964e-02,  ...,  5.3489e-02,
          -1.6019e-02, -7.1190e-02],
         [-2.8503e-01,  1.1747e-01, -1.5353e-01,  ..., -8.4335e-02,
          -1.3983e-01, -4.5874e-02]],

        [[-3.0728e-02, -2.2883e-02,  1.1706e-01,  ..., -6.1340e-02,
          -7.0654e-02,  6.5459e-02],
         [-4.9138e-02,  6.2130e-02,  6.1528e-02,  ..., -8.9119e-02,
           2.4976e-02, -4.0653e-02],
         [ 1.0144e-01, -2.2936e-02, -7.9205e-02,  ...,  2.4590e-02,
           8.9666e-02, -2.7690e-02],
         ...,
         [-2.0670e-01, -8.1327e-02, -9.0799e-02,  ...,  1.0378e-01,
          -1.0461e-01, -4.5537e-02],
         [-2.8364e-03, -1.1176e-01,  7.5967e-02,  ...,  1.6483e-02,
           1.1579e-01,  2.4834e-02],
         [ 1.9938e-02, -9.4369e-02, -1.5234e-02,  ..., -2.6757e-02,
          -5.4615e-02,  6.9603e-02]],

        ...,

        [[ 5.9446e-04,  5.4984e-03, -1.4549e-01,  ..., -1.3331e-01,
          -1.3899e-01,  3.0106e-02],
         [-3.3367e-02,  1.4214e-01,  6.3844e-03,  ...,  1.1881e-01,
           1.1572e-02,  3.4485e-02],
         [-9.1217e-02,  6.2717e-02, -1.1823e-02,  ..., -5.2989e-02,
           4.1516e-03, -8.6008e-02],
         ...,
         [-8.8983e-02, -1.5927e-01, -2.6691e-02,  ..., -1.1257e-01,
           9.7391e-02, -4.7121e-02],
         [ 5.1648e-02, -1.5082e-01, -1.1520e-01,  ..., -7.4658e-02,
           1.2060e-01,  9.0812e-02],
         [-7.7983e-03, -1.3197e-01,  3.3814e-02,  ...,  2.0930e-01,
           1.2316e-02, -1.2935e-02]],

        [[-5.6603e-02, -2.9034e-02, -2.8582e-02,  ..., -6.8762e-02,
          -4.4987e-02, -1.6068e-01],
         [-1.0121e-01,  8.8062e-03,  6.1055e-02,  ...,  1.7101e-01,
          -9.1139e-02,  3.6568e-02],
         [-1.5126e-02, -1.3835e-01, -7.9994e-02,  ..., -1.1707e-01,
          -4.7931e-02, -8.1187e-02],
         ...,
         [-2.5464e-02,  4.6429e-02, -2.0095e-01,  ...,  2.3362e-02,
          -1.3234e-01, -1.5812e-01],
         [-4.2573e-02, -9.3103e-02, -1.3677e-02,  ..., -8.1212e-02,
           3.6041e-02, -2.2094e-02],
         [-5.8488e-02,  1.9451e-01,  3.4808e-02,  ...,  1.0213e-01,
          -9.3456e-02, -7.3874e-02]],

        [[ 9.9622e-02, -8.3018e-02, -8.6414e-03,  ..., -5.1884e-03,
          -2.3395e-02, -9.3936e-03],
         [-8.8316e-02,  2.5872e-02, -1.5326e-01,  ..., -6.9998e-02,
          -5.2505e-03, -5.9808e-02],
         [-6.1611e-02,  8.4293e-03, -1.5618e-02,  ..., -9.0415e-02,
          -5.9652e-03, -1.0427e-01],
         ...,
         [-2.2825e-02, -5.5901e-02, -7.9203e-02,  ..., -5.3150e-02,
           2.2899e-03,  4.0320e-03],
         [-4.8537e-02,  1.1415e-01, -5.0335e-02,  ..., -1.1773e-01,
          -1.6516e-02, -1.2749e-02],
         [-8.3269e-02, -7.9003e-02, -4.1684e-02,  ..., -5.7115e-02,
           1.0909e-01, -3.8088e-02]]], grad_fn=<StackBackward0>), 'stoch': tensor([[[1., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 1.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[1., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 1.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 1., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [1., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]])}
train_step: Starting state deter shape: torch.Size([16, 50, 128])
train_step: Starting state stoch shape: torch.Size([16, 50, 1024])
After ensuring logits/stoch: {'deter': tensor([[[-6.6949e-02, -1.0147e-01, -8.4348e-02,  ..., -8.4080e-03,
           3.3955e-02, -1.0932e-01],
         [ 8.1011e-03, -2.3589e-02,  5.9346e-02,  ..., -1.8255e-01,
           4.0068e-02,  3.7156e-02],
         [-1.2137e-01, -2.6239e-02,  5.8589e-02,  ..., -3.8982e-02,
          -1.0226e-02, -7.5544e-02],
         ...,
         [-2.4110e-02,  7.9202e-02, -5.7118e-02,  ..., -9.2764e-02,
           1.2977e-02, -9.6744e-02],
         [-7.9048e-03,  7.3407e-02, -1.6405e-02,  ..., -4.5094e-02,
          -9.2610e-04, -9.9754e-03],
         [ 1.6461e-01,  1.3171e-01, -5.9368e-02,  ...,  3.6986e-02,
           1.1400e-01, -1.7692e-02]],

        [[ 7.5682e-03,  1.0467e-01, -1.7761e-01,  ...,  3.9953e-02,
           5.8375e-02, -1.6229e-01],
         [ 9.1839e-02, -5.1087e-02, -1.5305e-01,  ...,  2.4818e-02,
          -1.5682e-01,  3.8404e-02],
         [ 1.7027e-01, -2.2130e-02, -2.8232e-02,  ...,  4.7767e-02,
          -2.2780e-02,  9.0693e-05],
         ...,
         [-1.0986e-01,  1.9251e-01, -9.8373e-02,  ...,  2.8286e-02,
          -5.8555e-02, -8.5629e-02],
         [-4.9954e-02,  6.0322e-02, -2.7964e-02,  ...,  5.3489e-02,
          -1.6019e-02, -7.1190e-02],
         [-2.8503e-01,  1.1747e-01, -1.5353e-01,  ..., -8.4335e-02,
          -1.3983e-01, -4.5874e-02]],

        [[-3.0728e-02, -2.2883e-02,  1.1706e-01,  ..., -6.1340e-02,
          -7.0654e-02,  6.5459e-02],
         [-4.9138e-02,  6.2130e-02,  6.1528e-02,  ..., -8.9119e-02,
           2.4976e-02, -4.0653e-02],
         [ 1.0144e-01, -2.2936e-02, -7.9205e-02,  ...,  2.4590e-02,
           8.9666e-02, -2.7690e-02],
         ...,
         [-2.0670e-01, -8.1327e-02, -9.0799e-02,  ...,  1.0378e-01,
          -1.0461e-01, -4.5537e-02],
         [-2.8364e-03, -1.1176e-01,  7.5967e-02,  ...,  1.6483e-02,
           1.1579e-01,  2.4834e-02],
         [ 1.9938e-02, -9.4369e-02, -1.5234e-02,  ..., -2.6757e-02,
          -5.4615e-02,  6.9603e-02]],

        ...,

        [[ 5.9446e-04,  5.4984e-03, -1.4549e-01,  ..., -1.3331e-01,
          -1.3899e-01,  3.0106e-02],
         [-3.3367e-02,  1.4214e-01,  6.3844e-03,  ...,  1.1881e-01,
           1.1572e-02,  3.4485e-02],
         [-9.1217e-02,  6.2717e-02, -1.1823e-02,  ..., -5.2989e-02,
           4.1516e-03, -8.6008e-02],
         ...,
         [-8.8983e-02, -1.5927e-01, -2.6691e-02,  ..., -1.1257e-01,
           9.7391e-02, -4.7121e-02],
         [ 5.1648e-02, -1.5082e-01, -1.1520e-01,  ..., -7.4658e-02,
           1.2060e-01,  9.0812e-02],
         [-7.7983e-03, -1.3197e-01,  3.3814e-02,  ...,  2.0930e-01,
           1.2316e-02, -1.2935e-02]],

        [[-5.6603e-02, -2.9034e-02, -2.8582e-02,  ..., -6.8762e-02,
          -4.4987e-02, -1.6068e-01],
         [-1.0121e-01,  8.8062e-03,  6.1055e-02,  ...,  1.7101e-01,
          -9.1139e-02,  3.6568e-02],
         [-1.5126e-02, -1.3835e-01, -7.9994e-02,  ..., -1.1707e-01,
          -4.7931e-02, -8.1187e-02],
         ...,
         [-2.5464e-02,  4.6429e-02, -2.0095e-01,  ...,  2.3362e-02,
          -1.3234e-01, -1.5812e-01],
         [-4.2573e-02, -9.3103e-02, -1.3677e-02,  ..., -8.1212e-02,
           3.6041e-02, -2.2094e-02],
         [-5.8488e-02,  1.9451e-01,  3.4808e-02,  ...,  1.0213e-01,
          -9.3456e-02, -7.3874e-02]],

        [[ 9.9622e-02, -8.3018e-02, -8.6414e-03,  ..., -5.1884e-03,
          -2.3395e-02, -9.3936e-03],
         [-8.8316e-02,  2.5872e-02, -1.5326e-01,  ..., -6.9998e-02,
          -5.2505e-03, -5.9808e-02],
         [-6.1611e-02,  8.4293e-03, -1.5618e-02,  ..., -9.0415e-02,
          -5.9652e-03, -1.0427e-01],
         ...,
         [-2.2825e-02, -5.5901e-02, -7.9203e-02,  ..., -5.3150e-02,
           2.2899e-03,  4.0320e-03],
         [-4.8537e-02,  1.1415e-01, -5.0335e-02,  ..., -1.1773e-01,
          -1.6516e-02, -1.2749e-02],
         [-8.3269e-02, -7.9003e-02, -4.1684e-02,  ..., -5.7115e-02,
           1.0909e-01, -3.8088e-02]]], grad_fn=<StackBackward0>), 'stoch': tensor([[[1., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 1.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[1., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 1.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 1., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [1., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]]), 'logits': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]])}
train_step: Normalized hidden_state shape: torch.Size([1, 16, 128])
train_step: Normalized stoch shape: torch.Size([16, 1024])
train_step: Normalized deter shape: torch.Size([16, 128])
train_step: Post-imagine_trajectory: Imagined features shape: torch.Size([16, 15, 1152])
train_step: Post-imagine_trajectory: Imagined actions shape: torch.Size([16, 15, 2])
train_step: Post-imagine_trajectory: Imagined action indices shape: torch.Size([16, 15])
train_step: Post-imagine_trajectory: Imagined state deter shape: torch.Size([16, 15, 128])
train_step: Post-imagine_trajectory: Imagined state stoch shape: torch.Size([16, 15, 1024])
Reward shape: torch.Size([16, 15, 1]), Value shape: torch.Size([16, 15, 1]), Slow Value shape: torch.Size([16, 15, 1]), Discount shape: torch.Size([16, 15, 1, 1])
Return targets length: 15, First target shape: torch.Size([16, 16, 1])
train_step: Actor distribution shape: torch.Size([16, 15, 2])
train_step: Action log probabilities shape: torch.Size([16, 15])
train_step: Action log probabilities sample: tensor([[-0.7063, -0.2664],
        [-0.2476, -0.4017]], grad_fn=<SliceBackward0>)
train_step: Advantages shape: torch.Size([16, 15, 16, 15])
train_step: Advantages sample: tensor([[[[-7.4876, -7.4876, -7.4876, -7.4876, -7.4876, -7.4876, -7.4876,
           -7.4876, -7.4876, -7.4876, -7.4876, -7.4876, -7.4876, -7.4876,
           -7.4876],
          [-7.4876, -7.4876, -7.4876, -7.4876, -7.4876, -7.4876, -7.4876,
           -7.4876, -7.4876, -7.4876, -7.4876, -7.4876, -7.4876, -7.4876,
           -7.4876],
          [-7.4876, -7.4876, -7.4876, -7.4876, -7.4876, -7.4876, -7.4876,
           -7.4876, -7.4876, -7.4876, -7.4876, -7.4876, -7.4876, -7.4876,
           -7.4876],
          [-7.4876, -7.4876, -7.4876, -7.4876, -7.4876, -7.4876, -7.4876,
           -7.4876, -7.4876, -7.4876, -7.4876, -7.4876, -7.4876, -7.4876,
           -7.4876],
          [-6.5125, -6.5125, -6.5125, -6.5125, -6.5125, -6.5125, -6.5125,
           -6.5125, -6.5125, -6.5125, -6.5125, -6.5125, -6.5125, -6.5125,
           -6.5125],
          [-7.4876, -7.4876, -7.4876, -7.4876, -7.4876, -7.4876, -7.4876,
           -7.4876, -7.4876, -7.4876, -7.4876, -7.4876, -7.4876, -7.4876,
           -7.4876],
          [-7.4876, -7.4876, -7.4876, -7.4876, -7.4876, -7.4876, -7.4876,
           -7.4876, -7.4876, -7.4876, -7.4876, -7.4876, -7.4876, -7.4876,
           -7.4876],
          [-7.4876, -7.4876, -7.4876, -7.4876, -7.4876, -7.4876, -7.4876,
           -7.4876, -7.4876, -7.4876, -7.4876, -7.4876, -7.4876, -7.4876,
           -7.4876],
          [-1.5098, -1.5098, -1.5098, -1.5098, -1.5098, -1.5098, -1.5098,
           -1.5098, -1.5098, -1.5098, -1.5098, -1.5098, -1.5098, -1.5098,
           -1.5098],
          [-7.4876, -7.4876, -7.4876, -7.4876, -7.4876, -7.4876, -7.4876,
           -7.4876, -7.4876, -7.4876, -7.4876, -7.4876, -7.4876, -7.4876,
           -7.4876],
          [-7.4876, -7.4876, -7.4876, -7.4876, -7.4876, -7.4876, -7.4876,
           -7.4876, -7.4876, -7.4876, -7.4876, -7.4876, -7.4876, -7.4876,
           -7.4876],
          [-5.2402, -5.2402, -5.2402, -5.2402, -5.2402, -5.2402, -5.2402,
           -5.2402, -5.2402, -5.2402, -5.2402, -5.2402, -5.2402, -5.2402,
           -5.2402],
          [-0.9445, -0.9445, -0.9445, -0.9445, -0.9445, -0.9445, -0.9445,
           -0.9445, -0.9445, -0.9445, -0.9445, -0.9445, -0.9445, -0.9445,
           -0.9445],
          [-5.7320, -5.7320, -5.7320, -5.7320, -5.7320, -5.7320, -5.7320,
           -5.7320, -5.7320, -5.7320, -5.7320, -5.7320, -5.7320, -5.7320,
           -5.7320],
          [-5.7320, -5.7320, -5.7320, -5.7320, -5.7320, -5.7320, -5.7320,
           -5.7320, -5.7320, -5.7320, -5.7320, -5.7320, -5.7320, -5.7320,
           -5.7320],
          [-7.4876, -7.4876, -7.4876, -7.4876, -7.4876, -7.4876, -7.4876,
           -7.4876, -7.4876, -7.4876, -7.4876, -7.4876, -7.4876, -7.4876,
           -7.4876]],

         [[-6.9082, -6.9082, -6.9082, -6.9082, -6.9082, -6.9082, -6.9082,
           -6.9082, -6.9082, -6.9082, -6.9082, -6.9082, -6.9082, -6.9082,
           -6.9082],
          [-6.9082, -6.9082, -6.9082, -6.9082, -6.9082, -6.9082, -6.9082,
           -6.9082, -6.9082, -6.9082, -6.9082, -6.9082, -6.9082, -6.9082,
           -6.9082],
          [-6.9082, -6.9082, -6.9082, -6.9082, -6.9082, -6.9082, -6.9082,
           -6.9082, -6.9082, -6.9082, -6.9082, -6.9082, -6.9082, -6.9082,
           -6.9082],
          [-6.9082, -6.9082, -6.9082, -6.9082, -6.9082, -6.9082, -6.9082,
           -6.9082, -6.9082, -6.9082, -6.9082, -6.9082, -6.9082, -6.9082,
           -6.9082],
          [-5.8787, -5.8786, -5.8787, -5.8787, -5.8787, -5.8787, -5.8787,
           -5.8787, -5.8787, -5.8787, -5.8787, -5.8787, -5.8787, -5.8787,
           -5.8787],
          [-6.9082, -6.9082, -6.9082, -6.9082, -6.9082, -6.9082, -6.9082,
           -6.9082, -6.9082, -6.9082, -6.9082, -6.9082, -6.9082, -6.9082,
           -6.9082],
          [-6.9082, -6.9082, -6.9082, -6.9082, -6.9082, -6.9082, -6.9082,
           -6.9082, -6.9082, -6.9082, -6.9082, -6.9082, -6.9082, -6.9082,
           -6.9082],
          [-6.9082, -6.9082, -6.9082, -6.9082, -6.9082, -6.9082, -6.9082,
           -6.9082, -6.9082, -6.9082, -6.9082, -6.9082, -6.9082, -6.9082,
           -6.9082],
          [-0.5968, -0.5968, -0.5968, -0.5968, -0.5968, -0.5968, -0.5968,
           -0.5968, -0.5968, -0.5968, -0.5968, -0.5968, -0.5968, -0.5968,
           -0.5968],
          [-6.9082, -6.9082, -6.9082, -6.9082, -6.9082, -6.9082, -6.9082,
           -6.9082, -6.9082, -6.9082, -6.9082, -6.9082, -6.9082, -6.9082,
           -6.9082],
          [-6.9082, -6.9082, -6.9082, -6.9082, -6.9082, -6.9082, -6.9082,
           -6.9082, -6.9082, -6.9082, -6.9082, -6.9082, -6.9082, -6.9082,
           -6.9082],
          [-4.5354, -4.5354, -4.5354, -4.5354, -4.5354, -4.5354, -4.5354,
           -4.5354, -4.5354, -4.5354, -4.5354, -4.5354, -4.5354, -4.5354,
           -4.5354],
          [-2.4845, -2.4845, -2.4845, -2.4845, -2.4845, -2.4845, -2.4845,
           -2.4845, -2.4845, -2.4845, -2.4845, -2.4845, -2.4845, -2.4845,
           -2.4845],
          [-5.0546, -5.0546, -5.0546, -5.0546, -5.0546, -5.0546, -5.0546,
           -5.0546, -5.0546, -5.0546, -5.0546, -5.0546, -5.0546, -5.0546,
           -5.0546],
          [-5.0546, -5.0546, -5.0546, -5.0546, -5.0546, -5.0546, -5.0546,
           -5.0546, -5.0546, -5.0546, -5.0546, -5.0546, -5.0546, -5.0546,
           -5.0546],
          [-6.9082, -6.9082, -6.9082, -6.9082, -6.9082, -6.9082, -6.9082,
           -6.9082, -6.9082, -6.9082, -6.9082, -6.9082, -6.9082, -6.9082,
           -6.9082]]],


        [[[-6.8606, -6.8606, -6.8606, -6.8606, -6.8606, -6.8606, -6.8606,
           -6.8606, -6.8606, -6.8606, -6.8606, -6.8606, -6.8606, -6.8606,
           -6.8606],
          [-6.8606, -6.8606, -6.8606, -6.8606, -6.8606, -6.8606, -6.8606,
           -6.8606, -6.8606, -6.8606, -6.8606, -6.8606, -6.8606, -6.8606,
           -6.8606],
          [-6.8606, -6.8606, -6.8606, -6.8606, -6.8606, -6.8606, -6.8606,
           -6.8606, -6.8606, -6.8606, -6.8606, -6.8606, -6.8606, -6.8606,
           -6.8606],
          [-6.8606, -6.8606, -6.8606, -6.8606, -6.8606, -6.8606, -6.8606,
           -6.8606, -6.8606, -6.8606, -6.8606, -6.8606, -6.8606, -6.8606,
           -6.8606],
          [-5.9142, -5.9142, -5.9142, -5.9142, -5.9142, -5.9142, -5.9142,
           -5.9142, -5.9142, -5.9142, -5.9142, -5.9142, -5.9142, -5.9142,
           -5.9142],
          [-6.8606, -6.8606, -6.8606, -6.8606, -6.8606, -6.8606, -6.8606,
           -6.8606, -6.8606, -6.8606, -6.8606, -6.8606, -6.8606, -6.8606,
           -6.8606],
          [-6.8606, -6.8606, -6.8606, -6.8606, -6.8606, -6.8606, -6.8606,
           -6.8606, -6.8606, -6.8606, -6.8606, -6.8606, -6.8606, -6.8606,
           -6.8606],
          [-6.8606, -6.8606, -6.8606, -6.8606, -6.8606, -6.8606, -6.8606,
           -6.8606, -6.8606, -6.8606, -6.8606, -6.8606, -6.8606, -6.8606,
           -6.8606],
          [-1.8681, -1.8681, -1.8681, -1.8681, -1.8681, -1.8681, -1.8681,
           -1.8681, -1.8681, -1.8681, -1.8681, -1.8681, -1.8681, -1.8681,
           -1.8681],
          [-6.8606, -6.8606, -6.8606, -6.8606, -6.8606, -6.8606, -6.8606,
           -6.8606, -6.8606, -6.8606, -6.8606, -6.8606, -6.8606, -6.8606,
           -6.8606],
          [-6.8606, -6.8606, -6.8606, -6.8606, -6.8606, -6.8606, -6.8606,
           -6.8606, -6.8606, -6.8606, -6.8606, -6.8606, -6.8606, -6.8606,
           -6.8606],
          [-5.0161, -5.0161, -5.0161, -5.0161, -5.0161, -5.0161, -5.0161,
           -5.0161, -5.0161, -5.0161, -5.0161, -5.0161, -5.0161, -5.0161,
           -5.0161],
          [-0.5504, -0.5504, -0.5504, -0.5504, -0.5504, -0.5504, -0.5504,
           -0.5504, -0.5504, -0.5504, -0.5504, -0.5504, -0.5504, -0.5504,
           -0.5504],
          [-5.4746, -5.4746, -5.4746, -5.4746, -5.4746, -5.4746, -5.4746,
           -5.4746, -5.4746, -5.4746, -5.4746, -5.4746, -5.4746, -5.4746,
           -5.4746],
          [-5.4746, -5.4746, -5.4746, -5.4746, -5.4746, -5.4746, -5.4746,
           -5.4746, -5.4746, -5.4746, -5.4746, -5.4746, -5.4746, -5.4746,
           -5.4746],
          [-6.8606, -6.8606, -6.8606, -6.8606, -6.8606, -6.8606, -6.8606,
           -6.8606, -6.8606, -6.8606, -6.8606, -6.8606, -6.8606, -6.8606,
           -6.8606]],

         [[-6.6622, -6.6622, -6.6622, -6.6622, -6.6622, -6.6622, -6.6622,
           -6.6622, -6.6622, -6.6622, -6.6622, -6.6622, -6.6622, -6.6622,
           -6.6622],
          [-6.6622, -6.6622, -6.6622, -6.6622, -6.6622, -6.6622, -6.6622,
           -6.6622, -6.6622, -6.6622, -6.6622, -6.6622, -6.6622, -6.6622,
           -6.6622],
          [-6.6622, -6.6622, -6.6622, -6.6622, -6.6622, -6.6622, -6.6622,
           -6.6622, -6.6622, -6.6622, -6.6622, -6.6622, -6.6622, -6.6622,
           -6.6622],
          [-6.6622, -6.6622, -6.6622, -6.6622, -6.6622, -6.6622, -6.6622,
           -6.6622, -6.6622, -6.6622, -6.6622, -6.6622, -6.6622, -6.6622,
           -6.6622],
          [-5.6631, -5.6630, -5.6631, -5.6630, -5.6630, -5.6630, -5.6630,
           -5.6630, -5.6630, -5.6630, -5.6631, -5.6630, -5.6631, -5.6630,
           -5.6631],
          [-6.6622, -6.6622, -6.6622, -6.6622, -6.6622, -6.6622, -6.6622,
           -6.6622, -6.6622, -6.6622, -6.6622, -6.6622, -6.6622, -6.6622,
           -6.6622],
          [-6.6622, -6.6622, -6.6622, -6.6622, -6.6622, -6.6622, -6.6622,
           -6.6622, -6.6622, -6.6622, -6.6622, -6.6622, -6.6622, -6.6622,
           -6.6622],
          [-6.6622, -6.6622, -6.6622, -6.6622, -6.6622, -6.6622, -6.6622,
           -6.6622, -6.6622, -6.6622, -6.6622, -6.6622, -6.6622, -6.6622,
           -6.6622],
          [-1.3912, -1.3912, -1.3912, -1.3912, -1.3912, -1.3912, -1.3912,
           -1.3912, -1.3912, -1.3912, -1.3912, -1.3912, -1.3912, -1.3912,
           -1.3912],
          [-6.6622, -6.6622, -6.6622, -6.6622, -6.6622, -6.6622, -6.6622,
           -6.6622, -6.6622, -6.6622, -6.6622, -6.6622, -6.6622, -6.6622,
           -6.6622],
          [-6.6622, -6.6622, -6.6622, -6.6622, -6.6622, -6.6622, -6.6622,
           -6.6622, -6.6622, -6.6622, -6.6622, -6.6622, -6.6622, -6.6622,
           -6.6622],
          [-4.7149, -4.7148, -4.7149, -4.7148, -4.7148, -4.7148, -4.7148,
           -4.7148, -4.7148, -4.7148, -4.7149, -4.7148, -4.7149, -4.7148,
           -4.7149],
          [-3.8745, -3.8745, -3.8745, -3.8745, -3.8745, -3.8745, -3.8745,
           -3.8745, -3.8745, -3.8745, -3.8745, -3.8745, -3.8745, -3.8745,
           -3.8745],
          [-5.1989, -5.1989, -5.1989, -5.1989, -5.1989, -5.1989, -5.1989,
           -5.1989, -5.1989, -5.1989, -5.1989, -5.1989, -5.1989, -5.1989,
           -5.1989],
          [-5.1989, -5.1989, -5.1989, -5.1989, -5.1989, -5.1989, -5.1989,
           -5.1989, -5.1989, -5.1989, -5.1989, -5.1989, -5.1989, -5.1989,
           -5.1989],
          [-6.6622, -6.6622, -6.6622, -6.6622, -6.6622, -6.6622, -6.6622,
           -6.6622, -6.6622, -6.6622, -6.6622, -6.6622, -6.6622, -6.6622,
           -6.6622]]]], grad_fn=<SliceBackward0>)
train_step: Return scale: 1.3415356415158057
train_step: Scaled advantages shape: torch.Size([16, 15, 16, 15])
train_step: Scaled advantages sample: tensor([[[[-5.5814, -5.5814, -5.5814, -5.5814, -5.5814, -5.5814, -5.5814,
           -5.5814, -5.5814, -5.5814, -5.5814, -5.5814, -5.5814, -5.5814,
           -5.5814],
          [-5.5814, -5.5814, -5.5814, -5.5814, -5.5814, -5.5814, -5.5814,
           -5.5814, -5.5814, -5.5814, -5.5814, -5.5814, -5.5814, -5.5814,
           -5.5814],
          [-5.5814, -5.5814, -5.5814, -5.5814, -5.5814, -5.5814, -5.5814,
           -5.5814, -5.5814, -5.5814, -5.5814, -5.5814, -5.5814, -5.5814,
           -5.5814],
          [-5.5814, -5.5814, -5.5814, -5.5814, -5.5814, -5.5814, -5.5814,
           -5.5814, -5.5814, -5.5814, -5.5814, -5.5814, -5.5814, -5.5814,
           -5.5814],
          [-4.8545, -4.8545, -4.8545, -4.8545, -4.8545, -4.8545, -4.8545,
           -4.8545, -4.8545, -4.8545, -4.8545, -4.8545, -4.8545, -4.8545,
           -4.8545],
          [-5.5814, -5.5814, -5.5814, -5.5814, -5.5814, -5.5814, -5.5814,
           -5.5814, -5.5814, -5.5814, -5.5814, -5.5814, -5.5814, -5.5814,
           -5.5814],
          [-5.5814, -5.5814, -5.5814, -5.5814, -5.5814, -5.5814, -5.5814,
           -5.5814, -5.5814, -5.5814, -5.5814, -5.5814, -5.5814, -5.5814,
           -5.5814],
          [-5.5814, -5.5814, -5.5814, -5.5814, -5.5814, -5.5814, -5.5814,
           -5.5814, -5.5814, -5.5814, -5.5814, -5.5814, -5.5814, -5.5814,
           -5.5814],
          [-1.1254, -1.1254, -1.1254, -1.1254, -1.1254, -1.1254, -1.1254,
           -1.1254, -1.1254, -1.1254, -1.1254, -1.1254, -1.1254, -1.1254,
           -1.1254],
          [-5.5814, -5.5814, -5.5814, -5.5814, -5.5814, -5.5814, -5.5814,
           -5.5814, -5.5814, -5.5814, -5.5814, -5.5814, -5.5814, -5.5814,
           -5.5814],
          [-5.5814, -5.5814, -5.5814, -5.5814, -5.5814, -5.5814, -5.5814,
           -5.5814, -5.5814, -5.5814, -5.5814, -5.5814, -5.5814, -5.5814,
           -5.5814],
          [-3.9061, -3.9061, -3.9061, -3.9061, -3.9061, -3.9061, -3.9061,
           -3.9061, -3.9061, -3.9061, -3.9061, -3.9061, -3.9061, -3.9061,
           -3.9061],
          [-0.9445, -0.9445, -0.9445, -0.9445, -0.9445, -0.9445, -0.9445,
           -0.9445, -0.9445, -0.9445, -0.9445, -0.9445, -0.9445, -0.9445,
           -0.9445],
          [-4.2727, -4.2727, -4.2727, -4.2727, -4.2727, -4.2727, -4.2727,
           -4.2727, -4.2727, -4.2727, -4.2727, -4.2727, -4.2727, -4.2727,
           -4.2727],
          [-4.2727, -4.2727, -4.2727, -4.2727, -4.2727, -4.2727, -4.2727,
           -4.2727, -4.2727, -4.2727, -4.2727, -4.2727, -4.2727, -4.2727,
           -4.2727],
          [-5.5814, -5.5814, -5.5814, -5.5814, -5.5814, -5.5814, -5.5814,
           -5.5814, -5.5814, -5.5814, -5.5814, -5.5814, -5.5814, -5.5814,
           -5.5814]],

         [[-5.1495, -5.1495, -5.1495, -5.1495, -5.1495, -5.1495, -5.1495,
           -5.1495, -5.1495, -5.1495, -5.1495, -5.1495, -5.1495, -5.1495,
           -5.1495],
          [-5.1495, -5.1495, -5.1495, -5.1495, -5.1495, -5.1495, -5.1495,
           -5.1495, -5.1495, -5.1495, -5.1495, -5.1495, -5.1495, -5.1495,
           -5.1495],
          [-5.1495, -5.1495, -5.1495, -5.1495, -5.1495, -5.1495, -5.1495,
           -5.1495, -5.1495, -5.1495, -5.1495, -5.1495, -5.1495, -5.1495,
           -5.1495],
          [-5.1495, -5.1495, -5.1495, -5.1495, -5.1495, -5.1495, -5.1495,
           -5.1495, -5.1495, -5.1495, -5.1495, -5.1495, -5.1495, -5.1495,
           -5.1495],
          [-4.3820, -4.3820, -4.3820, -4.3820, -4.3820, -4.3820, -4.3820,
           -4.3820, -4.3820, -4.3820, -4.3820, -4.3820, -4.3820, -4.3820,
           -4.3820],
          [-5.1495, -5.1495, -5.1495, -5.1495, -5.1495, -5.1495, -5.1495,
           -5.1495, -5.1495, -5.1495, -5.1495, -5.1495, -5.1495, -5.1495,
           -5.1495],
          [-5.1495, -5.1495, -5.1495, -5.1495, -5.1495, -5.1495, -5.1495,
           -5.1495, -5.1495, -5.1495, -5.1495, -5.1495, -5.1495, -5.1495,
           -5.1495],
          [-5.1495, -5.1495, -5.1495, -5.1495, -5.1495, -5.1495, -5.1495,
           -5.1495, -5.1495, -5.1495, -5.1495, -5.1495, -5.1495, -5.1495,
           -5.1495],
          [-0.5968, -0.5968, -0.5968, -0.5968, -0.5968, -0.5968, -0.5968,
           -0.5968, -0.5968, -0.5968, -0.5968, -0.5968, -0.5968, -0.5968,
           -0.5968],
          [-5.1495, -5.1495, -5.1495, -5.1495, -5.1495, -5.1495, -5.1495,
           -5.1495, -5.1495, -5.1495, -5.1495, -5.1495, -5.1495, -5.1495,
           -5.1495],
          [-5.1495, -5.1495, -5.1495, -5.1495, -5.1495, -5.1495, -5.1495,
           -5.1495, -5.1495, -5.1495, -5.1495, -5.1495, -5.1495, -5.1495,
           -5.1495],
          [-3.3807, -3.3807, -3.3807, -3.3807, -3.3807, -3.3807, -3.3807,
           -3.3807, -3.3807, -3.3807, -3.3807, -3.3807, -3.3807, -3.3807,
           -3.3807],
          [-1.8520, -1.8520, -1.8520, -1.8520, -1.8520, -1.8520, -1.8520,
           -1.8520, -1.8520, -1.8520, -1.8520, -1.8520, -1.8520, -1.8520,
           -1.8520],
          [-3.7678, -3.7678, -3.7678, -3.7678, -3.7678, -3.7678, -3.7678,
           -3.7678, -3.7678, -3.7678, -3.7678, -3.7678, -3.7678, -3.7678,
           -3.7678],
          [-3.7678, -3.7678, -3.7678, -3.7678, -3.7678, -3.7678, -3.7678,
           -3.7678, -3.7678, -3.7678, -3.7678, -3.7678, -3.7678, -3.7678,
           -3.7678],
          [-5.1495, -5.1495, -5.1495, -5.1495, -5.1495, -5.1495, -5.1495,
           -5.1495, -5.1495, -5.1495, -5.1495, -5.1495, -5.1495, -5.1495,
           -5.1495]]],


        [[[-5.1140, -5.1140, -5.1140, -5.1140, -5.1140, -5.1140, -5.1140,
           -5.1140, -5.1140, -5.1140, -5.1140, -5.1140, -5.1140, -5.1140,
           -5.1140],
          [-5.1140, -5.1140, -5.1140, -5.1140, -5.1140, -5.1140, -5.1140,
           -5.1140, -5.1140, -5.1140, -5.1140, -5.1140, -5.1140, -5.1140,
           -5.1140],
          [-5.1140, -5.1140, -5.1140, -5.1140, -5.1140, -5.1140, -5.1140,
           -5.1140, -5.1140, -5.1140, -5.1140, -5.1140, -5.1140, -5.1140,
           -5.1140],
          [-5.1140, -5.1140, -5.1140, -5.1140, -5.1140, -5.1140, -5.1140,
           -5.1140, -5.1140, -5.1140, -5.1140, -5.1140, -5.1140, -5.1140,
           -5.1140],
          [-4.4085, -4.4085, -4.4085, -4.4085, -4.4085, -4.4085, -4.4085,
           -4.4085, -4.4085, -4.4085, -4.4085, -4.4085, -4.4085, -4.4085,
           -4.4085],
          [-5.1140, -5.1140, -5.1140, -5.1140, -5.1140, -5.1140, -5.1140,
           -5.1140, -5.1140, -5.1140, -5.1140, -5.1140, -5.1140, -5.1140,
           -5.1140],
          [-5.1140, -5.1140, -5.1140, -5.1140, -5.1140, -5.1140, -5.1140,
           -5.1140, -5.1140, -5.1140, -5.1140, -5.1140, -5.1140, -5.1140,
           -5.1140],
          [-5.1140, -5.1140, -5.1140, -5.1140, -5.1140, -5.1140, -5.1140,
           -5.1140, -5.1140, -5.1140, -5.1140, -5.1140, -5.1140, -5.1140,
           -5.1140],
          [-1.3925, -1.3925, -1.3925, -1.3925, -1.3925, -1.3925, -1.3925,
           -1.3925, -1.3925, -1.3925, -1.3925, -1.3925, -1.3925, -1.3925,
           -1.3925],
          [-5.1140, -5.1140, -5.1140, -5.1140, -5.1140, -5.1140, -5.1140,
           -5.1140, -5.1140, -5.1140, -5.1140, -5.1140, -5.1140, -5.1140,
           -5.1140],
          [-5.1140, -5.1140, -5.1140, -5.1140, -5.1140, -5.1140, -5.1140,
           -5.1140, -5.1140, -5.1140, -5.1140, -5.1140, -5.1140, -5.1140,
           -5.1140],
          [-3.7391, -3.7391, -3.7391, -3.7391, -3.7391, -3.7391, -3.7391,
           -3.7391, -3.7391, -3.7391, -3.7391, -3.7391, -3.7391, -3.7391,
           -3.7391],
          [-0.5504, -0.5504, -0.5504, -0.5504, -0.5504, -0.5504, -0.5504,
           -0.5504, -0.5504, -0.5504, -0.5504, -0.5504, -0.5504, -0.5504,
           -0.5504],
          [-4.0809, -4.0809, -4.0809, -4.0809, -4.0809, -4.0809, -4.0809,
           -4.0809, -4.0809, -4.0809, -4.0809, -4.0809, -4.0809, -4.0809,
           -4.0809],
          [-4.0809, -4.0809, -4.0809, -4.0809, -4.0809, -4.0809, -4.0809,
           -4.0809, -4.0809, -4.0809, -4.0809, -4.0809, -4.0809, -4.0809,
           -4.0809],
          [-5.1140, -5.1140, -5.1140, -5.1140, -5.1140, -5.1140, -5.1140,
           -5.1140, -5.1140, -5.1140, -5.1140, -5.1140, -5.1140, -5.1140,
           -5.1140]],

         [[-4.9661, -4.9661, -4.9661, -4.9661, -4.9661, -4.9661, -4.9661,
           -4.9661, -4.9661, -4.9661, -4.9661, -4.9661, -4.9661, -4.9661,
           -4.9661],
          [-4.9661, -4.9661, -4.9661, -4.9661, -4.9661, -4.9661, -4.9661,
           -4.9661, -4.9661, -4.9661, -4.9661, -4.9661, -4.9661, -4.9661,
           -4.9661],
          [-4.9661, -4.9661, -4.9661, -4.9661, -4.9661, -4.9661, -4.9661,
           -4.9661, -4.9661, -4.9661, -4.9661, -4.9661, -4.9661, -4.9661,
           -4.9661],
          [-4.9661, -4.9661, -4.9661, -4.9661, -4.9661, -4.9661, -4.9661,
           -4.9661, -4.9661, -4.9661, -4.9661, -4.9661, -4.9661, -4.9661,
           -4.9661],
          [-4.2213, -4.2213, -4.2213, -4.2213, -4.2213, -4.2213, -4.2213,
           -4.2213, -4.2213, -4.2213, -4.2213, -4.2213, -4.2213, -4.2213,
           -4.2213],
          [-4.9661, -4.9661, -4.9661, -4.9661, -4.9661, -4.9661, -4.9661,
           -4.9661, -4.9661, -4.9661, -4.9661, -4.9661, -4.9661, -4.9661,
           -4.9661],
          [-4.9661, -4.9661, -4.9661, -4.9661, -4.9661, -4.9661, -4.9661,
           -4.9661, -4.9661, -4.9661, -4.9661, -4.9661, -4.9661, -4.9661,
           -4.9661],
          [-4.9661, -4.9661, -4.9661, -4.9661, -4.9661, -4.9661, -4.9661,
           -4.9661, -4.9661, -4.9661, -4.9661, -4.9661, -4.9661, -4.9661,
           -4.9661],
          [-1.0370, -1.0370, -1.0370, -1.0370, -1.0370, -1.0370, -1.0370,
           -1.0370, -1.0370, -1.0370, -1.0370, -1.0370, -1.0370, -1.0370,
           -1.0370],
          [-4.9661, -4.9661, -4.9661, -4.9661, -4.9661, -4.9661, -4.9661,
           -4.9661, -4.9661, -4.9661, -4.9661, -4.9661, -4.9661, -4.9661,
           -4.9661],
          [-4.9661, -4.9661, -4.9661, -4.9661, -4.9661, -4.9661, -4.9661,
           -4.9661, -4.9661, -4.9661, -4.9661, -4.9661, -4.9661, -4.9661,
           -4.9661],
          [-3.5145, -3.5145, -3.5145, -3.5145, -3.5145, -3.5145, -3.5145,
           -3.5145, -3.5145, -3.5145, -3.5145, -3.5145, -3.5145, -3.5145,
           -3.5145],
          [-2.8881, -2.8881, -2.8881, -2.8881, -2.8881, -2.8881, -2.8881,
           -2.8881, -2.8881, -2.8881, -2.8881, -2.8881, -2.8881, -2.8881,
           -2.8881],
          [-3.8753, -3.8753, -3.8754, -3.8753, -3.8753, -3.8753, -3.8753,
           -3.8753, -3.8753, -3.8753, -3.8753, -3.8753, -3.8753, -3.8753,
           -3.8753],
          [-3.8753, -3.8753, -3.8754, -3.8753, -3.8753, -3.8753, -3.8753,
           -3.8753, -3.8753, -3.8753, -3.8753, -3.8753, -3.8753, -3.8753,
           -3.8753],
          [-4.9661, -4.9661, -4.9661, -4.9661, -4.9661, -4.9661, -4.9661,
           -4.9661, -4.9661, -4.9661, -4.9661, -4.9661, -4.9661, -4.9661,
           -4.9661]]]], grad_fn=<SliceBackward0>)
train_step: Entropy shape: torch.Size([16, 15])
train_step: Entropy sample: tensor([[0.6931, 0.5439],
        [0.5261, 0.6348]], grad_fn=<SliceBackward0>)
train_step: Entropy coefficient: 0.01
train_step: Actor loss: -1.4946033954620361
train_step: returns shape after mean: torch.Size([16, 15])
train_step: target_indices shape: torch.Size([16, 15])
train_step: value_logits shape: torch.Size([16, 15, 255])
train_step: target_twohot shape: torch.Size([16, 15, 255])
--- Starting train_step at 2025-04-01 01:57:50 ---
Full starting_state: {'deter': tensor([[[ 0.0887, -0.0565, -0.0951,  ..., -0.0050, -0.0731,  0.0320],
         [ 0.0197,  0.0200, -0.1711,  ..., -0.1298,  0.0389, -0.0923],
         [ 0.0899,  0.1121, -0.0102,  ...,  0.1084,  0.2146, -0.1989],
         ...,
         [-0.0179,  0.1187,  0.1473,  ..., -0.0437,  0.0242, -0.0628],
         [-0.0377,  0.1324, -0.0959,  ..., -0.0419,  0.0038, -0.0250],
         [-0.1827, -0.0236, -0.1054,  ..., -0.0480, -0.0226,  0.0860]],

        [[ 0.1099, -0.0833,  0.0363,  ...,  0.0246, -0.0792,  0.1395],
         [-0.0802,  0.0468, -0.0259,  ..., -0.0260, -0.0322,  0.0181],
         [-0.0730, -0.1378, -0.0832,  ..., -0.2428,  0.0986, -0.0751],
         ...,
         [-0.0553, -0.1210, -0.1621,  ..., -0.1079, -0.0747, -0.2392],
         [-0.0532,  0.0376,  0.0306,  ..., -0.0970, -0.0591, -0.1796],
         [ 0.0062, -0.1083, -0.0725,  ...,  0.0605,  0.0200, -0.1753]],

        [[ 0.0406,  0.1002,  0.0555,  ...,  0.0284, -0.0735, -0.2224],
         [ 0.1781, -0.0844, -0.0626,  ..., -0.0038, -0.0067, -0.1171],
         [ 0.0770,  0.0582, -0.0607,  ...,  0.1719,  0.0276, -0.0544],
         ...,
         [ 0.1472,  0.0637, -0.0062,  ...,  0.0177,  0.0072, -0.0161],
         [ 0.0153, -0.0459, -0.1689,  ...,  0.1040, -0.0780,  0.0507],
         [ 0.1204,  0.0543, -0.0856,  ...,  0.0691, -0.0504, -0.1296]],

        ...,

        [[-0.0881, -0.0940, -0.0491,  ...,  0.2314,  0.0812, -0.1822],
         [ 0.0802,  0.0926, -0.1283,  ..., -0.0551,  0.1020, -0.0419],
         [ 0.0739, -0.0380,  0.1126,  ...,  0.0416,  0.0291,  0.0646],
         ...,
         [-0.2384, -0.0063, -0.0895,  ..., -0.1180,  0.0871, -0.1590],
         [-0.1282,  0.0971,  0.0721,  ...,  0.1566, -0.1118,  0.0258],
         [ 0.0116,  0.0015, -0.0279,  ..., -0.0468,  0.0705, -0.0576]],

        [[-0.1452, -0.1281,  0.0560,  ..., -0.0894, -0.0658, -0.0015],
         [ 0.0360,  0.0143, -0.1048,  ..., -0.0755, -0.1055, -0.0247],
         [-0.0788, -0.0901,  0.0105,  ..., -0.0483, -0.0171,  0.0565],
         ...,
         [-0.0015, -0.1140, -0.0170,  ...,  0.0453, -0.0467, -0.0477],
         [-0.0513, -0.1199, -0.1674,  ..., -0.0022,  0.0035, -0.0027],
         [-0.1693, -0.0698, -0.0235,  ..., -0.1678,  0.0112, -0.0532]],

        [[-0.0605, -0.1524, -0.0665,  ..., -0.0059,  0.0285,  0.0454],
         [-0.1076,  0.0171, -0.0559,  ..., -0.0328,  0.0612, -0.0772],
         [ 0.0281,  0.0761, -0.1465,  ..., -0.0982, -0.0890,  0.0851],
         ...,
         [ 0.0445,  0.0455,  0.0641,  ...,  0.1833, -0.0123, -0.0519],
         [-0.0844,  0.0335,  0.0192,  ...,  0.0267,  0.0445, -0.0007],
         [ 0.0132,  0.0982, -0.1295,  ...,  0.1733,  0.0361,  0.0358]]],
       grad_fn=<StackBackward0>), 'stoch': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 1., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 1., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 1., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]])}
train_step: Starting state deter shape: torch.Size([16, 50, 128])
train_step: Starting state stoch shape: torch.Size([16, 50, 1024])
After ensuring logits/stoch: {'deter': tensor([[[ 0.0887, -0.0565, -0.0951,  ..., -0.0050, -0.0731,  0.0320],
         [ 0.0197,  0.0200, -0.1711,  ..., -0.1298,  0.0389, -0.0923],
         [ 0.0899,  0.1121, -0.0102,  ...,  0.1084,  0.2146, -0.1989],
         ...,
         [-0.0179,  0.1187,  0.1473,  ..., -0.0437,  0.0242, -0.0628],
         [-0.0377,  0.1324, -0.0959,  ..., -0.0419,  0.0038, -0.0250],
         [-0.1827, -0.0236, -0.1054,  ..., -0.0480, -0.0226,  0.0860]],

        [[ 0.1099, -0.0833,  0.0363,  ...,  0.0246, -0.0792,  0.1395],
         [-0.0802,  0.0468, -0.0259,  ..., -0.0260, -0.0322,  0.0181],
         [-0.0730, -0.1378, -0.0832,  ..., -0.2428,  0.0986, -0.0751],
         ...,
         [-0.0553, -0.1210, -0.1621,  ..., -0.1079, -0.0747, -0.2392],
         [-0.0532,  0.0376,  0.0306,  ..., -0.0970, -0.0591, -0.1796],
         [ 0.0062, -0.1083, -0.0725,  ...,  0.0605,  0.0200, -0.1753]],

        [[ 0.0406,  0.1002,  0.0555,  ...,  0.0284, -0.0735, -0.2224],
         [ 0.1781, -0.0844, -0.0626,  ..., -0.0038, -0.0067, -0.1171],
         [ 0.0770,  0.0582, -0.0607,  ...,  0.1719,  0.0276, -0.0544],
         ...,
         [ 0.1472,  0.0637, -0.0062,  ...,  0.0177,  0.0072, -0.0161],
         [ 0.0153, -0.0459, -0.1689,  ...,  0.1040, -0.0780,  0.0507],
         [ 0.1204,  0.0543, -0.0856,  ...,  0.0691, -0.0504, -0.1296]],

        ...,

        [[-0.0881, -0.0940, -0.0491,  ...,  0.2314,  0.0812, -0.1822],
         [ 0.0802,  0.0926, -0.1283,  ..., -0.0551,  0.1020, -0.0419],
         [ 0.0739, -0.0380,  0.1126,  ...,  0.0416,  0.0291,  0.0646],
         ...,
         [-0.2384, -0.0063, -0.0895,  ..., -0.1180,  0.0871, -0.1590],
         [-0.1282,  0.0971,  0.0721,  ...,  0.1566, -0.1118,  0.0258],
         [ 0.0116,  0.0015, -0.0279,  ..., -0.0468,  0.0705, -0.0576]],

        [[-0.1452, -0.1281,  0.0560,  ..., -0.0894, -0.0658, -0.0015],
         [ 0.0360,  0.0143, -0.1048,  ..., -0.0755, -0.1055, -0.0247],
         [-0.0788, -0.0901,  0.0105,  ..., -0.0483, -0.0171,  0.0565],
         ...,
         [-0.0015, -0.1140, -0.0170,  ...,  0.0453, -0.0467, -0.0477],
         [-0.0513, -0.1199, -0.1674,  ..., -0.0022,  0.0035, -0.0027],
         [-0.1693, -0.0698, -0.0235,  ..., -0.1678,  0.0112, -0.0532]],

        [[-0.0605, -0.1524, -0.0665,  ..., -0.0059,  0.0285,  0.0454],
         [-0.1076,  0.0171, -0.0559,  ..., -0.0328,  0.0612, -0.0772],
         [ 0.0281,  0.0761, -0.1465,  ..., -0.0982, -0.0890,  0.0851],
         ...,
         [ 0.0445,  0.0455,  0.0641,  ...,  0.1833, -0.0123, -0.0519],
         [-0.0844,  0.0335,  0.0192,  ...,  0.0267,  0.0445, -0.0007],
         [ 0.0132,  0.0982, -0.1295,  ...,  0.1733,  0.0361,  0.0358]]],
       grad_fn=<StackBackward0>), 'stoch': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 1., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 1., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 1., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]]), 'logits': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]])}
train_step: Normalized hidden_state shape: torch.Size([1, 16, 128])
train_step: Normalized stoch shape: torch.Size([16, 1024])
train_step: Normalized deter shape: torch.Size([16, 128])
train_step: Post-imagine_trajectory: Imagined features shape: torch.Size([16, 15, 1152])
train_step: Post-imagine_trajectory: Imagined actions shape: torch.Size([16, 15, 2])
train_step: Post-imagine_trajectory: Imagined action indices shape: torch.Size([16, 15])
train_step: Post-imagine_trajectory: Imagined state deter shape: torch.Size([16, 15, 128])
train_step: Post-imagine_trajectory: Imagined state stoch shape: torch.Size([16, 15, 1024])
Reward shape: torch.Size([16, 15, 1]), Value shape: torch.Size([16, 15, 1]), Slow Value shape: torch.Size([16, 15, 1]), Discount shape: torch.Size([16, 15, 1, 1])
Return targets length: 15, First target shape: torch.Size([16, 16, 1])
train_step: Actor distribution shape: torch.Size([16, 15, 2])
train_step: Action log probabilities shape: torch.Size([16, 15])
train_step: Action log probabilities sample: tensor([[-0.0713, -0.2415],
        [-1.6181, -0.2890]], grad_fn=<SliceBackward0>)
train_step: Advantages shape: torch.Size([16, 15, 16, 15])
train_step: Advantages sample: tensor([[[[-6.4896, -6.4896, -6.4896, -6.4896, -6.4896, -6.4896, -6.4896,
           -6.4896, -6.4896, -6.4896, -6.4896, -6.4896, -6.4896, -6.4896,
           -6.4897],
          [-6.4896, -6.4896, -6.4896, -6.4896, -6.4896, -6.4896, -6.4896,
           -6.4896, -6.4896, -6.4896, -6.4896, -6.4896, -6.4896, -6.4896,
           -6.4897],
          [-6.4896, -6.4896, -6.4896, -6.4896, -6.4896, -6.4896, -6.4896,
           -6.4896, -6.4896, -6.4896, -6.4896, -6.4896, -6.4896, -6.4896,
           -6.4897],
          [-6.4896, -6.4896, -6.4896, -6.4896, -6.4896, -6.4896, -6.4896,
           -6.4896, -6.4896, -6.4896, -6.4896, -6.4896, -6.4896, -6.4896,
           -6.4897],
          [-6.4896, -6.4896, -6.4896, -6.4896, -6.4896, -6.4896, -6.4896,
           -6.4896, -6.4896, -6.4896, -6.4896, -6.4896, -6.4896, -6.4896,
           -6.4897],
          [-6.4896, -6.4896, -6.4896, -6.4896, -6.4896, -6.4896, -6.4896,
           -6.4896, -6.4896, -6.4896, -6.4896, -6.4896, -6.4896, -6.4896,
           -6.4897],
          [-6.4896, -6.4896, -6.4896, -6.4896, -6.4896, -6.4896, -6.4896,
           -6.4896, -6.4896, -6.4896, -6.4896, -6.4896, -6.4896, -6.4896,
           -6.4897],
          [-6.4896, -6.4896, -6.4896, -6.4896, -6.4896, -6.4896, -6.4896,
           -6.4896, -6.4896, -6.4896, -6.4896, -6.4896, -6.4896, -6.4896,
           -6.4897],
          [-6.4896, -6.4896, -6.4896, -6.4896, -6.4896, -6.4896, -6.4896,
           -6.4896, -6.4896, -6.4896, -6.4896, -6.4896, -6.4896, -6.4896,
           -6.4897],
          [-6.4896, -6.4896, -6.4896, -6.4896, -6.4896, -6.4896, -6.4896,
           -6.4896, -6.4896, -6.4896, -6.4896, -6.4896, -6.4896, -6.4896,
           -6.4897],
          [-6.4896, -6.4896, -6.4896, -6.4896, -6.4896, -6.4896, -6.4896,
           -6.4896, -6.4896, -6.4896, -6.4896, -6.4896, -6.4896, -6.4896,
           -6.4897],
          [-6.4896, -6.4896, -6.4896, -6.4896, -6.4896, -6.4896, -6.4896,
           -6.4896, -6.4896, -6.4896, -6.4896, -6.4896, -6.4896, -6.4896,
           -6.4897],
          [-5.9026, -5.9026, -5.9026, -5.9026, -5.9026, -5.9026, -5.9026,
           -5.9026, -5.9026, -5.9026, -5.9026, -5.9026, -5.9026, -5.9026,
           -5.9026],
          [-6.4896, -6.4896, -6.4896, -6.4896, -6.4896, -6.4896, -6.4896,
           -6.4896, -6.4896, -6.4896, -6.4896, -6.4896, -6.4896, -6.4896,
           -6.4897],
          [-6.4896, -6.4896, -6.4896, -6.4896, -6.4896, -6.4896, -6.4896,
           -6.4896, -6.4896, -6.4896, -6.4896, -6.4896, -6.4896, -6.4896,
           -6.4897],
          [-6.4896, -6.4896, -6.4896, -6.4896, -6.4896, -6.4896, -6.4896,
           -6.4896, -6.4896, -6.4896, -6.4896, -6.4896, -6.4896, -6.4896,
           -6.4897]],

         [[-6.2753, -6.2753, -6.2753, -6.2753, -6.2753, -6.2753, -6.2753,
           -6.2753, -6.2753, -6.2753, -6.2753, -6.2753, -6.2753, -6.2753,
           -6.2753],
          [-6.2753, -6.2753, -6.2753, -6.2753, -6.2753, -6.2753, -6.2753,
           -6.2753, -6.2753, -6.2753, -6.2753, -6.2753, -6.2753, -6.2753,
           -6.2753],
          [-6.2753, -6.2753, -6.2753, -6.2753, -6.2753, -6.2753, -6.2753,
           -6.2753, -6.2753, -6.2753, -6.2753, -6.2753, -6.2753, -6.2753,
           -6.2753],
          [-6.2753, -6.2753, -6.2753, -6.2753, -6.2753, -6.2753, -6.2753,
           -6.2753, -6.2753, -6.2753, -6.2753, -6.2753, -6.2753, -6.2753,
           -6.2753],
          [-6.2753, -6.2753, -6.2753, -6.2753, -6.2753, -6.2753, -6.2753,
           -6.2753, -6.2753, -6.2753, -6.2753, -6.2753, -6.2753, -6.2753,
           -6.2753],
          [-6.2753, -6.2753, -6.2753, -6.2753, -6.2753, -6.2753, -6.2753,
           -6.2753, -6.2753, -6.2753, -6.2753, -6.2753, -6.2753, -6.2753,
           -6.2753],
          [-6.2753, -6.2753, -6.2753, -6.2753, -6.2753, -6.2753, -6.2753,
           -6.2753, -6.2753, -6.2753, -6.2753, -6.2753, -6.2753, -6.2753,
           -6.2753],
          [-6.2753, -6.2753, -6.2753, -6.2753, -6.2753, -6.2753, -6.2753,
           -6.2753, -6.2753, -6.2753, -6.2753, -6.2753, -6.2753, -6.2753,
           -6.2753],
          [-6.2753, -6.2753, -6.2753, -6.2753, -6.2753, -6.2753, -6.2753,
           -6.2753, -6.2753, -6.2753, -6.2753, -6.2753, -6.2753, -6.2753,
           -6.2753],
          [-6.2753, -6.2753, -6.2753, -6.2753, -6.2753, -6.2753, -6.2753,
           -6.2753, -6.2753, -6.2753, -6.2753, -6.2753, -6.2753, -6.2753,
           -6.2753],
          [-6.2753, -6.2753, -6.2753, -6.2753, -6.2753, -6.2753, -6.2753,
           -6.2753, -6.2753, -6.2753, -6.2753, -6.2753, -6.2753, -6.2753,
           -6.2753],
          [-6.2753, -6.2753, -6.2753, -6.2753, -6.2753, -6.2753, -6.2753,
           -6.2753, -6.2753, -6.2753, -6.2753, -6.2753, -6.2753, -6.2753,
           -6.2753],
          [-5.6555, -5.6555, -5.6555, -5.6555, -5.6555, -5.6555, -5.6555,
           -5.6555, -5.6555, -5.6555, -5.6555, -5.6555, -5.6555, -5.6555,
           -5.6555],
          [-6.2753, -6.2753, -6.2753, -6.2753, -6.2753, -6.2753, -6.2753,
           -6.2753, -6.2753, -6.2753, -6.2753, -6.2753, -6.2753, -6.2753,
           -6.2753],
          [-6.2753, -6.2753, -6.2753, -6.2753, -6.2753, -6.2753, -6.2753,
           -6.2753, -6.2753, -6.2753, -6.2753, -6.2753, -6.2753, -6.2753,
           -6.2753],
          [-6.2753, -6.2753, -6.2753, -6.2753, -6.2753, -6.2753, -6.2753,
           -6.2753, -6.2753, -6.2753, -6.2753, -6.2753, -6.2753, -6.2753,
           -6.2753]]],


        [[[-6.5288, -6.5288, -6.5288, -6.5288, -6.5288, -6.5288, -6.5288,
           -6.5288, -6.5288, -6.5288, -6.5288, -6.5288, -6.5288, -6.5288,
           -6.5288],
          [-6.5288, -6.5288, -6.5288, -6.5288, -6.5288, -6.5288, -6.5288,
           -6.5288, -6.5288, -6.5288, -6.5288, -6.5288, -6.5288, -6.5288,
           -6.5288],
          [-6.5288, -6.5288, -6.5288, -6.5288, -6.5288, -6.5288, -6.5288,
           -6.5288, -6.5288, -6.5288, -6.5288, -6.5288, -6.5288, -6.5288,
           -6.5288],
          [-6.5288, -6.5288, -6.5288, -6.5288, -6.5288, -6.5288, -6.5288,
           -6.5288, -6.5288, -6.5288, -6.5288, -6.5288, -6.5288, -6.5288,
           -6.5288],
          [-6.5288, -6.5288, -6.5288, -6.5288, -6.5288, -6.5288, -6.5288,
           -6.5288, -6.5288, -6.5288, -6.5288, -6.5288, -6.5288, -6.5288,
           -6.5288],
          [-6.5288, -6.5288, -6.5288, -6.5288, -6.5288, -6.5288, -6.5288,
           -6.5288, -6.5288, -6.5288, -6.5288, -6.5288, -6.5288, -6.5288,
           -6.5288],
          [-6.5288, -6.5288, -6.5288, -6.5288, -6.5288, -6.5288, -6.5288,
           -6.5288, -6.5288, -6.5288, -6.5288, -6.5288, -6.5288, -6.5288,
           -6.5288],
          [-6.5288, -6.5288, -6.5288, -6.5288, -6.5288, -6.5288, -6.5288,
           -6.5288, -6.5288, -6.5288, -6.5288, -6.5288, -6.5288, -6.5288,
           -6.5288],
          [-6.5288, -6.5288, -6.5288, -6.5288, -6.5288, -6.5288, -6.5288,
           -6.5288, -6.5288, -6.5288, -6.5288, -6.5288, -6.5288, -6.5288,
           -6.5288],
          [-6.5288, -6.5288, -6.5288, -6.5288, -6.5288, -6.5288, -6.5288,
           -6.5288, -6.5288, -6.5288, -6.5288, -6.5288, -6.5288, -6.5288,
           -6.5288],
          [-6.5288, -6.5288, -6.5288, -6.5288, -6.5288, -6.5288, -6.5288,
           -6.5288, -6.5288, -6.5288, -6.5288, -6.5288, -6.5288, -6.5288,
           -6.5288],
          [-6.5288, -6.5288, -6.5288, -6.5288, -6.5288, -6.5288, -6.5288,
           -6.5288, -6.5288, -6.5288, -6.5288, -6.5288, -6.5288, -6.5288,
           -6.5288],
          [-6.2314, -6.2314, -6.2314, -6.2314, -6.2314, -6.2314, -6.2314,
           -6.2314, -6.2314, -6.2314, -6.2314, -6.2314, -6.2314, -6.2314,
           -6.2314],
          [-6.5288, -6.5288, -6.5288, -6.5288, -6.5288, -6.5288, -6.5288,
           -6.5288, -6.5288, -6.5288, -6.5288, -6.5288, -6.5288, -6.5288,
           -6.5288],
          [-6.5288, -6.5288, -6.5288, -6.5288, -6.5288, -6.5288, -6.5288,
           -6.5288, -6.5288, -6.5288, -6.5288, -6.5288, -6.5288, -6.5288,
           -6.5288],
          [-6.5288, -6.5288, -6.5288, -6.5288, -6.5288, -6.5288, -6.5288,
           -6.5288, -6.5288, -6.5288, -6.5288, -6.5288, -6.5288, -6.5288,
           -6.5288]],

         [[-5.4663, -5.4663, -5.4663, -5.4663, -5.4663, -5.4663, -5.4663,
           -5.4663, -5.4663, -5.4663, -5.4663, -5.4663, -5.4663, -5.4663,
           -5.4663],
          [-5.4663, -5.4663, -5.4663, -5.4663, -5.4663, -5.4663, -5.4663,
           -5.4663, -5.4663, -5.4663, -5.4663, -5.4663, -5.4663, -5.4663,
           -5.4663],
          [-5.4663, -5.4663, -5.4663, -5.4663, -5.4663, -5.4663, -5.4663,
           -5.4663, -5.4663, -5.4663, -5.4663, -5.4663, -5.4663, -5.4663,
           -5.4663],
          [-5.4663, -5.4663, -5.4663, -5.4663, -5.4663, -5.4663, -5.4663,
           -5.4663, -5.4663, -5.4663, -5.4663, -5.4663, -5.4663, -5.4663,
           -5.4663],
          [-5.4663, -5.4663, -5.4663, -5.4663, -5.4663, -5.4663, -5.4663,
           -5.4663, -5.4663, -5.4663, -5.4663, -5.4663, -5.4663, -5.4663,
           -5.4663],
          [-5.4663, -5.4663, -5.4663, -5.4663, -5.4663, -5.4663, -5.4663,
           -5.4663, -5.4663, -5.4663, -5.4663, -5.4663, -5.4663, -5.4663,
           -5.4663],
          [-5.4663, -5.4663, -5.4663, -5.4663, -5.4663, -5.4663, -5.4663,
           -5.4663, -5.4663, -5.4663, -5.4663, -5.4663, -5.4663, -5.4663,
           -5.4663],
          [-5.4663, -5.4663, -5.4663, -5.4663, -5.4663, -5.4663, -5.4663,
           -5.4663, -5.4663, -5.4663, -5.4663, -5.4663, -5.4663, -5.4663,
           -5.4663],
          [-5.4663, -5.4663, -5.4663, -5.4663, -5.4663, -5.4663, -5.4663,
           -5.4663, -5.4663, -5.4663, -5.4663, -5.4663, -5.4663, -5.4663,
           -5.4663],
          [-5.4663, -5.4663, -5.4663, -5.4663, -5.4663, -5.4663, -5.4663,
           -5.4663, -5.4663, -5.4663, -5.4663, -5.4663, -5.4663, -5.4663,
           -5.4663],
          [-5.4663, -5.4663, -5.4663, -5.4663, -5.4663, -5.4663, -5.4663,
           -5.4663, -5.4663, -5.4663, -5.4663, -5.4663, -5.4663, -5.4663,
           -5.4663],
          [-5.4663, -5.4663, -5.4663, -5.4663, -5.4663, -5.4663, -5.4663,
           -5.4663, -5.4663, -5.4663, -5.4663, -5.4663, -5.4663, -5.4663,
           -5.4663],
          [-5.1523, -5.1522, -5.1523, -5.1522, -5.1522, -5.1523, -5.1523,
           -5.1523, -5.1522, -5.1523, -5.1522, -5.1522, -5.1522, -5.1523,
           -5.1522],
          [-5.4663, -5.4663, -5.4663, -5.4663, -5.4663, -5.4663, -5.4663,
           -5.4663, -5.4663, -5.4663, -5.4663, -5.4663, -5.4663, -5.4663,
           -5.4663],
          [-5.4663, -5.4663, -5.4663, -5.4663, -5.4663, -5.4663, -5.4663,
           -5.4663, -5.4663, -5.4663, -5.4663, -5.4663, -5.4663, -5.4663,
           -5.4663],
          [-5.4663, -5.4663, -5.4663, -5.4663, -5.4663, -5.4663, -5.4663,
           -5.4663, -5.4663, -5.4663, -5.4663, -5.4663, -5.4663, -5.4663,
           -5.4663]]]], grad_fn=<SliceBackward0>)
train_step: Return scale: 1.3934602807232825
train_step: Scaled advantages shape: torch.Size([16, 15, 16, 15])
train_step: Scaled advantages sample: tensor([[[[-4.6572, -4.6572, -4.6572, -4.6572, -4.6572, -4.6572, -4.6572,
           -4.6572, -4.6572, -4.6572, -4.6572, -4.6572, -4.6572, -4.6572,
           -4.6572],
          [-4.6572, -4.6572, -4.6572, -4.6572, -4.6572, -4.6572, -4.6572,
           -4.6572, -4.6572, -4.6572, -4.6572, -4.6572, -4.6572, -4.6572,
           -4.6572],
          [-4.6572, -4.6572, -4.6572, -4.6572, -4.6572, -4.6572, -4.6572,
           -4.6572, -4.6572, -4.6572, -4.6572, -4.6572, -4.6572, -4.6572,
           -4.6572],
          [-4.6572, -4.6572, -4.6572, -4.6572, -4.6572, -4.6572, -4.6572,
           -4.6572, -4.6572, -4.6572, -4.6572, -4.6572, -4.6572, -4.6572,
           -4.6572],
          [-4.6572, -4.6572, -4.6572, -4.6572, -4.6572, -4.6572, -4.6572,
           -4.6572, -4.6572, -4.6572, -4.6572, -4.6572, -4.6572, -4.6572,
           -4.6572],
          [-4.6572, -4.6572, -4.6572, -4.6572, -4.6572, -4.6572, -4.6572,
           -4.6572, -4.6572, -4.6572, -4.6572, -4.6572, -4.6572, -4.6572,
           -4.6572],
          [-4.6572, -4.6572, -4.6572, -4.6572, -4.6572, -4.6572, -4.6572,
           -4.6572, -4.6572, -4.6572, -4.6572, -4.6572, -4.6572, -4.6572,
           -4.6572],
          [-4.6572, -4.6572, -4.6572, -4.6572, -4.6572, -4.6572, -4.6572,
           -4.6572, -4.6572, -4.6572, -4.6572, -4.6572, -4.6572, -4.6572,
           -4.6572],
          [-4.6572, -4.6572, -4.6572, -4.6572, -4.6572, -4.6572, -4.6572,
           -4.6572, -4.6572, -4.6572, -4.6572, -4.6572, -4.6572, -4.6572,
           -4.6572],
          [-4.6572, -4.6572, -4.6572, -4.6572, -4.6572, -4.6572, -4.6572,
           -4.6572, -4.6572, -4.6572, -4.6572, -4.6572, -4.6572, -4.6572,
           -4.6572],
          [-4.6572, -4.6572, -4.6572, -4.6572, -4.6572, -4.6572, -4.6572,
           -4.6572, -4.6572, -4.6572, -4.6572, -4.6572, -4.6572, -4.6572,
           -4.6572],
          [-4.6572, -4.6572, -4.6572, -4.6572, -4.6572, -4.6572, -4.6572,
           -4.6572, -4.6572, -4.6572, -4.6572, -4.6572, -4.6572, -4.6572,
           -4.6572],
          [-4.2360, -4.2360, -4.2360, -4.2360, -4.2360, -4.2360, -4.2360,
           -4.2360, -4.2360, -4.2360, -4.2360, -4.2360, -4.2360, -4.2360,
           -4.2360],
          [-4.6572, -4.6572, -4.6572, -4.6572, -4.6572, -4.6572, -4.6572,
           -4.6572, -4.6572, -4.6572, -4.6572, -4.6572, -4.6572, -4.6572,
           -4.6572],
          [-4.6572, -4.6572, -4.6572, -4.6572, -4.6572, -4.6572, -4.6572,
           -4.6572, -4.6572, -4.6572, -4.6572, -4.6572, -4.6572, -4.6572,
           -4.6572],
          [-4.6572, -4.6572, -4.6572, -4.6572, -4.6572, -4.6572, -4.6572,
           -4.6572, -4.6572, -4.6572, -4.6572, -4.6572, -4.6572, -4.6572,
           -4.6572]],

         [[-4.5034, -4.5034, -4.5034, -4.5034, -4.5034, -4.5034, -4.5034,
           -4.5034, -4.5034, -4.5034, -4.5034, -4.5034, -4.5034, -4.5034,
           -4.5034],
          [-4.5034, -4.5034, -4.5034, -4.5034, -4.5034, -4.5034, -4.5034,
           -4.5034, -4.5034, -4.5034, -4.5034, -4.5034, -4.5034, -4.5034,
           -4.5034],
          [-4.5034, -4.5034, -4.5034, -4.5034, -4.5034, -4.5034, -4.5034,
           -4.5034, -4.5034, -4.5034, -4.5034, -4.5034, -4.5034, -4.5034,
           -4.5034],
          [-4.5034, -4.5034, -4.5034, -4.5034, -4.5034, -4.5034, -4.5034,
           -4.5034, -4.5034, -4.5034, -4.5034, -4.5034, -4.5034, -4.5034,
           -4.5034],
          [-4.5034, -4.5034, -4.5034, -4.5034, -4.5034, -4.5034, -4.5034,
           -4.5034, -4.5034, -4.5034, -4.5034, -4.5034, -4.5034, -4.5034,
           -4.5034],
          [-4.5034, -4.5034, -4.5034, -4.5034, -4.5034, -4.5034, -4.5034,
           -4.5034, -4.5034, -4.5034, -4.5034, -4.5034, -4.5034, -4.5034,
           -4.5034],
          [-4.5034, -4.5034, -4.5034, -4.5034, -4.5034, -4.5034, -4.5034,
           -4.5034, -4.5034, -4.5034, -4.5034, -4.5034, -4.5034, -4.5034,
           -4.5034],
          [-4.5034, -4.5034, -4.5034, -4.5034, -4.5034, -4.5034, -4.5034,
           -4.5034, -4.5034, -4.5034, -4.5034, -4.5034, -4.5034, -4.5034,
           -4.5034],
          [-4.5034, -4.5034, -4.5034, -4.5034, -4.5034, -4.5034, -4.5034,
           -4.5034, -4.5034, -4.5034, -4.5034, -4.5034, -4.5034, -4.5034,
           -4.5034],
          [-4.5034, -4.5034, -4.5034, -4.5034, -4.5034, -4.5034, -4.5034,
           -4.5034, -4.5034, -4.5034, -4.5034, -4.5034, -4.5034, -4.5034,
           -4.5034],
          [-4.5034, -4.5034, -4.5034, -4.5034, -4.5034, -4.5034, -4.5034,
           -4.5034, -4.5034, -4.5034, -4.5034, -4.5034, -4.5034, -4.5034,
           -4.5034],
          [-4.5034, -4.5034, -4.5034, -4.5034, -4.5034, -4.5034, -4.5034,
           -4.5034, -4.5034, -4.5034, -4.5034, -4.5034, -4.5034, -4.5034,
           -4.5034],
          [-4.0586, -4.0586, -4.0586, -4.0586, -4.0586, -4.0586, -4.0586,
           -4.0586, -4.0586, -4.0586, -4.0586, -4.0586, -4.0586, -4.0586,
           -4.0586],
          [-4.5034, -4.5034, -4.5034, -4.5034, -4.5034, -4.5034, -4.5034,
           -4.5034, -4.5034, -4.5034, -4.5034, -4.5034, -4.5034, -4.5034,
           -4.5034],
          [-4.5034, -4.5034, -4.5034, -4.5034, -4.5034, -4.5034, -4.5034,
           -4.5034, -4.5034, -4.5034, -4.5034, -4.5034, -4.5034, -4.5034,
           -4.5034],
          [-4.5034, -4.5034, -4.5034, -4.5034, -4.5034, -4.5034, -4.5034,
           -4.5034, -4.5034, -4.5034, -4.5034, -4.5034, -4.5034, -4.5034,
           -4.5034]]],


        [[[-4.6853, -4.6853, -4.6853, -4.6853, -4.6853, -4.6853, -4.6853,
           -4.6853, -4.6853, -4.6853, -4.6853, -4.6853, -4.6853, -4.6853,
           -4.6853],
          [-4.6853, -4.6853, -4.6853, -4.6853, -4.6853, -4.6853, -4.6853,
           -4.6853, -4.6853, -4.6853, -4.6853, -4.6853, -4.6853, -4.6853,
           -4.6853],
          [-4.6853, -4.6853, -4.6853, -4.6853, -4.6853, -4.6853, -4.6853,
           -4.6853, -4.6853, -4.6853, -4.6853, -4.6853, -4.6853, -4.6853,
           -4.6853],
          [-4.6853, -4.6853, -4.6853, -4.6853, -4.6853, -4.6853, -4.6853,
           -4.6853, -4.6853, -4.6853, -4.6853, -4.6853, -4.6853, -4.6853,
           -4.6853],
          [-4.6853, -4.6853, -4.6853, -4.6853, -4.6853, -4.6853, -4.6853,
           -4.6853, -4.6853, -4.6853, -4.6853, -4.6853, -4.6853, -4.6853,
           -4.6853],
          [-4.6853, -4.6853, -4.6853, -4.6853, -4.6853, -4.6853, -4.6853,
           -4.6853, -4.6853, -4.6853, -4.6853, -4.6853, -4.6853, -4.6853,
           -4.6853],
          [-4.6853, -4.6853, -4.6853, -4.6853, -4.6853, -4.6853, -4.6853,
           -4.6853, -4.6853, -4.6853, -4.6853, -4.6853, -4.6853, -4.6853,
           -4.6853],
          [-4.6853, -4.6853, -4.6853, -4.6853, -4.6853, -4.6853, -4.6853,
           -4.6853, -4.6853, -4.6853, -4.6853, -4.6853, -4.6853, -4.6853,
           -4.6853],
          [-4.6853, -4.6853, -4.6853, -4.6853, -4.6853, -4.6853, -4.6853,
           -4.6853, -4.6853, -4.6853, -4.6853, -4.6853, -4.6853, -4.6853,
           -4.6853],
          [-4.6853, -4.6853, -4.6853, -4.6853, -4.6853, -4.6853, -4.6853,
           -4.6853, -4.6853, -4.6853, -4.6853, -4.6853, -4.6853, -4.6853,
           -4.6853],
          [-4.6853, -4.6853, -4.6853, -4.6853, -4.6853, -4.6853, -4.6853,
           -4.6853, -4.6853, -4.6853, -4.6853, -4.6853, -4.6853, -4.6853,
           -4.6853],
          [-4.6853, -4.6853, -4.6853, -4.6853, -4.6853, -4.6853, -4.6853,
           -4.6853, -4.6853, -4.6853, -4.6853, -4.6853, -4.6853, -4.6853,
           -4.6853],
          [-4.4719, -4.4719, -4.4719, -4.4719, -4.4719, -4.4719, -4.4719,
           -4.4719, -4.4719, -4.4719, -4.4719, -4.4719, -4.4719, -4.4719,
           -4.4719],
          [-4.6853, -4.6853, -4.6853, -4.6853, -4.6853, -4.6853, -4.6853,
           -4.6853, -4.6853, -4.6853, -4.6853, -4.6853, -4.6853, -4.6853,
           -4.6853],
          [-4.6853, -4.6853, -4.6853, -4.6853, -4.6853, -4.6853, -4.6853,
           -4.6853, -4.6853, -4.6853, -4.6853, -4.6853, -4.6853, -4.6853,
           -4.6853],
          [-4.6853, -4.6853, -4.6853, -4.6853, -4.6853, -4.6853, -4.6853,
           -4.6853, -4.6853, -4.6853, -4.6853, -4.6853, -4.6853, -4.6853,
           -4.6853]],

         [[-3.9228, -3.9228, -3.9228, -3.9228, -3.9228, -3.9228, -3.9228,
           -3.9228, -3.9228, -3.9228, -3.9228, -3.9228, -3.9228, -3.9228,
           -3.9228],
          [-3.9228, -3.9228, -3.9228, -3.9228, -3.9228, -3.9228, -3.9228,
           -3.9228, -3.9228, -3.9228, -3.9228, -3.9228, -3.9228, -3.9228,
           -3.9228],
          [-3.9228, -3.9228, -3.9228, -3.9228, -3.9228, -3.9228, -3.9228,
           -3.9228, -3.9228, -3.9228, -3.9228, -3.9228, -3.9228, -3.9228,
           -3.9228],
          [-3.9228, -3.9228, -3.9228, -3.9228, -3.9228, -3.9228, -3.9228,
           -3.9228, -3.9228, -3.9228, -3.9228, -3.9228, -3.9228, -3.9228,
           -3.9228],
          [-3.9228, -3.9228, -3.9228, -3.9228, -3.9228, -3.9228, -3.9228,
           -3.9228, -3.9228, -3.9228, -3.9228, -3.9228, -3.9228, -3.9228,
           -3.9228],
          [-3.9228, -3.9228, -3.9228, -3.9228, -3.9228, -3.9228, -3.9228,
           -3.9228, -3.9228, -3.9228, -3.9228, -3.9228, -3.9228, -3.9228,
           -3.9228],
          [-3.9228, -3.9228, -3.9228, -3.9228, -3.9228, -3.9228, -3.9228,
           -3.9228, -3.9228, -3.9228, -3.9228, -3.9228, -3.9228, -3.9228,
           -3.9228],
          [-3.9228, -3.9228, -3.9228, -3.9228, -3.9228, -3.9228, -3.9228,
           -3.9228, -3.9228, -3.9228, -3.9228, -3.9228, -3.9228, -3.9228,
           -3.9228],
          [-3.9228, -3.9228, -3.9228, -3.9228, -3.9228, -3.9228, -3.9228,
           -3.9228, -3.9228, -3.9228, -3.9228, -3.9228, -3.9228, -3.9228,
           -3.9228],
          [-3.9228, -3.9228, -3.9228, -3.9228, -3.9228, -3.9228, -3.9228,
           -3.9228, -3.9228, -3.9228, -3.9228, -3.9228, -3.9228, -3.9228,
           -3.9228],
          [-3.9228, -3.9228, -3.9228, -3.9228, -3.9228, -3.9228, -3.9228,
           -3.9228, -3.9228, -3.9228, -3.9228, -3.9228, -3.9228, -3.9228,
           -3.9228],
          [-3.9228, -3.9228, -3.9228, -3.9228, -3.9228, -3.9228, -3.9228,
           -3.9228, -3.9228, -3.9228, -3.9228, -3.9228, -3.9228, -3.9228,
           -3.9228],
          [-3.6975, -3.6974, -3.6975, -3.6974, -3.6974, -3.6975, -3.6975,
           -3.6975, -3.6974, -3.6975, -3.6974, -3.6974, -3.6974, -3.6975,
           -3.6974],
          [-3.9228, -3.9228, -3.9228, -3.9228, -3.9228, -3.9228, -3.9228,
           -3.9228, -3.9228, -3.9228, -3.9228, -3.9228, -3.9228, -3.9228,
           -3.9228],
          [-3.9228, -3.9228, -3.9228, -3.9228, -3.9228, -3.9228, -3.9228,
           -3.9228, -3.9228, -3.9228, -3.9228, -3.9228, -3.9228, -3.9228,
           -3.9228],
          [-3.9228, -3.9228, -3.9228, -3.9228, -3.9228, -3.9228, -3.9228,
           -3.9228, -3.9228, -3.9228, -3.9228, -3.9228, -3.9228, -3.9228,
           -3.9228]]]], grad_fn=<SliceBackward0>)
train_step: Entropy shape: torch.Size([16, 15])
train_step: Entropy sample: tensor([[0.2505, 0.5199],
        [0.4980, 0.5634]], grad_fn=<SliceBackward0>)
train_step: Entropy coefficient: 0.01
train_step: Actor loss: -1.6479660272598267
train_step: returns shape after mean: torch.Size([16, 15])
train_step: target_indices shape: torch.Size([16, 15])
train_step: value_logits shape: torch.Size([16, 15, 255])
train_step: target_twohot shape: torch.Size([16, 15, 255])
--- Starting train_step at 2025-04-01 01:58:06 ---
Full starting_state: {'deter': tensor([[[-0.0922,  0.0195, -0.0325,  ...,  0.0428, -0.0045,  0.0119],
         [-0.1555,  0.0794, -0.0430,  ...,  0.0308,  0.0671,  0.2203],
         [-0.1057,  0.0227, -0.0123,  ..., -0.0934,  0.1375, -0.1084],
         ...,
         [ 0.0818, -0.0176, -0.1057,  ...,  0.1279,  0.1267, -0.0830],
         [ 0.0381, -0.0469,  0.1475,  ...,  0.0748, -0.0066,  0.0856],
         [-0.1517,  0.0734, -0.1631,  ..., -0.0859, -0.2145, -0.1605]],

        [[-0.1008, -0.0959, -0.0470,  ...,  0.1792, -0.0141,  0.0518],
         [-0.1117,  0.0976, -0.0013,  ..., -0.0419, -0.0328,  0.0125],
         [-0.0797, -0.0482, -0.0519,  ..., -0.1535,  0.0477, -0.1544],
         ...,
         [-0.0599, -0.0554, -0.0068,  ...,  0.2071,  0.0724,  0.0508],
         [ 0.0116,  0.1381,  0.1305,  ...,  0.0616, -0.0137, -0.1774],
         [ 0.0850, -0.2041,  0.0192,  ...,  0.0867, -0.1378, -0.2391]],

        [[-0.1825, -0.0480,  0.0175,  ...,  0.0241,  0.1022, -0.0175],
         [ 0.0713,  0.0996, -0.0934,  ..., -0.0361, -0.1156, -0.0074],
         [-0.0152, -0.0137, -0.1255,  ...,  0.0223,  0.1520, -0.1641],
         ...,
         [-0.1925,  0.1361,  0.0819,  ..., -0.0476,  0.0523, -0.0291],
         [-0.0576,  0.0131, -0.0487,  ..., -0.1418,  0.0552, -0.0829],
         [ 0.1123,  0.0864,  0.0784,  ..., -0.0021,  0.0786, -0.0232]],

        ...,

        [[ 0.1327,  0.0017, -0.1214,  ..., -0.1011,  0.0016,  0.0924],
         [ 0.0313,  0.0589, -0.0217,  ..., -0.1301, -0.0182, -0.0115],
         [-0.0797, -0.0331,  0.0997,  ...,  0.0570,  0.0612, -0.0425],
         ...,
         [ 0.0305, -0.0172, -0.0397,  ...,  0.1787, -0.1197, -0.0463],
         [-0.0467,  0.0113,  0.0253,  ..., -0.0196, -0.0681, -0.0234],
         [ 0.0147,  0.0357, -0.1870,  ...,  0.1285,  0.0192, -0.0004]],

        [[ 0.0804, -0.0996, -0.0256,  ...,  0.0797, -0.0221, -0.0437],
         [ 0.0097,  0.1074,  0.1244,  ...,  0.0925, -0.0560, -0.0832],
         [ 0.0847, -0.1578, -0.0808,  ..., -0.0148, -0.0882,  0.0527],
         ...,
         [-0.0595, -0.0012,  0.1367,  ..., -0.1157, -0.1594, -0.0186],
         [-0.0448,  0.0398, -0.0736,  ..., -0.1663,  0.0444, -0.0362],
         [ 0.0370,  0.0364, -0.0554,  ...,  0.0227, -0.0343,  0.0311]],

        [[-0.1137,  0.0273, -0.1304,  ...,  0.0673,  0.1323, -0.0205],
         [-0.0663,  0.0717,  0.0684,  ...,  0.0816,  0.0568, -0.0068],
         [-0.0022, -0.0178, -0.1513,  ..., -0.0778, -0.0217, -0.0592],
         ...,
         [-0.0832, -0.0700, -0.0994,  ..., -0.1818,  0.0901, -0.1637],
         [-0.0204,  0.1155, -0.1010,  ..., -0.0159,  0.0107,  0.0695],
         [-0.0923, -0.0218, -0.1852,  ...,  0.0759,  0.0999, -0.1030]]],
       grad_fn=<StackBackward0>), 'stoch': tensor([[[0., 0., 0.,  ..., 1., 0., 0.],
         [1., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 1.,  ..., 0., 0., 1.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 1.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 1.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]])}
train_step: Starting state deter shape: torch.Size([16, 50, 128])
train_step: Starting state stoch shape: torch.Size([16, 50, 1024])
After ensuring logits/stoch: {'deter': tensor([[[-0.0922,  0.0195, -0.0325,  ...,  0.0428, -0.0045,  0.0119],
         [-0.1555,  0.0794, -0.0430,  ...,  0.0308,  0.0671,  0.2203],
         [-0.1057,  0.0227, -0.0123,  ..., -0.0934,  0.1375, -0.1084],
         ...,
         [ 0.0818, -0.0176, -0.1057,  ...,  0.1279,  0.1267, -0.0830],
         [ 0.0381, -0.0469,  0.1475,  ...,  0.0748, -0.0066,  0.0856],
         [-0.1517,  0.0734, -0.1631,  ..., -0.0859, -0.2145, -0.1605]],

        [[-0.1008, -0.0959, -0.0470,  ...,  0.1792, -0.0141,  0.0518],
         [-0.1117,  0.0976, -0.0013,  ..., -0.0419, -0.0328,  0.0125],
         [-0.0797, -0.0482, -0.0519,  ..., -0.1535,  0.0477, -0.1544],
         ...,
         [-0.0599, -0.0554, -0.0068,  ...,  0.2071,  0.0724,  0.0508],
         [ 0.0116,  0.1381,  0.1305,  ...,  0.0616, -0.0137, -0.1774],
         [ 0.0850, -0.2041,  0.0192,  ...,  0.0867, -0.1378, -0.2391]],

        [[-0.1825, -0.0480,  0.0175,  ...,  0.0241,  0.1022, -0.0175],
         [ 0.0713,  0.0996, -0.0934,  ..., -0.0361, -0.1156, -0.0074],
         [-0.0152, -0.0137, -0.1255,  ...,  0.0223,  0.1520, -0.1641],
         ...,
         [-0.1925,  0.1361,  0.0819,  ..., -0.0476,  0.0523, -0.0291],
         [-0.0576,  0.0131, -0.0487,  ..., -0.1418,  0.0552, -0.0829],
         [ 0.1123,  0.0864,  0.0784,  ..., -0.0021,  0.0786, -0.0232]],

        ...,

        [[ 0.1327,  0.0017, -0.1214,  ..., -0.1011,  0.0016,  0.0924],
         [ 0.0313,  0.0589, -0.0217,  ..., -0.1301, -0.0182, -0.0115],
         [-0.0797, -0.0331,  0.0997,  ...,  0.0570,  0.0612, -0.0425],
         ...,
         [ 0.0305, -0.0172, -0.0397,  ...,  0.1787, -0.1197, -0.0463],
         [-0.0467,  0.0113,  0.0253,  ..., -0.0196, -0.0681, -0.0234],
         [ 0.0147,  0.0357, -0.1870,  ...,  0.1285,  0.0192, -0.0004]],

        [[ 0.0804, -0.0996, -0.0256,  ...,  0.0797, -0.0221, -0.0437],
         [ 0.0097,  0.1074,  0.1244,  ...,  0.0925, -0.0560, -0.0832],
         [ 0.0847, -0.1578, -0.0808,  ..., -0.0148, -0.0882,  0.0527],
         ...,
         [-0.0595, -0.0012,  0.1367,  ..., -0.1157, -0.1594, -0.0186],
         [-0.0448,  0.0398, -0.0736,  ..., -0.1663,  0.0444, -0.0362],
         [ 0.0370,  0.0364, -0.0554,  ...,  0.0227, -0.0343,  0.0311]],

        [[-0.1137,  0.0273, -0.1304,  ...,  0.0673,  0.1323, -0.0205],
         [-0.0663,  0.0717,  0.0684,  ...,  0.0816,  0.0568, -0.0068],
         [-0.0022, -0.0178, -0.1513,  ..., -0.0778, -0.0217, -0.0592],
         ...,
         [-0.0832, -0.0700, -0.0994,  ..., -0.1818,  0.0901, -0.1637],
         [-0.0204,  0.1155, -0.1010,  ..., -0.0159,  0.0107,  0.0695],
         [-0.0923, -0.0218, -0.1852,  ...,  0.0759,  0.0999, -0.1030]]],
       grad_fn=<StackBackward0>), 'stoch': tensor([[[0., 0., 0.,  ..., 1., 0., 0.],
         [1., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 1.,  ..., 0., 0., 1.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 1.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 1.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]]), 'logits': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]])}
train_step: Normalized hidden_state shape: torch.Size([1, 16, 128])
train_step: Normalized stoch shape: torch.Size([16, 1024])
train_step: Normalized deter shape: torch.Size([16, 128])
train_step: Post-imagine_trajectory: Imagined features shape: torch.Size([16, 15, 1152])
train_step: Post-imagine_trajectory: Imagined actions shape: torch.Size([16, 15, 2])
train_step: Post-imagine_trajectory: Imagined action indices shape: torch.Size([16, 15])
train_step: Post-imagine_trajectory: Imagined state deter shape: torch.Size([16, 15, 128])
train_step: Post-imagine_trajectory: Imagined state stoch shape: torch.Size([16, 15, 1024])
Reward shape: torch.Size([16, 15, 1]), Value shape: torch.Size([16, 15, 1]), Slow Value shape: torch.Size([16, 15, 1]), Discount shape: torch.Size([16, 15, 1, 1])
Return targets length: 15, First target shape: torch.Size([16, 16, 1])
train_step: Actor distribution shape: torch.Size([16, 15, 2])
train_step: Action log probabilities shape: torch.Size([16, 15])
train_step: Action log probabilities sample: tensor([[-0.3252, -0.9768],
        [-0.3446, -0.1920]], grad_fn=<SliceBackward0>)
train_step: Advantages shape: torch.Size([16, 15, 16, 15])
train_step: Advantages sample: tensor([[[[-7.4516, -7.4516, -7.4516, -7.4516, -7.4516, -7.4516, -7.4516,
           -7.4516, -7.4516, -7.4516, -7.4516, -7.4516, -7.4516, -7.4516,
           -7.4516],
          [-7.4516, -7.4516, -7.4516, -7.4516, -7.4516, -7.4516, -7.4516,
           -7.4516, -7.4516, -7.4516, -7.4516, -7.4516, -7.4516, -7.4516,
           -7.4516],
          [-7.4516, -7.4516, -7.4516, -7.4516, -7.4516, -7.4516, -7.4516,
           -7.4516, -7.4516, -7.4516, -7.4516, -7.4516, -7.4516, -7.4516,
           -7.4516],
          [-7.4516, -7.4516, -7.4516, -7.4516, -7.4516, -7.4516, -7.4516,
           -7.4516, -7.4516, -7.4516, -7.4516, -7.4516, -7.4516, -7.4516,
           -7.4516],
          [-7.4516, -7.4516, -7.4516, -7.4516, -7.4516, -7.4516, -7.4516,
           -7.4516, -7.4516, -7.4516, -7.4516, -7.4516, -7.4516, -7.4516,
           -7.4516],
          [-7.4516, -7.4516, -7.4516, -7.4516, -7.4516, -7.4516, -7.4516,
           -7.4516, -7.4516, -7.4516, -7.4516, -7.4516, -7.4516, -7.4516,
           -7.4516],
          [-7.4516, -7.4516, -7.4516, -7.4516, -7.4516, -7.4516, -7.4516,
           -7.4516, -7.4516, -7.4516, -7.4516, -7.4516, -7.4516, -7.4516,
           -7.4516],
          [-7.4516, -7.4516, -7.4516, -7.4516, -7.4516, -7.4516, -7.4516,
           -7.4516, -7.4516, -7.4516, -7.4516, -7.4516, -7.4516, -7.4516,
           -7.4516],
          [-7.4516, -7.4516, -7.4516, -7.4516, -7.4516, -7.4516, -7.4516,
           -7.4516, -7.4516, -7.4516, -7.4516, -7.4516, -7.4516, -7.4516,
           -7.4516],
          [-1.1572, -1.1572, -1.1572, -1.1572, -1.1572, -1.1572, -1.1572,
           -1.1572, -1.1572, -1.1572, -1.1572, -1.1572, -1.1572, -1.1572,
           -1.1572],
          [-7.4516, -7.4516, -7.4516, -7.4516, -7.4516, -7.4516, -7.4516,
           -7.4516, -7.4516, -7.4516, -7.4516, -7.4516, -7.4516, -7.4516,
           -7.4516],
          [-7.4516, -7.4516, -7.4516, -7.4516, -7.4516, -7.4516, -7.4516,
           -7.4516, -7.4516, -7.4516, -7.4516, -7.4516, -7.4516, -7.4516,
           -7.4516],
          [-7.4516, -7.4516, -7.4516, -7.4516, -7.4516, -7.4516, -7.4516,
           -7.4516, -7.4516, -7.4516, -7.4516, -7.4516, -7.4516, -7.4516,
           -7.4516],
          [-7.4516, -7.4516, -7.4516, -7.4516, -7.4516, -7.4516, -7.4516,
           -7.4516, -7.4516, -7.4516, -7.4516, -7.4516, -7.4516, -7.4516,
           -7.4516],
          [-7.4516, -7.4516, -7.4516, -7.4516, -7.4516, -7.4516, -7.4516,
           -7.4516, -7.4516, -7.4516, -7.4516, -7.4516, -7.4516, -7.4516,
           -7.4516],
          [-7.4516, -7.4516, -7.4516, -7.4516, -7.4516, -7.4516, -7.4516,
           -7.4516, -7.4516, -7.4516, -7.4516, -7.4516, -7.4516, -7.4516,
           -7.4516]],

         [[-6.6456, -6.6456, -6.6456, -6.6456, -6.6456, -6.6456, -6.6456,
           -6.6456, -6.6456, -6.6456, -6.6456, -6.6456, -6.6456, -6.6456,
           -6.6456],
          [-6.6456, -6.6456, -6.6456, -6.6456, -6.6456, -6.6456, -6.6456,
           -6.6456, -6.6456, -6.6456, -6.6456, -6.6456, -6.6456, -6.6456,
           -6.6456],
          [-6.6456, -6.6456, -6.6456, -6.6456, -6.6456, -6.6456, -6.6456,
           -6.6456, -6.6456, -6.6456, -6.6456, -6.6456, -6.6456, -6.6456,
           -6.6456],
          [-6.6456, -6.6456, -6.6456, -6.6456, -6.6456, -6.6456, -6.6456,
           -6.6456, -6.6456, -6.6456, -6.6456, -6.6456, -6.6456, -6.6456,
           -6.6456],
          [-6.6456, -6.6456, -6.6456, -6.6456, -6.6456, -6.6456, -6.6456,
           -6.6456, -6.6456, -6.6456, -6.6456, -6.6456, -6.6456, -6.6456,
           -6.6456],
          [-6.6456, -6.6456, -6.6456, -6.6456, -6.6456, -6.6456, -6.6456,
           -6.6456, -6.6456, -6.6456, -6.6456, -6.6456, -6.6456, -6.6456,
           -6.6456],
          [-6.6456, -6.6456, -6.6456, -6.6456, -6.6456, -6.6456, -6.6456,
           -6.6456, -6.6456, -6.6456, -6.6456, -6.6456, -6.6456, -6.6456,
           -6.6456],
          [-6.6456, -6.6456, -6.6456, -6.6456, -6.6456, -6.6456, -6.6456,
           -6.6456, -6.6456, -6.6456, -6.6456, -6.6456, -6.6456, -6.6456,
           -6.6456],
          [-6.6456, -6.6456, -6.6456, -6.6456, -6.6456, -6.6456, -6.6456,
           -6.6456, -6.6456, -6.6456, -6.6456, -6.6456, -6.6456, -6.6456,
           -6.6456],
          [-6.6456, -6.6456, -6.6456, -6.6456, -6.6456, -6.6456, -6.6456,
           -6.6456, -6.6456, -6.6456, -6.6456, -6.6456, -6.6456, -6.6456,
           -6.6456],
          [-6.6456, -6.6456, -6.6456, -6.6456, -6.6456, -6.6456, -6.6456,
           -6.6456, -6.6456, -6.6456, -6.6456, -6.6456, -6.6456, -6.6456,
           -6.6456],
          [-6.6456, -6.6456, -6.6456, -6.6456, -6.6456, -6.6456, -6.6456,
           -6.6456, -6.6456, -6.6456, -6.6456, -6.6456, -6.6456, -6.6456,
           -6.6456],
          [-6.6456, -6.6456, -6.6456, -6.6456, -6.6456, -6.6456, -6.6456,
           -6.6456, -6.6456, -6.6456, -6.6456, -6.6456, -6.6456, -6.6456,
           -6.6456],
          [-6.6456, -6.6456, -6.6456, -6.6456, -6.6456, -6.6456, -6.6456,
           -6.6456, -6.6456, -6.6456, -6.6456, -6.6456, -6.6456, -6.6456,
           -6.6456],
          [-6.6456, -6.6456, -6.6456, -6.6456, -6.6456, -6.6456, -6.6456,
           -6.6456, -6.6456, -6.6456, -6.6456, -6.6456, -6.6456, -6.6456,
           -6.6456],
          [-6.6456, -6.6456, -6.6456, -6.6456, -6.6456, -6.6456, -6.6456,
           -6.6456, -6.6456, -6.6456, -6.6456, -6.6456, -6.6456, -6.6456,
           -6.6456]]],


        [[[-6.0644, -6.0643, -6.0644, -6.0644, -6.0643, -6.0644, -6.0643,
           -6.0644, -6.0643, -6.0644, -6.0644, -6.0643, -6.0643, -6.0643,
           -6.0644],
          [-6.0644, -6.0643, -6.0644, -6.0644, -6.0643, -6.0644, -6.0643,
           -6.0644, -6.0643, -6.0644, -6.0644, -6.0643, -6.0643, -6.0643,
           -6.0644],
          [-6.0644, -6.0643, -6.0644, -6.0644, -6.0643, -6.0644, -6.0643,
           -6.0644, -6.0643, -6.0644, -6.0644, -6.0643, -6.0643, -6.0643,
           -6.0644],
          [-6.0644, -6.0643, -6.0644, -6.0644, -6.0643, -6.0644, -6.0643,
           -6.0644, -6.0643, -6.0644, -6.0644, -6.0643, -6.0643, -6.0643,
           -6.0644],
          [-6.0644, -6.0643, -6.0644, -6.0644, -6.0643, -6.0644, -6.0643,
           -6.0644, -6.0643, -6.0644, -6.0644, -6.0643, -6.0643, -6.0643,
           -6.0644],
          [-6.0644, -6.0643, -6.0644, -6.0644, -6.0643, -6.0644, -6.0643,
           -6.0644, -6.0643, -6.0644, -6.0644, -6.0643, -6.0643, -6.0643,
           -6.0644],
          [-6.0644, -6.0643, -6.0644, -6.0644, -6.0643, -6.0644, -6.0643,
           -6.0644, -6.0643, -6.0644, -6.0644, -6.0643, -6.0643, -6.0643,
           -6.0644],
          [-6.0644, -6.0643, -6.0644, -6.0644, -6.0643, -6.0644, -6.0643,
           -6.0644, -6.0643, -6.0644, -6.0644, -6.0643, -6.0643, -6.0643,
           -6.0644],
          [-6.0644, -6.0643, -6.0644, -6.0644, -6.0643, -6.0644, -6.0643,
           -6.0644, -6.0643, -6.0644, -6.0644, -6.0643, -6.0643, -6.0643,
           -6.0644],
          [-0.5636, -0.5636, -0.5636, -0.5636, -0.5636, -0.5636, -0.5636,
           -0.5636, -0.5636, -0.5636, -0.5636, -0.5636, -0.5636, -0.5636,
           -0.5636],
          [-6.0644, -6.0643, -6.0644, -6.0644, -6.0643, -6.0644, -6.0643,
           -6.0644, -6.0643, -6.0644, -6.0644, -6.0643, -6.0643, -6.0643,
           -6.0644],
          [-6.0644, -6.0643, -6.0644, -6.0644, -6.0643, -6.0644, -6.0643,
           -6.0644, -6.0643, -6.0644, -6.0644, -6.0643, -6.0643, -6.0643,
           -6.0644],
          [-6.0644, -6.0643, -6.0644, -6.0644, -6.0643, -6.0644, -6.0643,
           -6.0644, -6.0643, -6.0644, -6.0644, -6.0643, -6.0643, -6.0643,
           -6.0644],
          [-6.0644, -6.0643, -6.0644, -6.0644, -6.0643, -6.0644, -6.0643,
           -6.0644, -6.0643, -6.0644, -6.0644, -6.0643, -6.0643, -6.0643,
           -6.0644],
          [-6.0644, -6.0643, -6.0644, -6.0644, -6.0643, -6.0644, -6.0643,
           -6.0644, -6.0643, -6.0644, -6.0644, -6.0643, -6.0643, -6.0643,
           -6.0644],
          [-6.0644, -6.0643, -6.0644, -6.0644, -6.0643, -6.0644, -6.0643,
           -6.0644, -6.0643, -6.0644, -6.0644, -6.0643, -6.0643, -6.0643,
           -6.0644]],

         [[-5.8076, -5.8076, -5.8076, -5.8076, -5.8076, -5.8076, -5.8076,
           -5.8076, -5.8076, -5.8076, -5.8076, -5.8076, -5.8076, -5.8076,
           -5.8076],
          [-5.8076, -5.8076, -5.8076, -5.8076, -5.8076, -5.8076, -5.8076,
           -5.8076, -5.8076, -5.8076, -5.8076, -5.8076, -5.8076, -5.8076,
           -5.8076],
          [-5.8076, -5.8076, -5.8076, -5.8076, -5.8076, -5.8076, -5.8076,
           -5.8076, -5.8076, -5.8076, -5.8076, -5.8076, -5.8076, -5.8076,
           -5.8076],
          [-5.8076, -5.8076, -5.8076, -5.8076, -5.8076, -5.8076, -5.8076,
           -5.8076, -5.8076, -5.8076, -5.8076, -5.8076, -5.8076, -5.8076,
           -5.8076],
          [-5.8076, -5.8076, -5.8076, -5.8076, -5.8076, -5.8076, -5.8076,
           -5.8076, -5.8076, -5.8076, -5.8076, -5.8076, -5.8076, -5.8076,
           -5.8076],
          [-5.8076, -5.8076, -5.8076, -5.8076, -5.8076, -5.8076, -5.8076,
           -5.8076, -5.8076, -5.8076, -5.8076, -5.8076, -5.8076, -5.8076,
           -5.8076],
          [-5.8076, -5.8076, -5.8076, -5.8076, -5.8076, -5.8076, -5.8076,
           -5.8076, -5.8076, -5.8076, -5.8076, -5.8076, -5.8076, -5.8076,
           -5.8076],
          [-5.8076, -5.8076, -5.8076, -5.8076, -5.8076, -5.8076, -5.8076,
           -5.8076, -5.8076, -5.8076, -5.8076, -5.8076, -5.8076, -5.8076,
           -5.8076],
          [-5.8076, -5.8076, -5.8076, -5.8076, -5.8076, -5.8076, -5.8076,
           -5.8076, -5.8076, -5.8076, -5.8076, -5.8076, -5.8076, -5.8076,
           -5.8076],
          [-5.8076, -5.8076, -5.8076, -5.8076, -5.8076, -5.8076, -5.8076,
           -5.8076, -5.8076, -5.8076, -5.8076, -5.8076, -5.8076, -5.8076,
           -5.8076],
          [-5.8076, -5.8076, -5.8076, -5.8076, -5.8076, -5.8076, -5.8076,
           -5.8076, -5.8076, -5.8076, -5.8076, -5.8076, -5.8076, -5.8076,
           -5.8076],
          [-5.8076, -5.8076, -5.8076, -5.8076, -5.8076, -5.8076, -5.8076,
           -5.8076, -5.8076, -5.8076, -5.8076, -5.8076, -5.8076, -5.8076,
           -5.8076],
          [-5.8076, -5.8076, -5.8076, -5.8076, -5.8076, -5.8076, -5.8076,
           -5.8076, -5.8076, -5.8076, -5.8076, -5.8076, -5.8076, -5.8076,
           -5.8076],
          [-5.8076, -5.8076, -5.8076, -5.8076, -5.8076, -5.8076, -5.8076,
           -5.8076, -5.8076, -5.8076, -5.8076, -5.8076, -5.8076, -5.8076,
           -5.8076],
          [-5.8076, -5.8076, -5.8076, -5.8076, -5.8076, -5.8076, -5.8076,
           -5.8076, -5.8076, -5.8076, -5.8076, -5.8076, -5.8076, -5.8076,
           -5.8076],
          [-5.8076, -5.8076, -5.8076, -5.8076, -5.8076, -5.8076, -5.8076,
           -5.8076, -5.8076, -5.8076, -5.8076, -5.8076, -5.8076, -5.8076,
           -5.8076]]]], grad_fn=<SliceBackward0>)
train_step: Return scale: 1.4501611665453908
train_step: Scaled advantages shape: torch.Size([16, 15, 16, 15])
train_step: Scaled advantages sample: tensor([[[[-5.1385, -5.1385, -5.1385, -5.1385, -5.1385, -5.1385, -5.1385,
           -5.1385, -5.1385, -5.1385, -5.1385, -5.1385, -5.1385, -5.1385,
           -5.1385],
          [-5.1385, -5.1385, -5.1385, -5.1385, -5.1385, -5.1385, -5.1385,
           -5.1385, -5.1385, -5.1385, -5.1385, -5.1385, -5.1385, -5.1385,
           -5.1385],
          [-5.1385, -5.1385, -5.1385, -5.1385, -5.1385, -5.1385, -5.1385,
           -5.1385, -5.1385, -5.1385, -5.1385, -5.1385, -5.1385, -5.1385,
           -5.1385],
          [-5.1385, -5.1385, -5.1385, -5.1385, -5.1385, -5.1385, -5.1385,
           -5.1385, -5.1385, -5.1385, -5.1385, -5.1385, -5.1385, -5.1385,
           -5.1385],
          [-5.1385, -5.1385, -5.1385, -5.1385, -5.1385, -5.1385, -5.1385,
           -5.1385, -5.1385, -5.1385, -5.1385, -5.1385, -5.1385, -5.1385,
           -5.1385],
          [-5.1385, -5.1385, -5.1385, -5.1385, -5.1385, -5.1385, -5.1385,
           -5.1385, -5.1385, -5.1385, -5.1385, -5.1385, -5.1385, -5.1385,
           -5.1385],
          [-5.1385, -5.1385, -5.1385, -5.1385, -5.1385, -5.1385, -5.1385,
           -5.1385, -5.1385, -5.1385, -5.1385, -5.1385, -5.1385, -5.1385,
           -5.1385],
          [-5.1385, -5.1385, -5.1385, -5.1385, -5.1385, -5.1385, -5.1385,
           -5.1385, -5.1385, -5.1385, -5.1385, -5.1385, -5.1385, -5.1385,
           -5.1385],
          [-5.1385, -5.1385, -5.1385, -5.1385, -5.1385, -5.1385, -5.1385,
           -5.1385, -5.1385, -5.1385, -5.1385, -5.1385, -5.1385, -5.1385,
           -5.1385],
          [-0.7980, -0.7980, -0.7980, -0.7980, -0.7980, -0.7980, -0.7980,
           -0.7980, -0.7980, -0.7980, -0.7980, -0.7980, -0.7980, -0.7980,
           -0.7980],
          [-5.1385, -5.1385, -5.1385, -5.1385, -5.1385, -5.1385, -5.1385,
           -5.1385, -5.1385, -5.1385, -5.1385, -5.1385, -5.1385, -5.1385,
           -5.1385],
          [-5.1385, -5.1385, -5.1385, -5.1385, -5.1385, -5.1385, -5.1385,
           -5.1385, -5.1385, -5.1385, -5.1385, -5.1385, -5.1385, -5.1385,
           -5.1385],
          [-5.1385, -5.1385, -5.1385, -5.1385, -5.1385, -5.1385, -5.1385,
           -5.1385, -5.1385, -5.1385, -5.1385, -5.1385, -5.1385, -5.1385,
           -5.1385],
          [-5.1385, -5.1385, -5.1385, -5.1385, -5.1385, -5.1385, -5.1385,
           -5.1385, -5.1385, -5.1385, -5.1385, -5.1385, -5.1385, -5.1385,
           -5.1385],
          [-5.1385, -5.1385, -5.1385, -5.1385, -5.1385, -5.1385, -5.1385,
           -5.1385, -5.1385, -5.1385, -5.1385, -5.1385, -5.1385, -5.1385,
           -5.1385],
          [-5.1385, -5.1385, -5.1385, -5.1385, -5.1385, -5.1385, -5.1385,
           -5.1385, -5.1385, -5.1385, -5.1385, -5.1385, -5.1385, -5.1385,
           -5.1385]],

         [[-4.5826, -4.5826, -4.5826, -4.5827, -4.5826, -4.5826, -4.5826,
           -4.5826, -4.5826, -4.5826, -4.5826, -4.5826, -4.5826, -4.5826,
           -4.5826],
          [-4.5826, -4.5826, -4.5826, -4.5827, -4.5826, -4.5826, -4.5826,
           -4.5826, -4.5826, -4.5826, -4.5826, -4.5826, -4.5826, -4.5826,
           -4.5826],
          [-4.5826, -4.5826, -4.5826, -4.5827, -4.5826, -4.5826, -4.5826,
           -4.5826, -4.5826, -4.5826, -4.5826, -4.5826, -4.5826, -4.5826,
           -4.5826],
          [-4.5826, -4.5826, -4.5826, -4.5827, -4.5826, -4.5826, -4.5826,
           -4.5826, -4.5826, -4.5826, -4.5826, -4.5826, -4.5826, -4.5826,
           -4.5826],
          [-4.5826, -4.5826, -4.5826, -4.5827, -4.5826, -4.5826, -4.5826,
           -4.5826, -4.5826, -4.5826, -4.5826, -4.5826, -4.5826, -4.5826,
           -4.5826],
          [-4.5826, -4.5826, -4.5826, -4.5827, -4.5826, -4.5826, -4.5826,
           -4.5826, -4.5826, -4.5826, -4.5826, -4.5826, -4.5826, -4.5826,
           -4.5826],
          [-4.5826, -4.5826, -4.5826, -4.5827, -4.5826, -4.5826, -4.5826,
           -4.5826, -4.5826, -4.5826, -4.5826, -4.5826, -4.5826, -4.5826,
           -4.5826],
          [-4.5826, -4.5826, -4.5826, -4.5827, -4.5826, -4.5826, -4.5826,
           -4.5826, -4.5826, -4.5826, -4.5826, -4.5826, -4.5826, -4.5826,
           -4.5826],
          [-4.5826, -4.5826, -4.5826, -4.5827, -4.5826, -4.5826, -4.5826,
           -4.5826, -4.5826, -4.5826, -4.5826, -4.5826, -4.5826, -4.5826,
           -4.5826],
          [-4.5826, -4.5826, -4.5826, -4.5827, -4.5826, -4.5826, -4.5826,
           -4.5826, -4.5826, -4.5826, -4.5826, -4.5826, -4.5826, -4.5826,
           -4.5826],
          [-4.5826, -4.5826, -4.5826, -4.5827, -4.5826, -4.5826, -4.5826,
           -4.5826, -4.5826, -4.5826, -4.5826, -4.5826, -4.5826, -4.5826,
           -4.5826],
          [-4.5826, -4.5826, -4.5826, -4.5827, -4.5826, -4.5826, -4.5826,
           -4.5826, -4.5826, -4.5826, -4.5826, -4.5826, -4.5826, -4.5826,
           -4.5826],
          [-4.5826, -4.5826, -4.5826, -4.5827, -4.5826, -4.5826, -4.5826,
           -4.5826, -4.5826, -4.5826, -4.5826, -4.5826, -4.5826, -4.5826,
           -4.5826],
          [-4.5826, -4.5826, -4.5826, -4.5827, -4.5826, -4.5826, -4.5826,
           -4.5826, -4.5826, -4.5826, -4.5826, -4.5826, -4.5826, -4.5826,
           -4.5826],
          [-4.5826, -4.5826, -4.5826, -4.5827, -4.5826, -4.5826, -4.5826,
           -4.5826, -4.5826, -4.5826, -4.5826, -4.5826, -4.5826, -4.5826,
           -4.5826],
          [-4.5826, -4.5826, -4.5826, -4.5827, -4.5826, -4.5826, -4.5826,
           -4.5826, -4.5826, -4.5826, -4.5826, -4.5826, -4.5826, -4.5826,
           -4.5826]]],


        [[[-4.1818, -4.1818, -4.1818, -4.1818, -4.1818, -4.1818, -4.1818,
           -4.1818, -4.1818, -4.1818, -4.1818, -4.1818, -4.1818, -4.1818,
           -4.1818],
          [-4.1818, -4.1818, -4.1818, -4.1818, -4.1818, -4.1818, -4.1818,
           -4.1818, -4.1818, -4.1818, -4.1818, -4.1818, -4.1818, -4.1818,
           -4.1818],
          [-4.1818, -4.1818, -4.1818, -4.1818, -4.1818, -4.1818, -4.1818,
           -4.1818, -4.1818, -4.1818, -4.1818, -4.1818, -4.1818, -4.1818,
           -4.1818],
          [-4.1818, -4.1818, -4.1818, -4.1818, -4.1818, -4.1818, -4.1818,
           -4.1818, -4.1818, -4.1818, -4.1818, -4.1818, -4.1818, -4.1818,
           -4.1818],
          [-4.1818, -4.1818, -4.1818, -4.1818, -4.1818, -4.1818, -4.1818,
           -4.1818, -4.1818, -4.1818, -4.1818, -4.1818, -4.1818, -4.1818,
           -4.1818],
          [-4.1818, -4.1818, -4.1818, -4.1818, -4.1818, -4.1818, -4.1818,
           -4.1818, -4.1818, -4.1818, -4.1818, -4.1818, -4.1818, -4.1818,
           -4.1818],
          [-4.1818, -4.1818, -4.1818, -4.1818, -4.1818, -4.1818, -4.1818,
           -4.1818, -4.1818, -4.1818, -4.1818, -4.1818, -4.1818, -4.1818,
           -4.1818],
          [-4.1818, -4.1818, -4.1818, -4.1818, -4.1818, -4.1818, -4.1818,
           -4.1818, -4.1818, -4.1818, -4.1818, -4.1818, -4.1818, -4.1818,
           -4.1818],
          [-4.1818, -4.1818, -4.1818, -4.1818, -4.1818, -4.1818, -4.1818,
           -4.1818, -4.1818, -4.1818, -4.1818, -4.1818, -4.1818, -4.1818,
           -4.1818],
          [-0.5636, -0.5636, -0.5636, -0.5636, -0.5636, -0.5636, -0.5636,
           -0.5636, -0.5636, -0.5636, -0.5636, -0.5636, -0.5636, -0.5636,
           -0.5636],
          [-4.1818, -4.1818, -4.1818, -4.1818, -4.1818, -4.1818, -4.1818,
           -4.1818, -4.1818, -4.1818, -4.1818, -4.1818, -4.1818, -4.1818,
           -4.1818],
          [-4.1818, -4.1818, -4.1818, -4.1818, -4.1818, -4.1818, -4.1818,
           -4.1818, -4.1818, -4.1818, -4.1818, -4.1818, -4.1818, -4.1818,
           -4.1818],
          [-4.1818, -4.1818, -4.1818, -4.1818, -4.1818, -4.1818, -4.1818,
           -4.1818, -4.1818, -4.1818, -4.1818, -4.1818, -4.1818, -4.1818,
           -4.1818],
          [-4.1818, -4.1818, -4.1818, -4.1818, -4.1818, -4.1818, -4.1818,
           -4.1818, -4.1818, -4.1818, -4.1818, -4.1818, -4.1818, -4.1818,
           -4.1818],
          [-4.1818, -4.1818, -4.1818, -4.1818, -4.1818, -4.1818, -4.1818,
           -4.1818, -4.1818, -4.1818, -4.1818, -4.1818, -4.1818, -4.1818,
           -4.1818],
          [-4.1818, -4.1818, -4.1818, -4.1818, -4.1818, -4.1818, -4.1818,
           -4.1818, -4.1818, -4.1818, -4.1818, -4.1818, -4.1818, -4.1818,
           -4.1818]],

         [[-4.0048, -4.0048, -4.0048, -4.0048, -4.0048, -4.0048, -4.0048,
           -4.0048, -4.0048, -4.0048, -4.0048, -4.0048, -4.0048, -4.0048,
           -4.0048],
          [-4.0048, -4.0048, -4.0048, -4.0048, -4.0048, -4.0048, -4.0048,
           -4.0048, -4.0048, -4.0048, -4.0048, -4.0048, -4.0048, -4.0048,
           -4.0048],
          [-4.0048, -4.0048, -4.0048, -4.0048, -4.0048, -4.0048, -4.0048,
           -4.0048, -4.0048, -4.0048, -4.0048, -4.0048, -4.0048, -4.0048,
           -4.0048],
          [-4.0048, -4.0048, -4.0048, -4.0048, -4.0048, -4.0048, -4.0048,
           -4.0048, -4.0048, -4.0048, -4.0048, -4.0048, -4.0048, -4.0048,
           -4.0048],
          [-4.0048, -4.0048, -4.0048, -4.0048, -4.0048, -4.0048, -4.0048,
           -4.0048, -4.0048, -4.0048, -4.0048, -4.0048, -4.0048, -4.0048,
           -4.0048],
          [-4.0048, -4.0048, -4.0048, -4.0048, -4.0048, -4.0048, -4.0048,
           -4.0048, -4.0048, -4.0048, -4.0048, -4.0048, -4.0048, -4.0048,
           -4.0048],
          [-4.0048, -4.0048, -4.0048, -4.0048, -4.0048, -4.0048, -4.0048,
           -4.0048, -4.0048, -4.0048, -4.0048, -4.0048, -4.0048, -4.0048,
           -4.0048],
          [-4.0048, -4.0048, -4.0048, -4.0048, -4.0048, -4.0048, -4.0048,
           -4.0048, -4.0048, -4.0048, -4.0048, -4.0048, -4.0048, -4.0048,
           -4.0048],
          [-4.0048, -4.0048, -4.0048, -4.0048, -4.0048, -4.0048, -4.0048,
           -4.0048, -4.0048, -4.0048, -4.0048, -4.0048, -4.0048, -4.0048,
           -4.0048],
          [-4.0048, -4.0048, -4.0048, -4.0048, -4.0048, -4.0048, -4.0048,
           -4.0048, -4.0048, -4.0048, -4.0048, -4.0048, -4.0048, -4.0048,
           -4.0048],
          [-4.0048, -4.0048, -4.0048, -4.0048, -4.0048, -4.0048, -4.0048,
           -4.0048, -4.0048, -4.0048, -4.0048, -4.0048, -4.0048, -4.0048,
           -4.0048],
          [-4.0048, -4.0048, -4.0048, -4.0048, -4.0048, -4.0048, -4.0048,
           -4.0048, -4.0048, -4.0048, -4.0048, -4.0048, -4.0048, -4.0048,
           -4.0048],
          [-4.0048, -4.0048, -4.0048, -4.0048, -4.0048, -4.0048, -4.0048,
           -4.0048, -4.0048, -4.0048, -4.0048, -4.0048, -4.0048, -4.0048,
           -4.0048],
          [-4.0048, -4.0048, -4.0048, -4.0048, -4.0048, -4.0048, -4.0048,
           -4.0048, -4.0048, -4.0048, -4.0048, -4.0048, -4.0048, -4.0048,
           -4.0048],
          [-4.0048, -4.0048, -4.0048, -4.0048, -4.0048, -4.0048, -4.0048,
           -4.0048, -4.0048, -4.0048, -4.0048, -4.0048, -4.0048, -4.0048,
           -4.0048],
          [-4.0048, -4.0048, -4.0048, -4.0048, -4.0048, -4.0048, -4.0048,
           -4.0048, -4.0048, -4.0048, -4.0048, -4.0048, -4.0048, -4.0048,
           -4.0048]]]], grad_fn=<SliceBackward0>)
train_step: Entropy shape: torch.Size([16, 15])
train_step: Entropy sample: tensor([[0.5907, 0.6623],
        [0.6035, 0.4632]], grad_fn=<SliceBackward0>)
train_step: Entropy coefficient: 0.01
train_step: Actor loss: -1.6348286867141724
train_step: returns shape after mean: torch.Size([16, 15])
train_step: target_indices shape: torch.Size([16, 15])
train_step: value_logits shape: torch.Size([16, 15, 255])
train_step: target_twohot shape: torch.Size([16, 15, 255])
--- Starting train_step at 2025-04-01 01:58:22 ---
Full starting_state: {'deter': tensor([[[-4.1389e-02, -5.2289e-02,  4.9771e-02,  ...,  1.3207e-01,
           1.3310e-02,  1.2286e-01],
         [-1.0764e-01,  9.0286e-02,  8.3606e-02,  ...,  8.5445e-02,
           4.5786e-02, -5.2462e-02],
         [-4.0700e-02,  1.7502e-02, -4.4301e-02,  ..., -2.8422e-01,
           8.1266e-02,  5.6987e-02],
         ...,
         [-1.4278e-01,  9.1089e-02, -1.1793e-01,  ..., -1.1616e-02,
           4.7063e-02,  1.1005e-02],
         [ 1.5965e-01, -1.1286e-01, -5.1977e-02,  ...,  3.8965e-02,
           2.5867e-02, -5.8523e-02],
         [-1.6169e-01, -4.1791e-02, -1.4081e-01,  ..., -9.2220e-02,
           1.7471e-02,  1.6096e-01]],

        [[-6.3938e-02,  8.3333e-02, -4.9858e-03,  ..., -3.2299e-02,
           8.0746e-02, -1.9714e-02],
         [-1.0098e-02, -6.0871e-02,  2.5443e-02,  ..., -1.5085e-02,
          -5.4519e-02,  3.5473e-02],
         [-1.5691e-01, -7.8516e-02, -5.8553e-02,  ..., -1.2468e-01,
           3.9872e-03, -2.5622e-02],
         ...,
         [ 8.8725e-02, -1.5980e-02, -7.8779e-03,  ...,  9.9965e-02,
          -2.2030e-02,  6.1774e-02],
         [-3.9276e-02, -9.7720e-04,  2.6865e-02,  ..., -1.3595e-02,
          -3.5668e-02, -3.9438e-03],
         [-6.9667e-02, -1.0048e-02, -1.2702e-01,  ..., -1.2655e-01,
           4.8278e-02,  6.4415e-02]],

        [[ 4.6040e-02,  3.2378e-02, -7.4054e-02,  ...,  2.3864e-02,
           2.8235e-02, -1.3801e-02],
         [ 1.4989e-02,  1.4699e-02, -5.5094e-02,  ...,  5.7425e-02,
           7.7462e-02, -1.6711e-02],
         [-8.3205e-02, -7.2522e-02, -1.4522e-01,  ..., -9.6866e-03,
           7.1347e-02, -4.8405e-02],
         ...,
         [ 2.2165e-02,  1.1971e-02, -7.8674e-02,  ...,  2.6565e-02,
           5.4649e-03, -9.8427e-02],
         [-8.7668e-02,  1.0091e-02,  1.1871e-01,  ..., -8.5077e-03,
          -3.4785e-02,  2.0787e-02],
         [-1.7698e-01, -7.8071e-02,  2.2311e-02,  ...,  2.5280e-02,
           1.2899e-01, -1.2041e-01]],

        ...,

        [[ 1.8243e-02, -1.3447e-02,  9.8679e-02,  ..., -9.2566e-02,
           4.2795e-02,  6.7721e-02],
         [ 6.0067e-02, -6.4281e-02, -2.0163e-01,  ..., -4.6866e-02,
          -9.1456e-03, -2.9700e-02],
         [ 1.8852e-02, -8.6269e-02,  4.3813e-02,  ...,  1.3566e-01,
          -1.4602e-01,  1.0885e-01],
         ...,
         [ 1.6168e-01, -2.0809e-01, -2.3458e-01,  ...,  2.0573e-03,
           1.0672e-01,  1.9987e-04],
         [-1.5705e-01,  2.0390e-02, -5.0212e-02,  ..., -2.6584e-02,
           7.0621e-02,  3.2438e-02],
         [-5.1514e-02,  8.7978e-02, -1.7698e-01,  ...,  9.6764e-04,
           6.7346e-02, -1.3951e-02]],

        [[-1.0921e-01,  7.6635e-02, -4.7290e-02,  ...,  1.0402e-02,
           1.8440e-03, -7.8014e-02],
         [-1.4560e-01, -1.2932e-01,  3.7602e-02,  ...,  2.1398e-02,
          -1.4812e-02, -1.0091e-01],
         [-1.9605e-01,  1.9666e-02,  1.4805e-01,  ...,  2.3314e-03,
           4.1781e-02, -2.9157e-02],
         ...,
         [-1.2133e-02,  6.5466e-02, -1.2907e-01,  ...,  1.7062e-02,
          -1.1593e-01,  5.4453e-02],
         [-1.7410e-01,  1.0028e-01,  1.6304e-02,  ...,  2.6776e-02,
           7.7829e-02, -3.5681e-02],
         [-2.9627e-03,  3.1878e-02, -1.5247e-01,  ...,  9.4961e-02,
           1.8099e-02, -1.2993e-01]],

        [[-1.7177e-01,  1.5936e-01, -8.0412e-02,  ...,  4.8823e-02,
          -3.0116e-02, -1.2436e-01],
         [ 8.1849e-02,  5.5788e-02,  1.3631e-02,  ...,  7.3808e-02,
           5.7896e-02, -4.6530e-02],
         [-1.0724e-01, -3.7991e-02, -1.7630e-01,  ..., -1.2605e-01,
          -7.4325e-02,  4.5172e-02],
         ...,
         [-1.6131e-01, -7.6782e-02,  2.0081e-02,  ...,  3.7640e-02,
          -3.8457e-02, -1.6043e-01],
         [-1.5594e-01, -4.3191e-02, -6.4811e-02,  ...,  5.4129e-02,
          -5.5263e-02,  6.4193e-02],
         [ 1.8781e-02, -8.0707e-02, -3.7271e-02,  ..., -2.4870e-01,
           1.3572e-01, -3.6742e-02]]], grad_fn=<StackBackward0>), 'stoch': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [1., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 1., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 1., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 1., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 1.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [1., 0., 0.,  ..., 1., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]])}
train_step: Starting state deter shape: torch.Size([16, 50, 128])
train_step: Starting state stoch shape: torch.Size([16, 50, 1024])
After ensuring logits/stoch: {'deter': tensor([[[-4.1389e-02, -5.2289e-02,  4.9771e-02,  ...,  1.3207e-01,
           1.3310e-02,  1.2286e-01],
         [-1.0764e-01,  9.0286e-02,  8.3606e-02,  ...,  8.5445e-02,
           4.5786e-02, -5.2462e-02],
         [-4.0700e-02,  1.7502e-02, -4.4301e-02,  ..., -2.8422e-01,
           8.1266e-02,  5.6987e-02],
         ...,
         [-1.4278e-01,  9.1089e-02, -1.1793e-01,  ..., -1.1616e-02,
           4.7063e-02,  1.1005e-02],
         [ 1.5965e-01, -1.1286e-01, -5.1977e-02,  ...,  3.8965e-02,
           2.5867e-02, -5.8523e-02],
         [-1.6169e-01, -4.1791e-02, -1.4081e-01,  ..., -9.2220e-02,
           1.7471e-02,  1.6096e-01]],

        [[-6.3938e-02,  8.3333e-02, -4.9858e-03,  ..., -3.2299e-02,
           8.0746e-02, -1.9714e-02],
         [-1.0098e-02, -6.0871e-02,  2.5443e-02,  ..., -1.5085e-02,
          -5.4519e-02,  3.5473e-02],
         [-1.5691e-01, -7.8516e-02, -5.8553e-02,  ..., -1.2468e-01,
           3.9872e-03, -2.5622e-02],
         ...,
         [ 8.8725e-02, -1.5980e-02, -7.8779e-03,  ...,  9.9965e-02,
          -2.2030e-02,  6.1774e-02],
         [-3.9276e-02, -9.7720e-04,  2.6865e-02,  ..., -1.3595e-02,
          -3.5668e-02, -3.9438e-03],
         [-6.9667e-02, -1.0048e-02, -1.2702e-01,  ..., -1.2655e-01,
           4.8278e-02,  6.4415e-02]],

        [[ 4.6040e-02,  3.2378e-02, -7.4054e-02,  ...,  2.3864e-02,
           2.8235e-02, -1.3801e-02],
         [ 1.4989e-02,  1.4699e-02, -5.5094e-02,  ...,  5.7425e-02,
           7.7462e-02, -1.6711e-02],
         [-8.3205e-02, -7.2522e-02, -1.4522e-01,  ..., -9.6866e-03,
           7.1347e-02, -4.8405e-02],
         ...,
         [ 2.2165e-02,  1.1971e-02, -7.8674e-02,  ...,  2.6565e-02,
           5.4649e-03, -9.8427e-02],
         [-8.7668e-02,  1.0091e-02,  1.1871e-01,  ..., -8.5077e-03,
          -3.4785e-02,  2.0787e-02],
         [-1.7698e-01, -7.8071e-02,  2.2311e-02,  ...,  2.5280e-02,
           1.2899e-01, -1.2041e-01]],

        ...,

        [[ 1.8243e-02, -1.3447e-02,  9.8679e-02,  ..., -9.2566e-02,
           4.2795e-02,  6.7721e-02],
         [ 6.0067e-02, -6.4281e-02, -2.0163e-01,  ..., -4.6866e-02,
          -9.1456e-03, -2.9700e-02],
         [ 1.8852e-02, -8.6269e-02,  4.3813e-02,  ...,  1.3566e-01,
          -1.4602e-01,  1.0885e-01],
         ...,
         [ 1.6168e-01, -2.0809e-01, -2.3458e-01,  ...,  2.0573e-03,
           1.0672e-01,  1.9987e-04],
         [-1.5705e-01,  2.0390e-02, -5.0212e-02,  ..., -2.6584e-02,
           7.0621e-02,  3.2438e-02],
         [-5.1514e-02,  8.7978e-02, -1.7698e-01,  ...,  9.6764e-04,
           6.7346e-02, -1.3951e-02]],

        [[-1.0921e-01,  7.6635e-02, -4.7290e-02,  ...,  1.0402e-02,
           1.8440e-03, -7.8014e-02],
         [-1.4560e-01, -1.2932e-01,  3.7602e-02,  ...,  2.1398e-02,
          -1.4812e-02, -1.0091e-01],
         [-1.9605e-01,  1.9666e-02,  1.4805e-01,  ...,  2.3314e-03,
           4.1781e-02, -2.9157e-02],
         ...,
         [-1.2133e-02,  6.5466e-02, -1.2907e-01,  ...,  1.7062e-02,
          -1.1593e-01,  5.4453e-02],
         [-1.7410e-01,  1.0028e-01,  1.6304e-02,  ...,  2.6776e-02,
           7.7829e-02, -3.5681e-02],
         [-2.9627e-03,  3.1878e-02, -1.5247e-01,  ...,  9.4961e-02,
           1.8099e-02, -1.2993e-01]],

        [[-1.7177e-01,  1.5936e-01, -8.0412e-02,  ...,  4.8823e-02,
          -3.0116e-02, -1.2436e-01],
         [ 8.1849e-02,  5.5788e-02,  1.3631e-02,  ...,  7.3808e-02,
           5.7896e-02, -4.6530e-02],
         [-1.0724e-01, -3.7991e-02, -1.7630e-01,  ..., -1.2605e-01,
          -7.4325e-02,  4.5172e-02],
         ...,
         [-1.6131e-01, -7.6782e-02,  2.0081e-02,  ...,  3.7640e-02,
          -3.8457e-02, -1.6043e-01],
         [-1.5594e-01, -4.3191e-02, -6.4811e-02,  ...,  5.4129e-02,
          -5.5263e-02,  6.4193e-02],
         [ 1.8781e-02, -8.0707e-02, -3.7271e-02,  ..., -2.4870e-01,
           1.3572e-01, -3.6742e-02]]], grad_fn=<StackBackward0>), 'stoch': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [1., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 1., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 1., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 1., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 1.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [1., 0., 0.,  ..., 1., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]]), 'logits': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]])}
train_step: Normalized hidden_state shape: torch.Size([1, 16, 128])
train_step: Normalized stoch shape: torch.Size([16, 1024])
train_step: Normalized deter shape: torch.Size([16, 128])
train_step: Post-imagine_trajectory: Imagined features shape: torch.Size([16, 15, 1152])
train_step: Post-imagine_trajectory: Imagined actions shape: torch.Size([16, 15, 2])
train_step: Post-imagine_trajectory: Imagined action indices shape: torch.Size([16, 15])
train_step: Post-imagine_trajectory: Imagined state deter shape: torch.Size([16, 15, 128])
train_step: Post-imagine_trajectory: Imagined state stoch shape: torch.Size([16, 15, 1024])
Reward shape: torch.Size([16, 15, 1]), Value shape: torch.Size([16, 15, 1]), Slow Value shape: torch.Size([16, 15, 1]), Discount shape: torch.Size([16, 15, 1, 1])
Return targets length: 15, First target shape: torch.Size([16, 16, 1])
train_step: Actor distribution shape: torch.Size([16, 15, 2])
train_step: Action log probabilities shape: torch.Size([16, 15])
train_step: Action log probabilities sample: tensor([[-0.1949, -0.1948],
        [-2.1899, -1.8515]], grad_fn=<SliceBackward0>)
train_step: Advantages shape: torch.Size([16, 15, 16, 15])
train_step: Advantages sample: tensor([[[[-8.0005, -8.0005, -8.0005, -8.0005, -8.0005, -8.0005, -8.0005,
           -8.0005, -8.0005, -8.0005, -8.0005, -8.0005, -8.0005, -8.0005,
           -8.0005],
          [-8.0005, -8.0005, -8.0005, -8.0005, -8.0005, -8.0005, -8.0005,
           -8.0005, -8.0005, -8.0005, -8.0005, -8.0005, -8.0005, -8.0005,
           -8.0005],
          [-8.0005, -8.0005, -8.0005, -8.0005, -8.0005, -8.0005, -8.0005,
           -8.0005, -8.0005, -8.0005, -8.0005, -8.0005, -8.0005, -8.0005,
           -8.0005],
          [-8.0005, -8.0005, -8.0005, -8.0005, -8.0005, -8.0005, -8.0005,
           -8.0005, -8.0005, -8.0005, -8.0005, -8.0005, -8.0005, -8.0005,
           -8.0005],
          [-8.0005, -8.0005, -8.0005, -8.0005, -8.0005, -8.0005, -8.0005,
           -8.0005, -8.0005, -8.0005, -8.0005, -8.0005, -8.0005, -8.0005,
           -8.0005],
          [-8.0005, -8.0005, -8.0005, -8.0005, -8.0005, -8.0005, -8.0005,
           -8.0005, -8.0005, -8.0005, -8.0005, -8.0005, -8.0005, -8.0005,
           -8.0005],
          [-8.0005, -8.0005, -8.0005, -8.0005, -8.0005, -8.0005, -8.0005,
           -8.0005, -8.0005, -8.0005, -8.0005, -8.0005, -8.0005, -8.0005,
           -8.0005],
          [-8.0005, -8.0005, -8.0005, -8.0005, -8.0005, -8.0005, -8.0005,
           -8.0005, -8.0005, -8.0005, -8.0005, -8.0005, -8.0005, -8.0005,
           -8.0005],
          [-8.0005, -8.0005, -8.0005, -8.0005, -8.0005, -8.0005, -8.0005,
           -8.0005, -8.0005, -8.0005, -8.0005, -8.0005, -8.0005, -8.0005,
           -8.0005],
          [-8.0005, -8.0005, -8.0005, -8.0005, -8.0005, -8.0005, -8.0005,
           -8.0005, -8.0005, -8.0005, -8.0005, -8.0005, -8.0005, -8.0005,
           -8.0005],
          [-8.0005, -8.0005, -8.0005, -8.0005, -8.0005, -8.0005, -8.0005,
           -8.0005, -8.0005, -8.0005, -8.0005, -8.0005, -8.0005, -8.0005,
           -8.0005],
          [-8.0005, -8.0005, -8.0005, -8.0005, -8.0005, -8.0005, -8.0005,
           -8.0005, -8.0005, -8.0005, -8.0005, -8.0005, -8.0005, -8.0005,
           -8.0005],
          [-8.0005, -8.0005, -8.0005, -8.0005, -8.0005, -8.0005, -8.0005,
           -8.0005, -8.0005, -8.0005, -8.0005, -8.0005, -8.0005, -8.0005,
           -8.0005],
          [-8.0005, -8.0005, -8.0005, -8.0005, -8.0005, -8.0005, -8.0005,
           -8.0005, -8.0005, -8.0005, -8.0005, -8.0005, -8.0005, -8.0005,
           -8.0005],
          [-8.0005, -8.0005, -8.0005, -8.0005, -8.0005, -8.0005, -8.0005,
           -8.0005, -8.0005, -8.0005, -8.0005, -8.0005, -8.0005, -8.0005,
           -8.0005],
          [-8.0005, -8.0005, -8.0005, -8.0005, -8.0005, -8.0005, -8.0005,
           -8.0005, -8.0005, -8.0005, -8.0005, -8.0005, -8.0005, -8.0005,
           -8.0005]],

         [[-7.4974, -7.4974, -7.4974, -7.4974, -7.4974, -7.4974, -7.4974,
           -7.4974, -7.4974, -7.4974, -7.4974, -7.4974, -7.4974, -7.4974,
           -7.4974],
          [-7.4974, -7.4974, -7.4974, -7.4974, -7.4974, -7.4974, -7.4974,
           -7.4974, -7.4974, -7.4974, -7.4974, -7.4974, -7.4974, -7.4974,
           -7.4974],
          [-7.4974, -7.4974, -7.4974, -7.4974, -7.4974, -7.4974, -7.4974,
           -7.4974, -7.4974, -7.4974, -7.4974, -7.4974, -7.4974, -7.4974,
           -7.4974],
          [-7.4974, -7.4974, -7.4974, -7.4974, -7.4974, -7.4974, -7.4974,
           -7.4974, -7.4974, -7.4974, -7.4974, -7.4974, -7.4974, -7.4974,
           -7.4974],
          [-7.4974, -7.4974, -7.4974, -7.4974, -7.4974, -7.4974, -7.4974,
           -7.4974, -7.4974, -7.4974, -7.4974, -7.4974, -7.4974, -7.4974,
           -7.4974],
          [-7.4974, -7.4974, -7.4974, -7.4974, -7.4974, -7.4974, -7.4974,
           -7.4974, -7.4974, -7.4974, -7.4974, -7.4974, -7.4974, -7.4974,
           -7.4974],
          [-7.4974, -7.4974, -7.4974, -7.4974, -7.4974, -7.4974, -7.4974,
           -7.4974, -7.4974, -7.4974, -7.4974, -7.4974, -7.4974, -7.4974,
           -7.4974],
          [-7.4974, -7.4974, -7.4974, -7.4974, -7.4974, -7.4974, -7.4974,
           -7.4974, -7.4974, -7.4974, -7.4974, -7.4974, -7.4974, -7.4974,
           -7.4974],
          [-7.4974, -7.4974, -7.4974, -7.4974, -7.4974, -7.4974, -7.4974,
           -7.4974, -7.4974, -7.4974, -7.4974, -7.4974, -7.4974, -7.4974,
           -7.4974],
          [-7.4974, -7.4974, -7.4974, -7.4974, -7.4974, -7.4974, -7.4974,
           -7.4974, -7.4974, -7.4974, -7.4974, -7.4974, -7.4974, -7.4974,
           -7.4974],
          [-7.4974, -7.4974, -7.4974, -7.4974, -7.4974, -7.4974, -7.4974,
           -7.4974, -7.4974, -7.4974, -7.4974, -7.4974, -7.4974, -7.4974,
           -7.4974],
          [-7.4974, -7.4974, -7.4974, -7.4974, -7.4974, -7.4974, -7.4974,
           -7.4974, -7.4974, -7.4974, -7.4974, -7.4974, -7.4974, -7.4974,
           -7.4974],
          [-7.4974, -7.4974, -7.4974, -7.4974, -7.4974, -7.4974, -7.4974,
           -7.4974, -7.4974, -7.4974, -7.4974, -7.4974, -7.4974, -7.4974,
           -7.4974],
          [-7.4974, -7.4974, -7.4974, -7.4974, -7.4974, -7.4974, -7.4974,
           -7.4974, -7.4974, -7.4974, -7.4974, -7.4974, -7.4974, -7.4974,
           -7.4974],
          [-7.4974, -7.4974, -7.4974, -7.4974, -7.4974, -7.4974, -7.4974,
           -7.4974, -7.4974, -7.4974, -7.4974, -7.4974, -7.4974, -7.4974,
           -7.4974],
          [-7.4974, -7.4974, -7.4974, -7.4974, -7.4974, -7.4974, -7.4974,
           -7.4974, -7.4974, -7.4974, -7.4974, -7.4974, -7.4974, -7.4974,
           -7.4974]]],


        [[[-6.3157, -6.3157, -6.3157, -6.3157, -6.3157, -6.3157, -6.3157,
           -6.3157, -6.3157, -6.3157, -6.3157, -6.3157, -6.3157, -6.3157,
           -6.3157],
          [-6.3157, -6.3157, -6.3157, -6.3157, -6.3157, -6.3157, -6.3157,
           -6.3157, -6.3157, -6.3157, -6.3157, -6.3157, -6.3157, -6.3157,
           -6.3157],
          [-6.3157, -6.3157, -6.3157, -6.3157, -6.3157, -6.3157, -6.3157,
           -6.3157, -6.3157, -6.3157, -6.3157, -6.3157, -6.3157, -6.3157,
           -6.3157],
          [-6.3157, -6.3157, -6.3157, -6.3157, -6.3157, -6.3157, -6.3157,
           -6.3157, -6.3157, -6.3157, -6.3157, -6.3157, -6.3157, -6.3157,
           -6.3157],
          [-6.3157, -6.3157, -6.3157, -6.3157, -6.3157, -6.3157, -6.3157,
           -6.3157, -6.3157, -6.3157, -6.3157, -6.3157, -6.3157, -6.3157,
           -6.3157],
          [-6.3157, -6.3157, -6.3157, -6.3157, -6.3157, -6.3157, -6.3157,
           -6.3157, -6.3157, -6.3157, -6.3157, -6.3157, -6.3157, -6.3157,
           -6.3157],
          [-6.3157, -6.3157, -6.3157, -6.3157, -6.3157, -6.3157, -6.3157,
           -6.3157, -6.3157, -6.3157, -6.3157, -6.3157, -6.3157, -6.3157,
           -6.3157],
          [-6.3157, -6.3157, -6.3157, -6.3157, -6.3157, -6.3157, -6.3157,
           -6.3157, -6.3157, -6.3157, -6.3157, -6.3157, -6.3157, -6.3157,
           -6.3157],
          [-6.3157, -6.3157, -6.3157, -6.3157, -6.3157, -6.3157, -6.3157,
           -6.3157, -6.3157, -6.3157, -6.3157, -6.3157, -6.3157, -6.3157,
           -6.3157],
          [-6.3157, -6.3157, -6.3157, -6.3157, -6.3157, -6.3157, -6.3157,
           -6.3157, -6.3157, -6.3157, -6.3157, -6.3157, -6.3157, -6.3157,
           -6.3157],
          [-6.3157, -6.3157, -6.3157, -6.3157, -6.3157, -6.3157, -6.3157,
           -6.3157, -6.3157, -6.3157, -6.3157, -6.3157, -6.3157, -6.3157,
           -6.3157],
          [-6.3157, -6.3157, -6.3157, -6.3157, -6.3157, -6.3157, -6.3157,
           -6.3157, -6.3157, -6.3157, -6.3157, -6.3157, -6.3157, -6.3157,
           -6.3157],
          [-6.3157, -6.3157, -6.3157, -6.3157, -6.3157, -6.3157, -6.3157,
           -6.3157, -6.3157, -6.3157, -6.3157, -6.3157, -6.3157, -6.3157,
           -6.3157],
          [-6.3157, -6.3157, -6.3157, -6.3157, -6.3157, -6.3157, -6.3157,
           -6.3157, -6.3157, -6.3157, -6.3157, -6.3157, -6.3157, -6.3157,
           -6.3157],
          [-6.3157, -6.3157, -6.3157, -6.3157, -6.3157, -6.3157, -6.3157,
           -6.3157, -6.3157, -6.3157, -6.3157, -6.3157, -6.3157, -6.3157,
           -6.3157],
          [-6.3157, -6.3157, -6.3157, -6.3157, -6.3157, -6.3157, -6.3157,
           -6.3157, -6.3157, -6.3157, -6.3157, -6.3157, -6.3157, -6.3157,
           -6.3157]],

         [[-6.5684, -6.5684, -6.5685, -6.5684, -6.5684, -6.5684, -6.5684,
           -6.5684, -6.5685, -6.5684, -6.5684, -6.5684, -6.5684, -6.5684,
           -6.5684],
          [-6.5684, -6.5684, -6.5685, -6.5684, -6.5684, -6.5684, -6.5684,
           -6.5684, -6.5685, -6.5684, -6.5684, -6.5684, -6.5684, -6.5684,
           -6.5684],
          [-6.5684, -6.5684, -6.5685, -6.5684, -6.5684, -6.5684, -6.5684,
           -6.5684, -6.5685, -6.5684, -6.5684, -6.5684, -6.5684, -6.5684,
           -6.5684],
          [-6.5684, -6.5684, -6.5685, -6.5684, -6.5684, -6.5684, -6.5684,
           -6.5684, -6.5685, -6.5684, -6.5684, -6.5684, -6.5684, -6.5684,
           -6.5684],
          [-6.5684, -6.5684, -6.5685, -6.5684, -6.5684, -6.5684, -6.5684,
           -6.5684, -6.5685, -6.5684, -6.5684, -6.5684, -6.5684, -6.5684,
           -6.5684],
          [-6.5684, -6.5684, -6.5685, -6.5684, -6.5684, -6.5684, -6.5684,
           -6.5684, -6.5685, -6.5684, -6.5684, -6.5684, -6.5684, -6.5684,
           -6.5684],
          [-6.5684, -6.5684, -6.5685, -6.5684, -6.5684, -6.5684, -6.5684,
           -6.5684, -6.5685, -6.5684, -6.5684, -6.5684, -6.5684, -6.5684,
           -6.5684],
          [-6.5684, -6.5684, -6.5685, -6.5684, -6.5684, -6.5684, -6.5684,
           -6.5684, -6.5685, -6.5684, -6.5684, -6.5684, -6.5684, -6.5684,
           -6.5684],
          [-6.5684, -6.5684, -6.5685, -6.5684, -6.5684, -6.5684, -6.5684,
           -6.5684, -6.5685, -6.5684, -6.5684, -6.5684, -6.5684, -6.5684,
           -6.5684],
          [-6.5684, -6.5684, -6.5685, -6.5684, -6.5684, -6.5684, -6.5684,
           -6.5684, -6.5685, -6.5684, -6.5684, -6.5684, -6.5684, -6.5684,
           -6.5684],
          [-6.5684, -6.5684, -6.5685, -6.5684, -6.5684, -6.5684, -6.5684,
           -6.5684, -6.5685, -6.5684, -6.5684, -6.5684, -6.5684, -6.5684,
           -6.5684],
          [-6.5684, -6.5684, -6.5685, -6.5684, -6.5684, -6.5684, -6.5684,
           -6.5684, -6.5685, -6.5684, -6.5684, -6.5684, -6.5684, -6.5684,
           -6.5684],
          [-6.5684, -6.5684, -6.5685, -6.5684, -6.5684, -6.5684, -6.5684,
           -6.5684, -6.5685, -6.5684, -6.5684, -6.5684, -6.5684, -6.5684,
           -6.5684],
          [-6.5684, -6.5684, -6.5685, -6.5684, -6.5684, -6.5684, -6.5684,
           -6.5684, -6.5685, -6.5684, -6.5684, -6.5684, -6.5684, -6.5684,
           -6.5684],
          [-6.5684, -6.5684, -6.5685, -6.5684, -6.5684, -6.5684, -6.5684,
           -6.5684, -6.5685, -6.5684, -6.5684, -6.5684, -6.5684, -6.5684,
           -6.5684],
          [-6.5684, -6.5684, -6.5685, -6.5684, -6.5684, -6.5684, -6.5684,
           -6.5684, -6.5685, -6.5684, -6.5684, -6.5684, -6.5684, -6.5684,
           -6.5684]]]], grad_fn=<SliceBackward0>)
train_step: Return scale: 1.5057577565124367
train_step: Scaled advantages shape: torch.Size([16, 15, 16, 15])
train_step: Scaled advantages sample: tensor([[[[-5.3133, -5.3133, -5.3133, -5.3133, -5.3133, -5.3133, -5.3133,
           -5.3133, -5.3133, -5.3133, -5.3133, -5.3133, -5.3133, -5.3133,
           -5.3133],
          [-5.3133, -5.3133, -5.3133, -5.3133, -5.3133, -5.3133, -5.3133,
           -5.3133, -5.3133, -5.3133, -5.3133, -5.3133, -5.3133, -5.3133,
           -5.3133],
          [-5.3133, -5.3133, -5.3133, -5.3133, -5.3133, -5.3133, -5.3133,
           -5.3133, -5.3133, -5.3133, -5.3133, -5.3133, -5.3133, -5.3133,
           -5.3133],
          [-5.3133, -5.3133, -5.3133, -5.3133, -5.3133, -5.3133, -5.3133,
           -5.3133, -5.3133, -5.3133, -5.3133, -5.3133, -5.3133, -5.3133,
           -5.3133],
          [-5.3133, -5.3133, -5.3133, -5.3133, -5.3133, -5.3133, -5.3133,
           -5.3133, -5.3133, -5.3133, -5.3133, -5.3133, -5.3133, -5.3133,
           -5.3133],
          [-5.3133, -5.3133, -5.3133, -5.3133, -5.3133, -5.3133, -5.3133,
           -5.3133, -5.3133, -5.3133, -5.3133, -5.3133, -5.3133, -5.3133,
           -5.3133],
          [-5.3133, -5.3133, -5.3133, -5.3133, -5.3133, -5.3133, -5.3133,
           -5.3133, -5.3133, -5.3133, -5.3133, -5.3133, -5.3133, -5.3133,
           -5.3133],
          [-5.3133, -5.3133, -5.3133, -5.3133, -5.3133, -5.3133, -5.3133,
           -5.3133, -5.3133, -5.3133, -5.3133, -5.3133, -5.3133, -5.3133,
           -5.3133],
          [-5.3133, -5.3133, -5.3133, -5.3133, -5.3133, -5.3133, -5.3133,
           -5.3133, -5.3133, -5.3133, -5.3133, -5.3133, -5.3133, -5.3133,
           -5.3133],
          [-5.3133, -5.3133, -5.3133, -5.3133, -5.3133, -5.3133, -5.3133,
           -5.3133, -5.3133, -5.3133, -5.3133, -5.3133, -5.3133, -5.3133,
           -5.3133],
          [-5.3133, -5.3133, -5.3133, -5.3133, -5.3133, -5.3133, -5.3133,
           -5.3133, -5.3133, -5.3133, -5.3133, -5.3133, -5.3133, -5.3133,
           -5.3133],
          [-5.3133, -5.3133, -5.3133, -5.3133, -5.3133, -5.3133, -5.3133,
           -5.3133, -5.3133, -5.3133, -5.3133, -5.3133, -5.3133, -5.3133,
           -5.3133],
          [-5.3133, -5.3133, -5.3133, -5.3133, -5.3133, -5.3133, -5.3133,
           -5.3133, -5.3133, -5.3133, -5.3133, -5.3133, -5.3133, -5.3133,
           -5.3133],
          [-5.3133, -5.3133, -5.3133, -5.3133, -5.3133, -5.3133, -5.3133,
           -5.3133, -5.3133, -5.3133, -5.3133, -5.3133, -5.3133, -5.3133,
           -5.3133],
          [-5.3133, -5.3133, -5.3133, -5.3133, -5.3133, -5.3133, -5.3133,
           -5.3133, -5.3133, -5.3133, -5.3133, -5.3133, -5.3133, -5.3133,
           -5.3133],
          [-5.3133, -5.3133, -5.3133, -5.3133, -5.3133, -5.3133, -5.3133,
           -5.3133, -5.3133, -5.3133, -5.3133, -5.3133, -5.3133, -5.3133,
           -5.3133]],

         [[-4.9792, -4.9792, -4.9792, -4.9792, -4.9792, -4.9792, -4.9792,
           -4.9792, -4.9792, -4.9792, -4.9792, -4.9792, -4.9792, -4.9792,
           -4.9792],
          [-4.9792, -4.9792, -4.9792, -4.9792, -4.9792, -4.9792, -4.9792,
           -4.9792, -4.9792, -4.9792, -4.9792, -4.9792, -4.9792, -4.9792,
           -4.9792],
          [-4.9792, -4.9792, -4.9792, -4.9792, -4.9792, -4.9792, -4.9792,
           -4.9792, -4.9792, -4.9792, -4.9792, -4.9792, -4.9792, -4.9792,
           -4.9792],
          [-4.9792, -4.9792, -4.9792, -4.9792, -4.9792, -4.9792, -4.9792,
           -4.9792, -4.9792, -4.9792, -4.9792, -4.9792, -4.9792, -4.9792,
           -4.9792],
          [-4.9792, -4.9792, -4.9792, -4.9792, -4.9792, -4.9792, -4.9792,
           -4.9792, -4.9792, -4.9792, -4.9792, -4.9792, -4.9792, -4.9792,
           -4.9792],
          [-4.9792, -4.9792, -4.9792, -4.9792, -4.9792, -4.9792, -4.9792,
           -4.9792, -4.9792, -4.9792, -4.9792, -4.9792, -4.9792, -4.9792,
           -4.9792],
          [-4.9792, -4.9792, -4.9792, -4.9792, -4.9792, -4.9792, -4.9792,
           -4.9792, -4.9792, -4.9792, -4.9792, -4.9792, -4.9792, -4.9792,
           -4.9792],
          [-4.9792, -4.9792, -4.9792, -4.9792, -4.9792, -4.9792, -4.9792,
           -4.9792, -4.9792, -4.9792, -4.9792, -4.9792, -4.9792, -4.9792,
           -4.9792],
          [-4.9792, -4.9792, -4.9792, -4.9792, -4.9792, -4.9792, -4.9792,
           -4.9792, -4.9792, -4.9792, -4.9792, -4.9792, -4.9792, -4.9792,
           -4.9792],
          [-4.9792, -4.9792, -4.9792, -4.9792, -4.9792, -4.9792, -4.9792,
           -4.9792, -4.9792, -4.9792, -4.9792, -4.9792, -4.9792, -4.9792,
           -4.9792],
          [-4.9792, -4.9792, -4.9792, -4.9792, -4.9792, -4.9792, -4.9792,
           -4.9792, -4.9792, -4.9792, -4.9792, -4.9792, -4.9792, -4.9792,
           -4.9792],
          [-4.9792, -4.9792, -4.9792, -4.9792, -4.9792, -4.9792, -4.9792,
           -4.9792, -4.9792, -4.9792, -4.9792, -4.9792, -4.9792, -4.9792,
           -4.9792],
          [-4.9792, -4.9792, -4.9792, -4.9792, -4.9792, -4.9792, -4.9792,
           -4.9792, -4.9792, -4.9792, -4.9792, -4.9792, -4.9792, -4.9792,
           -4.9792],
          [-4.9792, -4.9792, -4.9792, -4.9792, -4.9792, -4.9792, -4.9792,
           -4.9792, -4.9792, -4.9792, -4.9792, -4.9792, -4.9792, -4.9792,
           -4.9792],
          [-4.9792, -4.9792, -4.9792, -4.9792, -4.9792, -4.9792, -4.9792,
           -4.9792, -4.9792, -4.9792, -4.9792, -4.9792, -4.9792, -4.9792,
           -4.9792],
          [-4.9792, -4.9792, -4.9792, -4.9792, -4.9792, -4.9792, -4.9792,
           -4.9792, -4.9792, -4.9792, -4.9792, -4.9792, -4.9792, -4.9792,
           -4.9792]]],


        [[[-4.1944, -4.1944, -4.1944, -4.1944, -4.1944, -4.1944, -4.1944,
           -4.1944, -4.1944, -4.1944, -4.1944, -4.1944, -4.1944, -4.1944,
           -4.1944],
          [-4.1944, -4.1944, -4.1944, -4.1944, -4.1944, -4.1944, -4.1944,
           -4.1944, -4.1944, -4.1944, -4.1944, -4.1944, -4.1944, -4.1944,
           -4.1944],
          [-4.1944, -4.1944, -4.1944, -4.1944, -4.1944, -4.1944, -4.1944,
           -4.1944, -4.1944, -4.1944, -4.1944, -4.1944, -4.1944, -4.1944,
           -4.1944],
          [-4.1944, -4.1944, -4.1944, -4.1944, -4.1944, -4.1944, -4.1944,
           -4.1944, -4.1944, -4.1944, -4.1944, -4.1944, -4.1944, -4.1944,
           -4.1944],
          [-4.1944, -4.1944, -4.1944, -4.1944, -4.1944, -4.1944, -4.1944,
           -4.1944, -4.1944, -4.1944, -4.1944, -4.1944, -4.1944, -4.1944,
           -4.1944],
          [-4.1944, -4.1944, -4.1944, -4.1944, -4.1944, -4.1944, -4.1944,
           -4.1944, -4.1944, -4.1944, -4.1944, -4.1944, -4.1944, -4.1944,
           -4.1944],
          [-4.1944, -4.1944, -4.1944, -4.1944, -4.1944, -4.1944, -4.1944,
           -4.1944, -4.1944, -4.1944, -4.1944, -4.1944, -4.1944, -4.1944,
           -4.1944],
          [-4.1944, -4.1944, -4.1944, -4.1944, -4.1944, -4.1944, -4.1944,
           -4.1944, -4.1944, -4.1944, -4.1944, -4.1944, -4.1944, -4.1944,
           -4.1944],
          [-4.1944, -4.1944, -4.1944, -4.1944, -4.1944, -4.1944, -4.1944,
           -4.1944, -4.1944, -4.1944, -4.1944, -4.1944, -4.1944, -4.1944,
           -4.1944],
          [-4.1944, -4.1944, -4.1944, -4.1944, -4.1944, -4.1944, -4.1944,
           -4.1944, -4.1944, -4.1944, -4.1944, -4.1944, -4.1944, -4.1944,
           -4.1944],
          [-4.1944, -4.1944, -4.1944, -4.1944, -4.1944, -4.1944, -4.1944,
           -4.1944, -4.1944, -4.1944, -4.1944, -4.1944, -4.1944, -4.1944,
           -4.1944],
          [-4.1944, -4.1944, -4.1944, -4.1944, -4.1944, -4.1944, -4.1944,
           -4.1944, -4.1944, -4.1944, -4.1944, -4.1944, -4.1944, -4.1944,
           -4.1944],
          [-4.1944, -4.1944, -4.1944, -4.1944, -4.1944, -4.1944, -4.1944,
           -4.1944, -4.1944, -4.1944, -4.1944, -4.1944, -4.1944, -4.1944,
           -4.1944],
          [-4.1944, -4.1944, -4.1944, -4.1944, -4.1944, -4.1944, -4.1944,
           -4.1944, -4.1944, -4.1944, -4.1944, -4.1944, -4.1944, -4.1944,
           -4.1944],
          [-4.1944, -4.1944, -4.1944, -4.1944, -4.1944, -4.1944, -4.1944,
           -4.1944, -4.1944, -4.1944, -4.1944, -4.1944, -4.1944, -4.1944,
           -4.1944],
          [-4.1944, -4.1944, -4.1944, -4.1944, -4.1944, -4.1944, -4.1944,
           -4.1944, -4.1944, -4.1944, -4.1944, -4.1944, -4.1944, -4.1944,
           -4.1944]],

         [[-4.3622, -4.3622, -4.3622, -4.3622, -4.3622, -4.3622, -4.3622,
           -4.3622, -4.3622, -4.3622, -4.3622, -4.3622, -4.3622, -4.3622,
           -4.3622],
          [-4.3622, -4.3622, -4.3622, -4.3622, -4.3622, -4.3622, -4.3622,
           -4.3622, -4.3622, -4.3622, -4.3622, -4.3622, -4.3622, -4.3622,
           -4.3622],
          [-4.3622, -4.3622, -4.3622, -4.3622, -4.3622, -4.3622, -4.3622,
           -4.3622, -4.3622, -4.3622, -4.3622, -4.3622, -4.3622, -4.3622,
           -4.3622],
          [-4.3622, -4.3622, -4.3622, -4.3622, -4.3622, -4.3622, -4.3622,
           -4.3622, -4.3622, -4.3622, -4.3622, -4.3622, -4.3622, -4.3622,
           -4.3622],
          [-4.3622, -4.3622, -4.3622, -4.3622, -4.3622, -4.3622, -4.3622,
           -4.3622, -4.3622, -4.3622, -4.3622, -4.3622, -4.3622, -4.3622,
           -4.3622],
          [-4.3622, -4.3622, -4.3622, -4.3622, -4.3622, -4.3622, -4.3622,
           -4.3622, -4.3622, -4.3622, -4.3622, -4.3622, -4.3622, -4.3622,
           -4.3622],
          [-4.3622, -4.3622, -4.3622, -4.3622, -4.3622, -4.3622, -4.3622,
           -4.3622, -4.3622, -4.3622, -4.3622, -4.3622, -4.3622, -4.3622,
           -4.3622],
          [-4.3622, -4.3622, -4.3622, -4.3622, -4.3622, -4.3622, -4.3622,
           -4.3622, -4.3622, -4.3622, -4.3622, -4.3622, -4.3622, -4.3622,
           -4.3622],
          [-4.3622, -4.3622, -4.3622, -4.3622, -4.3622, -4.3622, -4.3622,
           -4.3622, -4.3622, -4.3622, -4.3622, -4.3622, -4.3622, -4.3622,
           -4.3622],
          [-4.3622, -4.3622, -4.3622, -4.3622, -4.3622, -4.3622, -4.3622,
           -4.3622, -4.3622, -4.3622, -4.3622, -4.3622, -4.3622, -4.3622,
           -4.3622],
          [-4.3622, -4.3622, -4.3622, -4.3622, -4.3622, -4.3622, -4.3622,
           -4.3622, -4.3622, -4.3622, -4.3622, -4.3622, -4.3622, -4.3622,
           -4.3622],
          [-4.3622, -4.3622, -4.3622, -4.3622, -4.3622, -4.3622, -4.3622,
           -4.3622, -4.3622, -4.3622, -4.3622, -4.3622, -4.3622, -4.3622,
           -4.3622],
          [-4.3622, -4.3622, -4.3622, -4.3622, -4.3622, -4.3622, -4.3622,
           -4.3622, -4.3622, -4.3622, -4.3622, -4.3622, -4.3622, -4.3622,
           -4.3622],
          [-4.3622, -4.3622, -4.3622, -4.3622, -4.3622, -4.3622, -4.3622,
           -4.3622, -4.3622, -4.3622, -4.3622, -4.3622, -4.3622, -4.3622,
           -4.3622],
          [-4.3622, -4.3622, -4.3622, -4.3622, -4.3622, -4.3622, -4.3622,
           -4.3622, -4.3622, -4.3622, -4.3622, -4.3622, -4.3622, -4.3622,
           -4.3622],
          [-4.3622, -4.3622, -4.3622, -4.3622, -4.3622, -4.3622, -4.3622,
           -4.3622, -4.3622, -4.3622, -4.3622, -4.3622, -4.3622, -4.3622,
           -4.3622]]]], grad_fn=<SliceBackward0>)
train_step: Entropy shape: torch.Size([16, 15])
train_step: Entropy sample: tensor([[0.4670, 0.4668],
        [0.3505, 0.4347]], grad_fn=<SliceBackward0>)
train_step: Entropy coefficient: 0.01
train_step: Actor loss: -1.4258520603179932
train_step: returns shape after mean: torch.Size([16, 15])
train_step: target_indices shape: torch.Size([16, 15])
train_step: value_logits shape: torch.Size([16, 15, 255])
train_step: target_twohot shape: torch.Size([16, 15, 255])
--- Starting train_step at 2025-04-01 01:58:38 ---
Full starting_state: {'deter': tensor([[[-2.6757e-02, -4.8048e-02, -3.8289e-02,  ..., -2.6023e-04,
          -6.4311e-02,  2.2633e-02],
         [-7.1739e-02, -1.1338e-01, -1.2332e-01,  ..., -7.4033e-02,
           2.1325e-02, -3.3824e-02],
         [ 5.8355e-02, -4.6540e-02, -3.0234e-02,  ..., -1.8836e-01,
           1.5188e-01, -9.0983e-02],
         ...,
         [-8.2063e-02,  3.7984e-03,  1.4803e-01,  ..., -1.4556e-01,
           5.5652e-02, -1.3549e-01],
         [-8.8898e-02, -1.1515e-01,  3.8159e-02,  ..., -1.3417e-01,
          -7.3050e-02,  2.6615e-02],
         [ 4.6149e-02,  1.0719e-02, -1.9845e-01,  ...,  5.9308e-02,
          -1.5385e-02,  8.4344e-03]],

        [[ 1.2019e-01,  1.4005e-02, -4.2142e-02,  ...,  1.5219e-01,
           1.5559e-02,  1.1077e-01],
         [-1.1800e-01,  2.2857e-02, -1.5093e-01,  ..., -1.0928e-02,
           9.0599e-02, -1.4266e-01],
         [-6.0631e-03,  1.2159e-02, -9.8976e-02,  ..., -4.3280e-02,
           2.0827e-03, -1.0495e-01],
         ...,
         [-2.9162e-02, -1.2815e-01, -2.0739e-01,  ..., -3.3965e-02,
          -9.5359e-02, -5.0560e-02],
         [ 5.7087e-02, -7.3615e-02, -6.4606e-02,  ..., -1.5734e-02,
           4.5442e-02, -1.6269e-02],
         [ 1.6990e-01, -1.5554e-01,  2.1688e-02,  ...,  1.8095e-01,
           2.1496e-02,  5.8232e-02]],

        [[-3.1763e-02, -3.4482e-02, -9.0548e-02,  ..., -9.3245e-02,
           2.2268e-02,  4.4610e-02],
         [-9.0170e-02,  1.5627e-02, -8.2401e-02,  ..., -1.2165e-01,
          -5.3764e-02,  6.9985e-02],
         [ 1.0037e-02,  4.3584e-02, -2.5199e-02,  ...,  2.8935e-02,
          -5.4799e-03,  1.3122e-01],
         ...,
         [-2.7145e-01,  1.3279e-01,  3.1364e-02,  ...,  5.8835e-02,
           1.4571e-01,  1.1501e-01],
         [ 6.6452e-04, -2.6354e-02,  2.4160e-02,  ..., -6.1166e-02,
           8.7931e-02,  3.7197e-02],
         [-6.0407e-02, -8.0126e-02, -1.4718e-01,  ...,  5.6444e-02,
          -6.6507e-02, -1.2359e-02]],

        ...,

        [[ 2.6947e-02, -8.7089e-02,  1.5348e-02,  ...,  3.0651e-02,
           4.5172e-02, -7.0560e-02],
         [-6.7455e-02, -1.4589e-01,  1.3842e-02,  ...,  1.9302e-02,
           3.7009e-02,  1.1973e-01],
         [ 5.4427e-02,  8.3835e-03, -8.1326e-03,  ..., -9.6999e-02,
           2.8422e-02,  6.0756e-02],
         ...,
         [ 2.9735e-02,  1.2471e-01, -1.1584e-01,  ..., -3.4504e-02,
          -2.5342e-02, -3.9026e-02],
         [ 4.2833e-02,  6.7687e-02, -7.3171e-02,  ..., -6.7932e-02,
          -1.7842e-01, -2.7389e-02],
         [-8.4109e-02,  1.0236e-01, -1.8733e-01,  ...,  1.5781e-01,
           1.1891e-01, -6.4719e-02]],

        [[-9.8067e-02,  5.7715e-02, -7.7991e-02,  ...,  1.0490e-02,
           1.1319e-01, -3.6060e-03],
         [-9.9631e-02,  3.9109e-02,  2.6822e-02,  ...,  1.5103e-01,
           1.2959e-01, -1.4385e-01],
         [ 7.7568e-02, -1.0746e-01, -3.3570e-02,  ...,  3.0682e-02,
           3.8160e-02, -4.5572e-02],
         ...,
         [ 1.0190e-01, -8.2542e-02,  1.0632e-02,  ..., -6.8066e-02,
           1.0223e-01,  1.2368e-01],
         [-8.0822e-02,  4.2670e-02, -3.8198e-04,  ..., -1.2616e-02,
           2.8120e-02,  2.0354e-02],
         [-1.5836e-03, -5.5386e-02,  1.9327e-02,  ...,  2.7512e-02,
          -5.5332e-02, -6.4839e-02]],

        [[-2.4303e-03, -8.3702e-02, -9.2576e-03,  ..., -1.1164e-02,
           8.8062e-03,  2.9107e-02],
         [ 2.0125e-01,  8.7808e-02,  1.9839e-02,  ...,  5.8708e-02,
           2.3515e-02,  7.9324e-04],
         [-1.3532e-01, -1.4638e-01,  3.8514e-02,  ..., -8.4189e-02,
           3.0022e-02, -4.3379e-02],
         ...,
         [ 1.1267e-01,  5.2617e-02, -7.4204e-04,  ..., -1.6568e-03,
           7.0808e-03, -1.4214e-01],
         [ 7.2998e-04,  6.1642e-02,  1.2182e-02,  ...,  9.4585e-03,
          -1.0109e-01, -1.0992e-02],
         [-9.2360e-03, -7.7757e-02, -1.1671e-01,  ...,  3.0828e-02,
          -1.3081e-02, -3.5172e-02]]], grad_fn=<StackBackward0>), 'stoch': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 1., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 1.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[1., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]])}
train_step: Starting state deter shape: torch.Size([16, 50, 128])
train_step: Starting state stoch shape: torch.Size([16, 50, 1024])
After ensuring logits/stoch: {'deter': tensor([[[-2.6757e-02, -4.8048e-02, -3.8289e-02,  ..., -2.6023e-04,
          -6.4311e-02,  2.2633e-02],
         [-7.1739e-02, -1.1338e-01, -1.2332e-01,  ..., -7.4033e-02,
           2.1325e-02, -3.3824e-02],
         [ 5.8355e-02, -4.6540e-02, -3.0234e-02,  ..., -1.8836e-01,
           1.5188e-01, -9.0983e-02],
         ...,
         [-8.2063e-02,  3.7984e-03,  1.4803e-01,  ..., -1.4556e-01,
           5.5652e-02, -1.3549e-01],
         [-8.8898e-02, -1.1515e-01,  3.8159e-02,  ..., -1.3417e-01,
          -7.3050e-02,  2.6615e-02],
         [ 4.6149e-02,  1.0719e-02, -1.9845e-01,  ...,  5.9308e-02,
          -1.5385e-02,  8.4344e-03]],

        [[ 1.2019e-01,  1.4005e-02, -4.2142e-02,  ...,  1.5219e-01,
           1.5559e-02,  1.1077e-01],
         [-1.1800e-01,  2.2857e-02, -1.5093e-01,  ..., -1.0928e-02,
           9.0599e-02, -1.4266e-01],
         [-6.0631e-03,  1.2159e-02, -9.8976e-02,  ..., -4.3280e-02,
           2.0827e-03, -1.0495e-01],
         ...,
         [-2.9162e-02, -1.2815e-01, -2.0739e-01,  ..., -3.3965e-02,
          -9.5359e-02, -5.0560e-02],
         [ 5.7087e-02, -7.3615e-02, -6.4606e-02,  ..., -1.5734e-02,
           4.5442e-02, -1.6269e-02],
         [ 1.6990e-01, -1.5554e-01,  2.1688e-02,  ...,  1.8095e-01,
           2.1496e-02,  5.8232e-02]],

        [[-3.1763e-02, -3.4482e-02, -9.0548e-02,  ..., -9.3245e-02,
           2.2268e-02,  4.4610e-02],
         [-9.0170e-02,  1.5627e-02, -8.2401e-02,  ..., -1.2165e-01,
          -5.3764e-02,  6.9985e-02],
         [ 1.0037e-02,  4.3584e-02, -2.5199e-02,  ...,  2.8935e-02,
          -5.4799e-03,  1.3122e-01],
         ...,
         [-2.7145e-01,  1.3279e-01,  3.1364e-02,  ...,  5.8835e-02,
           1.4571e-01,  1.1501e-01],
         [ 6.6452e-04, -2.6354e-02,  2.4160e-02,  ..., -6.1166e-02,
           8.7931e-02,  3.7197e-02],
         [-6.0407e-02, -8.0126e-02, -1.4718e-01,  ...,  5.6444e-02,
          -6.6507e-02, -1.2359e-02]],

        ...,

        [[ 2.6947e-02, -8.7089e-02,  1.5348e-02,  ...,  3.0651e-02,
           4.5172e-02, -7.0560e-02],
         [-6.7455e-02, -1.4589e-01,  1.3842e-02,  ...,  1.9302e-02,
           3.7009e-02,  1.1973e-01],
         [ 5.4427e-02,  8.3835e-03, -8.1326e-03,  ..., -9.6999e-02,
           2.8422e-02,  6.0756e-02],
         ...,
         [ 2.9735e-02,  1.2471e-01, -1.1584e-01,  ..., -3.4504e-02,
          -2.5342e-02, -3.9026e-02],
         [ 4.2833e-02,  6.7687e-02, -7.3171e-02,  ..., -6.7932e-02,
          -1.7842e-01, -2.7389e-02],
         [-8.4109e-02,  1.0236e-01, -1.8733e-01,  ...,  1.5781e-01,
           1.1891e-01, -6.4719e-02]],

        [[-9.8067e-02,  5.7715e-02, -7.7991e-02,  ...,  1.0490e-02,
           1.1319e-01, -3.6060e-03],
         [-9.9631e-02,  3.9109e-02,  2.6822e-02,  ...,  1.5103e-01,
           1.2959e-01, -1.4385e-01],
         [ 7.7568e-02, -1.0746e-01, -3.3570e-02,  ...,  3.0682e-02,
           3.8160e-02, -4.5572e-02],
         ...,
         [ 1.0190e-01, -8.2542e-02,  1.0632e-02,  ..., -6.8066e-02,
           1.0223e-01,  1.2368e-01],
         [-8.0822e-02,  4.2670e-02, -3.8198e-04,  ..., -1.2616e-02,
           2.8120e-02,  2.0354e-02],
         [-1.5836e-03, -5.5386e-02,  1.9327e-02,  ...,  2.7512e-02,
          -5.5332e-02, -6.4839e-02]],

        [[-2.4303e-03, -8.3702e-02, -9.2576e-03,  ..., -1.1164e-02,
           8.8062e-03,  2.9107e-02],
         [ 2.0125e-01,  8.7808e-02,  1.9839e-02,  ...,  5.8708e-02,
           2.3515e-02,  7.9324e-04],
         [-1.3532e-01, -1.4638e-01,  3.8514e-02,  ..., -8.4189e-02,
           3.0022e-02, -4.3379e-02],
         ...,
         [ 1.1267e-01,  5.2617e-02, -7.4204e-04,  ..., -1.6568e-03,
           7.0808e-03, -1.4214e-01],
         [ 7.2998e-04,  6.1642e-02,  1.2182e-02,  ...,  9.4585e-03,
          -1.0109e-01, -1.0992e-02],
         [-9.2360e-03, -7.7757e-02, -1.1671e-01,  ...,  3.0828e-02,
          -1.3081e-02, -3.5172e-02]]], grad_fn=<StackBackward0>), 'stoch': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 1., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 1.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[1., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]]), 'logits': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]])}
train_step: Normalized hidden_state shape: torch.Size([1, 16, 128])
train_step: Normalized stoch shape: torch.Size([16, 1024])
train_step: Normalized deter shape: torch.Size([16, 128])
train_step: Post-imagine_trajectory: Imagined features shape: torch.Size([16, 15, 1152])
train_step: Post-imagine_trajectory: Imagined actions shape: torch.Size([16, 15, 2])
train_step: Post-imagine_trajectory: Imagined action indices shape: torch.Size([16, 15])
train_step: Post-imagine_trajectory: Imagined state deter shape: torch.Size([16, 15, 128])
train_step: Post-imagine_trajectory: Imagined state stoch shape: torch.Size([16, 15, 1024])
Reward shape: torch.Size([16, 15, 1]), Value shape: torch.Size([16, 15, 1]), Slow Value shape: torch.Size([16, 15, 1]), Discount shape: torch.Size([16, 15, 1, 1])
Return targets length: 15, First target shape: torch.Size([16, 16, 1])
train_step: Actor distribution shape: torch.Size([16, 15, 2])
train_step: Action log probabilities shape: torch.Size([16, 15])
train_step: Action log probabilities sample: tensor([[-0.1580, -1.0609],
        [-0.9382, -0.2979]], grad_fn=<SliceBackward0>)
train_step: Advantages shape: torch.Size([16, 15, 16, 15])
train_step: Advantages sample: tensor([[[[-3.9873, -3.9872, -3.9873, -3.9873, -3.9872, -3.9873, -3.9872,
           -3.9873, -3.9873, -3.9873, -3.9872, -3.9872, -3.9872, -3.9873,
           -3.9873],
          [-3.9873, -3.9872, -3.9873, -3.9873, -3.9872, -3.9873, -3.9872,
           -3.9873, -3.9873, -3.9873, -3.9872, -3.9872, -3.9872, -3.9873,
           -3.9873],
          [-3.9873, -3.9872, -3.9873, -3.9873, -3.9872, -3.9873, -3.9872,
           -3.9873, -3.9873, -3.9873, -3.9872, -3.9872, -3.9872, -3.9873,
           -3.9873],
          [-3.9873, -3.9872, -3.9873, -3.9873, -3.9872, -3.9873, -3.9872,
           -3.9873, -3.9873, -3.9873, -3.9872, -3.9872, -3.9872, -3.9873,
           -3.9873],
          [-3.9873, -3.9872, -3.9873, -3.9873, -3.9872, -3.9873, -3.9872,
           -3.9873, -3.9873, -3.9873, -3.9872, -3.9872, -3.9872, -3.9873,
           -3.9873],
          [-3.9873, -3.9872, -3.9873, -3.9873, -3.9872, -3.9873, -3.9872,
           -3.9873, -3.9873, -3.9873, -3.9872, -3.9872, -3.9872, -3.9873,
           -3.9873],
          [-3.9873, -3.9872, -3.9873, -3.9873, -3.9872, -3.9873, -3.9872,
           -3.9873, -3.9873, -3.9873, -3.9872, -3.9872, -3.9872, -3.9873,
           -3.9873],
          [-3.9873, -3.9872, -3.9873, -3.9873, -3.9872, -3.9873, -3.9872,
           -3.9873, -3.9873, -3.9873, -3.9872, -3.9872, -3.9872, -3.9873,
           -3.9873],
          [-3.9873, -3.9872, -3.9873, -3.9873, -3.9872, -3.9873, -3.9872,
           -3.9873, -3.9873, -3.9873, -3.9872, -3.9872, -3.9872, -3.9873,
           -3.9873],
          [-3.9873, -3.9872, -3.9873, -3.9873, -3.9872, -3.9873, -3.9872,
           -3.9873, -3.9873, -3.9873, -3.9872, -3.9872, -3.9872, -3.9873,
           -3.9873],
          [-3.9873, -3.9872, -3.9873, -3.9873, -3.9872, -3.9873, -3.9872,
           -3.9873, -3.9873, -3.9873, -3.9872, -3.9872, -3.9872, -3.9873,
           -3.9873],
          [-3.9873, -3.9872, -3.9873, -3.9873, -3.9872, -3.9873, -3.9872,
           -3.9873, -3.9873, -3.9873, -3.9872, -3.9872, -3.9872, -3.9873,
           -3.9873],
          [-3.9873, -3.9872, -3.9873, -3.9873, -3.9872, -3.9873, -3.9872,
           -3.9873, -3.9873, -3.9873, -3.9872, -3.9872, -3.9872, -3.9873,
           -3.9873],
          [-3.9873, -3.9872, -3.9873, -3.9873, -3.9872, -3.9873, -3.9872,
           -3.9873, -3.9873, -3.9873, -3.9872, -3.9872, -3.9872, -3.9873,
           -3.9873],
          [-3.9873, -3.9872, -3.9873, -3.9873, -3.9872, -3.9873, -3.9872,
           -3.9873, -3.9873, -3.9873, -3.9872, -3.9872, -3.9872, -3.9873,
           -3.9873],
          [-3.9873, -3.9872, -3.9873, -3.9873, -3.9872, -3.9873, -3.9872,
           -3.9873, -3.9873, -3.9873, -3.9872, -3.9872, -3.9872, -3.9873,
           -3.9873]],

         [[-3.8013, -3.8012, -3.8012, -3.8012, -3.8012, -3.8012, -3.8012,
           -3.8012, -3.8012, -3.8012, -3.8012, -3.8012, -3.8012, -3.8012,
           -3.8012],
          [-3.8013, -3.8012, -3.8012, -3.8012, -3.8012, -3.8012, -3.8012,
           -3.8012, -3.8012, -3.8012, -3.8012, -3.8012, -3.8012, -3.8012,
           -3.8012],
          [-3.8013, -3.8012, -3.8012, -3.8012, -3.8012, -3.8012, -3.8012,
           -3.8012, -3.8012, -3.8012, -3.8012, -3.8012, -3.8012, -3.8012,
           -3.8012],
          [-3.8013, -3.8012, -3.8012, -3.8012, -3.8012, -3.8012, -3.8012,
           -3.8012, -3.8012, -3.8012, -3.8012, -3.8012, -3.8012, -3.8012,
           -3.8012],
          [-3.8013, -3.8012, -3.8012, -3.8012, -3.8012, -3.8012, -3.8012,
           -3.8012, -3.8012, -3.8012, -3.8012, -3.8012, -3.8012, -3.8012,
           -3.8012],
          [-3.8013, -3.8012, -3.8012, -3.8012, -3.8012, -3.8012, -3.8012,
           -3.8012, -3.8012, -3.8012, -3.8012, -3.8012, -3.8012, -3.8012,
           -3.8012],
          [-3.8013, -3.8012, -3.8012, -3.8012, -3.8012, -3.8012, -3.8012,
           -3.8012, -3.8012, -3.8012, -3.8012, -3.8012, -3.8012, -3.8012,
           -3.8012],
          [-3.8013, -3.8012, -3.8012, -3.8012, -3.8012, -3.8012, -3.8012,
           -3.8012, -3.8012, -3.8012, -3.8012, -3.8012, -3.8012, -3.8012,
           -3.8012],
          [-3.8013, -3.8012, -3.8012, -3.8012, -3.8012, -3.8012, -3.8012,
           -3.8012, -3.8012, -3.8012, -3.8012, -3.8012, -3.8012, -3.8012,
           -3.8012],
          [-3.8013, -3.8012, -3.8012, -3.8012, -3.8012, -3.8012, -3.8012,
           -3.8012, -3.8012, -3.8012, -3.8012, -3.8012, -3.8012, -3.8012,
           -3.8012],
          [-3.8013, -3.8012, -3.8012, -3.8012, -3.8012, -3.8012, -3.8012,
           -3.8012, -3.8012, -3.8012, -3.8012, -3.8012, -3.8012, -3.8012,
           -3.8012],
          [-3.8013, -3.8012, -3.8012, -3.8012, -3.8012, -3.8012, -3.8012,
           -3.8012, -3.8012, -3.8012, -3.8012, -3.8012, -3.8012, -3.8012,
           -3.8012],
          [-3.8013, -3.8012, -3.8012, -3.8012, -3.8012, -3.8012, -3.8012,
           -3.8012, -3.8012, -3.8012, -3.8012, -3.8012, -3.8012, -3.8012,
           -3.8012],
          [-3.8013, -3.8012, -3.8012, -3.8012, -3.8012, -3.8012, -3.8012,
           -3.8012, -3.8012, -3.8012, -3.8012, -3.8012, -3.8012, -3.8012,
           -3.8012],
          [-3.8013, -3.8012, -3.8012, -3.8012, -3.8012, -3.8012, -3.8012,
           -3.8012, -3.8012, -3.8012, -3.8012, -3.8012, -3.8012, -3.8012,
           -3.8012],
          [-3.8013, -3.8012, -3.8012, -3.8012, -3.8012, -3.8012, -3.8012,
           -3.8012, -3.8012, -3.8012, -3.8012, -3.8012, -3.8012, -3.8012,
           -3.8012]]],


        [[[-6.3512, -6.3512, -6.3512, -6.3512, -6.3512, -6.3512, -6.3512,
           -6.3512, -6.3512, -6.3512, -6.3512, -6.3512, -6.3512, -6.3512,
           -6.3512],
          [-6.3512, -6.3512, -6.3512, -6.3512, -6.3512, -6.3512, -6.3512,
           -6.3512, -6.3512, -6.3512, -6.3512, -6.3512, -6.3512, -6.3512,
           -6.3512],
          [-6.3512, -6.3512, -6.3512, -6.3512, -6.3512, -6.3512, -6.3512,
           -6.3512, -6.3512, -6.3512, -6.3512, -6.3512, -6.3512, -6.3512,
           -6.3512],
          [-6.3512, -6.3512, -6.3512, -6.3512, -6.3512, -6.3512, -6.3512,
           -6.3512, -6.3512, -6.3512, -6.3512, -6.3512, -6.3512, -6.3512,
           -6.3512],
          [-6.3512, -6.3512, -6.3512, -6.3512, -6.3512, -6.3512, -6.3512,
           -6.3512, -6.3512, -6.3512, -6.3512, -6.3512, -6.3512, -6.3512,
           -6.3512],
          [-6.3512, -6.3512, -6.3512, -6.3512, -6.3512, -6.3512, -6.3512,
           -6.3512, -6.3512, -6.3512, -6.3512, -6.3512, -6.3512, -6.3512,
           -6.3512],
          [-6.3512, -6.3512, -6.3512, -6.3512, -6.3512, -6.3512, -6.3512,
           -6.3512, -6.3512, -6.3512, -6.3512, -6.3512, -6.3512, -6.3512,
           -6.3512],
          [-6.3512, -6.3512, -6.3512, -6.3512, -6.3512, -6.3512, -6.3512,
           -6.3512, -6.3512, -6.3512, -6.3512, -6.3512, -6.3512, -6.3512,
           -6.3512],
          [-6.3512, -6.3512, -6.3512, -6.3512, -6.3512, -6.3512, -6.3512,
           -6.3512, -6.3512, -6.3512, -6.3512, -6.3512, -6.3512, -6.3512,
           -6.3512],
          [-6.3512, -6.3512, -6.3512, -6.3512, -6.3512, -6.3512, -6.3512,
           -6.3512, -6.3512, -6.3512, -6.3512, -6.3512, -6.3512, -6.3512,
           -6.3512],
          [-6.3512, -6.3512, -6.3512, -6.3512, -6.3512, -6.3512, -6.3512,
           -6.3512, -6.3512, -6.3512, -6.3512, -6.3512, -6.3512, -6.3512,
           -6.3512],
          [-6.3512, -6.3512, -6.3512, -6.3512, -6.3512, -6.3512, -6.3512,
           -6.3512, -6.3512, -6.3512, -6.3512, -6.3512, -6.3512, -6.3512,
           -6.3512],
          [-6.3512, -6.3512, -6.3512, -6.3512, -6.3512, -6.3512, -6.3512,
           -6.3512, -6.3512, -6.3512, -6.3512, -6.3512, -6.3512, -6.3512,
           -6.3512],
          [-6.3512, -6.3512, -6.3512, -6.3512, -6.3512, -6.3512, -6.3512,
           -6.3512, -6.3512, -6.3512, -6.3512, -6.3512, -6.3512, -6.3512,
           -6.3512],
          [-6.3512, -6.3512, -6.3512, -6.3512, -6.3512, -6.3512, -6.3512,
           -6.3512, -6.3512, -6.3512, -6.3512, -6.3512, -6.3512, -6.3512,
           -6.3512],
          [-6.3512, -6.3512, -6.3512, -6.3512, -6.3512, -6.3512, -6.3512,
           -6.3512, -6.3512, -6.3512, -6.3512, -6.3512, -6.3512, -6.3512,
           -6.3512]],

         [[-6.0875, -6.0874, -6.0874, -6.0875, -6.0875, -6.0874, -6.0875,
           -6.0875, -6.0875, -6.0874, -6.0874, -6.0875, -6.0874, -6.0874,
           -6.0875],
          [-6.0875, -6.0874, -6.0874, -6.0875, -6.0875, -6.0874, -6.0875,
           -6.0875, -6.0875, -6.0874, -6.0874, -6.0875, -6.0874, -6.0874,
           -6.0875],
          [-6.0875, -6.0874, -6.0874, -6.0875, -6.0875, -6.0874, -6.0875,
           -6.0875, -6.0875, -6.0874, -6.0874, -6.0875, -6.0874, -6.0874,
           -6.0875],
          [-6.0875, -6.0874, -6.0874, -6.0875, -6.0875, -6.0874, -6.0875,
           -6.0875, -6.0875, -6.0874, -6.0874, -6.0875, -6.0874, -6.0874,
           -6.0875],
          [-6.0875, -6.0874, -6.0874, -6.0875, -6.0875, -6.0874, -6.0875,
           -6.0875, -6.0875, -6.0874, -6.0874, -6.0875, -6.0874, -6.0874,
           -6.0875],
          [-6.0875, -6.0874, -6.0874, -6.0875, -6.0875, -6.0874, -6.0875,
           -6.0875, -6.0875, -6.0874, -6.0874, -6.0875, -6.0874, -6.0874,
           -6.0875],
          [-6.0875, -6.0874, -6.0874, -6.0875, -6.0875, -6.0874, -6.0875,
           -6.0875, -6.0875, -6.0874, -6.0874, -6.0875, -6.0874, -6.0874,
           -6.0875],
          [-6.0875, -6.0874, -6.0874, -6.0875, -6.0875, -6.0874, -6.0875,
           -6.0875, -6.0875, -6.0874, -6.0874, -6.0875, -6.0874, -6.0874,
           -6.0875],
          [-6.0875, -6.0874, -6.0874, -6.0875, -6.0875, -6.0874, -6.0875,
           -6.0875, -6.0875, -6.0874, -6.0874, -6.0875, -6.0874, -6.0874,
           -6.0875],
          [-6.0875, -6.0874, -6.0874, -6.0875, -6.0875, -6.0874, -6.0875,
           -6.0875, -6.0875, -6.0874, -6.0874, -6.0875, -6.0874, -6.0874,
           -6.0875],
          [-6.0875, -6.0874, -6.0874, -6.0875, -6.0875, -6.0874, -6.0875,
           -6.0875, -6.0875, -6.0874, -6.0874, -6.0875, -6.0874, -6.0874,
           -6.0875],
          [-6.0875, -6.0874, -6.0874, -6.0875, -6.0875, -6.0874, -6.0875,
           -6.0875, -6.0875, -6.0874, -6.0874, -6.0875, -6.0874, -6.0874,
           -6.0875],
          [-6.0875, -6.0874, -6.0874, -6.0875, -6.0875, -6.0874, -6.0875,
           -6.0875, -6.0875, -6.0874, -6.0874, -6.0875, -6.0874, -6.0874,
           -6.0875],
          [-6.0875, -6.0874, -6.0874, -6.0875, -6.0875, -6.0874, -6.0875,
           -6.0875, -6.0875, -6.0874, -6.0874, -6.0875, -6.0874, -6.0874,
           -6.0875],
          [-6.0875, -6.0874, -6.0874, -6.0875, -6.0875, -6.0874, -6.0875,
           -6.0875, -6.0875, -6.0874, -6.0874, -6.0875, -6.0874, -6.0874,
           -6.0875],
          [-6.0875, -6.0874, -6.0874, -6.0875, -6.0875, -6.0874, -6.0875,
           -6.0875, -6.0875, -6.0874, -6.0874, -6.0875, -6.0874, -6.0874,
           -6.0875]]]], grad_fn=<SliceBackward0>)
train_step: Return scale: 1.5502015914581841
train_step: Scaled advantages shape: torch.Size([16, 15, 16, 15])
train_step: Scaled advantages sample: tensor([[[[-2.5721, -2.5721, -2.5721, -2.5721, -2.5721, -2.5721, -2.5721,
           -2.5721, -2.5721, -2.5721, -2.5721, -2.5721, -2.5721, -2.5721,
           -2.5721],
          [-2.5721, -2.5721, -2.5721, -2.5721, -2.5721, -2.5721, -2.5721,
           -2.5721, -2.5721, -2.5721, -2.5721, -2.5721, -2.5721, -2.5721,
           -2.5721],
          [-2.5721, -2.5721, -2.5721, -2.5721, -2.5721, -2.5721, -2.5721,
           -2.5721, -2.5721, -2.5721, -2.5721, -2.5721, -2.5721, -2.5721,
           -2.5721],
          [-2.5721, -2.5721, -2.5721, -2.5721, -2.5721, -2.5721, -2.5721,
           -2.5721, -2.5721, -2.5721, -2.5721, -2.5721, -2.5721, -2.5721,
           -2.5721],
          [-2.5721, -2.5721, -2.5721, -2.5721, -2.5721, -2.5721, -2.5721,
           -2.5721, -2.5721, -2.5721, -2.5721, -2.5721, -2.5721, -2.5721,
           -2.5721],
          [-2.5721, -2.5721, -2.5721, -2.5721, -2.5721, -2.5721, -2.5721,
           -2.5721, -2.5721, -2.5721, -2.5721, -2.5721, -2.5721, -2.5721,
           -2.5721],
          [-2.5721, -2.5721, -2.5721, -2.5721, -2.5721, -2.5721, -2.5721,
           -2.5721, -2.5721, -2.5721, -2.5721, -2.5721, -2.5721, -2.5721,
           -2.5721],
          [-2.5721, -2.5721, -2.5721, -2.5721, -2.5721, -2.5721, -2.5721,
           -2.5721, -2.5721, -2.5721, -2.5721, -2.5721, -2.5721, -2.5721,
           -2.5721],
          [-2.5721, -2.5721, -2.5721, -2.5721, -2.5721, -2.5721, -2.5721,
           -2.5721, -2.5721, -2.5721, -2.5721, -2.5721, -2.5721, -2.5721,
           -2.5721],
          [-2.5721, -2.5721, -2.5721, -2.5721, -2.5721, -2.5721, -2.5721,
           -2.5721, -2.5721, -2.5721, -2.5721, -2.5721, -2.5721, -2.5721,
           -2.5721],
          [-2.5721, -2.5721, -2.5721, -2.5721, -2.5721, -2.5721, -2.5721,
           -2.5721, -2.5721, -2.5721, -2.5721, -2.5721, -2.5721, -2.5721,
           -2.5721],
          [-2.5721, -2.5721, -2.5721, -2.5721, -2.5721, -2.5721, -2.5721,
           -2.5721, -2.5721, -2.5721, -2.5721, -2.5721, -2.5721, -2.5721,
           -2.5721],
          [-2.5721, -2.5721, -2.5721, -2.5721, -2.5721, -2.5721, -2.5721,
           -2.5721, -2.5721, -2.5721, -2.5721, -2.5721, -2.5721, -2.5721,
           -2.5721],
          [-2.5721, -2.5721, -2.5721, -2.5721, -2.5721, -2.5721, -2.5721,
           -2.5721, -2.5721, -2.5721, -2.5721, -2.5721, -2.5721, -2.5721,
           -2.5721],
          [-2.5721, -2.5721, -2.5721, -2.5721, -2.5721, -2.5721, -2.5721,
           -2.5721, -2.5721, -2.5721, -2.5721, -2.5721, -2.5721, -2.5721,
           -2.5721],
          [-2.5721, -2.5721, -2.5721, -2.5721, -2.5721, -2.5721, -2.5721,
           -2.5721, -2.5721, -2.5721, -2.5721, -2.5721, -2.5721, -2.5721,
           -2.5721]],

         [[-2.4521, -2.4521, -2.4521, -2.4521, -2.4521, -2.4521, -2.4521,
           -2.4521, -2.4521, -2.4521, -2.4521, -2.4521, -2.4521, -2.4521,
           -2.4521],
          [-2.4521, -2.4521, -2.4521, -2.4521, -2.4521, -2.4521, -2.4521,
           -2.4521, -2.4521, -2.4521, -2.4521, -2.4521, -2.4521, -2.4521,
           -2.4521],
          [-2.4521, -2.4521, -2.4521, -2.4521, -2.4521, -2.4521, -2.4521,
           -2.4521, -2.4521, -2.4521, -2.4521, -2.4521, -2.4521, -2.4521,
           -2.4521],
          [-2.4521, -2.4521, -2.4521, -2.4521, -2.4521, -2.4521, -2.4521,
           -2.4521, -2.4521, -2.4521, -2.4521, -2.4521, -2.4521, -2.4521,
           -2.4521],
          [-2.4521, -2.4521, -2.4521, -2.4521, -2.4521, -2.4521, -2.4521,
           -2.4521, -2.4521, -2.4521, -2.4521, -2.4521, -2.4521, -2.4521,
           -2.4521],
          [-2.4521, -2.4521, -2.4521, -2.4521, -2.4521, -2.4521, -2.4521,
           -2.4521, -2.4521, -2.4521, -2.4521, -2.4521, -2.4521, -2.4521,
           -2.4521],
          [-2.4521, -2.4521, -2.4521, -2.4521, -2.4521, -2.4521, -2.4521,
           -2.4521, -2.4521, -2.4521, -2.4521, -2.4521, -2.4521, -2.4521,
           -2.4521],
          [-2.4521, -2.4521, -2.4521, -2.4521, -2.4521, -2.4521, -2.4521,
           -2.4521, -2.4521, -2.4521, -2.4521, -2.4521, -2.4521, -2.4521,
           -2.4521],
          [-2.4521, -2.4521, -2.4521, -2.4521, -2.4521, -2.4521, -2.4521,
           -2.4521, -2.4521, -2.4521, -2.4521, -2.4521, -2.4521, -2.4521,
           -2.4521],
          [-2.4521, -2.4521, -2.4521, -2.4521, -2.4521, -2.4521, -2.4521,
           -2.4521, -2.4521, -2.4521, -2.4521, -2.4521, -2.4521, -2.4521,
           -2.4521],
          [-2.4521, -2.4521, -2.4521, -2.4521, -2.4521, -2.4521, -2.4521,
           -2.4521, -2.4521, -2.4521, -2.4521, -2.4521, -2.4521, -2.4521,
           -2.4521],
          [-2.4521, -2.4521, -2.4521, -2.4521, -2.4521, -2.4521, -2.4521,
           -2.4521, -2.4521, -2.4521, -2.4521, -2.4521, -2.4521, -2.4521,
           -2.4521],
          [-2.4521, -2.4521, -2.4521, -2.4521, -2.4521, -2.4521, -2.4521,
           -2.4521, -2.4521, -2.4521, -2.4521, -2.4521, -2.4521, -2.4521,
           -2.4521],
          [-2.4521, -2.4521, -2.4521, -2.4521, -2.4521, -2.4521, -2.4521,
           -2.4521, -2.4521, -2.4521, -2.4521, -2.4521, -2.4521, -2.4521,
           -2.4521],
          [-2.4521, -2.4521, -2.4521, -2.4521, -2.4521, -2.4521, -2.4521,
           -2.4521, -2.4521, -2.4521, -2.4521, -2.4521, -2.4521, -2.4521,
           -2.4521],
          [-2.4521, -2.4521, -2.4521, -2.4521, -2.4521, -2.4521, -2.4521,
           -2.4521, -2.4521, -2.4521, -2.4521, -2.4521, -2.4521, -2.4521,
           -2.4521]]],


        [[[-4.0970, -4.0970, -4.0970, -4.0970, -4.0970, -4.0970, -4.0970,
           -4.0970, -4.0970, -4.0970, -4.0970, -4.0970, -4.0970, -4.0970,
           -4.0970],
          [-4.0970, -4.0970, -4.0970, -4.0970, -4.0970, -4.0970, -4.0970,
           -4.0970, -4.0970, -4.0970, -4.0970, -4.0970, -4.0970, -4.0970,
           -4.0970],
          [-4.0970, -4.0970, -4.0970, -4.0970, -4.0970, -4.0970, -4.0970,
           -4.0970, -4.0970, -4.0970, -4.0970, -4.0970, -4.0970, -4.0970,
           -4.0970],
          [-4.0970, -4.0970, -4.0970, -4.0970, -4.0970, -4.0970, -4.0970,
           -4.0970, -4.0970, -4.0970, -4.0970, -4.0970, -4.0970, -4.0970,
           -4.0970],
          [-4.0970, -4.0970, -4.0970, -4.0970, -4.0970, -4.0970, -4.0970,
           -4.0970, -4.0970, -4.0970, -4.0970, -4.0970, -4.0970, -4.0970,
           -4.0970],
          [-4.0970, -4.0970, -4.0970, -4.0970, -4.0970, -4.0970, -4.0970,
           -4.0970, -4.0970, -4.0970, -4.0970, -4.0970, -4.0970, -4.0970,
           -4.0970],
          [-4.0970, -4.0970, -4.0970, -4.0970, -4.0970, -4.0970, -4.0970,
           -4.0970, -4.0970, -4.0970, -4.0970, -4.0970, -4.0970, -4.0970,
           -4.0970],
          [-4.0970, -4.0970, -4.0970, -4.0970, -4.0970, -4.0970, -4.0970,
           -4.0970, -4.0970, -4.0970, -4.0970, -4.0970, -4.0970, -4.0970,
           -4.0970],
          [-4.0970, -4.0970, -4.0970, -4.0970, -4.0970, -4.0970, -4.0970,
           -4.0970, -4.0970, -4.0970, -4.0970, -4.0970, -4.0970, -4.0970,
           -4.0970],
          [-4.0970, -4.0970, -4.0970, -4.0970, -4.0970, -4.0970, -4.0970,
           -4.0970, -4.0970, -4.0970, -4.0970, -4.0970, -4.0970, -4.0970,
           -4.0970],
          [-4.0970, -4.0970, -4.0970, -4.0970, -4.0970, -4.0970, -4.0970,
           -4.0970, -4.0970, -4.0970, -4.0970, -4.0970, -4.0970, -4.0970,
           -4.0970],
          [-4.0970, -4.0970, -4.0970, -4.0970, -4.0970, -4.0970, -4.0970,
           -4.0970, -4.0970, -4.0970, -4.0970, -4.0970, -4.0970, -4.0970,
           -4.0970],
          [-4.0970, -4.0970, -4.0970, -4.0970, -4.0970, -4.0970, -4.0970,
           -4.0970, -4.0970, -4.0970, -4.0970, -4.0970, -4.0970, -4.0970,
           -4.0970],
          [-4.0970, -4.0970, -4.0970, -4.0970, -4.0970, -4.0970, -4.0970,
           -4.0970, -4.0970, -4.0970, -4.0970, -4.0970, -4.0970, -4.0970,
           -4.0970],
          [-4.0970, -4.0970, -4.0970, -4.0970, -4.0970, -4.0970, -4.0970,
           -4.0970, -4.0970, -4.0970, -4.0970, -4.0970, -4.0970, -4.0970,
           -4.0970],
          [-4.0970, -4.0970, -4.0970, -4.0970, -4.0970, -4.0970, -4.0970,
           -4.0970, -4.0970, -4.0970, -4.0970, -4.0970, -4.0970, -4.0970,
           -4.0970]],

         [[-3.9269, -3.9269, -3.9269, -3.9269, -3.9269, -3.9269, -3.9269,
           -3.9269, -3.9269, -3.9269, -3.9269, -3.9269, -3.9269, -3.9269,
           -3.9269],
          [-3.9269, -3.9269, -3.9269, -3.9269, -3.9269, -3.9269, -3.9269,
           -3.9269, -3.9269, -3.9269, -3.9269, -3.9269, -3.9269, -3.9269,
           -3.9269],
          [-3.9269, -3.9269, -3.9269, -3.9269, -3.9269, -3.9269, -3.9269,
           -3.9269, -3.9269, -3.9269, -3.9269, -3.9269, -3.9269, -3.9269,
           -3.9269],
          [-3.9269, -3.9269, -3.9269, -3.9269, -3.9269, -3.9269, -3.9269,
           -3.9269, -3.9269, -3.9269, -3.9269, -3.9269, -3.9269, -3.9269,
           -3.9269],
          [-3.9269, -3.9269, -3.9269, -3.9269, -3.9269, -3.9269, -3.9269,
           -3.9269, -3.9269, -3.9269, -3.9269, -3.9269, -3.9269, -3.9269,
           -3.9269],
          [-3.9269, -3.9269, -3.9269, -3.9269, -3.9269, -3.9269, -3.9269,
           -3.9269, -3.9269, -3.9269, -3.9269, -3.9269, -3.9269, -3.9269,
           -3.9269],
          [-3.9269, -3.9269, -3.9269, -3.9269, -3.9269, -3.9269, -3.9269,
           -3.9269, -3.9269, -3.9269, -3.9269, -3.9269, -3.9269, -3.9269,
           -3.9269],
          [-3.9269, -3.9269, -3.9269, -3.9269, -3.9269, -3.9269, -3.9269,
           -3.9269, -3.9269, -3.9269, -3.9269, -3.9269, -3.9269, -3.9269,
           -3.9269],
          [-3.9269, -3.9269, -3.9269, -3.9269, -3.9269, -3.9269, -3.9269,
           -3.9269, -3.9269, -3.9269, -3.9269, -3.9269, -3.9269, -3.9269,
           -3.9269],
          [-3.9269, -3.9269, -3.9269, -3.9269, -3.9269, -3.9269, -3.9269,
           -3.9269, -3.9269, -3.9269, -3.9269, -3.9269, -3.9269, -3.9269,
           -3.9269],
          [-3.9269, -3.9269, -3.9269, -3.9269, -3.9269, -3.9269, -3.9269,
           -3.9269, -3.9269, -3.9269, -3.9269, -3.9269, -3.9269, -3.9269,
           -3.9269],
          [-3.9269, -3.9269, -3.9269, -3.9269, -3.9269, -3.9269, -3.9269,
           -3.9269, -3.9269, -3.9269, -3.9269, -3.9269, -3.9269, -3.9269,
           -3.9269],
          [-3.9269, -3.9269, -3.9269, -3.9269, -3.9269, -3.9269, -3.9269,
           -3.9269, -3.9269, -3.9269, -3.9269, -3.9269, -3.9269, -3.9269,
           -3.9269],
          [-3.9269, -3.9269, -3.9269, -3.9269, -3.9269, -3.9269, -3.9269,
           -3.9269, -3.9269, -3.9269, -3.9269, -3.9269, -3.9269, -3.9269,
           -3.9269],
          [-3.9269, -3.9269, -3.9269, -3.9269, -3.9269, -3.9269, -3.9269,
           -3.9269, -3.9269, -3.9269, -3.9269, -3.9269, -3.9269, -3.9269,
           -3.9269],
          [-3.9269, -3.9269, -3.9269, -3.9269, -3.9269, -3.9269, -3.9269,
           -3.9269, -3.9269, -3.9269, -3.9269, -3.9269, -3.9269, -3.9269,
           -3.9269]]]], grad_fn=<SliceBackward0>)
train_step: Entropy shape: torch.Size([16, 15])
train_step: Entropy sample: tensor([[0.4159, 0.6450],
        [0.6693, 0.5706]], grad_fn=<SliceBackward0>)
train_step: Entropy coefficient: 0.01
train_step: Actor loss: -1.348596215248108
train_step: returns shape after mean: torch.Size([16, 15])
train_step: target_indices shape: torch.Size([16, 15])
train_step: value_logits shape: torch.Size([16, 15, 255])
train_step: target_twohot shape: torch.Size([16, 15, 255])
--- Starting train_step at 2025-04-01 01:58:57 ---
Full starting_state: {'deter': tensor([[[ 0.0510, -0.0765,  0.0837,  ..., -0.0017,  0.1000,  0.0615],
         [ 0.0822, -0.0116, -0.1396,  ...,  0.0859, -0.1517, -0.0008],
         [-0.0640, -0.0887, -0.0063,  ...,  0.1063,  0.0669,  0.0945],
         ...,
         [-0.2452, -0.0099,  0.0511,  ..., -0.0711,  0.0400, -0.1165],
         [-0.1115,  0.0289, -0.0833,  ...,  0.0237,  0.2493, -0.0239],
         [-0.0085,  0.0225, -0.0386,  ...,  0.1355,  0.1036, -0.0159]],

        [[-0.0354,  0.0031, -0.0487,  ...,  0.1064,  0.0746, -0.1517],
         [ 0.0993, -0.0763, -0.0711,  ..., -0.0965,  0.1353, -0.0172],
         [-0.0160, -0.0847,  0.0771,  ..., -0.0522,  0.0816, -0.0783],
         ...,
         [-0.0086, -0.0028,  0.0185,  ...,  0.0282,  0.1678, -0.1388],
         [-0.0219, -0.0880, -0.0938,  ...,  0.1550, -0.0699, -0.1526],
         [-0.1936, -0.0156,  0.0169,  ...,  0.0457,  0.1270,  0.0721]],

        [[-0.0565,  0.0072,  0.0631,  ...,  0.0897,  0.0464, -0.0792],
         [-0.0978,  0.1294, -0.0529,  ..., -0.0303, -0.0329, -0.0362],
         [ 0.1296,  0.1533, -0.0605,  ...,  0.2088,  0.1292, -0.0004],
         ...,
         [-0.0184, -0.0567,  0.0458,  ..., -0.0484,  0.1845, -0.0253],
         [ 0.0751, -0.0094,  0.0422,  ...,  0.0415,  0.0812, -0.0755],
         [ 0.1105,  0.0375,  0.0096,  ...,  0.0588,  0.0873,  0.0615]],

        ...,

        [[ 0.1196, -0.0728,  0.0132,  ..., -0.2537, -0.0294,  0.0154],
         [ 0.1011, -0.0641,  0.1195,  ...,  0.0043,  0.0008, -0.0529],
         [ 0.0582, -0.0287, -0.0077,  ...,  0.0262,  0.0008,  0.0379],
         ...,
         [-0.0820, -0.0510, -0.1045,  ..., -0.0700,  0.0393,  0.0038],
         [-0.0707,  0.0401, -0.0636,  ...,  0.0880,  0.0281,  0.0441],
         [ 0.0102,  0.0886, -0.0641,  ...,  0.0606, -0.0679, -0.0726]],

        [[-0.1105,  0.0013, -0.0798,  ..., -0.0303, -0.0553,  0.0502],
         [-0.0943,  0.0768, -0.1645,  ...,  0.1586,  0.0236, -0.0278],
         [-0.1229, -0.2004, -0.1060,  ...,  0.0695,  0.1170, -0.0014],
         ...,
         [-0.1211, -0.1442,  0.0432,  ..., -0.0831,  0.0411, -0.1665],
         [-0.0502,  0.0605, -0.0241,  ...,  0.0668, -0.0196, -0.0220],
         [-0.0794,  0.0980, -0.0686,  ...,  0.2276,  0.1244, -0.1151]],

        [[-0.0243,  0.0304,  0.0059,  ..., -0.0091, -0.0117,  0.0341],
         [-0.0178,  0.0327, -0.0822,  ...,  0.1578, -0.1721, -0.0191],
         [-0.1077,  0.0580, -0.0342,  ...,  0.0281,  0.1418,  0.0258],
         ...,
         [-0.0822,  0.0499, -0.1208,  ..., -0.0734,  0.1409,  0.0527],
         [-0.0328, -0.0291, -0.1009,  ...,  0.0302, -0.0226, -0.1027],
         [-0.1649,  0.1364, -0.0674,  ...,  0.0944,  0.0683, -0.0244]]],
       grad_fn=<StackBackward0>), 'stoch': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 1.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 1.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 1.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 1., 0., 0.],
         [0., 1., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 1., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 1., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 1., 0.,  ..., 0., 0., 1.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 1., 0.]]])}
train_step: Starting state deter shape: torch.Size([16, 50, 128])
train_step: Starting state stoch shape: torch.Size([16, 50, 1024])
After ensuring logits/stoch: {'deter': tensor([[[ 0.0510, -0.0765,  0.0837,  ..., -0.0017,  0.1000,  0.0615],
         [ 0.0822, -0.0116, -0.1396,  ...,  0.0859, -0.1517, -0.0008],
         [-0.0640, -0.0887, -0.0063,  ...,  0.1063,  0.0669,  0.0945],
         ...,
         [-0.2452, -0.0099,  0.0511,  ..., -0.0711,  0.0400, -0.1165],
         [-0.1115,  0.0289, -0.0833,  ...,  0.0237,  0.2493, -0.0239],
         [-0.0085,  0.0225, -0.0386,  ...,  0.1355,  0.1036, -0.0159]],

        [[-0.0354,  0.0031, -0.0487,  ...,  0.1064,  0.0746, -0.1517],
         [ 0.0993, -0.0763, -0.0711,  ..., -0.0965,  0.1353, -0.0172],
         [-0.0160, -0.0847,  0.0771,  ..., -0.0522,  0.0816, -0.0783],
         ...,
         [-0.0086, -0.0028,  0.0185,  ...,  0.0282,  0.1678, -0.1388],
         [-0.0219, -0.0880, -0.0938,  ...,  0.1550, -0.0699, -0.1526],
         [-0.1936, -0.0156,  0.0169,  ...,  0.0457,  0.1270,  0.0721]],

        [[-0.0565,  0.0072,  0.0631,  ...,  0.0897,  0.0464, -0.0792],
         [-0.0978,  0.1294, -0.0529,  ..., -0.0303, -0.0329, -0.0362],
         [ 0.1296,  0.1533, -0.0605,  ...,  0.2088,  0.1292, -0.0004],
         ...,
         [-0.0184, -0.0567,  0.0458,  ..., -0.0484,  0.1845, -0.0253],
         [ 0.0751, -0.0094,  0.0422,  ...,  0.0415,  0.0812, -0.0755],
         [ 0.1105,  0.0375,  0.0096,  ...,  0.0588,  0.0873,  0.0615]],

        ...,

        [[ 0.1196, -0.0728,  0.0132,  ..., -0.2537, -0.0294,  0.0154],
         [ 0.1011, -0.0641,  0.1195,  ...,  0.0043,  0.0008, -0.0529],
         [ 0.0582, -0.0287, -0.0077,  ...,  0.0262,  0.0008,  0.0379],
         ...,
         [-0.0820, -0.0510, -0.1045,  ..., -0.0700,  0.0393,  0.0038],
         [-0.0707,  0.0401, -0.0636,  ...,  0.0880,  0.0281,  0.0441],
         [ 0.0102,  0.0886, -0.0641,  ...,  0.0606, -0.0679, -0.0726]],

        [[-0.1105,  0.0013, -0.0798,  ..., -0.0303, -0.0553,  0.0502],
         [-0.0943,  0.0768, -0.1645,  ...,  0.1586,  0.0236, -0.0278],
         [-0.1229, -0.2004, -0.1060,  ...,  0.0695,  0.1170, -0.0014],
         ...,
         [-0.1211, -0.1442,  0.0432,  ..., -0.0831,  0.0411, -0.1665],
         [-0.0502,  0.0605, -0.0241,  ...,  0.0668, -0.0196, -0.0220],
         [-0.0794,  0.0980, -0.0686,  ...,  0.2276,  0.1244, -0.1151]],

        [[-0.0243,  0.0304,  0.0059,  ..., -0.0091, -0.0117,  0.0341],
         [-0.0178,  0.0327, -0.0822,  ...,  0.1578, -0.1721, -0.0191],
         [-0.1077,  0.0580, -0.0342,  ...,  0.0281,  0.1418,  0.0258],
         ...,
         [-0.0822,  0.0499, -0.1208,  ..., -0.0734,  0.1409,  0.0527],
         [-0.0328, -0.0291, -0.1009,  ...,  0.0302, -0.0226, -0.1027],
         [-0.1649,  0.1364, -0.0674,  ...,  0.0944,  0.0683, -0.0244]]],
       grad_fn=<StackBackward0>), 'stoch': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 1.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 1.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 1.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 1., 0., 0.],
         [0., 1., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 1., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 1., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 1., 0.,  ..., 0., 0., 1.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 1., 0.]]]), 'logits': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]])}
train_step: Normalized hidden_state shape: torch.Size([1, 16, 128])
train_step: Normalized stoch shape: torch.Size([16, 1024])
train_step: Normalized deter shape: torch.Size([16, 128])
train_step: Post-imagine_trajectory: Imagined features shape: torch.Size([16, 15, 1152])
train_step: Post-imagine_trajectory: Imagined actions shape: torch.Size([16, 15, 2])
train_step: Post-imagine_trajectory: Imagined action indices shape: torch.Size([16, 15])
train_step: Post-imagine_trajectory: Imagined state deter shape: torch.Size([16, 15, 128])
train_step: Post-imagine_trajectory: Imagined state stoch shape: torch.Size([16, 15, 1024])
Reward shape: torch.Size([16, 15, 1]), Value shape: torch.Size([16, 15, 1]), Slow Value shape: torch.Size([16, 15, 1]), Discount shape: torch.Size([16, 15, 1, 1])
Return targets length: 15, First target shape: torch.Size([16, 16, 1])
train_step: Actor distribution shape: torch.Size([16, 15, 2])
train_step: Action log probabilities shape: torch.Size([16, 15])
train_step: Action log probabilities sample: tensor([[-0.2449, -0.0951],
        [-1.1237, -0.3723]], grad_fn=<SliceBackward0>)
train_step: Advantages shape: torch.Size([16, 15, 16, 15])
train_step: Advantages sample: tensor([[[[-9.9084, -9.9084, -9.9084, -9.9084, -9.9084, -9.9084, -9.9084,
           -9.9084, -9.9084, -9.9084, -9.9084, -9.9084, -9.9084, -9.9084,
           -9.9084],
          [-9.9084, -9.9084, -9.9084, -9.9084, -9.9084, -9.9084, -9.9084,
           -9.9084, -9.9084, -9.9084, -9.9084, -9.9084, -9.9084, -9.9084,
           -9.9084],
          [-9.9084, -9.9084, -9.9084, -9.9084, -9.9084, -9.9084, -9.9084,
           -9.9084, -9.9084, -9.9084, -9.9084, -9.9084, -9.9084, -9.9084,
           -9.9084],
          [-9.9084, -9.9084, -9.9084, -9.9084, -9.9084, -9.9084, -9.9084,
           -9.9084, -9.9084, -9.9084, -9.9084, -9.9084, -9.9084, -9.9084,
           -9.9084],
          [-9.9084, -9.9084, -9.9084, -9.9084, -9.9084, -9.9084, -9.9084,
           -9.9084, -9.9084, -9.9084, -9.9084, -9.9084, -9.9084, -9.9084,
           -9.9084],
          [-9.9084, -9.9084, -9.9084, -9.9084, -9.9084, -9.9084, -9.9084,
           -9.9084, -9.9084, -9.9084, -9.9084, -9.9084, -9.9084, -9.9084,
           -9.9084],
          [-9.9084, -9.9084, -9.9084, -9.9084, -9.9084, -9.9084, -9.9084,
           -9.9084, -9.9084, -9.9084, -9.9084, -9.9084, -9.9084, -9.9084,
           -9.9084],
          [-9.9084, -9.9084, -9.9084, -9.9084, -9.9084, -9.9084, -9.9084,
           -9.9084, -9.9084, -9.9084, -9.9084, -9.9084, -9.9084, -9.9084,
           -9.9084],
          [-9.9084, -9.9084, -9.9084, -9.9084, -9.9084, -9.9084, -9.9084,
           -9.9084, -9.9084, -9.9084, -9.9084, -9.9084, -9.9084, -9.9084,
           -9.9084],
          [-9.9084, -9.9084, -9.9084, -9.9084, -9.9084, -9.9084, -9.9084,
           -9.9084, -9.9084, -9.9084, -9.9084, -9.9084, -9.9084, -9.9084,
           -9.9084],
          [-9.9084, -9.9084, -9.9084, -9.9084, -9.9084, -9.9084, -9.9084,
           -9.9084, -9.9084, -9.9084, -9.9084, -9.9084, -9.9084, -9.9084,
           -9.9084],
          [-9.9084, -9.9084, -9.9084, -9.9084, -9.9084, -9.9084, -9.9084,
           -9.9084, -9.9084, -9.9084, -9.9084, -9.9084, -9.9084, -9.9084,
           -9.9084],
          [-9.9084, -9.9084, -9.9084, -9.9084, -9.9084, -9.9084, -9.9084,
           -9.9084, -9.9084, -9.9084, -9.9084, -9.9084, -9.9084, -9.9084,
           -9.9084],
          [-9.9084, -9.9084, -9.9084, -9.9084, -9.9084, -9.9084, -9.9084,
           -9.9084, -9.9084, -9.9084, -9.9084, -9.9084, -9.9084, -9.9084,
           -9.9084],
          [-9.9084, -9.9084, -9.9084, -9.9084, -9.9084, -9.9084, -9.9084,
           -9.9084, -9.9084, -9.9084, -9.9084, -9.9084, -9.9084, -9.9084,
           -9.9084],
          [-9.9084, -9.9084, -9.9084, -9.9084, -9.9084, -9.9084, -9.9084,
           -9.9084, -9.9084, -9.9084, -9.9084, -9.9084, -9.9084, -9.9084,
           -9.9084]],

         [[-9.1090, -9.1090, -9.1090, -9.1090, -9.1090, -9.1090, -9.1090,
           -9.1090, -9.1090, -9.1090, -9.1090, -9.1090, -9.1090, -9.1090,
           -9.1090],
          [-9.1090, -9.1090, -9.1090, -9.1090, -9.1090, -9.1090, -9.1090,
           -9.1090, -9.1090, -9.1090, -9.1090, -9.1090, -9.1090, -9.1090,
           -9.1090],
          [-9.1090, -9.1090, -9.1090, -9.1090, -9.1090, -9.1090, -9.1090,
           -9.1090, -9.1090, -9.1090, -9.1090, -9.1090, -9.1090, -9.1090,
           -9.1090],
          [-9.1090, -9.1090, -9.1090, -9.1090, -9.1090, -9.1090, -9.1090,
           -9.1090, -9.1090, -9.1090, -9.1090, -9.1090, -9.1090, -9.1090,
           -9.1090],
          [-9.1090, -9.1090, -9.1090, -9.1090, -9.1090, -9.1090, -9.1090,
           -9.1090, -9.1090, -9.1090, -9.1090, -9.1090, -9.1090, -9.1090,
           -9.1090],
          [-9.1090, -9.1090, -9.1090, -9.1090, -9.1090, -9.1090, -9.1090,
           -9.1090, -9.1090, -9.1090, -9.1090, -9.1090, -9.1090, -9.1090,
           -9.1090],
          [-9.1090, -9.1090, -9.1090, -9.1090, -9.1090, -9.1090, -9.1090,
           -9.1090, -9.1090, -9.1090, -9.1090, -9.1090, -9.1090, -9.1090,
           -9.1090],
          [-9.1090, -9.1090, -9.1090, -9.1090, -9.1090, -9.1090, -9.1090,
           -9.1090, -9.1090, -9.1090, -9.1090, -9.1090, -9.1090, -9.1090,
           -9.1090],
          [-9.1090, -9.1090, -9.1090, -9.1090, -9.1090, -9.1090, -9.1090,
           -9.1090, -9.1090, -9.1090, -9.1090, -9.1090, -9.1090, -9.1090,
           -9.1090],
          [-9.1090, -9.1090, -9.1090, -9.1090, -9.1090, -9.1090, -9.1090,
           -9.1090, -9.1090, -9.1090, -9.1090, -9.1090, -9.1090, -9.1090,
           -9.1090],
          [-9.1090, -9.1090, -9.1090, -9.1090, -9.1090, -9.1090, -9.1090,
           -9.1090, -9.1090, -9.1090, -9.1090, -9.1090, -9.1090, -9.1090,
           -9.1090],
          [-9.1090, -9.1090, -9.1090, -9.1090, -9.1090, -9.1090, -9.1090,
           -9.1090, -9.1090, -9.1090, -9.1090, -9.1090, -9.1090, -9.1090,
           -9.1090],
          [-9.1090, -9.1090, -9.1090, -9.1090, -9.1090, -9.1090, -9.1090,
           -9.1090, -9.1090, -9.1090, -9.1090, -9.1090, -9.1090, -9.1090,
           -9.1090],
          [-9.1090, -9.1090, -9.1090, -9.1090, -9.1090, -9.1090, -9.1090,
           -9.1090, -9.1090, -9.1090, -9.1090, -9.1090, -9.1090, -9.1090,
           -9.1090],
          [-9.1090, -9.1090, -9.1090, -9.1090, -9.1090, -9.1090, -9.1090,
           -9.1090, -9.1090, -9.1090, -9.1090, -9.1090, -9.1090, -9.1090,
           -9.1090],
          [-9.1090, -9.1090, -9.1090, -9.1090, -9.1090, -9.1090, -9.1090,
           -9.1090, -9.1090, -9.1090, -9.1090, -9.1090, -9.1090, -9.1090,
           -9.1090]]],


        [[[-4.8843, -4.8843, -4.8843, -4.8843, -4.8843, -4.8843, -4.8843,
           -4.8843, -4.8843, -4.8843, -4.8843, -4.8843, -4.8843, -4.8843,
           -4.8843],
          [-4.8843, -4.8843, -4.8843, -4.8843, -4.8843, -4.8843, -4.8843,
           -4.8843, -4.8843, -4.8843, -4.8843, -4.8843, -4.8843, -4.8843,
           -4.8843],
          [-4.8843, -4.8843, -4.8843, -4.8843, -4.8843, -4.8843, -4.8843,
           -4.8843, -4.8843, -4.8843, -4.8843, -4.8843, -4.8843, -4.8843,
           -4.8843],
          [-4.8843, -4.8843, -4.8843, -4.8843, -4.8843, -4.8843, -4.8843,
           -4.8843, -4.8843, -4.8843, -4.8843, -4.8843, -4.8843, -4.8843,
           -4.8843],
          [-4.8843, -4.8843, -4.8843, -4.8843, -4.8843, -4.8843, -4.8843,
           -4.8843, -4.8843, -4.8843, -4.8843, -4.8843, -4.8843, -4.8843,
           -4.8843],
          [-4.8843, -4.8843, -4.8843, -4.8843, -4.8843, -4.8843, -4.8843,
           -4.8843, -4.8843, -4.8843, -4.8843, -4.8843, -4.8843, -4.8843,
           -4.8843],
          [-4.8843, -4.8843, -4.8843, -4.8843, -4.8843, -4.8843, -4.8843,
           -4.8843, -4.8843, -4.8843, -4.8843, -4.8843, -4.8843, -4.8843,
           -4.8843],
          [-4.8843, -4.8843, -4.8843, -4.8843, -4.8843, -4.8843, -4.8843,
           -4.8843, -4.8843, -4.8843, -4.8843, -4.8843, -4.8843, -4.8843,
           -4.8843],
          [-4.8843, -4.8843, -4.8843, -4.8843, -4.8843, -4.8843, -4.8843,
           -4.8843, -4.8843, -4.8843, -4.8843, -4.8843, -4.8843, -4.8843,
           -4.8843],
          [-4.8843, -4.8843, -4.8843, -4.8843, -4.8843, -4.8843, -4.8843,
           -4.8843, -4.8843, -4.8843, -4.8843, -4.8843, -4.8843, -4.8843,
           -4.8843],
          [-4.8843, -4.8843, -4.8843, -4.8843, -4.8843, -4.8843, -4.8843,
           -4.8843, -4.8843, -4.8843, -4.8843, -4.8843, -4.8843, -4.8843,
           -4.8843],
          [-4.8843, -4.8843, -4.8843, -4.8843, -4.8843, -4.8843, -4.8843,
           -4.8843, -4.8843, -4.8843, -4.8843, -4.8843, -4.8843, -4.8843,
           -4.8843],
          [-4.8843, -4.8843, -4.8843, -4.8843, -4.8843, -4.8843, -4.8843,
           -4.8843, -4.8843, -4.8843, -4.8843, -4.8843, -4.8843, -4.8843,
           -4.8843],
          [-4.8843, -4.8843, -4.8843, -4.8843, -4.8843, -4.8843, -4.8843,
           -4.8843, -4.8843, -4.8843, -4.8843, -4.8843, -4.8843, -4.8843,
           -4.8843],
          [-4.8843, -4.8843, -4.8843, -4.8843, -4.8843, -4.8843, -4.8843,
           -4.8843, -4.8843, -4.8843, -4.8843, -4.8843, -4.8843, -4.8843,
           -4.8843],
          [-4.8843, -4.8843, -4.8843, -4.8843, -4.8843, -4.8843, -4.8843,
           -4.8843, -4.8843, -4.8843, -4.8843, -4.8843, -4.8843, -4.8843,
           -4.8843]],

         [[-5.0599, -5.0599, -5.0599, -5.0599, -5.0599, -5.0599, -5.0599,
           -5.0599, -5.0599, -5.0599, -5.0599, -5.0599, -5.0599, -5.0599,
           -5.0599],
          [-5.0599, -5.0599, -5.0599, -5.0599, -5.0599, -5.0599, -5.0599,
           -5.0599, -5.0599, -5.0599, -5.0599, -5.0599, -5.0599, -5.0599,
           -5.0599],
          [-5.0599, -5.0599, -5.0599, -5.0599, -5.0599, -5.0599, -5.0599,
           -5.0599, -5.0599, -5.0599, -5.0599, -5.0599, -5.0599, -5.0599,
           -5.0599],
          [-5.0599, -5.0599, -5.0599, -5.0599, -5.0599, -5.0599, -5.0599,
           -5.0599, -5.0599, -5.0599, -5.0599, -5.0599, -5.0599, -5.0599,
           -5.0599],
          [-5.0599, -5.0599, -5.0599, -5.0599, -5.0599, -5.0599, -5.0599,
           -5.0599, -5.0599, -5.0599, -5.0599, -5.0599, -5.0599, -5.0599,
           -5.0599],
          [-5.0599, -5.0599, -5.0599, -5.0599, -5.0599, -5.0599, -5.0599,
           -5.0599, -5.0599, -5.0599, -5.0599, -5.0599, -5.0599, -5.0599,
           -5.0599],
          [-5.0599, -5.0599, -5.0599, -5.0599, -5.0599, -5.0599, -5.0599,
           -5.0599, -5.0599, -5.0599, -5.0599, -5.0599, -5.0599, -5.0599,
           -5.0599],
          [-5.0599, -5.0599, -5.0599, -5.0599, -5.0599, -5.0599, -5.0599,
           -5.0599, -5.0599, -5.0599, -5.0599, -5.0599, -5.0599, -5.0599,
           -5.0599],
          [-5.0599, -5.0599, -5.0599, -5.0599, -5.0599, -5.0599, -5.0599,
           -5.0599, -5.0599, -5.0599, -5.0599, -5.0599, -5.0599, -5.0599,
           -5.0599],
          [-5.0599, -5.0599, -5.0599, -5.0599, -5.0599, -5.0599, -5.0599,
           -5.0599, -5.0599, -5.0599, -5.0599, -5.0599, -5.0599, -5.0599,
           -5.0599],
          [-5.0599, -5.0599, -5.0599, -5.0599, -5.0599, -5.0599, -5.0599,
           -5.0599, -5.0599, -5.0599, -5.0599, -5.0599, -5.0599, -5.0599,
           -5.0599],
          [-5.0599, -5.0599, -5.0599, -5.0599, -5.0599, -5.0599, -5.0599,
           -5.0599, -5.0599, -5.0599, -5.0599, -5.0599, -5.0599, -5.0599,
           -5.0599],
          [-5.0599, -5.0599, -5.0599, -5.0599, -5.0599, -5.0599, -5.0599,
           -5.0599, -5.0599, -5.0599, -5.0599, -5.0599, -5.0599, -5.0599,
           -5.0599],
          [-5.0599, -5.0599, -5.0599, -5.0599, -5.0599, -5.0599, -5.0599,
           -5.0599, -5.0599, -5.0599, -5.0599, -5.0599, -5.0599, -5.0599,
           -5.0599],
          [-5.0599, -5.0599, -5.0599, -5.0599, -5.0599, -5.0599, -5.0599,
           -5.0599, -5.0599, -5.0599, -5.0599, -5.0599, -5.0599, -5.0599,
           -5.0599],
          [-5.0599, -5.0599, -5.0599, -5.0599, -5.0599, -5.0599, -5.0599,
           -5.0599, -5.0599, -5.0599, -5.0599, -5.0599, -5.0599, -5.0599,
           -5.0599]]]], grad_fn=<SliceBackward0>)
train_step: Return scale: 1.6023744275571903
train_step: Scaled advantages shape: torch.Size([16, 15, 16, 15])
train_step: Scaled advantages sample: tensor([[[[-6.1836, -6.1836, -6.1836, -6.1836, -6.1836, -6.1836, -6.1836,
           -6.1836, -6.1836, -6.1836, -6.1836, -6.1836, -6.1836, -6.1836,
           -6.1836],
          [-6.1836, -6.1836, -6.1836, -6.1836, -6.1836, -6.1836, -6.1836,
           -6.1836, -6.1836, -6.1836, -6.1836, -6.1836, -6.1836, -6.1836,
           -6.1836],
          [-6.1836, -6.1836, -6.1836, -6.1836, -6.1836, -6.1836, -6.1836,
           -6.1836, -6.1836, -6.1836, -6.1836, -6.1836, -6.1836, -6.1836,
           -6.1836],
          [-6.1836, -6.1836, -6.1836, -6.1836, -6.1836, -6.1836, -6.1836,
           -6.1836, -6.1836, -6.1836, -6.1836, -6.1836, -6.1836, -6.1836,
           -6.1836],
          [-6.1836, -6.1836, -6.1836, -6.1836, -6.1836, -6.1836, -6.1836,
           -6.1836, -6.1836, -6.1836, -6.1836, -6.1836, -6.1836, -6.1836,
           -6.1836],
          [-6.1836, -6.1836, -6.1836, -6.1836, -6.1836, -6.1836, -6.1836,
           -6.1836, -6.1836, -6.1836, -6.1836, -6.1836, -6.1836, -6.1836,
           -6.1836],
          [-6.1836, -6.1836, -6.1836, -6.1836, -6.1836, -6.1836, -6.1836,
           -6.1836, -6.1836, -6.1836, -6.1836, -6.1836, -6.1836, -6.1836,
           -6.1836],
          [-6.1836, -6.1836, -6.1836, -6.1836, -6.1836, -6.1836, -6.1836,
           -6.1836, -6.1836, -6.1836, -6.1836, -6.1836, -6.1836, -6.1836,
           -6.1836],
          [-6.1836, -6.1836, -6.1836, -6.1836, -6.1836, -6.1836, -6.1836,
           -6.1836, -6.1836, -6.1836, -6.1836, -6.1836, -6.1836, -6.1836,
           -6.1836],
          [-6.1836, -6.1836, -6.1836, -6.1836, -6.1836, -6.1836, -6.1836,
           -6.1836, -6.1836, -6.1836, -6.1836, -6.1836, -6.1836, -6.1836,
           -6.1836],
          [-6.1836, -6.1836, -6.1836, -6.1836, -6.1836, -6.1836, -6.1836,
           -6.1836, -6.1836, -6.1836, -6.1836, -6.1836, -6.1836, -6.1836,
           -6.1836],
          [-6.1836, -6.1836, -6.1836, -6.1836, -6.1836, -6.1836, -6.1836,
           -6.1836, -6.1836, -6.1836, -6.1836, -6.1836, -6.1836, -6.1836,
           -6.1836],
          [-6.1836, -6.1836, -6.1836, -6.1836, -6.1836, -6.1836, -6.1836,
           -6.1836, -6.1836, -6.1836, -6.1836, -6.1836, -6.1836, -6.1836,
           -6.1836],
          [-6.1836, -6.1836, -6.1836, -6.1836, -6.1836, -6.1836, -6.1836,
           -6.1836, -6.1836, -6.1836, -6.1836, -6.1836, -6.1836, -6.1836,
           -6.1836],
          [-6.1836, -6.1836, -6.1836, -6.1836, -6.1836, -6.1836, -6.1836,
           -6.1836, -6.1836, -6.1836, -6.1836, -6.1836, -6.1836, -6.1836,
           -6.1836],
          [-6.1836, -6.1836, -6.1836, -6.1836, -6.1836, -6.1836, -6.1836,
           -6.1836, -6.1836, -6.1836, -6.1836, -6.1836, -6.1836, -6.1836,
           -6.1836]],

         [[-5.6847, -5.6847, -5.6847, -5.6847, -5.6847, -5.6847, -5.6847,
           -5.6847, -5.6847, -5.6847, -5.6847, -5.6847, -5.6847, -5.6847,
           -5.6847],
          [-5.6847, -5.6847, -5.6847, -5.6847, -5.6847, -5.6847, -5.6847,
           -5.6847, -5.6847, -5.6847, -5.6847, -5.6847, -5.6847, -5.6847,
           -5.6847],
          [-5.6847, -5.6847, -5.6847, -5.6847, -5.6847, -5.6847, -5.6847,
           -5.6847, -5.6847, -5.6847, -5.6847, -5.6847, -5.6847, -5.6847,
           -5.6847],
          [-5.6847, -5.6847, -5.6847, -5.6847, -5.6847, -5.6847, -5.6847,
           -5.6847, -5.6847, -5.6847, -5.6847, -5.6847, -5.6847, -5.6847,
           -5.6847],
          [-5.6847, -5.6847, -5.6847, -5.6847, -5.6847, -5.6847, -5.6847,
           -5.6847, -5.6847, -5.6847, -5.6847, -5.6847, -5.6847, -5.6847,
           -5.6847],
          [-5.6847, -5.6847, -5.6847, -5.6847, -5.6847, -5.6847, -5.6847,
           -5.6847, -5.6847, -5.6847, -5.6847, -5.6847, -5.6847, -5.6847,
           -5.6847],
          [-5.6847, -5.6847, -5.6847, -5.6847, -5.6847, -5.6847, -5.6847,
           -5.6847, -5.6847, -5.6847, -5.6847, -5.6847, -5.6847, -5.6847,
           -5.6847],
          [-5.6847, -5.6847, -5.6847, -5.6847, -5.6847, -5.6847, -5.6847,
           -5.6847, -5.6847, -5.6847, -5.6847, -5.6847, -5.6847, -5.6847,
           -5.6847],
          [-5.6847, -5.6847, -5.6847, -5.6847, -5.6847, -5.6847, -5.6847,
           -5.6847, -5.6847, -5.6847, -5.6847, -5.6847, -5.6847, -5.6847,
           -5.6847],
          [-5.6847, -5.6847, -5.6847, -5.6847, -5.6847, -5.6847, -5.6847,
           -5.6847, -5.6847, -5.6847, -5.6847, -5.6847, -5.6847, -5.6847,
           -5.6847],
          [-5.6847, -5.6847, -5.6847, -5.6847, -5.6847, -5.6847, -5.6847,
           -5.6847, -5.6847, -5.6847, -5.6847, -5.6847, -5.6847, -5.6847,
           -5.6847],
          [-5.6847, -5.6847, -5.6847, -5.6847, -5.6847, -5.6847, -5.6847,
           -5.6847, -5.6847, -5.6847, -5.6847, -5.6847, -5.6847, -5.6847,
           -5.6847],
          [-5.6847, -5.6847, -5.6847, -5.6847, -5.6847, -5.6847, -5.6847,
           -5.6847, -5.6847, -5.6847, -5.6847, -5.6847, -5.6847, -5.6847,
           -5.6847],
          [-5.6847, -5.6847, -5.6847, -5.6847, -5.6847, -5.6847, -5.6847,
           -5.6847, -5.6847, -5.6847, -5.6847, -5.6847, -5.6847, -5.6847,
           -5.6847],
          [-5.6847, -5.6847, -5.6847, -5.6847, -5.6847, -5.6847, -5.6847,
           -5.6847, -5.6847, -5.6847, -5.6847, -5.6847, -5.6847, -5.6847,
           -5.6847],
          [-5.6847, -5.6847, -5.6847, -5.6847, -5.6847, -5.6847, -5.6847,
           -5.6847, -5.6847, -5.6847, -5.6847, -5.6847, -5.6847, -5.6847,
           -5.6847]]],


        [[[-3.0482, -3.0481, -3.0482, -3.0482, -3.0482, -3.0482, -3.0482,
           -3.0482, -3.0482, -3.0482, -3.0482, -3.0482, -3.0482, -3.0482,
           -3.0481],
          [-3.0482, -3.0481, -3.0482, -3.0482, -3.0482, -3.0482, -3.0482,
           -3.0482, -3.0482, -3.0482, -3.0482, -3.0482, -3.0482, -3.0482,
           -3.0481],
          [-3.0482, -3.0481, -3.0482, -3.0482, -3.0482, -3.0482, -3.0482,
           -3.0482, -3.0482, -3.0482, -3.0482, -3.0482, -3.0482, -3.0482,
           -3.0481],
          [-3.0482, -3.0481, -3.0482, -3.0482, -3.0482, -3.0482, -3.0482,
           -3.0482, -3.0482, -3.0482, -3.0482, -3.0482, -3.0482, -3.0482,
           -3.0481],
          [-3.0482, -3.0481, -3.0482, -3.0482, -3.0482, -3.0482, -3.0482,
           -3.0482, -3.0482, -3.0482, -3.0482, -3.0482, -3.0482, -3.0482,
           -3.0481],
          [-3.0482, -3.0481, -3.0482, -3.0482, -3.0482, -3.0482, -3.0482,
           -3.0482, -3.0482, -3.0482, -3.0482, -3.0482, -3.0482, -3.0482,
           -3.0481],
          [-3.0482, -3.0481, -3.0482, -3.0482, -3.0482, -3.0482, -3.0482,
           -3.0482, -3.0482, -3.0482, -3.0482, -3.0482, -3.0482, -3.0482,
           -3.0481],
          [-3.0482, -3.0481, -3.0482, -3.0482, -3.0482, -3.0482, -3.0482,
           -3.0482, -3.0482, -3.0482, -3.0482, -3.0482, -3.0482, -3.0482,
           -3.0481],
          [-3.0482, -3.0481, -3.0482, -3.0482, -3.0482, -3.0482, -3.0482,
           -3.0482, -3.0482, -3.0482, -3.0482, -3.0482, -3.0482, -3.0482,
           -3.0481],
          [-3.0482, -3.0481, -3.0482, -3.0482, -3.0482, -3.0482, -3.0482,
           -3.0482, -3.0482, -3.0482, -3.0482, -3.0482, -3.0482, -3.0482,
           -3.0481],
          [-3.0482, -3.0481, -3.0482, -3.0482, -3.0482, -3.0482, -3.0482,
           -3.0482, -3.0482, -3.0482, -3.0482, -3.0482, -3.0482, -3.0482,
           -3.0481],
          [-3.0482, -3.0481, -3.0482, -3.0482, -3.0482, -3.0482, -3.0482,
           -3.0482, -3.0482, -3.0482, -3.0482, -3.0482, -3.0482, -3.0482,
           -3.0481],
          [-3.0482, -3.0481, -3.0482, -3.0482, -3.0482, -3.0482, -3.0482,
           -3.0482, -3.0482, -3.0482, -3.0482, -3.0482, -3.0482, -3.0482,
           -3.0481],
          [-3.0482, -3.0481, -3.0482, -3.0482, -3.0482, -3.0482, -3.0482,
           -3.0482, -3.0482, -3.0482, -3.0482, -3.0482, -3.0482, -3.0482,
           -3.0481],
          [-3.0482, -3.0481, -3.0482, -3.0482, -3.0482, -3.0482, -3.0482,
           -3.0482, -3.0482, -3.0482, -3.0482, -3.0482, -3.0482, -3.0482,
           -3.0481],
          [-3.0482, -3.0481, -3.0482, -3.0482, -3.0482, -3.0482, -3.0482,
           -3.0482, -3.0482, -3.0482, -3.0482, -3.0482, -3.0482, -3.0482,
           -3.0481]],

         [[-3.1578, -3.1578, -3.1578, -3.1578, -3.1577, -3.1578, -3.1578,
           -3.1578, -3.1578, -3.1578, -3.1578, -3.1578, -3.1578, -3.1578,
           -3.1578],
          [-3.1578, -3.1578, -3.1578, -3.1578, -3.1577, -3.1578, -3.1578,
           -3.1578, -3.1578, -3.1578, -3.1578, -3.1578, -3.1578, -3.1578,
           -3.1578],
          [-3.1578, -3.1578, -3.1578, -3.1578, -3.1577, -3.1578, -3.1578,
           -3.1578, -3.1578, -3.1578, -3.1578, -3.1578, -3.1578, -3.1578,
           -3.1578],
          [-3.1578, -3.1578, -3.1578, -3.1578, -3.1577, -3.1578, -3.1578,
           -3.1578, -3.1578, -3.1578, -3.1578, -3.1578, -3.1578, -3.1578,
           -3.1578],
          [-3.1578, -3.1578, -3.1578, -3.1578, -3.1577, -3.1578, -3.1578,
           -3.1578, -3.1578, -3.1578, -3.1578, -3.1578, -3.1578, -3.1578,
           -3.1578],
          [-3.1578, -3.1578, -3.1578, -3.1578, -3.1577, -3.1578, -3.1578,
           -3.1578, -3.1578, -3.1578, -3.1578, -3.1578, -3.1578, -3.1578,
           -3.1578],
          [-3.1578, -3.1578, -3.1578, -3.1578, -3.1577, -3.1578, -3.1578,
           -3.1578, -3.1578, -3.1578, -3.1578, -3.1578, -3.1578, -3.1578,
           -3.1578],
          [-3.1578, -3.1578, -3.1578, -3.1578, -3.1577, -3.1578, -3.1578,
           -3.1578, -3.1578, -3.1578, -3.1578, -3.1578, -3.1578, -3.1578,
           -3.1578],
          [-3.1578, -3.1578, -3.1578, -3.1578, -3.1577, -3.1578, -3.1578,
           -3.1578, -3.1578, -3.1578, -3.1578, -3.1578, -3.1578, -3.1578,
           -3.1578],
          [-3.1578, -3.1578, -3.1578, -3.1578, -3.1577, -3.1578, -3.1578,
           -3.1578, -3.1578, -3.1578, -3.1578, -3.1578, -3.1578, -3.1578,
           -3.1578],
          [-3.1578, -3.1578, -3.1578, -3.1578, -3.1577, -3.1578, -3.1578,
           -3.1578, -3.1578, -3.1578, -3.1578, -3.1578, -3.1578, -3.1578,
           -3.1578],
          [-3.1578, -3.1578, -3.1578, -3.1578, -3.1577, -3.1578, -3.1578,
           -3.1578, -3.1578, -3.1578, -3.1578, -3.1578, -3.1578, -3.1578,
           -3.1578],
          [-3.1578, -3.1578, -3.1578, -3.1578, -3.1577, -3.1578, -3.1578,
           -3.1578, -3.1578, -3.1578, -3.1578, -3.1578, -3.1578, -3.1578,
           -3.1578],
          [-3.1578, -3.1578, -3.1578, -3.1578, -3.1577, -3.1578, -3.1578,
           -3.1578, -3.1578, -3.1578, -3.1578, -3.1578, -3.1578, -3.1578,
           -3.1578],
          [-3.1578, -3.1578, -3.1578, -3.1578, -3.1577, -3.1578, -3.1578,
           -3.1578, -3.1578, -3.1578, -3.1578, -3.1578, -3.1578, -3.1578,
           -3.1578],
          [-3.1578, -3.1578, -3.1578, -3.1578, -3.1577, -3.1578, -3.1578,
           -3.1578, -3.1578, -3.1578, -3.1578, -3.1578, -3.1578, -3.1578,
           -3.1578]]]], grad_fn=<SliceBackward0>)
train_step: Entropy shape: torch.Size([16, 15])
train_step: Entropy sample: tensor([[0.5234, 0.3043],
        [0.6306, 0.6198]], grad_fn=<SliceBackward0>)
train_step: Entropy coefficient: 0.01
train_step: Actor loss: -1.2249951362609863
train_step: returns shape after mean: torch.Size([16, 15])
train_step: target_indices shape: torch.Size([16, 15])
train_step: value_logits shape: torch.Size([16, 15, 255])
train_step: target_twohot shape: torch.Size([16, 15, 255])
--- Starting train_step at 2025-04-01 01:59:17 ---
Full starting_state: {'deter': tensor([[[ 0.0100,  0.0385, -0.0323,  ..., -0.0034,  0.0858,  0.0866],
         [-0.0405, -0.0035, -0.0428,  ...,  0.0274,  0.0211,  0.1106],
         [-0.0584, -0.0277, -0.0552,  ...,  0.0991, -0.1734, -0.0196],
         ...,
         [-0.0172, -0.0421, -0.0630,  ...,  0.0618,  0.1274,  0.0609],
         [-0.0652, -0.1046,  0.0786,  ...,  0.0568,  0.0368, -0.0868],
         [-0.0010,  0.0096, -0.1506,  ..., -0.0339,  0.0396,  0.0130]],

        [[ 0.0430, -0.0251, -0.2459,  ..., -0.0999, -0.0610, -0.1493],
         [ 0.0319, -0.0021, -0.1402,  ..., -0.0877,  0.0108,  0.0040],
         [ 0.0572, -0.0062,  0.0439,  ..., -0.0634, -0.1254,  0.0374],
         ...,
         [-0.2553, -0.0338, -0.1081,  ..., -0.1449, -0.1106, -0.0471],
         [ 0.0693,  0.1121, -0.0584,  ...,  0.0353,  0.0233, -0.2881],
         [-0.1998, -0.0209,  0.0120,  ..., -0.0477, -0.0999,  0.0090]],

        [[ 0.0175, -0.0682, -0.0886,  ...,  0.1692, -0.0127, -0.0899],
         [ 0.0058, -0.1771, -0.0843,  ...,  0.0469,  0.1097, -0.2179],
         [-0.1362, -0.0528, -0.0516,  ..., -0.0757,  0.0737, -0.1160],
         ...,
         [ 0.1771,  0.1147, -0.0451,  ..., -0.1324, -0.1204, -0.0046],
         [ 0.0903, -0.0121, -0.1444,  ..., -0.0882, -0.0779,  0.1009],
         [-0.1227, -0.0057,  0.0581,  ..., -0.1111, -0.1039, -0.0167]],

        ...,

        [[-0.1023,  0.1314, -0.0464,  ...,  0.0474, -0.0439, -0.1449],
         [-0.0798, -0.1212,  0.1052,  ...,  0.0799,  0.0186,  0.0894],
         [ 0.0284,  0.0007, -0.0428,  ...,  0.1256, -0.1552, -0.0834],
         ...,
         [-0.1336, -0.0319,  0.1051,  ..., -0.1166, -0.0963, -0.0046],
         [-0.0936,  0.0866,  0.1381,  ...,  0.0682,  0.2141, -0.0449],
         [ 0.1646, -0.0443, -0.2263,  ..., -0.1588, -0.0363, -0.0447]],

        [[ 0.0207, -0.0107,  0.0165,  ..., -0.0829,  0.1234, -0.0400],
         [ 0.1677, -0.1403, -0.0279,  ...,  0.1091, -0.1448,  0.0128],
         [ 0.0348,  0.1403,  0.0744,  ..., -0.1270,  0.1342,  0.0680],
         ...,
         [-0.0536,  0.0083, -0.0811,  ..., -0.0850,  0.0675, -0.0536],
         [ 0.0554, -0.0758, -0.1875,  ..., -0.0478,  0.0185,  0.0017],
         [-0.0431, -0.0362, -0.1544,  ...,  0.0753,  0.0978, -0.0710]],

        [[ 0.0028, -0.1047, -0.0495,  ...,  0.1067, -0.0013,  0.0770],
         [-0.0240,  0.0144, -0.0185,  ...,  0.0977,  0.1765, -0.0313],
         [-0.1725, -0.0849, -0.0570,  ..., -0.0508, -0.1286,  0.0229],
         ...,
         [ 0.0018, -0.0290, -0.0404,  ...,  0.0622, -0.0223,  0.0147],
         [-0.1026, -0.0567, -0.0046,  ...,  0.1320, -0.0338, -0.0392],
         [ 0.0154,  0.0516, -0.1533,  ...,  0.0228,  0.0955, -0.0806]]],
       grad_fn=<StackBackward0>), 'stoch': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 1., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 1.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 1., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 1.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 1., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 1., 0.]],

        [[1., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]])}
train_step: Starting state deter shape: torch.Size([16, 50, 128])
train_step: Starting state stoch shape: torch.Size([16, 50, 1024])
After ensuring logits/stoch: {'deter': tensor([[[ 0.0100,  0.0385, -0.0323,  ..., -0.0034,  0.0858,  0.0866],
         [-0.0405, -0.0035, -0.0428,  ...,  0.0274,  0.0211,  0.1106],
         [-0.0584, -0.0277, -0.0552,  ...,  0.0991, -0.1734, -0.0196],
         ...,
         [-0.0172, -0.0421, -0.0630,  ...,  0.0618,  0.1274,  0.0609],
         [-0.0652, -0.1046,  0.0786,  ...,  0.0568,  0.0368, -0.0868],
         [-0.0010,  0.0096, -0.1506,  ..., -0.0339,  0.0396,  0.0130]],

        [[ 0.0430, -0.0251, -0.2459,  ..., -0.0999, -0.0610, -0.1493],
         [ 0.0319, -0.0021, -0.1402,  ..., -0.0877,  0.0108,  0.0040],
         [ 0.0572, -0.0062,  0.0439,  ..., -0.0634, -0.1254,  0.0374],
         ...,
         [-0.2553, -0.0338, -0.1081,  ..., -0.1449, -0.1106, -0.0471],
         [ 0.0693,  0.1121, -0.0584,  ...,  0.0353,  0.0233, -0.2881],
         [-0.1998, -0.0209,  0.0120,  ..., -0.0477, -0.0999,  0.0090]],

        [[ 0.0175, -0.0682, -0.0886,  ...,  0.1692, -0.0127, -0.0899],
         [ 0.0058, -0.1771, -0.0843,  ...,  0.0469,  0.1097, -0.2179],
         [-0.1362, -0.0528, -0.0516,  ..., -0.0757,  0.0737, -0.1160],
         ...,
         [ 0.1771,  0.1147, -0.0451,  ..., -0.1324, -0.1204, -0.0046],
         [ 0.0903, -0.0121, -0.1444,  ..., -0.0882, -0.0779,  0.1009],
         [-0.1227, -0.0057,  0.0581,  ..., -0.1111, -0.1039, -0.0167]],

        ...,

        [[-0.1023,  0.1314, -0.0464,  ...,  0.0474, -0.0439, -0.1449],
         [-0.0798, -0.1212,  0.1052,  ...,  0.0799,  0.0186,  0.0894],
         [ 0.0284,  0.0007, -0.0428,  ...,  0.1256, -0.1552, -0.0834],
         ...,
         [-0.1336, -0.0319,  0.1051,  ..., -0.1166, -0.0963, -0.0046],
         [-0.0936,  0.0866,  0.1381,  ...,  0.0682,  0.2141, -0.0449],
         [ 0.1646, -0.0443, -0.2263,  ..., -0.1588, -0.0363, -0.0447]],

        [[ 0.0207, -0.0107,  0.0165,  ..., -0.0829,  0.1234, -0.0400],
         [ 0.1677, -0.1403, -0.0279,  ...,  0.1091, -0.1448,  0.0128],
         [ 0.0348,  0.1403,  0.0744,  ..., -0.1270,  0.1342,  0.0680],
         ...,
         [-0.0536,  0.0083, -0.0811,  ..., -0.0850,  0.0675, -0.0536],
         [ 0.0554, -0.0758, -0.1875,  ..., -0.0478,  0.0185,  0.0017],
         [-0.0431, -0.0362, -0.1544,  ...,  0.0753,  0.0978, -0.0710]],

        [[ 0.0028, -0.1047, -0.0495,  ...,  0.1067, -0.0013,  0.0770],
         [-0.0240,  0.0144, -0.0185,  ...,  0.0977,  0.1765, -0.0313],
         [-0.1725, -0.0849, -0.0570,  ..., -0.0508, -0.1286,  0.0229],
         ...,
         [ 0.0018, -0.0290, -0.0404,  ...,  0.0622, -0.0223,  0.0147],
         [-0.1026, -0.0567, -0.0046,  ...,  0.1320, -0.0338, -0.0392],
         [ 0.0154,  0.0516, -0.1533,  ...,  0.0228,  0.0955, -0.0806]]],
       grad_fn=<StackBackward0>), 'stoch': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 1., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 1.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 1., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 1.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 1., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 1., 0.]],

        [[1., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]]), 'logits': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]])}
train_step: Normalized hidden_state shape: torch.Size([1, 16, 128])
train_step: Normalized stoch shape: torch.Size([16, 1024])
train_step: Normalized deter shape: torch.Size([16, 128])
train_step: Post-imagine_trajectory: Imagined features shape: torch.Size([16, 15, 1152])
train_step: Post-imagine_trajectory: Imagined actions shape: torch.Size([16, 15, 2])
train_step: Post-imagine_trajectory: Imagined action indices shape: torch.Size([16, 15])
train_step: Post-imagine_trajectory: Imagined state deter shape: torch.Size([16, 15, 128])
train_step: Post-imagine_trajectory: Imagined state stoch shape: torch.Size([16, 15, 1024])
Reward shape: torch.Size([16, 15, 1]), Value shape: torch.Size([16, 15, 1]), Slow Value shape: torch.Size([16, 15, 1]), Discount shape: torch.Size([16, 15, 1, 1])
Return targets length: 15, First target shape: torch.Size([16, 16, 1])
train_step: Actor distribution shape: torch.Size([16, 15, 2])
train_step: Action log probabilities shape: torch.Size([16, 15])
train_step: Action log probabilities sample: tensor([[-0.3047, -0.4468],
        [-0.4920, -0.6560]], grad_fn=<SliceBackward0>)
train_step: Advantages shape: torch.Size([16, 15, 16, 15])
train_step: Advantages sample: tensor([[[[-6.9658, -6.9658, -6.9659, -6.9658, -6.9658, -6.9658, -6.9658,
           -6.9658, -6.9659, -6.9658, -6.9658, -6.9658, -6.9658, -6.9658,
           -6.9658],
          [-6.9658, -6.9658, -6.9659, -6.9658, -6.9658, -6.9658, -6.9658,
           -6.9658, -6.9659, -6.9658, -6.9658, -6.9658, -6.9658, -6.9658,
           -6.9658],
          [-6.9658, -6.9658, -6.9659, -6.9658, -6.9658, -6.9658, -6.9658,
           -6.9658, -6.9659, -6.9658, -6.9658, -6.9658, -6.9658, -6.9658,
           -6.9658],
          [-6.9658, -6.9658, -6.9659, -6.9658, -6.9658, -6.9658, -6.9658,
           -6.9658, -6.9659, -6.9658, -6.9658, -6.9658, -6.9658, -6.9658,
           -6.9658],
          [-6.9658, -6.9658, -6.9659, -6.9658, -6.9658, -6.9658, -6.9658,
           -6.9658, -6.9659, -6.9658, -6.9658, -6.9658, -6.9658, -6.9658,
           -6.9658],
          [-6.9658, -6.9658, -6.9659, -6.9658, -6.9658, -6.9658, -6.9658,
           -6.9658, -6.9659, -6.9658, -6.9658, -6.9658, -6.9658, -6.9658,
           -6.9658],
          [-6.9658, -6.9658, -6.9659, -6.9658, -6.9658, -6.9658, -6.9658,
           -6.9658, -6.9659, -6.9658, -6.9658, -6.9658, -6.9658, -6.9658,
           -6.9658],
          [-6.9658, -6.9658, -6.9659, -6.9658, -6.9658, -6.9658, -6.9658,
           -6.9658, -6.9659, -6.9658, -6.9658, -6.9658, -6.9658, -6.9658,
           -6.9658],
          [-6.9658, -6.9658, -6.9659, -6.9658, -6.9658, -6.9658, -6.9658,
           -6.9658, -6.9659, -6.9658, -6.9658, -6.9658, -6.9658, -6.9658,
           -6.9658],
          [-6.9658, -6.9658, -6.9659, -6.9658, -6.9658, -6.9658, -6.9658,
           -6.9658, -6.9659, -6.9658, -6.9658, -6.9658, -6.9658, -6.9658,
           -6.9658],
          [-6.9658, -6.9658, -6.9659, -6.9658, -6.9658, -6.9658, -6.9658,
           -6.9658, -6.9659, -6.9658, -6.9658, -6.9658, -6.9658, -6.9658,
           -6.9658],
          [-6.9658, -6.9658, -6.9659, -6.9658, -6.9658, -6.9658, -6.9658,
           -6.9658, -6.9659, -6.9658, -6.9658, -6.9658, -6.9658, -6.9658,
           -6.9658],
          [-6.9658, -6.9658, -6.9659, -6.9658, -6.9658, -6.9658, -6.9658,
           -6.9658, -6.9659, -6.9658, -6.9658, -6.9658, -6.9658, -6.9658,
           -6.9658],
          [-6.9658, -6.9658, -6.9659, -6.9658, -6.9658, -6.9658, -6.9658,
           -6.9658, -6.9659, -6.9658, -6.9658, -6.9658, -6.9658, -6.9658,
           -6.9658],
          [-6.9658, -6.9658, -6.9659, -6.9658, -6.9658, -6.9658, -6.9658,
           -6.9658, -6.9659, -6.9658, -6.9658, -6.9658, -6.9658, -6.9658,
           -6.9658],
          [-6.9658, -6.9658, -6.9659, -6.9658, -6.9658, -6.9658, -6.9658,
           -6.9658, -6.9659, -6.9658, -6.9658, -6.9658, -6.9658, -6.9658,
           -6.9658]],

         [[-6.5268, -6.5269, -6.5269, -6.5269, -6.5269, -6.5269, -6.5269,
           -6.5269, -6.5268, -6.5268, -6.5268, -6.5268, -6.5268, -6.5269,
           -6.5269],
          [-6.5268, -6.5269, -6.5269, -6.5269, -6.5269, -6.5269, -6.5269,
           -6.5269, -6.5268, -6.5268, -6.5268, -6.5268, -6.5268, -6.5269,
           -6.5269],
          [-6.5268, -6.5269, -6.5269, -6.5269, -6.5269, -6.5269, -6.5269,
           -6.5269, -6.5268, -6.5268, -6.5268, -6.5268, -6.5268, -6.5269,
           -6.5269],
          [-6.5268, -6.5269, -6.5269, -6.5269, -6.5269, -6.5269, -6.5269,
           -6.5269, -6.5268, -6.5268, -6.5268, -6.5268, -6.5268, -6.5269,
           -6.5269],
          [-6.5268, -6.5269, -6.5269, -6.5269, -6.5269, -6.5269, -6.5269,
           -6.5269, -6.5268, -6.5268, -6.5268, -6.5268, -6.5268, -6.5269,
           -6.5269],
          [-6.5268, -6.5269, -6.5269, -6.5269, -6.5269, -6.5269, -6.5269,
           -6.5269, -6.5268, -6.5268, -6.5268, -6.5268, -6.5268, -6.5269,
           -6.5269],
          [-6.5268, -6.5269, -6.5269, -6.5269, -6.5269, -6.5269, -6.5269,
           -6.5269, -6.5268, -6.5268, -6.5268, -6.5268, -6.5268, -6.5269,
           -6.5269],
          [-6.5268, -6.5269, -6.5269, -6.5269, -6.5269, -6.5269, -6.5269,
           -6.5269, -6.5268, -6.5268, -6.5268, -6.5268, -6.5268, -6.5269,
           -6.5269],
          [-6.5268, -6.5269, -6.5269, -6.5269, -6.5269, -6.5269, -6.5269,
           -6.5269, -6.5268, -6.5268, -6.5268, -6.5268, -6.5268, -6.5269,
           -6.5269],
          [-6.5268, -6.5269, -6.5269, -6.5269, -6.5269, -6.5269, -6.5269,
           -6.5269, -6.5268, -6.5268, -6.5268, -6.5268, -6.5268, -6.5269,
           -6.5269],
          [-6.5268, -6.5269, -6.5269, -6.5269, -6.5269, -6.5269, -6.5269,
           -6.5269, -6.5268, -6.5268, -6.5268, -6.5268, -6.5268, -6.5269,
           -6.5269],
          [-6.5268, -6.5269, -6.5269, -6.5269, -6.5269, -6.5269, -6.5269,
           -6.5269, -6.5268, -6.5268, -6.5268, -6.5268, -6.5268, -6.5269,
           -6.5269],
          [-6.5268, -6.5269, -6.5269, -6.5269, -6.5269, -6.5269, -6.5269,
           -6.5269, -6.5268, -6.5268, -6.5268, -6.5268, -6.5268, -6.5269,
           -6.5269],
          [-6.5268, -6.5269, -6.5269, -6.5269, -6.5269, -6.5269, -6.5269,
           -6.5269, -6.5268, -6.5268, -6.5268, -6.5268, -6.5268, -6.5269,
           -6.5269],
          [-6.5268, -6.5269, -6.5269, -6.5269, -6.5269, -6.5269, -6.5269,
           -6.5269, -6.5268, -6.5268, -6.5268, -6.5268, -6.5268, -6.5269,
           -6.5269],
          [-6.5268, -6.5269, -6.5269, -6.5269, -6.5269, -6.5269, -6.5269,
           -6.5269, -6.5268, -6.5268, -6.5268, -6.5268, -6.5268, -6.5269,
           -6.5269]]],


        [[[-6.7006, -6.7006, -6.7007, -6.7006, -6.7006, -6.7006, -6.7006,
           -6.7006, -6.7006, -6.7006, -6.7006, -6.7006, -6.7006, -6.7006,
           -6.7006],
          [-6.7006, -6.7006, -6.7007, -6.7006, -6.7006, -6.7006, -6.7006,
           -6.7006, -6.7006, -6.7006, -6.7006, -6.7006, -6.7006, -6.7006,
           -6.7006],
          [-6.7006, -6.7006, -6.7007, -6.7006, -6.7006, -6.7006, -6.7006,
           -6.7006, -6.7006, -6.7006, -6.7006, -6.7006, -6.7006, -6.7006,
           -6.7006],
          [-6.7006, -6.7006, -6.7007, -6.7006, -6.7006, -6.7006, -6.7006,
           -6.7006, -6.7006, -6.7006, -6.7006, -6.7006, -6.7006, -6.7006,
           -6.7006],
          [-6.7006, -6.7006, -6.7007, -6.7006, -6.7006, -6.7006, -6.7006,
           -6.7006, -6.7006, -6.7006, -6.7006, -6.7006, -6.7006, -6.7006,
           -6.7006],
          [-6.7006, -6.7006, -6.7007, -6.7006, -6.7006, -6.7006, -6.7006,
           -6.7006, -6.7006, -6.7006, -6.7006, -6.7006, -6.7006, -6.7006,
           -6.7006],
          [-6.7006, -6.7006, -6.7007, -6.7006, -6.7006, -6.7006, -6.7006,
           -6.7006, -6.7006, -6.7006, -6.7006, -6.7006, -6.7006, -6.7006,
           -6.7006],
          [-6.7006, -6.7006, -6.7007, -6.7006, -6.7006, -6.7006, -6.7006,
           -6.7006, -6.7006, -6.7006, -6.7006, -6.7006, -6.7006, -6.7006,
           -6.7006],
          [-6.7006, -6.7006, -6.7007, -6.7006, -6.7006, -6.7006, -6.7006,
           -6.7006, -6.7006, -6.7006, -6.7006, -6.7006, -6.7006, -6.7006,
           -6.7006],
          [-6.7006, -6.7006, -6.7007, -6.7006, -6.7006, -6.7006, -6.7006,
           -6.7006, -6.7006, -6.7006, -6.7006, -6.7006, -6.7006, -6.7006,
           -6.7006],
          [-6.7006, -6.7006, -6.7007, -6.7006, -6.7006, -6.7006, -6.7006,
           -6.7006, -6.7006, -6.7006, -6.7006, -6.7006, -6.7006, -6.7006,
           -6.7006],
          [-6.7006, -6.7006, -6.7007, -6.7006, -6.7006, -6.7006, -6.7006,
           -6.7006, -6.7006, -6.7006, -6.7006, -6.7006, -6.7006, -6.7006,
           -6.7006],
          [-6.7006, -6.7006, -6.7007, -6.7006, -6.7006, -6.7006, -6.7006,
           -6.7006, -6.7006, -6.7006, -6.7006, -6.7006, -6.7006, -6.7006,
           -6.7006],
          [-6.7006, -6.7006, -6.7007, -6.7006, -6.7006, -6.7006, -6.7006,
           -6.7006, -6.7006, -6.7006, -6.7006, -6.7006, -6.7006, -6.7006,
           -6.7006],
          [-6.7006, -6.7006, -6.7007, -6.7006, -6.7006, -6.7006, -6.7006,
           -6.7006, -6.7006, -6.7006, -6.7006, -6.7006, -6.7006, -6.7006,
           -6.7006],
          [-6.7006, -6.7006, -6.7007, -6.7006, -6.7006, -6.7006, -6.7006,
           -6.7006, -6.7006, -6.7006, -6.7006, -6.7006, -6.7006, -6.7006,
           -6.7006]],

         [[-6.4248, -6.4248, -6.4248, -6.4248, -6.4248, -6.4248, -6.4248,
           -6.4248, -6.4248, -6.4247, -6.4247, -6.4247, -6.4248, -6.4248,
           -6.4248],
          [-6.4248, -6.4248, -6.4248, -6.4248, -6.4248, -6.4248, -6.4248,
           -6.4248, -6.4248, -6.4247, -6.4247, -6.4247, -6.4248, -6.4248,
           -6.4248],
          [-6.4248, -6.4248, -6.4248, -6.4248, -6.4248, -6.4248, -6.4248,
           -6.4248, -6.4248, -6.4247, -6.4247, -6.4247, -6.4248, -6.4248,
           -6.4248],
          [-6.4248, -6.4248, -6.4248, -6.4248, -6.4248, -6.4248, -6.4248,
           -6.4248, -6.4248, -6.4247, -6.4247, -6.4247, -6.4248, -6.4248,
           -6.4248],
          [-6.4248, -6.4248, -6.4248, -6.4248, -6.4248, -6.4248, -6.4248,
           -6.4248, -6.4248, -6.4247, -6.4247, -6.4247, -6.4248, -6.4248,
           -6.4248],
          [-6.4248, -6.4248, -6.4248, -6.4248, -6.4248, -6.4248, -6.4248,
           -6.4248, -6.4248, -6.4247, -6.4247, -6.4247, -6.4248, -6.4248,
           -6.4248],
          [-6.4248, -6.4248, -6.4248, -6.4248, -6.4248, -6.4248, -6.4248,
           -6.4248, -6.4248, -6.4247, -6.4247, -6.4247, -6.4248, -6.4248,
           -6.4248],
          [-6.4248, -6.4248, -6.4248, -6.4248, -6.4248, -6.4248, -6.4248,
           -6.4248, -6.4248, -6.4247, -6.4247, -6.4247, -6.4248, -6.4248,
           -6.4248],
          [-6.4248, -6.4248, -6.4248, -6.4248, -6.4248, -6.4248, -6.4248,
           -6.4248, -6.4248, -6.4247, -6.4247, -6.4247, -6.4248, -6.4248,
           -6.4248],
          [-6.4248, -6.4248, -6.4248, -6.4248, -6.4248, -6.4248, -6.4248,
           -6.4248, -6.4248, -6.4247, -6.4247, -6.4247, -6.4248, -6.4248,
           -6.4248],
          [-6.4248, -6.4248, -6.4248, -6.4248, -6.4248, -6.4248, -6.4248,
           -6.4248, -6.4248, -6.4247, -6.4247, -6.4247, -6.4248, -6.4248,
           -6.4248],
          [-6.4248, -6.4248, -6.4248, -6.4248, -6.4248, -6.4248, -6.4248,
           -6.4248, -6.4248, -6.4247, -6.4247, -6.4247, -6.4248, -6.4248,
           -6.4248],
          [-6.4248, -6.4248, -6.4248, -6.4248, -6.4248, -6.4248, -6.4248,
           -6.4248, -6.4248, -6.4247, -6.4247, -6.4247, -6.4248, -6.4248,
           -6.4248],
          [-6.4248, -6.4248, -6.4248, -6.4248, -6.4248, -6.4248, -6.4248,
           -6.4248, -6.4248, -6.4247, -6.4247, -6.4247, -6.4248, -6.4248,
           -6.4248],
          [-6.4248, -6.4248, -6.4248, -6.4248, -6.4248, -6.4248, -6.4248,
           -6.4248, -6.4248, -6.4247, -6.4247, -6.4247, -6.4248, -6.4248,
           -6.4248],
          [-6.4248, -6.4248, -6.4248, -6.4248, -6.4248, -6.4248, -6.4248,
           -6.4248, -6.4248, -6.4247, -6.4247, -6.4247, -6.4248, -6.4248,
           -6.4248]]]], grad_fn=<SliceBackward0>)
train_step: Return scale: 1.644214126179415
train_step: Scaled advantages shape: torch.Size([16, 15, 16, 15])
train_step: Scaled advantages sample: tensor([[[[-4.2366, -4.2366, -4.2366, -4.2366, -4.2366, -4.2366, -4.2366,
           -4.2366, -4.2366, -4.2366, -4.2366, -4.2366, -4.2366, -4.2366,
           -4.2366],
          [-4.2366, -4.2366, -4.2366, -4.2366, -4.2366, -4.2366, -4.2366,
           -4.2366, -4.2366, -4.2366, -4.2366, -4.2366, -4.2366, -4.2366,
           -4.2366],
          [-4.2366, -4.2366, -4.2366, -4.2366, -4.2366, -4.2366, -4.2366,
           -4.2366, -4.2366, -4.2366, -4.2366, -4.2366, -4.2366, -4.2366,
           -4.2366],
          [-4.2366, -4.2366, -4.2366, -4.2366, -4.2366, -4.2366, -4.2366,
           -4.2366, -4.2366, -4.2366, -4.2366, -4.2366, -4.2366, -4.2366,
           -4.2366],
          [-4.2366, -4.2366, -4.2366, -4.2366, -4.2366, -4.2366, -4.2366,
           -4.2366, -4.2366, -4.2366, -4.2366, -4.2366, -4.2366, -4.2366,
           -4.2366],
          [-4.2366, -4.2366, -4.2366, -4.2366, -4.2366, -4.2366, -4.2366,
           -4.2366, -4.2366, -4.2366, -4.2366, -4.2366, -4.2366, -4.2366,
           -4.2366],
          [-4.2366, -4.2366, -4.2366, -4.2366, -4.2366, -4.2366, -4.2366,
           -4.2366, -4.2366, -4.2366, -4.2366, -4.2366, -4.2366, -4.2366,
           -4.2366],
          [-4.2366, -4.2366, -4.2366, -4.2366, -4.2366, -4.2366, -4.2366,
           -4.2366, -4.2366, -4.2366, -4.2366, -4.2366, -4.2366, -4.2366,
           -4.2366],
          [-4.2366, -4.2366, -4.2366, -4.2366, -4.2366, -4.2366, -4.2366,
           -4.2366, -4.2366, -4.2366, -4.2366, -4.2366, -4.2366, -4.2366,
           -4.2366],
          [-4.2366, -4.2366, -4.2366, -4.2366, -4.2366, -4.2366, -4.2366,
           -4.2366, -4.2366, -4.2366, -4.2366, -4.2366, -4.2366, -4.2366,
           -4.2366],
          [-4.2366, -4.2366, -4.2366, -4.2366, -4.2366, -4.2366, -4.2366,
           -4.2366, -4.2366, -4.2366, -4.2366, -4.2366, -4.2366, -4.2366,
           -4.2366],
          [-4.2366, -4.2366, -4.2366, -4.2366, -4.2366, -4.2366, -4.2366,
           -4.2366, -4.2366, -4.2366, -4.2366, -4.2366, -4.2366, -4.2366,
           -4.2366],
          [-4.2366, -4.2366, -4.2366, -4.2366, -4.2366, -4.2366, -4.2366,
           -4.2366, -4.2366, -4.2366, -4.2366, -4.2366, -4.2366, -4.2366,
           -4.2366],
          [-4.2366, -4.2366, -4.2366, -4.2366, -4.2366, -4.2366, -4.2366,
           -4.2366, -4.2366, -4.2366, -4.2366, -4.2366, -4.2366, -4.2366,
           -4.2366],
          [-4.2366, -4.2366, -4.2366, -4.2366, -4.2366, -4.2366, -4.2366,
           -4.2366, -4.2366, -4.2366, -4.2366, -4.2366, -4.2366, -4.2366,
           -4.2366],
          [-4.2366, -4.2366, -4.2366, -4.2366, -4.2366, -4.2366, -4.2366,
           -4.2366, -4.2366, -4.2366, -4.2366, -4.2366, -4.2366, -4.2366,
           -4.2366]],

         [[-3.9696, -3.9696, -3.9696, -3.9696, -3.9696, -3.9696, -3.9696,
           -3.9696, -3.9696, -3.9696, -3.9696, -3.9696, -3.9696, -3.9696,
           -3.9696],
          [-3.9696, -3.9696, -3.9696, -3.9696, -3.9696, -3.9696, -3.9696,
           -3.9696, -3.9696, -3.9696, -3.9696, -3.9696, -3.9696, -3.9696,
           -3.9696],
          [-3.9696, -3.9696, -3.9696, -3.9696, -3.9696, -3.9696, -3.9696,
           -3.9696, -3.9696, -3.9696, -3.9696, -3.9696, -3.9696, -3.9696,
           -3.9696],
          [-3.9696, -3.9696, -3.9696, -3.9696, -3.9696, -3.9696, -3.9696,
           -3.9696, -3.9696, -3.9696, -3.9696, -3.9696, -3.9696, -3.9696,
           -3.9696],
          [-3.9696, -3.9696, -3.9696, -3.9696, -3.9696, -3.9696, -3.9696,
           -3.9696, -3.9696, -3.9696, -3.9696, -3.9696, -3.9696, -3.9696,
           -3.9696],
          [-3.9696, -3.9696, -3.9696, -3.9696, -3.9696, -3.9696, -3.9696,
           -3.9696, -3.9696, -3.9696, -3.9696, -3.9696, -3.9696, -3.9696,
           -3.9696],
          [-3.9696, -3.9696, -3.9696, -3.9696, -3.9696, -3.9696, -3.9696,
           -3.9696, -3.9696, -3.9696, -3.9696, -3.9696, -3.9696, -3.9696,
           -3.9696],
          [-3.9696, -3.9696, -3.9696, -3.9696, -3.9696, -3.9696, -3.9696,
           -3.9696, -3.9696, -3.9696, -3.9696, -3.9696, -3.9696, -3.9696,
           -3.9696],
          [-3.9696, -3.9696, -3.9696, -3.9696, -3.9696, -3.9696, -3.9696,
           -3.9696, -3.9696, -3.9696, -3.9696, -3.9696, -3.9696, -3.9696,
           -3.9696],
          [-3.9696, -3.9696, -3.9696, -3.9696, -3.9696, -3.9696, -3.9696,
           -3.9696, -3.9696, -3.9696, -3.9696, -3.9696, -3.9696, -3.9696,
           -3.9696],
          [-3.9696, -3.9696, -3.9696, -3.9696, -3.9696, -3.9696, -3.9696,
           -3.9696, -3.9696, -3.9696, -3.9696, -3.9696, -3.9696, -3.9696,
           -3.9696],
          [-3.9696, -3.9696, -3.9696, -3.9696, -3.9696, -3.9696, -3.9696,
           -3.9696, -3.9696, -3.9696, -3.9696, -3.9696, -3.9696, -3.9696,
           -3.9696],
          [-3.9696, -3.9696, -3.9696, -3.9696, -3.9696, -3.9696, -3.9696,
           -3.9696, -3.9696, -3.9696, -3.9696, -3.9696, -3.9696, -3.9696,
           -3.9696],
          [-3.9696, -3.9696, -3.9696, -3.9696, -3.9696, -3.9696, -3.9696,
           -3.9696, -3.9696, -3.9696, -3.9696, -3.9696, -3.9696, -3.9696,
           -3.9696],
          [-3.9696, -3.9696, -3.9696, -3.9696, -3.9696, -3.9696, -3.9696,
           -3.9696, -3.9696, -3.9696, -3.9696, -3.9696, -3.9696, -3.9696,
           -3.9696],
          [-3.9696, -3.9696, -3.9696, -3.9696, -3.9696, -3.9696, -3.9696,
           -3.9696, -3.9696, -3.9696, -3.9696, -3.9696, -3.9696, -3.9696,
           -3.9696]]],


        [[[-4.0753, -4.0753, -4.0753, -4.0753, -4.0753, -4.0753, -4.0753,
           -4.0753, -4.0753, -4.0753, -4.0753, -4.0753, -4.0753, -4.0753,
           -4.0753],
          [-4.0753, -4.0753, -4.0753, -4.0753, -4.0753, -4.0753, -4.0753,
           -4.0753, -4.0753, -4.0753, -4.0753, -4.0753, -4.0753, -4.0753,
           -4.0753],
          [-4.0753, -4.0753, -4.0753, -4.0753, -4.0753, -4.0753, -4.0753,
           -4.0753, -4.0753, -4.0753, -4.0753, -4.0753, -4.0753, -4.0753,
           -4.0753],
          [-4.0753, -4.0753, -4.0753, -4.0753, -4.0753, -4.0753, -4.0753,
           -4.0753, -4.0753, -4.0753, -4.0753, -4.0753, -4.0753, -4.0753,
           -4.0753],
          [-4.0753, -4.0753, -4.0753, -4.0753, -4.0753, -4.0753, -4.0753,
           -4.0753, -4.0753, -4.0753, -4.0753, -4.0753, -4.0753, -4.0753,
           -4.0753],
          [-4.0753, -4.0753, -4.0753, -4.0753, -4.0753, -4.0753, -4.0753,
           -4.0753, -4.0753, -4.0753, -4.0753, -4.0753, -4.0753, -4.0753,
           -4.0753],
          [-4.0753, -4.0753, -4.0753, -4.0753, -4.0753, -4.0753, -4.0753,
           -4.0753, -4.0753, -4.0753, -4.0753, -4.0753, -4.0753, -4.0753,
           -4.0753],
          [-4.0753, -4.0753, -4.0753, -4.0753, -4.0753, -4.0753, -4.0753,
           -4.0753, -4.0753, -4.0753, -4.0753, -4.0753, -4.0753, -4.0753,
           -4.0753],
          [-4.0753, -4.0753, -4.0753, -4.0753, -4.0753, -4.0753, -4.0753,
           -4.0753, -4.0753, -4.0753, -4.0753, -4.0753, -4.0753, -4.0753,
           -4.0753],
          [-4.0753, -4.0753, -4.0753, -4.0753, -4.0753, -4.0753, -4.0753,
           -4.0753, -4.0753, -4.0753, -4.0753, -4.0753, -4.0753, -4.0753,
           -4.0753],
          [-4.0753, -4.0753, -4.0753, -4.0753, -4.0753, -4.0753, -4.0753,
           -4.0753, -4.0753, -4.0753, -4.0753, -4.0753, -4.0753, -4.0753,
           -4.0753],
          [-4.0753, -4.0753, -4.0753, -4.0753, -4.0753, -4.0753, -4.0753,
           -4.0753, -4.0753, -4.0753, -4.0753, -4.0753, -4.0753, -4.0753,
           -4.0753],
          [-4.0753, -4.0753, -4.0753, -4.0753, -4.0753, -4.0753, -4.0753,
           -4.0753, -4.0753, -4.0753, -4.0753, -4.0753, -4.0753, -4.0753,
           -4.0753],
          [-4.0753, -4.0753, -4.0753, -4.0753, -4.0753, -4.0753, -4.0753,
           -4.0753, -4.0753, -4.0753, -4.0753, -4.0753, -4.0753, -4.0753,
           -4.0753],
          [-4.0753, -4.0753, -4.0753, -4.0753, -4.0753, -4.0753, -4.0753,
           -4.0753, -4.0753, -4.0753, -4.0753, -4.0753, -4.0753, -4.0753,
           -4.0753],
          [-4.0753, -4.0753, -4.0753, -4.0753, -4.0753, -4.0753, -4.0753,
           -4.0753, -4.0753, -4.0753, -4.0753, -4.0753, -4.0753, -4.0753,
           -4.0753]],

         [[-3.9075, -3.9075, -3.9075, -3.9075, -3.9075, -3.9075, -3.9075,
           -3.9075, -3.9075, -3.9075, -3.9075, -3.9075, -3.9075, -3.9075,
           -3.9075],
          [-3.9075, -3.9075, -3.9075, -3.9075, -3.9075, -3.9075, -3.9075,
           -3.9075, -3.9075, -3.9075, -3.9075, -3.9075, -3.9075, -3.9075,
           -3.9075],
          [-3.9075, -3.9075, -3.9075, -3.9075, -3.9075, -3.9075, -3.9075,
           -3.9075, -3.9075, -3.9075, -3.9075, -3.9075, -3.9075, -3.9075,
           -3.9075],
          [-3.9075, -3.9075, -3.9075, -3.9075, -3.9075, -3.9075, -3.9075,
           -3.9075, -3.9075, -3.9075, -3.9075, -3.9075, -3.9075, -3.9075,
           -3.9075],
          [-3.9075, -3.9075, -3.9075, -3.9075, -3.9075, -3.9075, -3.9075,
           -3.9075, -3.9075, -3.9075, -3.9075, -3.9075, -3.9075, -3.9075,
           -3.9075],
          [-3.9075, -3.9075, -3.9075, -3.9075, -3.9075, -3.9075, -3.9075,
           -3.9075, -3.9075, -3.9075, -3.9075, -3.9075, -3.9075, -3.9075,
           -3.9075],
          [-3.9075, -3.9075, -3.9075, -3.9075, -3.9075, -3.9075, -3.9075,
           -3.9075, -3.9075, -3.9075, -3.9075, -3.9075, -3.9075, -3.9075,
           -3.9075],
          [-3.9075, -3.9075, -3.9075, -3.9075, -3.9075, -3.9075, -3.9075,
           -3.9075, -3.9075, -3.9075, -3.9075, -3.9075, -3.9075, -3.9075,
           -3.9075],
          [-3.9075, -3.9075, -3.9075, -3.9075, -3.9075, -3.9075, -3.9075,
           -3.9075, -3.9075, -3.9075, -3.9075, -3.9075, -3.9075, -3.9075,
           -3.9075],
          [-3.9075, -3.9075, -3.9075, -3.9075, -3.9075, -3.9075, -3.9075,
           -3.9075, -3.9075, -3.9075, -3.9075, -3.9075, -3.9075, -3.9075,
           -3.9075],
          [-3.9075, -3.9075, -3.9075, -3.9075, -3.9075, -3.9075, -3.9075,
           -3.9075, -3.9075, -3.9075, -3.9075, -3.9075, -3.9075, -3.9075,
           -3.9075],
          [-3.9075, -3.9075, -3.9075, -3.9075, -3.9075, -3.9075, -3.9075,
           -3.9075, -3.9075, -3.9075, -3.9075, -3.9075, -3.9075, -3.9075,
           -3.9075],
          [-3.9075, -3.9075, -3.9075, -3.9075, -3.9075, -3.9075, -3.9075,
           -3.9075, -3.9075, -3.9075, -3.9075, -3.9075, -3.9075, -3.9075,
           -3.9075],
          [-3.9075, -3.9075, -3.9075, -3.9075, -3.9075, -3.9075, -3.9075,
           -3.9075, -3.9075, -3.9075, -3.9075, -3.9075, -3.9075, -3.9075,
           -3.9075],
          [-3.9075, -3.9075, -3.9075, -3.9075, -3.9075, -3.9075, -3.9075,
           -3.9075, -3.9075, -3.9075, -3.9075, -3.9075, -3.9075, -3.9075,
           -3.9075],
          [-3.9075, -3.9075, -3.9075, -3.9075, -3.9075, -3.9075, -3.9075,
           -3.9075, -3.9075, -3.9075, -3.9075, -3.9075, -3.9075, -3.9075,
           -3.9075]]]], grad_fn=<SliceBackward0>)
train_step: Entropy shape: torch.Size([16, 15])
train_step: Entropy sample: tensor([[0.5758, 0.6536],
        [0.6681, 0.6924]], grad_fn=<SliceBackward0>)
train_step: Entropy coefficient: 0.01
train_step: Actor loss: -1.2337892055511475
train_step: returns shape after mean: torch.Size([16, 15])
train_step: target_indices shape: torch.Size([16, 15])
train_step: value_logits shape: torch.Size([16, 15, 255])
train_step: target_twohot shape: torch.Size([16, 15, 255])
--- Starting train_step at 2025-04-01 01:59:34 ---
Full starting_state: {'deter': tensor([[[-1.4712e-02, -1.8714e-02, -5.3586e-02,  ...,  1.1500e-01,
           2.7811e-01,  1.8146e-03],
         [ 4.0480e-02,  5.2201e-02, -1.6810e-02,  ...,  1.5159e-01,
           2.1385e-01,  4.5486e-03],
         [-3.7606e-02, -6.2021e-02,  1.1800e-01,  ...,  6.8557e-02,
           7.2239e-02, -1.0709e-01],
         ...,
         [ 1.4526e-01, -8.5239e-02, -5.8141e-03,  ...,  1.5397e-01,
           5.7520e-02, -3.6398e-02],
         [-1.0840e-01,  4.9612e-03, -1.6830e-02,  ..., -7.0494e-02,
          -7.1993e-02, -6.7501e-02],
         [-1.2423e-01, -7.3930e-02, -9.3556e-03,  ...,  8.0213e-03,
          -2.4521e-02, -1.1487e-01]],

        [[ 3.9535e-02, -7.1558e-05, -1.0283e-01,  ..., -4.4163e-02,
          -5.2002e-02, -9.9380e-02],
         [-1.3425e-01,  1.1975e-01,  7.0351e-02,  ..., -1.1269e-01,
           1.3068e-01,  2.8385e-02],
         [-6.3646e-02, -3.8642e-02,  4.1690e-03,  ..., -1.2595e-01,
          -1.2164e-01, -8.0545e-02],
         ...,
         [-5.7626e-02, -3.8884e-02, -5.7951e-02,  ...,  5.3693e-02,
           1.5831e-02, -3.0379e-02],
         [-8.8376e-02,  2.9695e-02, -2.9736e-02,  ..., -3.6089e-02,
           9.3350e-02, -4.3888e-02],
         [ 6.0041e-02,  5.5756e-02, -1.1839e-01,  ...,  2.4145e-02,
           1.9966e-02, -4.3051e-02]],

        [[-3.8386e-02, -3.5396e-03, -4.4645e-02,  ..., -4.8940e-02,
           4.2266e-02,  6.2025e-02],
         [-3.7838e-02,  4.5116e-02, -3.1297e-02,  ..., -2.2854e-02,
          -1.4959e-01, -7.0381e-02],
         [-4.6787e-03, -5.8260e-02, -7.6410e-02,  ...,  2.8016e-02,
          -6.0948e-02,  4.5849e-02],
         ...,
         [ 1.4146e-01, -3.8025e-02, -5.5612e-02,  ..., -4.9713e-02,
          -1.0845e-01,  1.3736e-01],
         [ 7.2602e-02, -4.7921e-02,  3.2884e-02,  ...,  9.4010e-02,
           8.8641e-02,  7.9894e-02],
         [-6.3165e-02, -6.5356e-02, -1.6114e-02,  ...,  4.0595e-03,
           2.5121e-01,  1.1028e-02]],

        ...,

        [[-8.1500e-02, -5.4683e-02,  1.1764e-01,  ...,  2.0541e-01,
          -2.1339e-01,  4.4559e-03],
         [-1.7761e-02, -9.0277e-03,  2.6784e-02,  ...,  1.3306e-01,
           1.1398e-01, -2.8480e-01],
         [-2.6994e-03, -5.0636e-02, -1.5738e-01,  ...,  1.6047e-01,
           2.3197e-02,  8.4857e-02],
         ...,
         [ 9.8117e-02, -4.7786e-02,  4.2765e-02,  ..., -6.4415e-02,
           1.0964e-01, -4.3016e-02],
         [-1.0082e-01,  5.5268e-02,  7.9159e-02,  ..., -5.2787e-02,
          -1.3444e-01, -3.6553e-02],
         [-1.5048e-02,  1.1325e-01, -3.4088e-02,  ..., -1.4764e-01,
          -5.2160e-03, -1.1818e-01]],

        [[ 9.4766e-02, -4.5963e-02, -1.4438e-01,  ...,  7.9419e-02,
           1.0853e-01,  9.5521e-02],
         [-1.4787e-01, -9.3134e-02,  4.0369e-02,  ..., -1.0387e-01,
          -9.9501e-02, -1.1260e-01],
         [-3.6381e-02, -1.4125e-01,  7.3946e-02,  ..., -2.0232e-01,
           5.2572e-02,  8.3866e-03],
         ...,
         [ 4.0201e-03,  1.1091e-01,  2.4064e-02,  ...,  9.9584e-02,
           7.2133e-02,  1.2404e-01],
         [-1.6269e-01, -6.5278e-02, -1.3757e-01,  ..., -2.5975e-01,
           4.2340e-02, -3.1956e-02],
         [-2.9108e-02,  7.3163e-02, -1.1016e-01,  ..., -2.7122e-02,
           2.1505e-03,  6.7292e-02]],

        [[ 2.8513e-02, -9.8791e-02, -6.7401e-02,  ...,  1.5077e-01,
           8.7964e-02, -1.3462e-01],
         [ 7.6169e-02,  8.6983e-02, -2.7729e-02,  ..., -1.0694e-02,
          -6.5241e-02, -2.7837e-03],
         [-1.0866e-01, -3.7058e-02, -1.5912e-01,  ...,  5.8535e-02,
           1.6478e-01, -1.1557e-01],
         ...,
         [-1.0066e-01, -2.2997e-02,  8.1936e-02,  ..., -4.9700e-03,
           6.9456e-02, -6.8090e-02],
         [ 9.9970e-02, -1.5546e-02, -6.0726e-02,  ..., -7.7926e-02,
          -8.4097e-03,  4.4493e-02],
         [-5.4843e-02, -1.8144e-02, -6.6168e-02,  ..., -8.1041e-02,
           6.1063e-02,  6.4470e-02]]], grad_fn=<StackBackward0>), 'stoch': tensor([[[0., 0., 0.,  ..., 0., 1., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [1., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 1., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 1.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 1.,  ..., 0., 1., 0.],
         [0., 0., 0.,  ..., 0., 0., 1.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 1., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 1.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 1.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 1.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 1., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 1.,  ..., 0., 0., 0.]]])}
train_step: Starting state deter shape: torch.Size([16, 50, 128])
train_step: Starting state stoch shape: torch.Size([16, 50, 1024])
After ensuring logits/stoch: {'deter': tensor([[[-1.4712e-02, -1.8714e-02, -5.3586e-02,  ...,  1.1500e-01,
           2.7811e-01,  1.8146e-03],
         [ 4.0480e-02,  5.2201e-02, -1.6810e-02,  ...,  1.5159e-01,
           2.1385e-01,  4.5486e-03],
         [-3.7606e-02, -6.2021e-02,  1.1800e-01,  ...,  6.8557e-02,
           7.2239e-02, -1.0709e-01],
         ...,
         [ 1.4526e-01, -8.5239e-02, -5.8141e-03,  ...,  1.5397e-01,
           5.7520e-02, -3.6398e-02],
         [-1.0840e-01,  4.9612e-03, -1.6830e-02,  ..., -7.0494e-02,
          -7.1993e-02, -6.7501e-02],
         [-1.2423e-01, -7.3930e-02, -9.3556e-03,  ...,  8.0213e-03,
          -2.4521e-02, -1.1487e-01]],

        [[ 3.9535e-02, -7.1558e-05, -1.0283e-01,  ..., -4.4163e-02,
          -5.2002e-02, -9.9380e-02],
         [-1.3425e-01,  1.1975e-01,  7.0351e-02,  ..., -1.1269e-01,
           1.3068e-01,  2.8385e-02],
         [-6.3646e-02, -3.8642e-02,  4.1690e-03,  ..., -1.2595e-01,
          -1.2164e-01, -8.0545e-02],
         ...,
         [-5.7626e-02, -3.8884e-02, -5.7951e-02,  ...,  5.3693e-02,
           1.5831e-02, -3.0379e-02],
         [-8.8376e-02,  2.9695e-02, -2.9736e-02,  ..., -3.6089e-02,
           9.3350e-02, -4.3888e-02],
         [ 6.0041e-02,  5.5756e-02, -1.1839e-01,  ...,  2.4145e-02,
           1.9966e-02, -4.3051e-02]],

        [[-3.8386e-02, -3.5396e-03, -4.4645e-02,  ..., -4.8940e-02,
           4.2266e-02,  6.2025e-02],
         [-3.7838e-02,  4.5116e-02, -3.1297e-02,  ..., -2.2854e-02,
          -1.4959e-01, -7.0381e-02],
         [-4.6787e-03, -5.8260e-02, -7.6410e-02,  ...,  2.8016e-02,
          -6.0948e-02,  4.5849e-02],
         ...,
         [ 1.4146e-01, -3.8025e-02, -5.5612e-02,  ..., -4.9713e-02,
          -1.0845e-01,  1.3736e-01],
         [ 7.2602e-02, -4.7921e-02,  3.2884e-02,  ...,  9.4010e-02,
           8.8641e-02,  7.9894e-02],
         [-6.3165e-02, -6.5356e-02, -1.6114e-02,  ...,  4.0595e-03,
           2.5121e-01,  1.1028e-02]],

        ...,

        [[-8.1500e-02, -5.4683e-02,  1.1764e-01,  ...,  2.0541e-01,
          -2.1339e-01,  4.4559e-03],
         [-1.7761e-02, -9.0277e-03,  2.6784e-02,  ...,  1.3306e-01,
           1.1398e-01, -2.8480e-01],
         [-2.6994e-03, -5.0636e-02, -1.5738e-01,  ...,  1.6047e-01,
           2.3197e-02,  8.4857e-02],
         ...,
         [ 9.8117e-02, -4.7786e-02,  4.2765e-02,  ..., -6.4415e-02,
           1.0964e-01, -4.3016e-02],
         [-1.0082e-01,  5.5268e-02,  7.9159e-02,  ..., -5.2787e-02,
          -1.3444e-01, -3.6553e-02],
         [-1.5048e-02,  1.1325e-01, -3.4088e-02,  ..., -1.4764e-01,
          -5.2160e-03, -1.1818e-01]],

        [[ 9.4766e-02, -4.5963e-02, -1.4438e-01,  ...,  7.9419e-02,
           1.0853e-01,  9.5521e-02],
         [-1.4787e-01, -9.3134e-02,  4.0369e-02,  ..., -1.0387e-01,
          -9.9501e-02, -1.1260e-01],
         [-3.6381e-02, -1.4125e-01,  7.3946e-02,  ..., -2.0232e-01,
           5.2572e-02,  8.3866e-03],
         ...,
         [ 4.0201e-03,  1.1091e-01,  2.4064e-02,  ...,  9.9584e-02,
           7.2133e-02,  1.2404e-01],
         [-1.6269e-01, -6.5278e-02, -1.3757e-01,  ..., -2.5975e-01,
           4.2340e-02, -3.1956e-02],
         [-2.9108e-02,  7.3163e-02, -1.1016e-01,  ..., -2.7122e-02,
           2.1505e-03,  6.7292e-02]],

        [[ 2.8513e-02, -9.8791e-02, -6.7401e-02,  ...,  1.5077e-01,
           8.7964e-02, -1.3462e-01],
         [ 7.6169e-02,  8.6983e-02, -2.7729e-02,  ..., -1.0694e-02,
          -6.5241e-02, -2.7837e-03],
         [-1.0866e-01, -3.7058e-02, -1.5912e-01,  ...,  5.8535e-02,
           1.6478e-01, -1.1557e-01],
         ...,
         [-1.0066e-01, -2.2997e-02,  8.1936e-02,  ..., -4.9700e-03,
           6.9456e-02, -6.8090e-02],
         [ 9.9970e-02, -1.5546e-02, -6.0726e-02,  ..., -7.7926e-02,
          -8.4097e-03,  4.4493e-02],
         [-5.4843e-02, -1.8144e-02, -6.6168e-02,  ..., -8.1041e-02,
           6.1063e-02,  6.4470e-02]]], grad_fn=<StackBackward0>), 'stoch': tensor([[[0., 0., 0.,  ..., 0., 1., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [1., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 1., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 1.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 1.,  ..., 0., 1., 0.],
         [0., 0., 0.,  ..., 0., 0., 1.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 1., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 1.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 1.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 1.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 1., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 1.,  ..., 0., 0., 0.]]]), 'logits': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]])}
train_step: Normalized hidden_state shape: torch.Size([1, 16, 128])
train_step: Normalized stoch shape: torch.Size([16, 1024])
train_step: Normalized deter shape: torch.Size([16, 128])
train_step: Post-imagine_trajectory: Imagined features shape: torch.Size([16, 15, 1152])
train_step: Post-imagine_trajectory: Imagined actions shape: torch.Size([16, 15, 2])
train_step: Post-imagine_trajectory: Imagined action indices shape: torch.Size([16, 15])
train_step: Post-imagine_trajectory: Imagined state deter shape: torch.Size([16, 15, 128])
train_step: Post-imagine_trajectory: Imagined state stoch shape: torch.Size([16, 15, 1024])
Reward shape: torch.Size([16, 15, 1]), Value shape: torch.Size([16, 15, 1]), Slow Value shape: torch.Size([16, 15, 1]), Discount shape: torch.Size([16, 15, 1, 1])
Return targets length: 15, First target shape: torch.Size([16, 16, 1])
train_step: Actor distribution shape: torch.Size([16, 15, 2])
train_step: Action log probabilities shape: torch.Size([16, 15])
train_step: Action log probabilities sample: tensor([[-0.9078, -1.5332],
        [-0.6192, -0.1354]], grad_fn=<SliceBackward0>)
train_step: Advantages shape: torch.Size([16, 15, 16, 15])
train_step: Advantages sample: tensor([[[[-7.8110, -7.8110, -7.8110, -7.8110, -7.8110, -7.8111, -7.8110,
           -7.8110, -7.8110, -7.8110, -7.8110, -7.8110, -7.8110, -7.8110,
           -7.8110],
          [-7.8110, -7.8110, -7.8110, -7.8110, -7.8110, -7.8111, -7.8110,
           -7.8110, -7.8110, -7.8110, -7.8110, -7.8110, -7.8110, -7.8110,
           -7.8110],
          [-7.8110, -7.8110, -7.8110, -7.8110, -7.8110, -7.8111, -7.8110,
           -7.8110, -7.8110, -7.8110, -7.8110, -7.8110, -7.8110, -7.8110,
           -7.8110],
          [-7.8110, -7.8110, -7.8110, -7.8110, -7.8110, -7.8111, -7.8110,
           -7.8110, -7.8110, -7.8110, -7.8110, -7.8110, -7.8110, -7.8110,
           -7.8110],
          [-7.8110, -7.8110, -7.8110, -7.8110, -7.8110, -7.8111, -7.8110,
           -7.8110, -7.8110, -7.8110, -7.8110, -7.8110, -7.8110, -7.8110,
           -7.8110],
          [-7.8110, -7.8110, -7.8110, -7.8110, -7.8110, -7.8111, -7.8110,
           -7.8110, -7.8110, -7.8110, -7.8110, -7.8110, -7.8110, -7.8110,
           -7.8110],
          [-7.8110, -7.8110, -7.8110, -7.8110, -7.8110, -7.8111, -7.8110,
           -7.8110, -7.8110, -7.8110, -7.8110, -7.8110, -7.8110, -7.8110,
           -7.8110],
          [-7.8110, -7.8110, -7.8110, -7.8110, -7.8110, -7.8111, -7.8110,
           -7.8110, -7.8110, -7.8110, -7.8110, -7.8110, -7.8110, -7.8110,
           -7.8110],
          [-7.8110, -7.8110, -7.8110, -7.8110, -7.8110, -7.8111, -7.8110,
           -7.8110, -7.8110, -7.8110, -7.8110, -7.8110, -7.8110, -7.8110,
           -7.8110],
          [-7.8110, -7.8110, -7.8110, -7.8110, -7.8110, -7.8111, -7.8110,
           -7.8110, -7.8110, -7.8110, -7.8110, -7.8110, -7.8110, -7.8110,
           -7.8110],
          [-7.8110, -7.8110, -7.8110, -7.8110, -7.8110, -7.8111, -7.8110,
           -7.8110, -7.8110, -7.8110, -7.8110, -7.8110, -7.8110, -7.8110,
           -7.8110],
          [-7.8110, -7.8110, -7.8110, -7.8110, -7.8110, -7.8111, -7.8110,
           -7.8110, -7.8110, -7.8110, -7.8110, -7.8110, -7.8110, -7.8110,
           -7.8110],
          [-7.8110, -7.8110, -7.8110, -7.8110, -7.8110, -7.8111, -7.8110,
           -7.8110, -7.8110, -7.8110, -7.8110, -7.8110, -7.8110, -7.8110,
           -7.8110],
          [-7.8110, -7.8110, -7.8110, -7.8110, -7.8110, -7.8111, -7.8110,
           -7.8110, -7.8110, -7.8110, -7.8110, -7.8110, -7.8110, -7.8110,
           -7.8110],
          [-7.8110, -7.8110, -7.8110, -7.8110, -7.8110, -7.8111, -7.8110,
           -7.8110, -7.8110, -7.8110, -7.8110, -7.8110, -7.8110, -7.8110,
           -7.8110],
          [-7.8110, -7.8110, -7.8110, -7.8110, -7.8110, -7.8111, -7.8110,
           -7.8110, -7.8110, -7.8110, -7.8110, -7.8110, -7.8110, -7.8110,
           -7.8110]],

         [[-7.5202, -7.5202, -7.5202, -7.5202, -7.5202, -7.5202, -7.5202,
           -7.5202, -7.5202, -7.5202, -7.5203, -7.5202, -7.5202, -7.5203,
           -7.5202],
          [-7.5202, -7.5202, -7.5202, -7.5202, -7.5202, -7.5202, -7.5202,
           -7.5202, -7.5202, -7.5202, -7.5203, -7.5202, -7.5202, -7.5203,
           -7.5202],
          [-7.5202, -7.5202, -7.5202, -7.5202, -7.5202, -7.5202, -7.5202,
           -7.5202, -7.5202, -7.5202, -7.5203, -7.5202, -7.5202, -7.5203,
           -7.5202],
          [-7.5202, -7.5202, -7.5202, -7.5202, -7.5202, -7.5202, -7.5202,
           -7.5202, -7.5202, -7.5202, -7.5203, -7.5202, -7.5202, -7.5203,
           -7.5202],
          [-7.5202, -7.5202, -7.5202, -7.5202, -7.5202, -7.5202, -7.5202,
           -7.5202, -7.5202, -7.5202, -7.5203, -7.5202, -7.5202, -7.5203,
           -7.5202],
          [-7.5202, -7.5202, -7.5202, -7.5202, -7.5202, -7.5202, -7.5202,
           -7.5202, -7.5202, -7.5202, -7.5203, -7.5202, -7.5202, -7.5203,
           -7.5202],
          [-7.5202, -7.5202, -7.5202, -7.5202, -7.5202, -7.5202, -7.5202,
           -7.5202, -7.5202, -7.5202, -7.5203, -7.5202, -7.5202, -7.5203,
           -7.5202],
          [-7.5202, -7.5202, -7.5202, -7.5202, -7.5202, -7.5202, -7.5202,
           -7.5202, -7.5202, -7.5202, -7.5203, -7.5202, -7.5202, -7.5203,
           -7.5202],
          [-7.5202, -7.5202, -7.5202, -7.5202, -7.5202, -7.5202, -7.5202,
           -7.5202, -7.5202, -7.5202, -7.5203, -7.5202, -7.5202, -7.5203,
           -7.5202],
          [-7.5202, -7.5202, -7.5202, -7.5202, -7.5202, -7.5202, -7.5202,
           -7.5202, -7.5202, -7.5202, -7.5203, -7.5202, -7.5202, -7.5203,
           -7.5202],
          [-7.5202, -7.5202, -7.5202, -7.5202, -7.5202, -7.5202, -7.5202,
           -7.5202, -7.5202, -7.5202, -7.5203, -7.5202, -7.5202, -7.5203,
           -7.5202],
          [-7.5202, -7.5202, -7.5202, -7.5202, -7.5202, -7.5202, -7.5202,
           -7.5202, -7.5202, -7.5202, -7.5203, -7.5202, -7.5202, -7.5203,
           -7.5202],
          [-7.5202, -7.5202, -7.5202, -7.5202, -7.5202, -7.5202, -7.5202,
           -7.5202, -7.5202, -7.5202, -7.5203, -7.5202, -7.5202, -7.5203,
           -7.5202],
          [-7.5202, -7.5202, -7.5202, -7.5202, -7.5202, -7.5202, -7.5202,
           -7.5202, -7.5202, -7.5202, -7.5203, -7.5202, -7.5202, -7.5203,
           -7.5202],
          [-7.5202, -7.5202, -7.5202, -7.5202, -7.5202, -7.5202, -7.5202,
           -7.5202, -7.5202, -7.5202, -7.5203, -7.5202, -7.5202, -7.5203,
           -7.5202],
          [-7.5202, -7.5202, -7.5202, -7.5202, -7.5202, -7.5202, -7.5202,
           -7.5202, -7.5202, -7.5202, -7.5203, -7.5202, -7.5202, -7.5203,
           -7.5202]]],


        [[[-6.1958, -6.1958, -6.1958, -6.1958, -6.1958, -6.1959, -6.1958,
           -6.1958, -6.1958, -6.1958, -6.1958, -6.1958, -6.1958, -6.1959,
           -6.1958],
          [-6.1958, -6.1958, -6.1958, -6.1958, -6.1958, -6.1959, -6.1958,
           -6.1958, -6.1958, -6.1958, -6.1958, -6.1958, -6.1958, -6.1959,
           -6.1958],
          [-6.1958, -6.1958, -6.1958, -6.1958, -6.1958, -6.1959, -6.1958,
           -6.1958, -6.1958, -6.1958, -6.1958, -6.1958, -6.1958, -6.1959,
           -6.1958],
          [-6.1958, -6.1958, -6.1958, -6.1958, -6.1958, -6.1959, -6.1958,
           -6.1958, -6.1958, -6.1958, -6.1958, -6.1958, -6.1958, -6.1959,
           -6.1958],
          [-6.1958, -6.1958, -6.1958, -6.1958, -6.1958, -6.1959, -6.1958,
           -6.1958, -6.1958, -6.1958, -6.1958, -6.1958, -6.1958, -6.1959,
           -6.1958],
          [-6.1958, -6.1958, -6.1958, -6.1958, -6.1958, -6.1959, -6.1958,
           -6.1958, -6.1958, -6.1958, -6.1958, -6.1958, -6.1958, -6.1959,
           -6.1958],
          [-6.1958, -6.1958, -6.1958, -6.1958, -6.1958, -6.1959, -6.1958,
           -6.1958, -6.1958, -6.1958, -6.1958, -6.1958, -6.1958, -6.1959,
           -6.1958],
          [-6.1958, -6.1958, -6.1958, -6.1958, -6.1958, -6.1959, -6.1958,
           -6.1958, -6.1958, -6.1958, -6.1958, -6.1958, -6.1958, -6.1959,
           -6.1958],
          [-6.1958, -6.1958, -6.1958, -6.1958, -6.1958, -6.1959, -6.1958,
           -6.1958, -6.1958, -6.1958, -6.1958, -6.1958, -6.1958, -6.1959,
           -6.1958],
          [-6.1958, -6.1958, -6.1958, -6.1958, -6.1958, -6.1959, -6.1958,
           -6.1958, -6.1958, -6.1958, -6.1958, -6.1958, -6.1958, -6.1959,
           -6.1958],
          [-6.1958, -6.1958, -6.1958, -6.1958, -6.1958, -6.1959, -6.1958,
           -6.1958, -6.1958, -6.1958, -6.1958, -6.1958, -6.1958, -6.1959,
           -6.1958],
          [-6.1958, -6.1958, -6.1958, -6.1958, -6.1958, -6.1959, -6.1958,
           -6.1958, -6.1958, -6.1958, -6.1958, -6.1958, -6.1958, -6.1959,
           -6.1958],
          [-6.1958, -6.1958, -6.1958, -6.1958, -6.1958, -6.1959, -6.1958,
           -6.1958, -6.1958, -6.1958, -6.1958, -6.1958, -6.1958, -6.1959,
           -6.1958],
          [-6.1958, -6.1958, -6.1958, -6.1958, -6.1958, -6.1959, -6.1958,
           -6.1958, -6.1958, -6.1958, -6.1958, -6.1958, -6.1958, -6.1959,
           -6.1958],
          [-6.1958, -6.1958, -6.1958, -6.1958, -6.1958, -6.1959, -6.1958,
           -6.1958, -6.1958, -6.1958, -6.1958, -6.1958, -6.1958, -6.1959,
           -6.1958],
          [-6.1958, -6.1958, -6.1958, -6.1958, -6.1958, -6.1959, -6.1958,
           -6.1958, -6.1958, -6.1958, -6.1958, -6.1958, -6.1958, -6.1959,
           -6.1958]],

         [[-6.2521, -6.2521, -6.2521, -6.2521, -6.2521, -6.2521, -6.2521,
           -6.2521, -6.2521, -6.2521, -6.2522, -6.2521, -6.2521, -6.2522,
           -6.2521],
          [-6.2521, -6.2521, -6.2521, -6.2521, -6.2521, -6.2521, -6.2521,
           -6.2521, -6.2521, -6.2521, -6.2522, -6.2521, -6.2521, -6.2522,
           -6.2521],
          [-6.2521, -6.2521, -6.2521, -6.2521, -6.2521, -6.2521, -6.2521,
           -6.2521, -6.2521, -6.2521, -6.2522, -6.2521, -6.2521, -6.2522,
           -6.2521],
          [-6.2521, -6.2521, -6.2521, -6.2521, -6.2521, -6.2521, -6.2521,
           -6.2521, -6.2521, -6.2521, -6.2522, -6.2521, -6.2521, -6.2522,
           -6.2521],
          [-6.2521, -6.2521, -6.2521, -6.2521, -6.2521, -6.2521, -6.2521,
           -6.2521, -6.2521, -6.2521, -6.2522, -6.2521, -6.2521, -6.2522,
           -6.2521],
          [-6.2521, -6.2521, -6.2521, -6.2521, -6.2521, -6.2521, -6.2521,
           -6.2521, -6.2521, -6.2521, -6.2522, -6.2521, -6.2521, -6.2522,
           -6.2521],
          [-6.2521, -6.2521, -6.2521, -6.2521, -6.2521, -6.2521, -6.2521,
           -6.2521, -6.2521, -6.2521, -6.2522, -6.2521, -6.2521, -6.2522,
           -6.2521],
          [-6.2521, -6.2521, -6.2521, -6.2521, -6.2521, -6.2521, -6.2521,
           -6.2521, -6.2521, -6.2521, -6.2522, -6.2521, -6.2521, -6.2522,
           -6.2521],
          [-6.2521, -6.2521, -6.2521, -6.2521, -6.2521, -6.2521, -6.2521,
           -6.2521, -6.2521, -6.2521, -6.2522, -6.2521, -6.2521, -6.2522,
           -6.2521],
          [-6.2521, -6.2521, -6.2521, -6.2521, -6.2521, -6.2521, -6.2521,
           -6.2521, -6.2521, -6.2521, -6.2522, -6.2521, -6.2521, -6.2522,
           -6.2521],
          [-6.2521, -6.2521, -6.2521, -6.2521, -6.2521, -6.2521, -6.2521,
           -6.2521, -6.2521, -6.2521, -6.2522, -6.2521, -6.2521, -6.2522,
           -6.2521],
          [-6.2521, -6.2521, -6.2521, -6.2521, -6.2521, -6.2521, -6.2521,
           -6.2521, -6.2521, -6.2521, -6.2522, -6.2521, -6.2521, -6.2522,
           -6.2521],
          [-6.2521, -6.2521, -6.2521, -6.2521, -6.2521, -6.2521, -6.2521,
           -6.2521, -6.2521, -6.2521, -6.2522, -6.2521, -6.2521, -6.2522,
           -6.2521],
          [-6.2521, -6.2521, -6.2521, -6.2521, -6.2521, -6.2521, -6.2521,
           -6.2521, -6.2521, -6.2521, -6.2522, -6.2521, -6.2521, -6.2522,
           -6.2521],
          [-6.2521, -6.2521, -6.2521, -6.2521, -6.2521, -6.2521, -6.2521,
           -6.2521, -6.2521, -6.2521, -6.2522, -6.2521, -6.2521, -6.2522,
           -6.2521],
          [-6.2521, -6.2521, -6.2521, -6.2521, -6.2521, -6.2521, -6.2521,
           -6.2521, -6.2521, -6.2521, -6.2522, -6.2521, -6.2521, -6.2522,
           -6.2521]]]], grad_fn=<SliceBackward0>)
train_step: Return scale: 1.6904739627070229
train_step: Scaled advantages shape: torch.Size([16, 15, 16, 15])
train_step: Scaled advantages sample: tensor([[[[-4.6206, -4.6206, -4.6206, -4.6206, -4.6206, -4.6206, -4.6206,
           -4.6206, -4.6206, -4.6206, -4.6206, -4.6206, -4.6206, -4.6206,
           -4.6206],
          [-4.6206, -4.6206, -4.6206, -4.6206, -4.6206, -4.6206, -4.6206,
           -4.6206, -4.6206, -4.6206, -4.6206, -4.6206, -4.6206, -4.6206,
           -4.6206],
          [-4.6206, -4.6206, -4.6206, -4.6206, -4.6206, -4.6206, -4.6206,
           -4.6206, -4.6206, -4.6206, -4.6206, -4.6206, -4.6206, -4.6206,
           -4.6206],
          [-4.6206, -4.6206, -4.6206, -4.6206, -4.6206, -4.6206, -4.6206,
           -4.6206, -4.6206, -4.6206, -4.6206, -4.6206, -4.6206, -4.6206,
           -4.6206],
          [-4.6206, -4.6206, -4.6206, -4.6206, -4.6206, -4.6206, -4.6206,
           -4.6206, -4.6206, -4.6206, -4.6206, -4.6206, -4.6206, -4.6206,
           -4.6206],
          [-4.6206, -4.6206, -4.6206, -4.6206, -4.6206, -4.6206, -4.6206,
           -4.6206, -4.6206, -4.6206, -4.6206, -4.6206, -4.6206, -4.6206,
           -4.6206],
          [-4.6206, -4.6206, -4.6206, -4.6206, -4.6206, -4.6206, -4.6206,
           -4.6206, -4.6206, -4.6206, -4.6206, -4.6206, -4.6206, -4.6206,
           -4.6206],
          [-4.6206, -4.6206, -4.6206, -4.6206, -4.6206, -4.6206, -4.6206,
           -4.6206, -4.6206, -4.6206, -4.6206, -4.6206, -4.6206, -4.6206,
           -4.6206],
          [-4.6206, -4.6206, -4.6206, -4.6206, -4.6206, -4.6206, -4.6206,
           -4.6206, -4.6206, -4.6206, -4.6206, -4.6206, -4.6206, -4.6206,
           -4.6206],
          [-4.6206, -4.6206, -4.6206, -4.6206, -4.6206, -4.6206, -4.6206,
           -4.6206, -4.6206, -4.6206, -4.6206, -4.6206, -4.6206, -4.6206,
           -4.6206],
          [-4.6206, -4.6206, -4.6206, -4.6206, -4.6206, -4.6206, -4.6206,
           -4.6206, -4.6206, -4.6206, -4.6206, -4.6206, -4.6206, -4.6206,
           -4.6206],
          [-4.6206, -4.6206, -4.6206, -4.6206, -4.6206, -4.6206, -4.6206,
           -4.6206, -4.6206, -4.6206, -4.6206, -4.6206, -4.6206, -4.6206,
           -4.6206],
          [-4.6206, -4.6206, -4.6206, -4.6206, -4.6206, -4.6206, -4.6206,
           -4.6206, -4.6206, -4.6206, -4.6206, -4.6206, -4.6206, -4.6206,
           -4.6206],
          [-4.6206, -4.6206, -4.6206, -4.6206, -4.6206, -4.6206, -4.6206,
           -4.6206, -4.6206, -4.6206, -4.6206, -4.6206, -4.6206, -4.6206,
           -4.6206],
          [-4.6206, -4.6206, -4.6206, -4.6206, -4.6206, -4.6206, -4.6206,
           -4.6206, -4.6206, -4.6206, -4.6206, -4.6206, -4.6206, -4.6206,
           -4.6206],
          [-4.6206, -4.6206, -4.6206, -4.6206, -4.6206, -4.6206, -4.6206,
           -4.6206, -4.6206, -4.6206, -4.6206, -4.6206, -4.6206, -4.6206,
           -4.6206]],

         [[-4.4486, -4.4486, -4.4486, -4.4486, -4.4486, -4.4486, -4.4486,
           -4.4486, -4.4486, -4.4486, -4.4486, -4.4486, -4.4486, -4.4486,
           -4.4486],
          [-4.4486, -4.4486, -4.4486, -4.4486, -4.4486, -4.4486, -4.4486,
           -4.4486, -4.4486, -4.4486, -4.4486, -4.4486, -4.4486, -4.4486,
           -4.4486],
          [-4.4486, -4.4486, -4.4486, -4.4486, -4.4486, -4.4486, -4.4486,
           -4.4486, -4.4486, -4.4486, -4.4486, -4.4486, -4.4486, -4.4486,
           -4.4486],
          [-4.4486, -4.4486, -4.4486, -4.4486, -4.4486, -4.4486, -4.4486,
           -4.4486, -4.4486, -4.4486, -4.4486, -4.4486, -4.4486, -4.4486,
           -4.4486],
          [-4.4486, -4.4486, -4.4486, -4.4486, -4.4486, -4.4486, -4.4486,
           -4.4486, -4.4486, -4.4486, -4.4486, -4.4486, -4.4486, -4.4486,
           -4.4486],
          [-4.4486, -4.4486, -4.4486, -4.4486, -4.4486, -4.4486, -4.4486,
           -4.4486, -4.4486, -4.4486, -4.4486, -4.4486, -4.4486, -4.4486,
           -4.4486],
          [-4.4486, -4.4486, -4.4486, -4.4486, -4.4486, -4.4486, -4.4486,
           -4.4486, -4.4486, -4.4486, -4.4486, -4.4486, -4.4486, -4.4486,
           -4.4486],
          [-4.4486, -4.4486, -4.4486, -4.4486, -4.4486, -4.4486, -4.4486,
           -4.4486, -4.4486, -4.4486, -4.4486, -4.4486, -4.4486, -4.4486,
           -4.4486],
          [-4.4486, -4.4486, -4.4486, -4.4486, -4.4486, -4.4486, -4.4486,
           -4.4486, -4.4486, -4.4486, -4.4486, -4.4486, -4.4486, -4.4486,
           -4.4486],
          [-4.4486, -4.4486, -4.4486, -4.4486, -4.4486, -4.4486, -4.4486,
           -4.4486, -4.4486, -4.4486, -4.4486, -4.4486, -4.4486, -4.4486,
           -4.4486],
          [-4.4486, -4.4486, -4.4486, -4.4486, -4.4486, -4.4486, -4.4486,
           -4.4486, -4.4486, -4.4486, -4.4486, -4.4486, -4.4486, -4.4486,
           -4.4486],
          [-4.4486, -4.4486, -4.4486, -4.4486, -4.4486, -4.4486, -4.4486,
           -4.4486, -4.4486, -4.4486, -4.4486, -4.4486, -4.4486, -4.4486,
           -4.4486],
          [-4.4486, -4.4486, -4.4486, -4.4486, -4.4486, -4.4486, -4.4486,
           -4.4486, -4.4486, -4.4486, -4.4486, -4.4486, -4.4486, -4.4486,
           -4.4486],
          [-4.4486, -4.4486, -4.4486, -4.4486, -4.4486, -4.4486, -4.4486,
           -4.4486, -4.4486, -4.4486, -4.4486, -4.4486, -4.4486, -4.4486,
           -4.4486],
          [-4.4486, -4.4486, -4.4486, -4.4486, -4.4486, -4.4486, -4.4486,
           -4.4486, -4.4486, -4.4486, -4.4486, -4.4486, -4.4486, -4.4486,
           -4.4486],
          [-4.4486, -4.4486, -4.4486, -4.4486, -4.4486, -4.4486, -4.4486,
           -4.4486, -4.4486, -4.4486, -4.4486, -4.4486, -4.4486, -4.4486,
           -4.4486]]],


        [[[-3.6651, -3.6651, -3.6652, -3.6651, -3.6651, -3.6652, -3.6651,
           -3.6652, -3.6651, -3.6651, -3.6651, -3.6651, -3.6651, -3.6652,
           -3.6651],
          [-3.6651, -3.6651, -3.6652, -3.6651, -3.6651, -3.6652, -3.6651,
           -3.6652, -3.6651, -3.6651, -3.6651, -3.6651, -3.6651, -3.6652,
           -3.6651],
          [-3.6651, -3.6651, -3.6652, -3.6651, -3.6651, -3.6652, -3.6651,
           -3.6652, -3.6651, -3.6651, -3.6651, -3.6651, -3.6651, -3.6652,
           -3.6651],
          [-3.6651, -3.6651, -3.6652, -3.6651, -3.6651, -3.6652, -3.6651,
           -3.6652, -3.6651, -3.6651, -3.6651, -3.6651, -3.6651, -3.6652,
           -3.6651],
          [-3.6651, -3.6651, -3.6652, -3.6651, -3.6651, -3.6652, -3.6651,
           -3.6652, -3.6651, -3.6651, -3.6651, -3.6651, -3.6651, -3.6652,
           -3.6651],
          [-3.6651, -3.6651, -3.6652, -3.6651, -3.6651, -3.6652, -3.6651,
           -3.6652, -3.6651, -3.6651, -3.6651, -3.6651, -3.6651, -3.6652,
           -3.6651],
          [-3.6651, -3.6651, -3.6652, -3.6651, -3.6651, -3.6652, -3.6651,
           -3.6652, -3.6651, -3.6651, -3.6651, -3.6651, -3.6651, -3.6652,
           -3.6651],
          [-3.6651, -3.6651, -3.6652, -3.6651, -3.6651, -3.6652, -3.6651,
           -3.6652, -3.6651, -3.6651, -3.6651, -3.6651, -3.6651, -3.6652,
           -3.6651],
          [-3.6651, -3.6651, -3.6652, -3.6651, -3.6651, -3.6652, -3.6651,
           -3.6652, -3.6651, -3.6651, -3.6651, -3.6651, -3.6651, -3.6652,
           -3.6651],
          [-3.6651, -3.6651, -3.6652, -3.6651, -3.6651, -3.6652, -3.6651,
           -3.6652, -3.6651, -3.6651, -3.6651, -3.6651, -3.6651, -3.6652,
           -3.6651],
          [-3.6651, -3.6651, -3.6652, -3.6651, -3.6651, -3.6652, -3.6651,
           -3.6652, -3.6651, -3.6651, -3.6651, -3.6651, -3.6651, -3.6652,
           -3.6651],
          [-3.6651, -3.6651, -3.6652, -3.6651, -3.6651, -3.6652, -3.6651,
           -3.6652, -3.6651, -3.6651, -3.6651, -3.6651, -3.6651, -3.6652,
           -3.6651],
          [-3.6651, -3.6651, -3.6652, -3.6651, -3.6651, -3.6652, -3.6651,
           -3.6652, -3.6651, -3.6651, -3.6651, -3.6651, -3.6651, -3.6652,
           -3.6651],
          [-3.6651, -3.6651, -3.6652, -3.6651, -3.6651, -3.6652, -3.6651,
           -3.6652, -3.6651, -3.6651, -3.6651, -3.6651, -3.6651, -3.6652,
           -3.6651],
          [-3.6651, -3.6651, -3.6652, -3.6651, -3.6651, -3.6652, -3.6651,
           -3.6652, -3.6651, -3.6651, -3.6651, -3.6651, -3.6651, -3.6652,
           -3.6651],
          [-3.6651, -3.6651, -3.6652, -3.6651, -3.6651, -3.6652, -3.6651,
           -3.6652, -3.6651, -3.6651, -3.6651, -3.6651, -3.6651, -3.6652,
           -3.6651]],

         [[-3.6985, -3.6985, -3.6985, -3.6984, -3.6985, -3.6984, -3.6984,
           -3.6984, -3.6985, -3.6984, -3.6985, -3.6985, -3.6984, -3.6985,
           -3.6985],
          [-3.6985, -3.6985, -3.6985, -3.6984, -3.6985, -3.6984, -3.6984,
           -3.6984, -3.6985, -3.6984, -3.6985, -3.6985, -3.6984, -3.6985,
           -3.6985],
          [-3.6985, -3.6985, -3.6985, -3.6984, -3.6985, -3.6984, -3.6984,
           -3.6984, -3.6985, -3.6984, -3.6985, -3.6985, -3.6984, -3.6985,
           -3.6985],
          [-3.6985, -3.6985, -3.6985, -3.6984, -3.6985, -3.6984, -3.6984,
           -3.6984, -3.6985, -3.6984, -3.6985, -3.6985, -3.6984, -3.6985,
           -3.6985],
          [-3.6985, -3.6985, -3.6985, -3.6984, -3.6985, -3.6984, -3.6984,
           -3.6984, -3.6985, -3.6984, -3.6985, -3.6985, -3.6984, -3.6985,
           -3.6985],
          [-3.6985, -3.6985, -3.6985, -3.6984, -3.6985, -3.6984, -3.6984,
           -3.6984, -3.6985, -3.6984, -3.6985, -3.6985, -3.6984, -3.6985,
           -3.6985],
          [-3.6985, -3.6985, -3.6985, -3.6984, -3.6985, -3.6984, -3.6984,
           -3.6984, -3.6985, -3.6984, -3.6985, -3.6985, -3.6984, -3.6985,
           -3.6985],
          [-3.6985, -3.6985, -3.6985, -3.6984, -3.6985, -3.6984, -3.6984,
           -3.6984, -3.6985, -3.6984, -3.6985, -3.6985, -3.6984, -3.6985,
           -3.6985],
          [-3.6985, -3.6985, -3.6985, -3.6984, -3.6985, -3.6984, -3.6984,
           -3.6984, -3.6985, -3.6984, -3.6985, -3.6985, -3.6984, -3.6985,
           -3.6985],
          [-3.6985, -3.6985, -3.6985, -3.6984, -3.6985, -3.6984, -3.6984,
           -3.6984, -3.6985, -3.6984, -3.6985, -3.6985, -3.6984, -3.6985,
           -3.6985],
          [-3.6985, -3.6985, -3.6985, -3.6984, -3.6985, -3.6984, -3.6984,
           -3.6984, -3.6985, -3.6984, -3.6985, -3.6985, -3.6984, -3.6985,
           -3.6985],
          [-3.6985, -3.6985, -3.6985, -3.6984, -3.6985, -3.6984, -3.6984,
           -3.6984, -3.6985, -3.6984, -3.6985, -3.6985, -3.6984, -3.6985,
           -3.6985],
          [-3.6985, -3.6985, -3.6985, -3.6984, -3.6985, -3.6984, -3.6984,
           -3.6984, -3.6985, -3.6984, -3.6985, -3.6985, -3.6984, -3.6985,
           -3.6985],
          [-3.6985, -3.6985, -3.6985, -3.6984, -3.6985, -3.6984, -3.6984,
           -3.6984, -3.6985, -3.6984, -3.6985, -3.6985, -3.6984, -3.6985,
           -3.6985],
          [-3.6985, -3.6985, -3.6985, -3.6984, -3.6985, -3.6984, -3.6984,
           -3.6984, -3.6985, -3.6984, -3.6985, -3.6985, -3.6984, -3.6985,
           -3.6985],
          [-3.6985, -3.6985, -3.6985, -3.6984, -3.6985, -3.6984, -3.6984,
           -3.6984, -3.6985, -3.6984, -3.6985, -3.6985, -3.6984, -3.6985,
           -3.6985]]]], grad_fn=<SliceBackward0>)
train_step: Entropy shape: torch.Size([16, 15])
train_step: Entropy sample: tensor([[0.6744, 0.5216],
        [0.6902, 0.3800]], grad_fn=<SliceBackward0>)
train_step: Entropy coefficient: 0.01
train_step: Actor loss: -1.251279354095459
train_step: returns shape after mean: torch.Size([16, 15])
train_step: target_indices shape: torch.Size([16, 15])
train_step: value_logits shape: torch.Size([16, 15, 255])
train_step: target_twohot shape: torch.Size([16, 15, 255])
--- Starting train_step at 2025-04-01 01:59:54 ---
Full starting_state: {'deter': tensor([[[ 5.0253e-02, -1.3827e-02, -9.3958e-03,  ..., -7.6730e-02,
          -1.9547e-02, -1.2962e-02],
         [ 1.3699e-01, -9.5214e-02,  2.1997e-02,  ..., -1.0587e-01,
           1.4692e-01, -1.0167e-01],
         [-7.4584e-02,  1.2432e-01,  6.8081e-02,  ..., -1.3515e-01,
          -4.5869e-03,  2.7278e-03],
         ...,
         [ 1.0188e-01, -1.3126e-01,  1.0996e-01,  ..., -1.1130e-01,
          -5.1494e-02, -6.0481e-02],
         [-9.4180e-02, -1.4829e-01,  1.5791e-03,  ..., -2.5597e-02,
           6.7591e-03, -1.4440e-01],
         [-2.2980e-02, -7.0986e-02, -8.7092e-02,  ..., -5.0498e-03,
          -2.5709e-02, -7.7839e-02]],

        [[-2.4461e-02,  6.1110e-03, -6.4075e-02,  ...,  3.9985e-02,
          -3.3828e-03, -1.6869e-03],
         [-2.5790e-03, -1.9494e-01,  6.7540e-02,  ...,  2.2814e-02,
           1.0281e-01, -1.9808e-02],
         [ 5.0957e-02, -1.7137e-01, -1.0797e-01,  ...,  1.8988e-02,
          -3.3441e-02, -8.6181e-02],
         ...,
         [-9.5603e-02, -4.7401e-02, -1.3713e-01,  ...,  1.1480e-01,
           2.3221e-01, -6.1970e-02],
         [-1.8161e-02, -2.7861e-02, -9.5428e-02,  ...,  1.2835e-01,
           1.1224e-02, -1.1559e-01],
         [-6.5077e-02, -7.4642e-02, -1.5068e-01,  ...,  4.4129e-02,
          -8.1977e-04, -1.4383e-01]],

        [[-4.8869e-02, -1.0891e-01, -1.1715e-01,  ..., -8.9769e-03,
           6.2082e-02,  5.8099e-05],
         [-7.7702e-02, -2.0527e-01, -1.0541e-02,  ..., -6.7597e-02,
          -4.5387e-02,  2.1830e-02],
         [-6.4095e-02, -5.5601e-02, -2.3697e-02,  ...,  6.0027e-02,
           6.1444e-02, -6.0320e-02],
         ...,
         [ 1.3706e-01,  5.2285e-02,  5.8261e-02,  ...,  4.6435e-02,
          -2.3987e-02,  2.6686e-02],
         [-4.2114e-02, -3.7309e-02,  6.9034e-02,  ...,  3.3867e-02,
           7.3375e-02, -1.3467e-01],
         [-5.6687e-02, -8.7548e-02,  7.9375e-03,  ..., -6.7793e-02,
          -9.3136e-02, -4.3320e-02]],

        ...,

        [[ 9.6686e-02, -1.0740e-01,  1.8508e-01,  ..., -6.6529e-02,
          -1.6092e-02, -1.2292e-01],
         [ 4.8601e-02,  9.5187e-02,  9.9597e-02,  ...,  1.1301e-01,
           1.7618e-03,  1.0762e-01],
         [-1.4551e-01, -1.4277e-01, -1.7054e-01,  ...,  3.9619e-02,
           1.8795e-01,  2.3972e-02],
         ...,
         [-8.1889e-03, -1.0373e-01, -1.7439e-01,  ...,  1.5164e-02,
           3.7545e-02, -8.5068e-02],
         [-1.3046e-01, -9.8829e-03, -7.8628e-02,  ...,  1.3244e-01,
          -1.6897e-01, -1.3311e-01],
         [ 1.9420e-02, -1.8001e-02, -4.9156e-02,  ...,  8.9195e-02,
          -8.7174e-03, -7.5900e-02]],

        [[ 2.7068e-02, -1.7766e-02,  8.6857e-02,  ...,  3.5234e-02,
          -2.0263e-02, -1.9311e-02],
         [-1.6411e-01, -8.5190e-02, -8.8146e-02,  ..., -2.9401e-02,
           1.5965e-01, -3.3868e-02],
         [-7.0189e-02,  6.3371e-02, -3.6271e-02,  ...,  3.8862e-03,
           1.5264e-01, -2.1122e-02],
         ...,
         [ 4.0494e-02, -1.1035e-01, -2.0465e-01,  ..., -1.5449e-01,
          -1.9551e-02, -1.1593e-01],
         [ 4.8527e-03, -1.3317e-01, -4.6617e-03,  ..., -2.0760e-02,
           6.8387e-02, -2.3264e-02],
         [-9.2549e-02,  1.1167e-02, -9.2289e-02,  ..., -9.0981e-02,
          -8.7484e-02, -2.2030e-01]],

        [[-3.2336e-02, -8.5840e-02, -1.8946e-01,  ...,  2.7663e-02,
           6.4705e-02, -7.7338e-02],
         [-2.3716e-02, -6.8751e-02, -2.7654e-02,  ...,  3.3504e-02,
           3.2918e-03,  5.1888e-03],
         [ 2.0973e-02,  5.7281e-02, -9.9253e-02,  ..., -5.5629e-02,
          -8.3233e-02, -6.0202e-02],
         ...,
         [-2.6225e-03,  3.9226e-02, -1.2518e-01,  ..., -3.8263e-03,
           6.9186e-03, -1.0190e-01],
         [-1.8291e-01, -4.2672e-02,  1.1438e-03,  ..., -1.4591e-01,
          -6.0773e-02,  2.4776e-02],
         [ 3.3691e-02,  6.0345e-02, -1.9174e-01,  ...,  1.7146e-02,
           9.5735e-02,  7.3230e-02]]], grad_fn=<StackBackward0>), 'stoch': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 1.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 1., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 1., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]])}
train_step: Starting state deter shape: torch.Size([16, 50, 128])
train_step: Starting state stoch shape: torch.Size([16, 50, 1024])
After ensuring logits/stoch: {'deter': tensor([[[ 5.0253e-02, -1.3827e-02, -9.3958e-03,  ..., -7.6730e-02,
          -1.9547e-02, -1.2962e-02],
         [ 1.3699e-01, -9.5214e-02,  2.1997e-02,  ..., -1.0587e-01,
           1.4692e-01, -1.0167e-01],
         [-7.4584e-02,  1.2432e-01,  6.8081e-02,  ..., -1.3515e-01,
          -4.5869e-03,  2.7278e-03],
         ...,
         [ 1.0188e-01, -1.3126e-01,  1.0996e-01,  ..., -1.1130e-01,
          -5.1494e-02, -6.0481e-02],
         [-9.4180e-02, -1.4829e-01,  1.5791e-03,  ..., -2.5597e-02,
           6.7591e-03, -1.4440e-01],
         [-2.2980e-02, -7.0986e-02, -8.7092e-02,  ..., -5.0498e-03,
          -2.5709e-02, -7.7839e-02]],

        [[-2.4461e-02,  6.1110e-03, -6.4075e-02,  ...,  3.9985e-02,
          -3.3828e-03, -1.6869e-03],
         [-2.5790e-03, -1.9494e-01,  6.7540e-02,  ...,  2.2814e-02,
           1.0281e-01, -1.9808e-02],
         [ 5.0957e-02, -1.7137e-01, -1.0797e-01,  ...,  1.8988e-02,
          -3.3441e-02, -8.6181e-02],
         ...,
         [-9.5603e-02, -4.7401e-02, -1.3713e-01,  ...,  1.1480e-01,
           2.3221e-01, -6.1970e-02],
         [-1.8161e-02, -2.7861e-02, -9.5428e-02,  ...,  1.2835e-01,
           1.1224e-02, -1.1559e-01],
         [-6.5077e-02, -7.4642e-02, -1.5068e-01,  ...,  4.4129e-02,
          -8.1977e-04, -1.4383e-01]],

        [[-4.8869e-02, -1.0891e-01, -1.1715e-01,  ..., -8.9769e-03,
           6.2082e-02,  5.8099e-05],
         [-7.7702e-02, -2.0527e-01, -1.0541e-02,  ..., -6.7597e-02,
          -4.5387e-02,  2.1830e-02],
         [-6.4095e-02, -5.5601e-02, -2.3697e-02,  ...,  6.0027e-02,
           6.1444e-02, -6.0320e-02],
         ...,
         [ 1.3706e-01,  5.2285e-02,  5.8261e-02,  ...,  4.6435e-02,
          -2.3987e-02,  2.6686e-02],
         [-4.2114e-02, -3.7309e-02,  6.9034e-02,  ...,  3.3867e-02,
           7.3375e-02, -1.3467e-01],
         [-5.6687e-02, -8.7548e-02,  7.9375e-03,  ..., -6.7793e-02,
          -9.3136e-02, -4.3320e-02]],

        ...,

        [[ 9.6686e-02, -1.0740e-01,  1.8508e-01,  ..., -6.6529e-02,
          -1.6092e-02, -1.2292e-01],
         [ 4.8601e-02,  9.5187e-02,  9.9597e-02,  ...,  1.1301e-01,
           1.7618e-03,  1.0762e-01],
         [-1.4551e-01, -1.4277e-01, -1.7054e-01,  ...,  3.9619e-02,
           1.8795e-01,  2.3972e-02],
         ...,
         [-8.1889e-03, -1.0373e-01, -1.7439e-01,  ...,  1.5164e-02,
           3.7545e-02, -8.5068e-02],
         [-1.3046e-01, -9.8829e-03, -7.8628e-02,  ...,  1.3244e-01,
          -1.6897e-01, -1.3311e-01],
         [ 1.9420e-02, -1.8001e-02, -4.9156e-02,  ...,  8.9195e-02,
          -8.7174e-03, -7.5900e-02]],

        [[ 2.7068e-02, -1.7766e-02,  8.6857e-02,  ...,  3.5234e-02,
          -2.0263e-02, -1.9311e-02],
         [-1.6411e-01, -8.5190e-02, -8.8146e-02,  ..., -2.9401e-02,
           1.5965e-01, -3.3868e-02],
         [-7.0189e-02,  6.3371e-02, -3.6271e-02,  ...,  3.8862e-03,
           1.5264e-01, -2.1122e-02],
         ...,
         [ 4.0494e-02, -1.1035e-01, -2.0465e-01,  ..., -1.5449e-01,
          -1.9551e-02, -1.1593e-01],
         [ 4.8527e-03, -1.3317e-01, -4.6617e-03,  ..., -2.0760e-02,
           6.8387e-02, -2.3264e-02],
         [-9.2549e-02,  1.1167e-02, -9.2289e-02,  ..., -9.0981e-02,
          -8.7484e-02, -2.2030e-01]],

        [[-3.2336e-02, -8.5840e-02, -1.8946e-01,  ...,  2.7663e-02,
           6.4705e-02, -7.7338e-02],
         [-2.3716e-02, -6.8751e-02, -2.7654e-02,  ...,  3.3504e-02,
           3.2918e-03,  5.1888e-03],
         [ 2.0973e-02,  5.7281e-02, -9.9253e-02,  ..., -5.5629e-02,
          -8.3233e-02, -6.0202e-02],
         ...,
         [-2.6225e-03,  3.9226e-02, -1.2518e-01,  ..., -3.8263e-03,
           6.9186e-03, -1.0190e-01],
         [-1.8291e-01, -4.2672e-02,  1.1438e-03,  ..., -1.4591e-01,
          -6.0773e-02,  2.4776e-02],
         [ 3.3691e-02,  6.0345e-02, -1.9174e-01,  ...,  1.7146e-02,
           9.5735e-02,  7.3230e-02]]], grad_fn=<StackBackward0>), 'stoch': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 1.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 1., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 1., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]]), 'logits': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]])}
train_step: Normalized hidden_state shape: torch.Size([1, 16, 128])
train_step: Normalized stoch shape: torch.Size([16, 1024])
train_step: Normalized deter shape: torch.Size([16, 128])
train_step: Post-imagine_trajectory: Imagined features shape: torch.Size([16, 15, 1152])
train_step: Post-imagine_trajectory: Imagined actions shape: torch.Size([16, 15, 2])
train_step: Post-imagine_trajectory: Imagined action indices shape: torch.Size([16, 15])
train_step: Post-imagine_trajectory: Imagined state deter shape: torch.Size([16, 15, 128])
train_step: Post-imagine_trajectory: Imagined state stoch shape: torch.Size([16, 15, 1024])
Reward shape: torch.Size([16, 15, 1]), Value shape: torch.Size([16, 15, 1]), Slow Value shape: torch.Size([16, 15, 1]), Discount shape: torch.Size([16, 15, 1, 1])
Return targets length: 15, First target shape: torch.Size([16, 16, 1])
train_step: Actor distribution shape: torch.Size([16, 15, 2])
train_step: Action log probabilities shape: torch.Size([16, 15])
train_step: Action log probabilities sample: tensor([[-0.4455, -0.0709],
        [-0.1619, -0.9796]], grad_fn=<SliceBackward0>)
train_step: Advantages shape: torch.Size([16, 15, 16, 15])
train_step: Advantages sample: tensor([[[[-4.3986, -4.3985, -4.3986, -4.3986, -4.3986, -4.3985, -4.3985,
           -4.3985, -4.3985, -4.3985, -4.3985, -4.3985, -4.3986, -4.3985,
           -4.3985],
          [-4.3986, -4.3985, -4.3986, -4.3986, -4.3986, -4.3985, -4.3985,
           -4.3985, -4.3985, -4.3985, -4.3985, -4.3985, -4.3986, -4.3985,
           -4.3985],
          [-4.3986, -4.3985, -4.3986, -4.3986, -4.3986, -4.3985, -4.3985,
           -4.3985, -4.3985, -4.3985, -4.3985, -4.3985, -4.3986, -4.3985,
           -4.3985],
          [-4.3986, -4.3985, -4.3986, -4.3986, -4.3986, -4.3985, -4.3985,
           -4.3985, -4.3985, -4.3985, -4.3985, -4.3985, -4.3986, -4.3985,
           -4.3985],
          [-4.3986, -4.3985, -4.3986, -4.3986, -4.3986, -4.3985, -4.3985,
           -4.3985, -4.3985, -4.3985, -4.3985, -4.3985, -4.3986, -4.3985,
           -4.3985],
          [-4.3986, -4.3985, -4.3986, -4.3986, -4.3986, -4.3985, -4.3985,
           -4.3985, -4.3985, -4.3985, -4.3985, -4.3985, -4.3986, -4.3985,
           -4.3985],
          [-4.3986, -4.3985, -4.3986, -4.3986, -4.3986, -4.3985, -4.3985,
           -4.3985, -4.3985, -4.3985, -4.3985, -4.3985, -4.3986, -4.3985,
           -4.3985],
          [-4.3986, -4.3985, -4.3986, -4.3986, -4.3986, -4.3985, -4.3985,
           -4.3985, -4.3985, -4.3985, -4.3985, -4.3985, -4.3986, -4.3985,
           -4.3985],
          [-4.3986, -4.3985, -4.3986, -4.3986, -4.3986, -4.3985, -4.3985,
           -4.3985, -4.3985, -4.3985, -4.3985, -4.3985, -4.3986, -4.3985,
           -4.3985],
          [-4.3986, -4.3985, -4.3986, -4.3986, -4.3986, -4.3985, -4.3985,
           -4.3985, -4.3985, -4.3985, -4.3985, -4.3985, -4.3986, -4.3985,
           -4.3985],
          [-4.3986, -4.3985, -4.3986, -4.3986, -4.3986, -4.3985, -4.3985,
           -4.3985, -4.3985, -4.3985, -4.3985, -4.3985, -4.3986, -4.3985,
           -4.3985],
          [-4.3986, -4.3985, -4.3986, -4.3986, -4.3986, -4.3985, -4.3985,
           -4.3985, -4.3985, -4.3985, -4.3985, -4.3985, -4.3986, -4.3985,
           -4.3985],
          [-4.3986, -4.3985, -4.3986, -4.3986, -4.3986, -4.3985, -4.3985,
           -4.3985, -4.3985, -4.3985, -4.3985, -4.3985, -4.3986, -4.3985,
           -4.3985],
          [-4.3986, -4.3985, -4.3986, -4.3986, -4.3986, -4.3985, -4.3985,
           -4.3985, -4.3985, -4.3985, -4.3985, -4.3985, -4.3986, -4.3985,
           -4.3985],
          [-4.3986, -4.3985, -4.3986, -4.3986, -4.3986, -4.3985, -4.3985,
           -4.3985, -4.3985, -4.3985, -4.3985, -4.3985, -4.3986, -4.3985,
           -4.3985],
          [-4.3986, -4.3985, -4.3986, -4.3986, -4.3986, -4.3985, -4.3985,
           -4.3985, -4.3985, -4.3985, -4.3985, -4.3985, -4.3986, -4.3985,
           -4.3985]],

         [[-4.2572, -4.2572, -4.2573, -4.2573, -4.2573, -4.2572, -4.2572,
           -4.2573, -4.2572, -4.2573, -4.2573, -4.2573, -4.2572, -4.2572,
           -4.2572],
          [-4.2572, -4.2572, -4.2573, -4.2573, -4.2573, -4.2572, -4.2572,
           -4.2573, -4.2572, -4.2573, -4.2573, -4.2573, -4.2572, -4.2572,
           -4.2572],
          [-4.2572, -4.2572, -4.2573, -4.2573, -4.2573, -4.2572, -4.2572,
           -4.2573, -4.2572, -4.2573, -4.2573, -4.2573, -4.2572, -4.2572,
           -4.2572],
          [-4.2572, -4.2572, -4.2573, -4.2573, -4.2573, -4.2572, -4.2572,
           -4.2573, -4.2572, -4.2573, -4.2573, -4.2573, -4.2572, -4.2572,
           -4.2572],
          [-4.2572, -4.2572, -4.2573, -4.2573, -4.2573, -4.2572, -4.2572,
           -4.2573, -4.2572, -4.2573, -4.2573, -4.2573, -4.2572, -4.2572,
           -4.2572],
          [-4.2572, -4.2572, -4.2573, -4.2573, -4.2573, -4.2572, -4.2572,
           -4.2573, -4.2572, -4.2573, -4.2573, -4.2573, -4.2572, -4.2572,
           -4.2572],
          [-4.2572, -4.2572, -4.2573, -4.2573, -4.2573, -4.2572, -4.2572,
           -4.2573, -4.2572, -4.2573, -4.2573, -4.2573, -4.2572, -4.2572,
           -4.2572],
          [-4.2572, -4.2572, -4.2573, -4.2573, -4.2573, -4.2572, -4.2572,
           -4.2573, -4.2572, -4.2573, -4.2573, -4.2573, -4.2572, -4.2572,
           -4.2572],
          [-4.2572, -4.2572, -4.2573, -4.2573, -4.2573, -4.2572, -4.2572,
           -4.2573, -4.2572, -4.2573, -4.2573, -4.2573, -4.2572, -4.2572,
           -4.2572],
          [-4.2572, -4.2572, -4.2573, -4.2573, -4.2573, -4.2572, -4.2572,
           -4.2573, -4.2572, -4.2573, -4.2573, -4.2573, -4.2572, -4.2572,
           -4.2572],
          [-4.2572, -4.2572, -4.2573, -4.2573, -4.2573, -4.2572, -4.2572,
           -4.2573, -4.2572, -4.2573, -4.2573, -4.2573, -4.2572, -4.2572,
           -4.2572],
          [-4.2572, -4.2572, -4.2573, -4.2573, -4.2573, -4.2572, -4.2572,
           -4.2573, -4.2572, -4.2573, -4.2573, -4.2573, -4.2572, -4.2572,
           -4.2572],
          [-4.2572, -4.2572, -4.2573, -4.2573, -4.2573, -4.2572, -4.2572,
           -4.2573, -4.2572, -4.2573, -4.2573, -4.2573, -4.2572, -4.2572,
           -4.2572],
          [-4.2572, -4.2572, -4.2573, -4.2573, -4.2573, -4.2572, -4.2572,
           -4.2573, -4.2572, -4.2573, -4.2573, -4.2573, -4.2572, -4.2572,
           -4.2572],
          [-4.2572, -4.2572, -4.2573, -4.2573, -4.2573, -4.2572, -4.2572,
           -4.2573, -4.2572, -4.2573, -4.2573, -4.2573, -4.2572, -4.2572,
           -4.2572],
          [-4.2572, -4.2572, -4.2573, -4.2573, -4.2573, -4.2572, -4.2572,
           -4.2573, -4.2572, -4.2573, -4.2573, -4.2573, -4.2572, -4.2572,
           -4.2572]]],


        [[[-5.0758, -5.0757, -5.0758, -5.0758, -5.0758, -5.0757, -5.0757,
           -5.0757, -5.0758, -5.0757, -5.0758, -5.0757, -5.0758, -5.0757,
           -5.0757],
          [-5.0758, -5.0757, -5.0758, -5.0758, -5.0758, -5.0757, -5.0757,
           -5.0757, -5.0758, -5.0757, -5.0758, -5.0757, -5.0758, -5.0757,
           -5.0757],
          [-5.0758, -5.0757, -5.0758, -5.0758, -5.0758, -5.0757, -5.0757,
           -5.0757, -5.0758, -5.0757, -5.0758, -5.0757, -5.0758, -5.0757,
           -5.0757],
          [-5.0758, -5.0757, -5.0758, -5.0758, -5.0758, -5.0757, -5.0757,
           -5.0757, -5.0758, -5.0757, -5.0758, -5.0757, -5.0758, -5.0757,
           -5.0757],
          [-5.0758, -5.0757, -5.0758, -5.0758, -5.0758, -5.0757, -5.0757,
           -5.0757, -5.0758, -5.0757, -5.0758, -5.0757, -5.0758, -5.0757,
           -5.0757],
          [-5.0758, -5.0757, -5.0758, -5.0758, -5.0758, -5.0757, -5.0757,
           -5.0757, -5.0758, -5.0757, -5.0758, -5.0757, -5.0758, -5.0757,
           -5.0757],
          [-5.0758, -5.0757, -5.0758, -5.0758, -5.0758, -5.0757, -5.0757,
           -5.0757, -5.0758, -5.0757, -5.0758, -5.0757, -5.0758, -5.0757,
           -5.0757],
          [-5.0758, -5.0757, -5.0758, -5.0758, -5.0758, -5.0757, -5.0757,
           -5.0757, -5.0758, -5.0757, -5.0758, -5.0757, -5.0758, -5.0757,
           -5.0757],
          [-5.0758, -5.0757, -5.0758, -5.0758, -5.0758, -5.0757, -5.0757,
           -5.0757, -5.0758, -5.0757, -5.0758, -5.0757, -5.0758, -5.0757,
           -5.0757],
          [-5.0758, -5.0757, -5.0758, -5.0758, -5.0758, -5.0757, -5.0757,
           -5.0757, -5.0758, -5.0757, -5.0758, -5.0757, -5.0758, -5.0757,
           -5.0757],
          [-5.0758, -5.0757, -5.0758, -5.0758, -5.0758, -5.0757, -5.0757,
           -5.0757, -5.0758, -5.0757, -5.0758, -5.0757, -5.0758, -5.0757,
           -5.0757],
          [-5.0758, -5.0757, -5.0758, -5.0758, -5.0758, -5.0757, -5.0757,
           -5.0757, -5.0758, -5.0757, -5.0758, -5.0757, -5.0758, -5.0757,
           -5.0757],
          [-5.0758, -5.0757, -5.0758, -5.0758, -5.0758, -5.0757, -5.0757,
           -5.0757, -5.0758, -5.0757, -5.0758, -5.0757, -5.0758, -5.0757,
           -5.0757],
          [-5.0758, -5.0757, -5.0758, -5.0758, -5.0758, -5.0757, -5.0757,
           -5.0757, -5.0758, -5.0757, -5.0758, -5.0757, -5.0758, -5.0757,
           -5.0757],
          [-5.0758, -5.0757, -5.0758, -5.0758, -5.0758, -5.0757, -5.0757,
           -5.0757, -5.0758, -5.0757, -5.0758, -5.0757, -5.0758, -5.0757,
           -5.0757],
          [-5.0758, -5.0757, -5.0758, -5.0758, -5.0758, -5.0757, -5.0757,
           -5.0757, -5.0758, -5.0757, -5.0758, -5.0757, -5.0758, -5.0757,
           -5.0757]],

         [[-5.0339, -5.0339, -5.0339, -5.0339, -5.0340, -5.0339, -5.0339,
           -5.0339, -5.0339, -5.0340, -5.0340, -5.0339, -5.0339, -5.0339,
           -5.0339],
          [-5.0339, -5.0339, -5.0339, -5.0339, -5.0340, -5.0339, -5.0339,
           -5.0339, -5.0339, -5.0340, -5.0340, -5.0339, -5.0339, -5.0339,
           -5.0339],
          [-5.0339, -5.0339, -5.0339, -5.0339, -5.0340, -5.0339, -5.0339,
           -5.0339, -5.0339, -5.0340, -5.0340, -5.0339, -5.0339, -5.0339,
           -5.0339],
          [-5.0339, -5.0339, -5.0339, -5.0339, -5.0340, -5.0339, -5.0339,
           -5.0339, -5.0339, -5.0340, -5.0340, -5.0339, -5.0339, -5.0339,
           -5.0339],
          [-5.0339, -5.0339, -5.0339, -5.0339, -5.0340, -5.0339, -5.0339,
           -5.0339, -5.0339, -5.0340, -5.0340, -5.0339, -5.0339, -5.0339,
           -5.0339],
          [-5.0339, -5.0339, -5.0339, -5.0339, -5.0340, -5.0339, -5.0339,
           -5.0339, -5.0339, -5.0340, -5.0340, -5.0339, -5.0339, -5.0339,
           -5.0339],
          [-5.0339, -5.0339, -5.0339, -5.0339, -5.0340, -5.0339, -5.0339,
           -5.0339, -5.0339, -5.0340, -5.0340, -5.0339, -5.0339, -5.0339,
           -5.0339],
          [-5.0339, -5.0339, -5.0339, -5.0339, -5.0340, -5.0339, -5.0339,
           -5.0339, -5.0339, -5.0340, -5.0340, -5.0339, -5.0339, -5.0339,
           -5.0339],
          [-5.0339, -5.0339, -5.0339, -5.0339, -5.0340, -5.0339, -5.0339,
           -5.0339, -5.0339, -5.0340, -5.0340, -5.0339, -5.0339, -5.0339,
           -5.0339],
          [-5.0339, -5.0339, -5.0339, -5.0339, -5.0340, -5.0339, -5.0339,
           -5.0339, -5.0339, -5.0340, -5.0340, -5.0339, -5.0339, -5.0339,
           -5.0339],
          [-5.0339, -5.0339, -5.0339, -5.0339, -5.0340, -5.0339, -5.0339,
           -5.0339, -5.0339, -5.0340, -5.0340, -5.0339, -5.0339, -5.0339,
           -5.0339],
          [-5.0339, -5.0339, -5.0339, -5.0339, -5.0340, -5.0339, -5.0339,
           -5.0339, -5.0339, -5.0340, -5.0340, -5.0339, -5.0339, -5.0339,
           -5.0339],
          [-5.0339, -5.0339, -5.0339, -5.0339, -5.0340, -5.0339, -5.0339,
           -5.0339, -5.0339, -5.0340, -5.0340, -5.0339, -5.0339, -5.0339,
           -5.0339],
          [-5.0339, -5.0339, -5.0339, -5.0339, -5.0340, -5.0339, -5.0339,
           -5.0339, -5.0339, -5.0340, -5.0340, -5.0339, -5.0339, -5.0339,
           -5.0339],
          [-5.0339, -5.0339, -5.0339, -5.0339, -5.0340, -5.0339, -5.0339,
           -5.0339, -5.0339, -5.0340, -5.0340, -5.0339, -5.0339, -5.0339,
           -5.0339],
          [-5.0339, -5.0339, -5.0339, -5.0339, -5.0340, -5.0339, -5.0339,
           -5.0339, -5.0339, -5.0340, -5.0340, -5.0339, -5.0339, -5.0339,
           -5.0339]]]], grad_fn=<SliceBackward0>)
train_step: Return scale: 1.72867303946999
train_step: Scaled advantages shape: torch.Size([16, 15, 16, 15])
train_step: Scaled advantages sample: tensor([[[[-2.5445, -2.5444, -2.5445, -2.5445, -2.5445, -2.5444, -2.5445,
           -2.5444, -2.5445, -2.5444, -2.5445, -2.5445, -2.5445, -2.5444,
           -2.5444],
          [-2.5445, -2.5444, -2.5445, -2.5445, -2.5445, -2.5444, -2.5445,
           -2.5444, -2.5445, -2.5444, -2.5445, -2.5445, -2.5445, -2.5444,
           -2.5444],
          [-2.5445, -2.5444, -2.5445, -2.5445, -2.5445, -2.5444, -2.5445,
           -2.5444, -2.5445, -2.5444, -2.5445, -2.5445, -2.5445, -2.5444,
           -2.5444],
          [-2.5445, -2.5444, -2.5445, -2.5445, -2.5445, -2.5444, -2.5445,
           -2.5444, -2.5445, -2.5444, -2.5445, -2.5445, -2.5445, -2.5444,
           -2.5444],
          [-2.5445, -2.5444, -2.5445, -2.5445, -2.5445, -2.5444, -2.5445,
           -2.5444, -2.5445, -2.5444, -2.5445, -2.5445, -2.5445, -2.5444,
           -2.5444],
          [-2.5445, -2.5444, -2.5445, -2.5445, -2.5445, -2.5444, -2.5445,
           -2.5444, -2.5445, -2.5444, -2.5445, -2.5445, -2.5445, -2.5444,
           -2.5444],
          [-2.5445, -2.5444, -2.5445, -2.5445, -2.5445, -2.5444, -2.5445,
           -2.5444, -2.5445, -2.5444, -2.5445, -2.5445, -2.5445, -2.5444,
           -2.5444],
          [-2.5445, -2.5444, -2.5445, -2.5445, -2.5445, -2.5444, -2.5445,
           -2.5444, -2.5445, -2.5444, -2.5445, -2.5445, -2.5445, -2.5444,
           -2.5444],
          [-2.5445, -2.5444, -2.5445, -2.5445, -2.5445, -2.5444, -2.5445,
           -2.5444, -2.5445, -2.5444, -2.5445, -2.5445, -2.5445, -2.5444,
           -2.5444],
          [-2.5445, -2.5444, -2.5445, -2.5445, -2.5445, -2.5444, -2.5445,
           -2.5444, -2.5445, -2.5444, -2.5445, -2.5445, -2.5445, -2.5444,
           -2.5444],
          [-2.5445, -2.5444, -2.5445, -2.5445, -2.5445, -2.5444, -2.5445,
           -2.5444, -2.5445, -2.5444, -2.5445, -2.5445, -2.5445, -2.5444,
           -2.5444],
          [-2.5445, -2.5444, -2.5445, -2.5445, -2.5445, -2.5444, -2.5445,
           -2.5444, -2.5445, -2.5444, -2.5445, -2.5445, -2.5445, -2.5444,
           -2.5444],
          [-2.5445, -2.5444, -2.5445, -2.5445, -2.5445, -2.5444, -2.5445,
           -2.5444, -2.5445, -2.5444, -2.5445, -2.5445, -2.5445, -2.5444,
           -2.5444],
          [-2.5445, -2.5444, -2.5445, -2.5445, -2.5445, -2.5444, -2.5445,
           -2.5444, -2.5445, -2.5444, -2.5445, -2.5445, -2.5445, -2.5444,
           -2.5444],
          [-2.5445, -2.5444, -2.5445, -2.5445, -2.5445, -2.5444, -2.5445,
           -2.5444, -2.5445, -2.5444, -2.5445, -2.5445, -2.5445, -2.5444,
           -2.5444],
          [-2.5445, -2.5444, -2.5445, -2.5445, -2.5445, -2.5444, -2.5445,
           -2.5444, -2.5445, -2.5444, -2.5445, -2.5445, -2.5445, -2.5444,
           -2.5444]],

         [[-2.4627, -2.4627, -2.4627, -2.4627, -2.4627, -2.4627, -2.4627,
           -2.4627, -2.4627, -2.4627, -2.4627, -2.4627, -2.4627, -2.4627,
           -2.4627],
          [-2.4627, -2.4627, -2.4627, -2.4627, -2.4627, -2.4627, -2.4627,
           -2.4627, -2.4627, -2.4627, -2.4627, -2.4627, -2.4627, -2.4627,
           -2.4627],
          [-2.4627, -2.4627, -2.4627, -2.4627, -2.4627, -2.4627, -2.4627,
           -2.4627, -2.4627, -2.4627, -2.4627, -2.4627, -2.4627, -2.4627,
           -2.4627],
          [-2.4627, -2.4627, -2.4627, -2.4627, -2.4627, -2.4627, -2.4627,
           -2.4627, -2.4627, -2.4627, -2.4627, -2.4627, -2.4627, -2.4627,
           -2.4627],
          [-2.4627, -2.4627, -2.4627, -2.4627, -2.4627, -2.4627, -2.4627,
           -2.4627, -2.4627, -2.4627, -2.4627, -2.4627, -2.4627, -2.4627,
           -2.4627],
          [-2.4627, -2.4627, -2.4627, -2.4627, -2.4627, -2.4627, -2.4627,
           -2.4627, -2.4627, -2.4627, -2.4627, -2.4627, -2.4627, -2.4627,
           -2.4627],
          [-2.4627, -2.4627, -2.4627, -2.4627, -2.4627, -2.4627, -2.4627,
           -2.4627, -2.4627, -2.4627, -2.4627, -2.4627, -2.4627, -2.4627,
           -2.4627],
          [-2.4627, -2.4627, -2.4627, -2.4627, -2.4627, -2.4627, -2.4627,
           -2.4627, -2.4627, -2.4627, -2.4627, -2.4627, -2.4627, -2.4627,
           -2.4627],
          [-2.4627, -2.4627, -2.4627, -2.4627, -2.4627, -2.4627, -2.4627,
           -2.4627, -2.4627, -2.4627, -2.4627, -2.4627, -2.4627, -2.4627,
           -2.4627],
          [-2.4627, -2.4627, -2.4627, -2.4627, -2.4627, -2.4627, -2.4627,
           -2.4627, -2.4627, -2.4627, -2.4627, -2.4627, -2.4627, -2.4627,
           -2.4627],
          [-2.4627, -2.4627, -2.4627, -2.4627, -2.4627, -2.4627, -2.4627,
           -2.4627, -2.4627, -2.4627, -2.4627, -2.4627, -2.4627, -2.4627,
           -2.4627],
          [-2.4627, -2.4627, -2.4627, -2.4627, -2.4627, -2.4627, -2.4627,
           -2.4627, -2.4627, -2.4627, -2.4627, -2.4627, -2.4627, -2.4627,
           -2.4627],
          [-2.4627, -2.4627, -2.4627, -2.4627, -2.4627, -2.4627, -2.4627,
           -2.4627, -2.4627, -2.4627, -2.4627, -2.4627, -2.4627, -2.4627,
           -2.4627],
          [-2.4627, -2.4627, -2.4627, -2.4627, -2.4627, -2.4627, -2.4627,
           -2.4627, -2.4627, -2.4627, -2.4627, -2.4627, -2.4627, -2.4627,
           -2.4627],
          [-2.4627, -2.4627, -2.4627, -2.4627, -2.4627, -2.4627, -2.4627,
           -2.4627, -2.4627, -2.4627, -2.4627, -2.4627, -2.4627, -2.4627,
           -2.4627],
          [-2.4627, -2.4627, -2.4627, -2.4627, -2.4627, -2.4627, -2.4627,
           -2.4627, -2.4627, -2.4627, -2.4627, -2.4627, -2.4627, -2.4627,
           -2.4627]]],


        [[[-2.9362, -2.9362, -2.9362, -2.9362, -2.9362, -2.9362, -2.9362,
           -2.9362, -2.9362, -2.9362, -2.9362, -2.9362, -2.9362, -2.9362,
           -2.9362],
          [-2.9362, -2.9362, -2.9362, -2.9362, -2.9362, -2.9362, -2.9362,
           -2.9362, -2.9362, -2.9362, -2.9362, -2.9362, -2.9362, -2.9362,
           -2.9362],
          [-2.9362, -2.9362, -2.9362, -2.9362, -2.9362, -2.9362, -2.9362,
           -2.9362, -2.9362, -2.9362, -2.9362, -2.9362, -2.9362, -2.9362,
           -2.9362],
          [-2.9362, -2.9362, -2.9362, -2.9362, -2.9362, -2.9362, -2.9362,
           -2.9362, -2.9362, -2.9362, -2.9362, -2.9362, -2.9362, -2.9362,
           -2.9362],
          [-2.9362, -2.9362, -2.9362, -2.9362, -2.9362, -2.9362, -2.9362,
           -2.9362, -2.9362, -2.9362, -2.9362, -2.9362, -2.9362, -2.9362,
           -2.9362],
          [-2.9362, -2.9362, -2.9362, -2.9362, -2.9362, -2.9362, -2.9362,
           -2.9362, -2.9362, -2.9362, -2.9362, -2.9362, -2.9362, -2.9362,
           -2.9362],
          [-2.9362, -2.9362, -2.9362, -2.9362, -2.9362, -2.9362, -2.9362,
           -2.9362, -2.9362, -2.9362, -2.9362, -2.9362, -2.9362, -2.9362,
           -2.9362],
          [-2.9362, -2.9362, -2.9362, -2.9362, -2.9362, -2.9362, -2.9362,
           -2.9362, -2.9362, -2.9362, -2.9362, -2.9362, -2.9362, -2.9362,
           -2.9362],
          [-2.9362, -2.9362, -2.9362, -2.9362, -2.9362, -2.9362, -2.9362,
           -2.9362, -2.9362, -2.9362, -2.9362, -2.9362, -2.9362, -2.9362,
           -2.9362],
          [-2.9362, -2.9362, -2.9362, -2.9362, -2.9362, -2.9362, -2.9362,
           -2.9362, -2.9362, -2.9362, -2.9362, -2.9362, -2.9362, -2.9362,
           -2.9362],
          [-2.9362, -2.9362, -2.9362, -2.9362, -2.9362, -2.9362, -2.9362,
           -2.9362, -2.9362, -2.9362, -2.9362, -2.9362, -2.9362, -2.9362,
           -2.9362],
          [-2.9362, -2.9362, -2.9362, -2.9362, -2.9362, -2.9362, -2.9362,
           -2.9362, -2.9362, -2.9362, -2.9362, -2.9362, -2.9362, -2.9362,
           -2.9362],
          [-2.9362, -2.9362, -2.9362, -2.9362, -2.9362, -2.9362, -2.9362,
           -2.9362, -2.9362, -2.9362, -2.9362, -2.9362, -2.9362, -2.9362,
           -2.9362],
          [-2.9362, -2.9362, -2.9362, -2.9362, -2.9362, -2.9362, -2.9362,
           -2.9362, -2.9362, -2.9362, -2.9362, -2.9362, -2.9362, -2.9362,
           -2.9362],
          [-2.9362, -2.9362, -2.9362, -2.9362, -2.9362, -2.9362, -2.9362,
           -2.9362, -2.9362, -2.9362, -2.9362, -2.9362, -2.9362, -2.9362,
           -2.9362],
          [-2.9362, -2.9362, -2.9362, -2.9362, -2.9362, -2.9362, -2.9362,
           -2.9362, -2.9362, -2.9362, -2.9362, -2.9362, -2.9362, -2.9362,
           -2.9362]],

         [[-2.9120, -2.9120, -2.9120, -2.9120, -2.9120, -2.9120, -2.9120,
           -2.9120, -2.9120, -2.9120, -2.9120, -2.9120, -2.9120, -2.9120,
           -2.9120],
          [-2.9120, -2.9120, -2.9120, -2.9120, -2.9120, -2.9120, -2.9120,
           -2.9120, -2.9120, -2.9120, -2.9120, -2.9120, -2.9120, -2.9120,
           -2.9120],
          [-2.9120, -2.9120, -2.9120, -2.9120, -2.9120, -2.9120, -2.9120,
           -2.9120, -2.9120, -2.9120, -2.9120, -2.9120, -2.9120, -2.9120,
           -2.9120],
          [-2.9120, -2.9120, -2.9120, -2.9120, -2.9120, -2.9120, -2.9120,
           -2.9120, -2.9120, -2.9120, -2.9120, -2.9120, -2.9120, -2.9120,
           -2.9120],
          [-2.9120, -2.9120, -2.9120, -2.9120, -2.9120, -2.9120, -2.9120,
           -2.9120, -2.9120, -2.9120, -2.9120, -2.9120, -2.9120, -2.9120,
           -2.9120],
          [-2.9120, -2.9120, -2.9120, -2.9120, -2.9120, -2.9120, -2.9120,
           -2.9120, -2.9120, -2.9120, -2.9120, -2.9120, -2.9120, -2.9120,
           -2.9120],
          [-2.9120, -2.9120, -2.9120, -2.9120, -2.9120, -2.9120, -2.9120,
           -2.9120, -2.9120, -2.9120, -2.9120, -2.9120, -2.9120, -2.9120,
           -2.9120],
          [-2.9120, -2.9120, -2.9120, -2.9120, -2.9120, -2.9120, -2.9120,
           -2.9120, -2.9120, -2.9120, -2.9120, -2.9120, -2.9120, -2.9120,
           -2.9120],
          [-2.9120, -2.9120, -2.9120, -2.9120, -2.9120, -2.9120, -2.9120,
           -2.9120, -2.9120, -2.9120, -2.9120, -2.9120, -2.9120, -2.9120,
           -2.9120],
          [-2.9120, -2.9120, -2.9120, -2.9120, -2.9120, -2.9120, -2.9120,
           -2.9120, -2.9120, -2.9120, -2.9120, -2.9120, -2.9120, -2.9120,
           -2.9120],
          [-2.9120, -2.9120, -2.9120, -2.9120, -2.9120, -2.9120, -2.9120,
           -2.9120, -2.9120, -2.9120, -2.9120, -2.9120, -2.9120, -2.9120,
           -2.9120],
          [-2.9120, -2.9120, -2.9120, -2.9120, -2.9120, -2.9120, -2.9120,
           -2.9120, -2.9120, -2.9120, -2.9120, -2.9120, -2.9120, -2.9120,
           -2.9120],
          [-2.9120, -2.9120, -2.9120, -2.9120, -2.9120, -2.9120, -2.9120,
           -2.9120, -2.9120, -2.9120, -2.9120, -2.9120, -2.9120, -2.9120,
           -2.9120],
          [-2.9120, -2.9120, -2.9120, -2.9120, -2.9120, -2.9120, -2.9120,
           -2.9120, -2.9120, -2.9120, -2.9120, -2.9120, -2.9120, -2.9120,
           -2.9120],
          [-2.9120, -2.9120, -2.9120, -2.9120, -2.9120, -2.9120, -2.9120,
           -2.9120, -2.9120, -2.9120, -2.9120, -2.9120, -2.9120, -2.9120,
           -2.9120],
          [-2.9120, -2.9120, -2.9120, -2.9120, -2.9120, -2.9120, -2.9120,
           -2.9120, -2.9120, -2.9120, -2.9120, -2.9120, -2.9120, -2.9120,
           -2.9120]]]], grad_fn=<SliceBackward0>)
train_step: Entropy shape: torch.Size([16, 15])
train_step: Entropy sample: tensor([[0.6531, 0.2495],
        [0.4218, 0.6618]], grad_fn=<SliceBackward0>)
train_step: Entropy coefficient: 0.01
train_step: Actor loss: -1.0330991744995117
train_step: returns shape after mean: torch.Size([16, 15])
train_step: target_indices shape: torch.Size([16, 15])
train_step: value_logits shape: torch.Size([16, 15, 255])
train_step: target_twohot shape: torch.Size([16, 15, 255])
--- Starting train_step at 2025-04-01 02:00:14 ---
Full starting_state: {'deter': tensor([[[-0.0146, -0.0675,  0.0791,  ..., -0.0297,  0.0176, -0.0295],
         [ 0.0518,  0.0054,  0.0352,  ..., -0.0727, -0.0121, -0.0570],
         [ 0.0039,  0.1368, -0.1891,  ...,  0.0281,  0.0430,  0.0606],
         ...,
         [ 0.0575,  0.0304, -0.1828,  ..., -0.1419,  0.0885, -0.1261],
         [-0.1423,  0.0452, -0.1122,  ..., -0.0207,  0.1004, -0.1072],
         [-0.0317,  0.0283,  0.1473,  ..., -0.0592,  0.0556, -0.0072]],

        [[ 0.0490,  0.0490,  0.0101,  ..., -0.1034, -0.0568,  0.0395],
         [ 0.0112, -0.1062, -0.1453,  ...,  0.0342, -0.0603, -0.0249],
         [ 0.0430, -0.0633, -0.0370,  ..., -0.0188,  0.0835,  0.1354],
         ...,
         [-0.0018,  0.0673, -0.1774,  ..., -0.0213,  0.0518, -0.1373],
         [-0.0917,  0.0136,  0.0753,  ..., -0.1743,  0.1103,  0.0890],
         [-0.1725,  0.0820, -0.0316,  ...,  0.0783,  0.0025, -0.0979]],

        [[-0.0583, -0.0642, -0.1134,  ..., -0.0154,  0.1057,  0.0058],
         [-0.0461,  0.1056, -0.0352,  ...,  0.0091, -0.1228, -0.0712],
         [ 0.0347,  0.0039,  0.0503,  ...,  0.0301, -0.0203, -0.0210],
         ...,
         [-0.0451, -0.0645,  0.0200,  ...,  0.0746, -0.0454, -0.0304],
         [-0.0815, -0.0894, -0.1673,  ...,  0.1350, -0.0389,  0.0155],
         [ 0.0819, -0.0569, -0.1094,  ...,  0.0855,  0.1451, -0.1013]],

        ...,

        [[-0.0876, -0.1292,  0.0426,  ...,  0.0377, -0.0081, -0.0992],
         [ 0.0568,  0.0641, -0.0093,  ...,  0.1395,  0.0479, -0.0530],
         [ 0.0493, -0.0661, -0.1220,  ...,  0.1307, -0.1590,  0.0161],
         ...,
         [ 0.0248, -0.1228,  0.0118,  ...,  0.1169,  0.0813,  0.0993],
         [-0.1121,  0.0379, -0.0795,  ...,  0.0958,  0.0224, -0.0745],
         [-0.0787, -0.0318,  0.0443,  ...,  0.0529,  0.0456, -0.1870]],

        [[-0.0272, -0.0660,  0.0403,  ..., -0.0893,  0.0978, -0.0717],
         [-0.0898,  0.0785, -0.1847,  ..., -0.0419,  0.1114,  0.0510],
         [-0.0075,  0.0450,  0.0159,  ...,  0.0912,  0.0317, -0.1062],
         ...,
         [-0.1380, -0.1093, -0.0082,  ..., -0.0046,  0.0429, -0.0080],
         [ 0.0264, -0.1641,  0.0998,  ...,  0.1116, -0.0859,  0.0445],
         [-0.0429,  0.0053, -0.0054,  ...,  0.1318,  0.0590,  0.0033]],

        [[-0.0904, -0.0990,  0.0169,  ...,  0.1059,  0.0762,  0.0097],
         [ 0.0639,  0.0310,  0.0583,  ...,  0.0406,  0.0705, -0.0139],
         [ 0.0164,  0.1231, -0.0842,  ...,  0.1026,  0.0078, -0.0591],
         ...,
         [-0.0512, -0.0727, -0.0466,  ..., -0.0045, -0.0531, -0.0765],
         [-0.0960, -0.1623, -0.0254,  ..., -0.0800, -0.0086, -0.0455],
         [ 0.0830, -0.0082,  0.0850,  ...,  0.0366,  0.1769, -0.1499]]],
       grad_fn=<StackBackward0>), 'stoch': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [1., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 1., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 1., 0.,  ..., 0., 0., 1.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 1.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]])}
train_step: Starting state deter shape: torch.Size([16, 50, 128])
train_step: Starting state stoch shape: torch.Size([16, 50, 1024])
After ensuring logits/stoch: {'deter': tensor([[[-0.0146, -0.0675,  0.0791,  ..., -0.0297,  0.0176, -0.0295],
         [ 0.0518,  0.0054,  0.0352,  ..., -0.0727, -0.0121, -0.0570],
         [ 0.0039,  0.1368, -0.1891,  ...,  0.0281,  0.0430,  0.0606],
         ...,
         [ 0.0575,  0.0304, -0.1828,  ..., -0.1419,  0.0885, -0.1261],
         [-0.1423,  0.0452, -0.1122,  ..., -0.0207,  0.1004, -0.1072],
         [-0.0317,  0.0283,  0.1473,  ..., -0.0592,  0.0556, -0.0072]],

        [[ 0.0490,  0.0490,  0.0101,  ..., -0.1034, -0.0568,  0.0395],
         [ 0.0112, -0.1062, -0.1453,  ...,  0.0342, -0.0603, -0.0249],
         [ 0.0430, -0.0633, -0.0370,  ..., -0.0188,  0.0835,  0.1354],
         ...,
         [-0.0018,  0.0673, -0.1774,  ..., -0.0213,  0.0518, -0.1373],
         [-0.0917,  0.0136,  0.0753,  ..., -0.1743,  0.1103,  0.0890],
         [-0.1725,  0.0820, -0.0316,  ...,  0.0783,  0.0025, -0.0979]],

        [[-0.0583, -0.0642, -0.1134,  ..., -0.0154,  0.1057,  0.0058],
         [-0.0461,  0.1056, -0.0352,  ...,  0.0091, -0.1228, -0.0712],
         [ 0.0347,  0.0039,  0.0503,  ...,  0.0301, -0.0203, -0.0210],
         ...,
         [-0.0451, -0.0645,  0.0200,  ...,  0.0746, -0.0454, -0.0304],
         [-0.0815, -0.0894, -0.1673,  ...,  0.1350, -0.0389,  0.0155],
         [ 0.0819, -0.0569, -0.1094,  ...,  0.0855,  0.1451, -0.1013]],

        ...,

        [[-0.0876, -0.1292,  0.0426,  ...,  0.0377, -0.0081, -0.0992],
         [ 0.0568,  0.0641, -0.0093,  ...,  0.1395,  0.0479, -0.0530],
         [ 0.0493, -0.0661, -0.1220,  ...,  0.1307, -0.1590,  0.0161],
         ...,
         [ 0.0248, -0.1228,  0.0118,  ...,  0.1169,  0.0813,  0.0993],
         [-0.1121,  0.0379, -0.0795,  ...,  0.0958,  0.0224, -0.0745],
         [-0.0787, -0.0318,  0.0443,  ...,  0.0529,  0.0456, -0.1870]],

        [[-0.0272, -0.0660,  0.0403,  ..., -0.0893,  0.0978, -0.0717],
         [-0.0898,  0.0785, -0.1847,  ..., -0.0419,  0.1114,  0.0510],
         [-0.0075,  0.0450,  0.0159,  ...,  0.0912,  0.0317, -0.1062],
         ...,
         [-0.1380, -0.1093, -0.0082,  ..., -0.0046,  0.0429, -0.0080],
         [ 0.0264, -0.1641,  0.0998,  ...,  0.1116, -0.0859,  0.0445],
         [-0.0429,  0.0053, -0.0054,  ...,  0.1318,  0.0590,  0.0033]],

        [[-0.0904, -0.0990,  0.0169,  ...,  0.1059,  0.0762,  0.0097],
         [ 0.0639,  0.0310,  0.0583,  ...,  0.0406,  0.0705, -0.0139],
         [ 0.0164,  0.1231, -0.0842,  ...,  0.1026,  0.0078, -0.0591],
         ...,
         [-0.0512, -0.0727, -0.0466,  ..., -0.0045, -0.0531, -0.0765],
         [-0.0960, -0.1623, -0.0254,  ..., -0.0800, -0.0086, -0.0455],
         [ 0.0830, -0.0082,  0.0850,  ...,  0.0366,  0.1769, -0.1499]]],
       grad_fn=<StackBackward0>), 'stoch': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [1., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 1., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 1., 0.,  ..., 0., 0., 1.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 1.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]]), 'logits': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]])}
train_step: Normalized hidden_state shape: torch.Size([1, 16, 128])
train_step: Normalized stoch shape: torch.Size([16, 1024])
train_step: Normalized deter shape: torch.Size([16, 128])
train_step: Post-imagine_trajectory: Imagined features shape: torch.Size([16, 15, 1152])
train_step: Post-imagine_trajectory: Imagined actions shape: torch.Size([16, 15, 2])
train_step: Post-imagine_trajectory: Imagined action indices shape: torch.Size([16, 15])
train_step: Post-imagine_trajectory: Imagined state deter shape: torch.Size([16, 15, 128])
train_step: Post-imagine_trajectory: Imagined state stoch shape: torch.Size([16, 15, 1024])
Reward shape: torch.Size([16, 15, 1]), Value shape: torch.Size([16, 15, 1]), Slow Value shape: torch.Size([16, 15, 1]), Discount shape: torch.Size([16, 15, 1, 1])
Return targets length: 15, First target shape: torch.Size([16, 16, 1])
train_step: Actor distribution shape: torch.Size([16, 15, 2])
train_step: Action log probabilities shape: torch.Size([16, 15])
train_step: Action log probabilities sample: tensor([[-0.1756, -0.4107],
        [-1.5150, -0.5159]], grad_fn=<SliceBackward0>)
train_step: Advantages shape: torch.Size([16, 15, 16, 15])
train_step: Advantages sample: tensor([[[[-5.2424, -5.2425, -5.2425, -5.2425, -5.2424, -5.2425, -5.2425,
           -5.2424, -5.2424, -5.2424, -5.2425, -5.2424, -5.2425, -5.2424,
           -5.2424],
          [-5.2424, -5.2425, -5.2425, -5.2425, -5.2424, -5.2425, -5.2425,
           -5.2424, -5.2424, -5.2424, -5.2425, -5.2424, -5.2425, -5.2424,
           -5.2424],
          [-5.2424, -5.2425, -5.2425, -5.2425, -5.2424, -5.2425, -5.2425,
           -5.2424, -5.2424, -5.2424, -5.2425, -5.2424, -5.2425, -5.2424,
           -5.2424],
          [-5.2424, -5.2425, -5.2425, -5.2425, -5.2424, -5.2425, -5.2425,
           -5.2424, -5.2424, -5.2424, -5.2425, -5.2424, -5.2425, -5.2424,
           -5.2424],
          [-5.2424, -5.2425, -5.2425, -5.2425, -5.2424, -5.2425, -5.2425,
           -5.2424, -5.2424, -5.2424, -5.2425, -5.2424, -5.2425, -5.2424,
           -5.2424],
          [-5.2424, -5.2425, -5.2425, -5.2425, -5.2424, -5.2425, -5.2425,
           -5.2424, -5.2424, -5.2424, -5.2425, -5.2424, -5.2425, -5.2424,
           -5.2424],
          [-5.2424, -5.2425, -5.2425, -5.2425, -5.2424, -5.2425, -5.2425,
           -5.2424, -5.2424, -5.2424, -5.2425, -5.2424, -5.2425, -5.2424,
           -5.2424],
          [-5.2424, -5.2425, -5.2425, -5.2425, -5.2424, -5.2425, -5.2425,
           -5.2424, -5.2424, -5.2424, -5.2425, -5.2424, -5.2425, -5.2424,
           -5.2424],
          [-5.2424, -5.2425, -5.2425, -5.2425, -5.2424, -5.2425, -5.2425,
           -5.2424, -5.2424, -5.2424, -5.2425, -5.2424, -5.2425, -5.2424,
           -5.2424],
          [-5.2424, -5.2425, -5.2425, -5.2425, -5.2424, -5.2425, -5.2425,
           -5.2424, -5.2424, -5.2424, -5.2425, -5.2424, -5.2425, -5.2424,
           -5.2424],
          [-5.2424, -5.2425, -5.2425, -5.2425, -5.2424, -5.2425, -5.2425,
           -5.2424, -5.2424, -5.2424, -5.2425, -5.2424, -5.2425, -5.2424,
           -5.2424],
          [-5.2424, -5.2425, -5.2425, -5.2425, -5.2424, -5.2425, -5.2425,
           -5.2424, -5.2424, -5.2424, -5.2425, -5.2424, -5.2425, -5.2424,
           -5.2424],
          [-5.2424, -5.2425, -5.2425, -5.2425, -5.2424, -5.2425, -5.2425,
           -5.2424, -5.2424, -5.2424, -5.2425, -5.2424, -5.2425, -5.2424,
           -5.2424],
          [-5.2424, -5.2425, -5.2425, -5.2425, -5.2424, -5.2425, -5.2425,
           -5.2424, -5.2424, -5.2424, -5.2425, -5.2424, -5.2425, -5.2424,
           -5.2424],
          [-5.2424, -5.2425, -5.2425, -5.2425, -5.2424, -5.2425, -5.2425,
           -5.2424, -5.2424, -5.2424, -5.2425, -5.2424, -5.2425, -5.2424,
           -5.2424],
          [-5.2424, -5.2425, -5.2425, -5.2425, -5.2424, -5.2425, -5.2425,
           -5.2424, -5.2424, -5.2424, -5.2425, -5.2424, -5.2425, -5.2424,
           -5.2424]],

         [[-4.1812, -4.1812, -4.1813, -4.1812, -4.1812, -4.1813, -4.1812,
           -4.1812, -4.1813, -4.1812, -4.1812, -4.1812, -4.1812, -4.1812,
           -4.1812],
          [-4.1812, -4.1812, -4.1813, -4.1812, -4.1812, -4.1813, -4.1812,
           -4.1812, -4.1813, -4.1812, -4.1812, -4.1812, -4.1812, -4.1812,
           -4.1812],
          [-4.1812, -4.1812, -4.1813, -4.1812, -4.1812, -4.1813, -4.1812,
           -4.1812, -4.1813, -4.1812, -4.1812, -4.1812, -4.1812, -4.1812,
           -4.1812],
          [-4.1812, -4.1812, -4.1813, -4.1812, -4.1812, -4.1813, -4.1812,
           -4.1812, -4.1813, -4.1812, -4.1812, -4.1812, -4.1812, -4.1812,
           -4.1812],
          [-4.1812, -4.1812, -4.1813, -4.1812, -4.1812, -4.1813, -4.1812,
           -4.1812, -4.1813, -4.1812, -4.1812, -4.1812, -4.1812, -4.1812,
           -4.1812],
          [-4.1812, -4.1812, -4.1813, -4.1812, -4.1812, -4.1813, -4.1812,
           -4.1812, -4.1813, -4.1812, -4.1812, -4.1812, -4.1812, -4.1812,
           -4.1812],
          [-4.1812, -4.1812, -4.1813, -4.1812, -4.1812, -4.1813, -4.1812,
           -4.1812, -4.1813, -4.1812, -4.1812, -4.1812, -4.1812, -4.1812,
           -4.1812],
          [-4.1812, -4.1812, -4.1813, -4.1812, -4.1812, -4.1813, -4.1812,
           -4.1812, -4.1813, -4.1812, -4.1812, -4.1812, -4.1812, -4.1812,
           -4.1812],
          [-4.1812, -4.1812, -4.1813, -4.1812, -4.1812, -4.1813, -4.1812,
           -4.1812, -4.1813, -4.1812, -4.1812, -4.1812, -4.1812, -4.1812,
           -4.1812],
          [-4.1812, -4.1812, -4.1813, -4.1812, -4.1812, -4.1813, -4.1812,
           -4.1812, -4.1813, -4.1812, -4.1812, -4.1812, -4.1812, -4.1812,
           -4.1812],
          [-4.1812, -4.1812, -4.1813, -4.1812, -4.1812, -4.1813, -4.1812,
           -4.1812, -4.1813, -4.1812, -4.1812, -4.1812, -4.1812, -4.1812,
           -4.1812],
          [-4.1812, -4.1812, -4.1813, -4.1812, -4.1812, -4.1813, -4.1812,
           -4.1812, -4.1813, -4.1812, -4.1812, -4.1812, -4.1812, -4.1812,
           -4.1812],
          [-4.1812, -4.1812, -4.1813, -4.1812, -4.1812, -4.1813, -4.1812,
           -4.1812, -4.1813, -4.1812, -4.1812, -4.1812, -4.1812, -4.1812,
           -4.1812],
          [-4.1812, -4.1812, -4.1813, -4.1812, -4.1812, -4.1813, -4.1812,
           -4.1812, -4.1813, -4.1812, -4.1812, -4.1812, -4.1812, -4.1812,
           -4.1812],
          [-4.1812, -4.1812, -4.1813, -4.1812, -4.1812, -4.1813, -4.1812,
           -4.1812, -4.1813, -4.1812, -4.1812, -4.1812, -4.1812, -4.1812,
           -4.1812],
          [-4.1812, -4.1812, -4.1813, -4.1812, -4.1812, -4.1813, -4.1812,
           -4.1812, -4.1813, -4.1812, -4.1812, -4.1812, -4.1812, -4.1812,
           -4.1812]]],


        [[[-3.7646, -3.7647, -3.7646, -3.7646, -3.7646, -3.7647, -3.7646,
           -3.7646, -3.7646, -3.7646, -3.7647, -3.7646, -3.7647, -3.7646,
           -3.7646],
          [-3.7646, -3.7647, -3.7646, -3.7646, -3.7646, -3.7647, -3.7646,
           -3.7646, -3.7646, -3.7646, -3.7647, -3.7646, -3.7647, -3.7646,
           -3.7646],
          [-3.7646, -3.7647, -3.7646, -3.7646, -3.7646, -3.7647, -3.7646,
           -3.7646, -3.7646, -3.7646, -3.7647, -3.7646, -3.7647, -3.7646,
           -3.7646],
          [-3.7646, -3.7647, -3.7646, -3.7646, -3.7646, -3.7647, -3.7646,
           -3.7646, -3.7646, -3.7646, -3.7647, -3.7646, -3.7647, -3.7646,
           -3.7646],
          [-3.7646, -3.7647, -3.7646, -3.7646, -3.7646, -3.7647, -3.7646,
           -3.7646, -3.7646, -3.7646, -3.7647, -3.7646, -3.7647, -3.7646,
           -3.7646],
          [-3.7646, -3.7647, -3.7646, -3.7646, -3.7646, -3.7647, -3.7646,
           -3.7646, -3.7646, -3.7646, -3.7647, -3.7646, -3.7647, -3.7646,
           -3.7646],
          [-3.7646, -3.7647, -3.7646, -3.7646, -3.7646, -3.7647, -3.7646,
           -3.7646, -3.7646, -3.7646, -3.7647, -3.7646, -3.7647, -3.7646,
           -3.7646],
          [-3.7646, -3.7647, -3.7646, -3.7646, -3.7646, -3.7647, -3.7646,
           -3.7646, -3.7646, -3.7646, -3.7647, -3.7646, -3.7647, -3.7646,
           -3.7646],
          [-3.7646, -3.7647, -3.7646, -3.7646, -3.7646, -3.7647, -3.7646,
           -3.7646, -3.7646, -3.7646, -3.7647, -3.7646, -3.7647, -3.7646,
           -3.7646],
          [-3.7646, -3.7647, -3.7646, -3.7646, -3.7646, -3.7647, -3.7646,
           -3.7646, -3.7646, -3.7646, -3.7647, -3.7646, -3.7647, -3.7646,
           -3.7646],
          [-3.7646, -3.7647, -3.7646, -3.7646, -3.7646, -3.7647, -3.7646,
           -3.7646, -3.7646, -3.7646, -3.7647, -3.7646, -3.7647, -3.7646,
           -3.7646],
          [-3.7646, -3.7647, -3.7646, -3.7646, -3.7646, -3.7647, -3.7646,
           -3.7646, -3.7646, -3.7646, -3.7647, -3.7646, -3.7647, -3.7646,
           -3.7646],
          [-3.7646, -3.7647, -3.7646, -3.7646, -3.7646, -3.7647, -3.7646,
           -3.7646, -3.7646, -3.7646, -3.7647, -3.7646, -3.7647, -3.7646,
           -3.7646],
          [-3.7646, -3.7647, -3.7646, -3.7646, -3.7646, -3.7647, -3.7646,
           -3.7646, -3.7646, -3.7646, -3.7647, -3.7646, -3.7647, -3.7646,
           -3.7646],
          [-3.7646, -3.7647, -3.7646, -3.7646, -3.7646, -3.7647, -3.7646,
           -3.7646, -3.7646, -3.7646, -3.7647, -3.7646, -3.7647, -3.7646,
           -3.7646],
          [-3.7646, -3.7647, -3.7646, -3.7646, -3.7646, -3.7647, -3.7646,
           -3.7646, -3.7646, -3.7646, -3.7647, -3.7646, -3.7647, -3.7646,
           -3.7646]],

         [[-3.4846, -3.4845, -3.4846, -3.4845, -3.4846, -3.4846, -3.4846,
           -3.4846, -3.4846, -3.4846, -3.4845, -3.4846, -3.4845, -3.4846,
           -3.4846],
          [-3.4846, -3.4845, -3.4846, -3.4845, -3.4846, -3.4846, -3.4846,
           -3.4846, -3.4846, -3.4846, -3.4845, -3.4846, -3.4845, -3.4846,
           -3.4846],
          [-3.4846, -3.4845, -3.4846, -3.4845, -3.4846, -3.4846, -3.4846,
           -3.4846, -3.4846, -3.4846, -3.4845, -3.4846, -3.4845, -3.4846,
           -3.4846],
          [-3.4846, -3.4845, -3.4846, -3.4845, -3.4846, -3.4846, -3.4846,
           -3.4846, -3.4846, -3.4846, -3.4845, -3.4846, -3.4845, -3.4846,
           -3.4846],
          [-3.4846, -3.4845, -3.4846, -3.4845, -3.4846, -3.4846, -3.4846,
           -3.4846, -3.4846, -3.4846, -3.4845, -3.4846, -3.4845, -3.4846,
           -3.4846],
          [-3.4846, -3.4845, -3.4846, -3.4845, -3.4846, -3.4846, -3.4846,
           -3.4846, -3.4846, -3.4846, -3.4845, -3.4846, -3.4845, -3.4846,
           -3.4846],
          [-3.4846, -3.4845, -3.4846, -3.4845, -3.4846, -3.4846, -3.4846,
           -3.4846, -3.4846, -3.4846, -3.4845, -3.4846, -3.4845, -3.4846,
           -3.4846],
          [-3.4846, -3.4845, -3.4846, -3.4845, -3.4846, -3.4846, -3.4846,
           -3.4846, -3.4846, -3.4846, -3.4845, -3.4846, -3.4845, -3.4846,
           -3.4846],
          [-3.4846, -3.4845, -3.4846, -3.4845, -3.4846, -3.4846, -3.4846,
           -3.4846, -3.4846, -3.4846, -3.4845, -3.4846, -3.4845, -3.4846,
           -3.4846],
          [-3.4846, -3.4845, -3.4846, -3.4845, -3.4846, -3.4846, -3.4846,
           -3.4846, -3.4846, -3.4846, -3.4845, -3.4846, -3.4845, -3.4846,
           -3.4846],
          [-3.4846, -3.4845, -3.4846, -3.4845, -3.4846, -3.4846, -3.4846,
           -3.4846, -3.4846, -3.4846, -3.4845, -3.4846, -3.4845, -3.4846,
           -3.4846],
          [-3.4846, -3.4845, -3.4846, -3.4845, -3.4846, -3.4846, -3.4846,
           -3.4846, -3.4846, -3.4846, -3.4845, -3.4846, -3.4845, -3.4846,
           -3.4846],
          [-3.4846, -3.4845, -3.4846, -3.4845, -3.4846, -3.4846, -3.4846,
           -3.4846, -3.4846, -3.4846, -3.4845, -3.4846, -3.4845, -3.4846,
           -3.4846],
          [-3.4846, -3.4845, -3.4846, -3.4845, -3.4846, -3.4846, -3.4846,
           -3.4846, -3.4846, -3.4846, -3.4845, -3.4846, -3.4845, -3.4846,
           -3.4846],
          [-3.4846, -3.4845, -3.4846, -3.4845, -3.4846, -3.4846, -3.4846,
           -3.4846, -3.4846, -3.4846, -3.4845, -3.4846, -3.4845, -3.4846,
           -3.4846],
          [-3.4846, -3.4845, -3.4846, -3.4845, -3.4846, -3.4846, -3.4846,
           -3.4846, -3.4846, -3.4846, -3.4845, -3.4846, -3.4845, -3.4846,
           -3.4846]]]], grad_fn=<SliceBackward0>)
train_step: Return scale: 1.7646658180236163
train_step: Scaled advantages shape: torch.Size([16, 15, 16, 15])
train_step: Scaled advantages sample: tensor([[[[-2.9708, -2.9708, -2.9708, -2.9708, -2.9708, -2.9708, -2.9708,
           -2.9708, -2.9708, -2.9708, -2.9708, -2.9708, -2.9708, -2.9708,
           -2.9708],
          [-2.9708, -2.9708, -2.9708, -2.9708, -2.9708, -2.9708, -2.9708,
           -2.9708, -2.9708, -2.9708, -2.9708, -2.9708, -2.9708, -2.9708,
           -2.9708],
          [-2.9708, -2.9708, -2.9708, -2.9708, -2.9708, -2.9708, -2.9708,
           -2.9708, -2.9708, -2.9708, -2.9708, -2.9708, -2.9708, -2.9708,
           -2.9708],
          [-2.9708, -2.9708, -2.9708, -2.9708, -2.9708, -2.9708, -2.9708,
           -2.9708, -2.9708, -2.9708, -2.9708, -2.9708, -2.9708, -2.9708,
           -2.9708],
          [-2.9708, -2.9708, -2.9708, -2.9708, -2.9708, -2.9708, -2.9708,
           -2.9708, -2.9708, -2.9708, -2.9708, -2.9708, -2.9708, -2.9708,
           -2.9708],
          [-2.9708, -2.9708, -2.9708, -2.9708, -2.9708, -2.9708, -2.9708,
           -2.9708, -2.9708, -2.9708, -2.9708, -2.9708, -2.9708, -2.9708,
           -2.9708],
          [-2.9708, -2.9708, -2.9708, -2.9708, -2.9708, -2.9708, -2.9708,
           -2.9708, -2.9708, -2.9708, -2.9708, -2.9708, -2.9708, -2.9708,
           -2.9708],
          [-2.9708, -2.9708, -2.9708, -2.9708, -2.9708, -2.9708, -2.9708,
           -2.9708, -2.9708, -2.9708, -2.9708, -2.9708, -2.9708, -2.9708,
           -2.9708],
          [-2.9708, -2.9708, -2.9708, -2.9708, -2.9708, -2.9708, -2.9708,
           -2.9708, -2.9708, -2.9708, -2.9708, -2.9708, -2.9708, -2.9708,
           -2.9708],
          [-2.9708, -2.9708, -2.9708, -2.9708, -2.9708, -2.9708, -2.9708,
           -2.9708, -2.9708, -2.9708, -2.9708, -2.9708, -2.9708, -2.9708,
           -2.9708],
          [-2.9708, -2.9708, -2.9708, -2.9708, -2.9708, -2.9708, -2.9708,
           -2.9708, -2.9708, -2.9708, -2.9708, -2.9708, -2.9708, -2.9708,
           -2.9708],
          [-2.9708, -2.9708, -2.9708, -2.9708, -2.9708, -2.9708, -2.9708,
           -2.9708, -2.9708, -2.9708, -2.9708, -2.9708, -2.9708, -2.9708,
           -2.9708],
          [-2.9708, -2.9708, -2.9708, -2.9708, -2.9708, -2.9708, -2.9708,
           -2.9708, -2.9708, -2.9708, -2.9708, -2.9708, -2.9708, -2.9708,
           -2.9708],
          [-2.9708, -2.9708, -2.9708, -2.9708, -2.9708, -2.9708, -2.9708,
           -2.9708, -2.9708, -2.9708, -2.9708, -2.9708, -2.9708, -2.9708,
           -2.9708],
          [-2.9708, -2.9708, -2.9708, -2.9708, -2.9708, -2.9708, -2.9708,
           -2.9708, -2.9708, -2.9708, -2.9708, -2.9708, -2.9708, -2.9708,
           -2.9708],
          [-2.9708, -2.9708, -2.9708, -2.9708, -2.9708, -2.9708, -2.9708,
           -2.9708, -2.9708, -2.9708, -2.9708, -2.9708, -2.9708, -2.9708,
           -2.9708]],

         [[-2.3694, -2.3694, -2.3694, -2.3694, -2.3694, -2.3694, -2.3694,
           -2.3694, -2.3694, -2.3694, -2.3694, -2.3694, -2.3694, -2.3694,
           -2.3694],
          [-2.3694, -2.3694, -2.3694, -2.3694, -2.3694, -2.3694, -2.3694,
           -2.3694, -2.3694, -2.3694, -2.3694, -2.3694, -2.3694, -2.3694,
           -2.3694],
          [-2.3694, -2.3694, -2.3694, -2.3694, -2.3694, -2.3694, -2.3694,
           -2.3694, -2.3694, -2.3694, -2.3694, -2.3694, -2.3694, -2.3694,
           -2.3694],
          [-2.3694, -2.3694, -2.3694, -2.3694, -2.3694, -2.3694, -2.3694,
           -2.3694, -2.3694, -2.3694, -2.3694, -2.3694, -2.3694, -2.3694,
           -2.3694],
          [-2.3694, -2.3694, -2.3694, -2.3694, -2.3694, -2.3694, -2.3694,
           -2.3694, -2.3694, -2.3694, -2.3694, -2.3694, -2.3694, -2.3694,
           -2.3694],
          [-2.3694, -2.3694, -2.3694, -2.3694, -2.3694, -2.3694, -2.3694,
           -2.3694, -2.3694, -2.3694, -2.3694, -2.3694, -2.3694, -2.3694,
           -2.3694],
          [-2.3694, -2.3694, -2.3694, -2.3694, -2.3694, -2.3694, -2.3694,
           -2.3694, -2.3694, -2.3694, -2.3694, -2.3694, -2.3694, -2.3694,
           -2.3694],
          [-2.3694, -2.3694, -2.3694, -2.3694, -2.3694, -2.3694, -2.3694,
           -2.3694, -2.3694, -2.3694, -2.3694, -2.3694, -2.3694, -2.3694,
           -2.3694],
          [-2.3694, -2.3694, -2.3694, -2.3694, -2.3694, -2.3694, -2.3694,
           -2.3694, -2.3694, -2.3694, -2.3694, -2.3694, -2.3694, -2.3694,
           -2.3694],
          [-2.3694, -2.3694, -2.3694, -2.3694, -2.3694, -2.3694, -2.3694,
           -2.3694, -2.3694, -2.3694, -2.3694, -2.3694, -2.3694, -2.3694,
           -2.3694],
          [-2.3694, -2.3694, -2.3694, -2.3694, -2.3694, -2.3694, -2.3694,
           -2.3694, -2.3694, -2.3694, -2.3694, -2.3694, -2.3694, -2.3694,
           -2.3694],
          [-2.3694, -2.3694, -2.3694, -2.3694, -2.3694, -2.3694, -2.3694,
           -2.3694, -2.3694, -2.3694, -2.3694, -2.3694, -2.3694, -2.3694,
           -2.3694],
          [-2.3694, -2.3694, -2.3694, -2.3694, -2.3694, -2.3694, -2.3694,
           -2.3694, -2.3694, -2.3694, -2.3694, -2.3694, -2.3694, -2.3694,
           -2.3694],
          [-2.3694, -2.3694, -2.3694, -2.3694, -2.3694, -2.3694, -2.3694,
           -2.3694, -2.3694, -2.3694, -2.3694, -2.3694, -2.3694, -2.3694,
           -2.3694],
          [-2.3694, -2.3694, -2.3694, -2.3694, -2.3694, -2.3694, -2.3694,
           -2.3694, -2.3694, -2.3694, -2.3694, -2.3694, -2.3694, -2.3694,
           -2.3694],
          [-2.3694, -2.3694, -2.3694, -2.3694, -2.3694, -2.3694, -2.3694,
           -2.3694, -2.3694, -2.3694, -2.3694, -2.3694, -2.3694, -2.3694,
           -2.3694]]],


        [[[-2.1333, -2.1334, -2.1333, -2.1333, -2.1333, -2.1334, -2.1333,
           -2.1333, -2.1333, -2.1333, -2.1334, -2.1333, -2.1334, -2.1333,
           -2.1333],
          [-2.1333, -2.1334, -2.1333, -2.1333, -2.1333, -2.1334, -2.1333,
           -2.1333, -2.1333, -2.1333, -2.1334, -2.1333, -2.1334, -2.1333,
           -2.1333],
          [-2.1333, -2.1334, -2.1333, -2.1333, -2.1333, -2.1334, -2.1333,
           -2.1333, -2.1333, -2.1333, -2.1334, -2.1333, -2.1334, -2.1333,
           -2.1333],
          [-2.1333, -2.1334, -2.1333, -2.1333, -2.1333, -2.1334, -2.1333,
           -2.1333, -2.1333, -2.1333, -2.1334, -2.1333, -2.1334, -2.1333,
           -2.1333],
          [-2.1333, -2.1334, -2.1333, -2.1333, -2.1333, -2.1334, -2.1333,
           -2.1333, -2.1333, -2.1333, -2.1334, -2.1333, -2.1334, -2.1333,
           -2.1333],
          [-2.1333, -2.1334, -2.1333, -2.1333, -2.1333, -2.1334, -2.1333,
           -2.1333, -2.1333, -2.1333, -2.1334, -2.1333, -2.1334, -2.1333,
           -2.1333],
          [-2.1333, -2.1334, -2.1333, -2.1333, -2.1333, -2.1334, -2.1333,
           -2.1333, -2.1333, -2.1333, -2.1334, -2.1333, -2.1334, -2.1333,
           -2.1333],
          [-2.1333, -2.1334, -2.1333, -2.1333, -2.1333, -2.1334, -2.1333,
           -2.1333, -2.1333, -2.1333, -2.1334, -2.1333, -2.1334, -2.1333,
           -2.1333],
          [-2.1333, -2.1334, -2.1333, -2.1333, -2.1333, -2.1334, -2.1333,
           -2.1333, -2.1333, -2.1333, -2.1334, -2.1333, -2.1334, -2.1333,
           -2.1333],
          [-2.1333, -2.1334, -2.1333, -2.1333, -2.1333, -2.1334, -2.1333,
           -2.1333, -2.1333, -2.1333, -2.1334, -2.1333, -2.1334, -2.1333,
           -2.1333],
          [-2.1333, -2.1334, -2.1333, -2.1333, -2.1333, -2.1334, -2.1333,
           -2.1333, -2.1333, -2.1333, -2.1334, -2.1333, -2.1334, -2.1333,
           -2.1333],
          [-2.1333, -2.1334, -2.1333, -2.1333, -2.1333, -2.1334, -2.1333,
           -2.1333, -2.1333, -2.1333, -2.1334, -2.1333, -2.1334, -2.1333,
           -2.1333],
          [-2.1333, -2.1334, -2.1333, -2.1333, -2.1333, -2.1334, -2.1333,
           -2.1333, -2.1333, -2.1333, -2.1334, -2.1333, -2.1334, -2.1333,
           -2.1333],
          [-2.1333, -2.1334, -2.1333, -2.1333, -2.1333, -2.1334, -2.1333,
           -2.1333, -2.1333, -2.1333, -2.1334, -2.1333, -2.1334, -2.1333,
           -2.1333],
          [-2.1333, -2.1334, -2.1333, -2.1333, -2.1333, -2.1334, -2.1333,
           -2.1333, -2.1333, -2.1333, -2.1334, -2.1333, -2.1334, -2.1333,
           -2.1333],
          [-2.1333, -2.1334, -2.1333, -2.1333, -2.1333, -2.1334, -2.1333,
           -2.1333, -2.1333, -2.1333, -2.1334, -2.1333, -2.1334, -2.1333,
           -2.1333]],

         [[-1.9746, -1.9746, -1.9746, -1.9746, -1.9746, -1.9747, -1.9746,
           -1.9746, -1.9747, -1.9746, -1.9746, -1.9746, -1.9746, -1.9746,
           -1.9746],
          [-1.9746, -1.9746, -1.9746, -1.9746, -1.9746, -1.9747, -1.9746,
           -1.9746, -1.9747, -1.9746, -1.9746, -1.9746, -1.9746, -1.9746,
           -1.9746],
          [-1.9746, -1.9746, -1.9746, -1.9746, -1.9746, -1.9747, -1.9746,
           -1.9746, -1.9747, -1.9746, -1.9746, -1.9746, -1.9746, -1.9746,
           -1.9746],
          [-1.9746, -1.9746, -1.9746, -1.9746, -1.9746, -1.9747, -1.9746,
           -1.9746, -1.9747, -1.9746, -1.9746, -1.9746, -1.9746, -1.9746,
           -1.9746],
          [-1.9746, -1.9746, -1.9746, -1.9746, -1.9746, -1.9747, -1.9746,
           -1.9746, -1.9747, -1.9746, -1.9746, -1.9746, -1.9746, -1.9746,
           -1.9746],
          [-1.9746, -1.9746, -1.9746, -1.9746, -1.9746, -1.9747, -1.9746,
           -1.9746, -1.9747, -1.9746, -1.9746, -1.9746, -1.9746, -1.9746,
           -1.9746],
          [-1.9746, -1.9746, -1.9746, -1.9746, -1.9746, -1.9747, -1.9746,
           -1.9746, -1.9747, -1.9746, -1.9746, -1.9746, -1.9746, -1.9746,
           -1.9746],
          [-1.9746, -1.9746, -1.9746, -1.9746, -1.9746, -1.9747, -1.9746,
           -1.9746, -1.9747, -1.9746, -1.9746, -1.9746, -1.9746, -1.9746,
           -1.9746],
          [-1.9746, -1.9746, -1.9746, -1.9746, -1.9746, -1.9747, -1.9746,
           -1.9746, -1.9747, -1.9746, -1.9746, -1.9746, -1.9746, -1.9746,
           -1.9746],
          [-1.9746, -1.9746, -1.9746, -1.9746, -1.9746, -1.9747, -1.9746,
           -1.9746, -1.9747, -1.9746, -1.9746, -1.9746, -1.9746, -1.9746,
           -1.9746],
          [-1.9746, -1.9746, -1.9746, -1.9746, -1.9746, -1.9747, -1.9746,
           -1.9746, -1.9747, -1.9746, -1.9746, -1.9746, -1.9746, -1.9746,
           -1.9746],
          [-1.9746, -1.9746, -1.9746, -1.9746, -1.9746, -1.9747, -1.9746,
           -1.9746, -1.9747, -1.9746, -1.9746, -1.9746, -1.9746, -1.9746,
           -1.9746],
          [-1.9746, -1.9746, -1.9746, -1.9746, -1.9746, -1.9747, -1.9746,
           -1.9746, -1.9747, -1.9746, -1.9746, -1.9746, -1.9746, -1.9746,
           -1.9746],
          [-1.9746, -1.9746, -1.9746, -1.9746, -1.9746, -1.9747, -1.9746,
           -1.9746, -1.9747, -1.9746, -1.9746, -1.9746, -1.9746, -1.9746,
           -1.9746],
          [-1.9746, -1.9746, -1.9746, -1.9746, -1.9746, -1.9747, -1.9746,
           -1.9746, -1.9747, -1.9746, -1.9746, -1.9746, -1.9746, -1.9746,
           -1.9746],
          [-1.9746, -1.9746, -1.9746, -1.9746, -1.9746, -1.9747, -1.9746,
           -1.9746, -1.9747, -1.9746, -1.9746, -1.9746, -1.9746, -1.9746,
           -1.9746]]]], grad_fn=<SliceBackward0>)
train_step: Entropy shape: torch.Size([16, 15])
train_step: Entropy sample: tensor([[0.4413, 0.6389],
        [0.5267, 0.6742]], grad_fn=<SliceBackward0>)
train_step: Entropy coefficient: 0.01
train_step: Actor loss: -1.0226829051971436
train_step: returns shape after mean: torch.Size([16, 15])
train_step: target_indices shape: torch.Size([16, 15])
train_step: value_logits shape: torch.Size([16, 15, 255])
train_step: target_twohot shape: torch.Size([16, 15, 255])
--- Starting train_step at 2025-04-01 02:00:34 ---
Full starting_state: {'deter': tensor([[[ 4.1111e-02,  3.7628e-02,  1.7290e-02,  ..., -4.5544e-02,
           3.2032e-02, -7.8154e-02],
         [ 3.7037e-02, -3.3420e-02, -1.1737e-01,  ..., -1.1457e-01,
           6.3177e-02,  1.0939e-01],
         [ 1.0111e-02,  1.9816e-02,  3.7186e-02,  ..., -2.8161e-02,
           9.5312e-02, -3.5227e-02],
         ...,
         [ 2.5532e-02, -3.6786e-03,  4.2481e-02,  ..., -5.4814e-02,
           6.5923e-02, -1.4231e-01],
         [-1.2857e-01, -1.3080e-01, -4.0248e-02,  ..., -9.3111e-02,
           1.5751e-01, -2.2268e-02],
         [-7.5549e-03,  8.9874e-02, -1.2364e-01,  ...,  4.5011e-02,
           9.5911e-02, -1.0781e-01]],

        [[-3.4293e-02, -1.2864e-01, -1.0239e-01,  ...,  4.8450e-02,
           7.8621e-02,  1.6824e-02],
         [ 8.4134e-02,  2.5850e-02, -1.8390e-01,  ...,  4.8583e-02,
           6.4889e-03, -9.9342e-03],
         [-7.7250e-03,  2.1340e-01, -3.2674e-02,  ...,  3.4590e-02,
          -4.2985e-02, -1.0620e-01],
         ...,
         [-3.3479e-02, -1.5947e-01, -1.4322e-01,  ...,  1.2117e-01,
          -8.1992e-02, -6.1653e-02],
         [-7.7189e-02, -7.7914e-02,  1.6284e-01,  ...,  3.8786e-02,
           7.4671e-02, -1.7397e-01],
         [-5.8807e-02, -6.9970e-02, -3.9152e-02,  ...,  1.9160e-02,
          -2.2478e-02, -8.1176e-02]],

        [[-9.7828e-02, -1.0171e-02, -5.8298e-03,  ...,  3.0474e-02,
          -5.4559e-02, -6.6430e-02],
         [-1.5145e-02,  3.8200e-03, -1.2376e-01,  ...,  2.6799e-02,
          -1.9834e-01,  2.0970e-01],
         [-1.0466e-02, -2.4872e-02,  9.1591e-02,  ..., -1.4270e-01,
          -1.8352e-03,  4.6995e-02],
         ...,
         [-5.3876e-02, -1.2477e-02,  3.2567e-02,  ...,  9.8298e-02,
           3.4107e-02,  8.4455e-02],
         [-5.2098e-03, -1.4926e-02, -4.4817e-03,  ..., -1.1748e-01,
          -4.5943e-02,  1.7587e-02],
         [ 1.0195e-01,  5.8234e-03, -1.1009e-03,  ..., -5.5890e-02,
          -1.8366e-02, -1.0141e-01]],

        ...,

        [[-2.1809e-01, -1.1607e-02,  3.1654e-02,  ...,  4.0178e-02,
          -1.2198e-01, -1.3188e-01],
         [-8.1996e-02, -5.4147e-02,  1.1114e-02,  ..., -1.6239e-01,
          -5.3516e-02,  3.4258e-02],
         [-1.2701e-01, -2.8741e-02,  1.2224e-01,  ...,  5.7333e-02,
           1.9716e-02,  1.2178e-01],
         ...,
         [-5.8745e-02, -4.4990e-02, -5.3148e-02,  ..., -4.9702e-02,
           9.0908e-02, -5.5494e-02],
         [-6.9619e-02, -2.7110e-02,  6.3787e-02,  ..., -6.6801e-02,
          -9.4067e-03, -2.3221e-02],
         [-9.8652e-02, -4.0047e-02, -9.5342e-02,  ...,  6.7394e-02,
           4.4182e-02,  1.4588e-01]],

        [[-1.8456e-02, -8.2568e-02,  5.3653e-02,  ..., -4.3518e-02,
          -2.3481e-02,  1.6687e-01],
         [ 2.3569e-02,  6.3954e-02,  9.0108e-03,  ...,  8.0249e-02,
           2.4213e-02,  2.0999e-02],
         [-4.9846e-02,  1.0935e-01, -4.4525e-02,  ...,  2.4265e-01,
           6.3850e-02, -6.1838e-02],
         ...,
         [-1.9164e-01,  6.0233e-02, -1.4022e-02,  ..., -2.2255e-02,
           5.2310e-05,  1.2460e-01],
         [ 4.5953e-03,  1.0478e-01,  2.1083e-03,  ..., -5.1454e-02,
          -1.2039e-01, -2.6136e-01],
         [ 4.3813e-03, -1.2229e-02, -2.3517e-01,  ...,  1.4340e-01,
          -1.8496e-01,  1.7709e-01]],

        [[-3.9725e-02, -7.3888e-02, -1.3003e-01,  ..., -5.1704e-03,
           7.0599e-02, -1.8929e-01],
         [ 9.4896e-02,  4.3135e-02, -1.1750e-01,  ...,  8.8484e-02,
           6.1905e-02,  7.0036e-03],
         [-8.0391e-02,  5.3672e-02, -1.2569e-01,  ..., -1.3007e-01,
           3.3617e-02, -1.1289e-01],
         ...,
         [-4.9644e-02,  1.4132e-01, -1.4568e-02,  ...,  1.0485e-01,
          -1.4484e-01,  1.0052e-01],
         [ 1.2993e-01, -1.0366e-02, -1.0080e-01,  ...,  1.7951e-01,
           9.8402e-03, -1.1435e-01],
         [ 2.4898e-02, -5.9479e-02, -3.8236e-02,  ...,  1.5086e-01,
          -3.7527e-02,  1.1237e-01]]], grad_fn=<StackBackward0>), 'stoch': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 1.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 1., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 1.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [1., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 1., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 1., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]])}
train_step: Starting state deter shape: torch.Size([16, 50, 128])
train_step: Starting state stoch shape: torch.Size([16, 50, 1024])
After ensuring logits/stoch: {'deter': tensor([[[ 4.1111e-02,  3.7628e-02,  1.7290e-02,  ..., -4.5544e-02,
           3.2032e-02, -7.8154e-02],
         [ 3.7037e-02, -3.3420e-02, -1.1737e-01,  ..., -1.1457e-01,
           6.3177e-02,  1.0939e-01],
         [ 1.0111e-02,  1.9816e-02,  3.7186e-02,  ..., -2.8161e-02,
           9.5312e-02, -3.5227e-02],
         ...,
         [ 2.5532e-02, -3.6786e-03,  4.2481e-02,  ..., -5.4814e-02,
           6.5923e-02, -1.4231e-01],
         [-1.2857e-01, -1.3080e-01, -4.0248e-02,  ..., -9.3111e-02,
           1.5751e-01, -2.2268e-02],
         [-7.5549e-03,  8.9874e-02, -1.2364e-01,  ...,  4.5011e-02,
           9.5911e-02, -1.0781e-01]],

        [[-3.4293e-02, -1.2864e-01, -1.0239e-01,  ...,  4.8450e-02,
           7.8621e-02,  1.6824e-02],
         [ 8.4134e-02,  2.5850e-02, -1.8390e-01,  ...,  4.8583e-02,
           6.4889e-03, -9.9342e-03],
         [-7.7250e-03,  2.1340e-01, -3.2674e-02,  ...,  3.4590e-02,
          -4.2985e-02, -1.0620e-01],
         ...,
         [-3.3479e-02, -1.5947e-01, -1.4322e-01,  ...,  1.2117e-01,
          -8.1992e-02, -6.1653e-02],
         [-7.7189e-02, -7.7914e-02,  1.6284e-01,  ...,  3.8786e-02,
           7.4671e-02, -1.7397e-01],
         [-5.8807e-02, -6.9970e-02, -3.9152e-02,  ...,  1.9160e-02,
          -2.2478e-02, -8.1176e-02]],

        [[-9.7828e-02, -1.0171e-02, -5.8298e-03,  ...,  3.0474e-02,
          -5.4559e-02, -6.6430e-02],
         [-1.5145e-02,  3.8200e-03, -1.2376e-01,  ...,  2.6799e-02,
          -1.9834e-01,  2.0970e-01],
         [-1.0466e-02, -2.4872e-02,  9.1591e-02,  ..., -1.4270e-01,
          -1.8352e-03,  4.6995e-02],
         ...,
         [-5.3876e-02, -1.2477e-02,  3.2567e-02,  ...,  9.8298e-02,
           3.4107e-02,  8.4455e-02],
         [-5.2098e-03, -1.4926e-02, -4.4817e-03,  ..., -1.1748e-01,
          -4.5943e-02,  1.7587e-02],
         [ 1.0195e-01,  5.8234e-03, -1.1009e-03,  ..., -5.5890e-02,
          -1.8366e-02, -1.0141e-01]],

        ...,

        [[-2.1809e-01, -1.1607e-02,  3.1654e-02,  ...,  4.0178e-02,
          -1.2198e-01, -1.3188e-01],
         [-8.1996e-02, -5.4147e-02,  1.1114e-02,  ..., -1.6239e-01,
          -5.3516e-02,  3.4258e-02],
         [-1.2701e-01, -2.8741e-02,  1.2224e-01,  ...,  5.7333e-02,
           1.9716e-02,  1.2178e-01],
         ...,
         [-5.8745e-02, -4.4990e-02, -5.3148e-02,  ..., -4.9702e-02,
           9.0908e-02, -5.5494e-02],
         [-6.9619e-02, -2.7110e-02,  6.3787e-02,  ..., -6.6801e-02,
          -9.4067e-03, -2.3221e-02],
         [-9.8652e-02, -4.0047e-02, -9.5342e-02,  ...,  6.7394e-02,
           4.4182e-02,  1.4588e-01]],

        [[-1.8456e-02, -8.2568e-02,  5.3653e-02,  ..., -4.3518e-02,
          -2.3481e-02,  1.6687e-01],
         [ 2.3569e-02,  6.3954e-02,  9.0108e-03,  ...,  8.0249e-02,
           2.4213e-02,  2.0999e-02],
         [-4.9846e-02,  1.0935e-01, -4.4525e-02,  ...,  2.4265e-01,
           6.3850e-02, -6.1838e-02],
         ...,
         [-1.9164e-01,  6.0233e-02, -1.4022e-02,  ..., -2.2255e-02,
           5.2310e-05,  1.2460e-01],
         [ 4.5953e-03,  1.0478e-01,  2.1083e-03,  ..., -5.1454e-02,
          -1.2039e-01, -2.6136e-01],
         [ 4.3813e-03, -1.2229e-02, -2.3517e-01,  ...,  1.4340e-01,
          -1.8496e-01,  1.7709e-01]],

        [[-3.9725e-02, -7.3888e-02, -1.3003e-01,  ..., -5.1704e-03,
           7.0599e-02, -1.8929e-01],
         [ 9.4896e-02,  4.3135e-02, -1.1750e-01,  ...,  8.8484e-02,
           6.1905e-02,  7.0036e-03],
         [-8.0391e-02,  5.3672e-02, -1.2569e-01,  ..., -1.3007e-01,
           3.3617e-02, -1.1289e-01],
         ...,
         [-4.9644e-02,  1.4132e-01, -1.4568e-02,  ...,  1.0485e-01,
          -1.4484e-01,  1.0052e-01],
         [ 1.2993e-01, -1.0366e-02, -1.0080e-01,  ...,  1.7951e-01,
           9.8402e-03, -1.1435e-01],
         [ 2.4898e-02, -5.9479e-02, -3.8236e-02,  ...,  1.5086e-01,
          -3.7527e-02,  1.1237e-01]]], grad_fn=<StackBackward0>), 'stoch': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 1.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 1., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 1.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [1., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 1., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 1., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]]), 'logits': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]])}
train_step: Normalized hidden_state shape: torch.Size([1, 16, 128])
train_step: Normalized stoch shape: torch.Size([16, 1024])
train_step: Normalized deter shape: torch.Size([16, 128])
train_step: Post-imagine_trajectory: Imagined features shape: torch.Size([16, 15, 1152])
train_step: Post-imagine_trajectory: Imagined actions shape: torch.Size([16, 15, 2])
train_step: Post-imagine_trajectory: Imagined action indices shape: torch.Size([16, 15])
train_step: Post-imagine_trajectory: Imagined state deter shape: torch.Size([16, 15, 128])
train_step: Post-imagine_trajectory: Imagined state stoch shape: torch.Size([16, 15, 1024])
Reward shape: torch.Size([16, 15, 1]), Value shape: torch.Size([16, 15, 1]), Slow Value shape: torch.Size([16, 15, 1]), Discount shape: torch.Size([16, 15, 1, 1])
Return targets length: 15, First target shape: torch.Size([16, 16, 1])
train_step: Actor distribution shape: torch.Size([16, 15, 2])
train_step: Action log probabilities shape: torch.Size([16, 15])
train_step: Action log probabilities sample: tensor([[-0.4778, -0.9506],
        [-0.1570, -0.2109]], grad_fn=<SliceBackward0>)
train_step: Advantages shape: torch.Size([16, 15, 16, 15])
train_step: Advantages sample: tensor([[[[-4.0836, -4.0837, -4.0837, -4.0836, -4.0836, -4.0836, -4.0837,
           -4.0836, -4.0836, -4.0836, -4.0836, -4.0837, -4.0837, -4.0836,
           -4.0837],
          [-4.0836, -4.0837, -4.0837, -4.0836, -4.0836, -4.0836, -4.0837,
           -4.0836, -4.0836, -4.0836, -4.0836, -4.0837, -4.0837, -4.0836,
           -4.0837],
          [-4.0836, -4.0837, -4.0837, -4.0836, -4.0836, -4.0836, -4.0837,
           -4.0836, -4.0836, -4.0836, -4.0836, -4.0837, -4.0837, -4.0836,
           -4.0837],
          [-4.0836, -4.0837, -4.0837, -4.0836, -4.0836, -4.0836, -4.0837,
           -4.0836, -4.0836, -4.0836, -4.0836, -4.0837, -4.0837, -4.0836,
           -4.0837],
          [-4.0836, -4.0837, -4.0837, -4.0836, -4.0836, -4.0836, -4.0837,
           -4.0836, -4.0836, -4.0836, -4.0836, -4.0837, -4.0837, -4.0836,
           -4.0837],
          [-4.0836, -4.0837, -4.0837, -4.0836, -4.0836, -4.0836, -4.0837,
           -4.0836, -4.0836, -4.0836, -4.0836, -4.0837, -4.0837, -4.0836,
           -4.0837],
          [-4.0836, -4.0837, -4.0837, -4.0836, -4.0836, -4.0836, -4.0837,
           -4.0836, -4.0836, -4.0836, -4.0836, -4.0837, -4.0837, -4.0836,
           -4.0837],
          [-4.0836, -4.0837, -4.0837, -4.0836, -4.0836, -4.0836, -4.0837,
           -4.0836, -4.0836, -4.0836, -4.0836, -4.0837, -4.0837, -4.0836,
           -4.0837],
          [-4.0836, -4.0837, -4.0837, -4.0836, -4.0836, -4.0836, -4.0837,
           -4.0836, -4.0836, -4.0836, -4.0836, -4.0837, -4.0837, -4.0836,
           -4.0837],
          [-4.0836, -4.0837, -4.0837, -4.0836, -4.0836, -4.0836, -4.0837,
           -4.0836, -4.0836, -4.0836, -4.0836, -4.0837, -4.0837, -4.0836,
           -4.0837],
          [-4.0836, -4.0837, -4.0837, -4.0836, -4.0836, -4.0836, -4.0837,
           -4.0836, -4.0836, -4.0836, -4.0836, -4.0837, -4.0837, -4.0836,
           -4.0837],
          [-4.0836, -4.0837, -4.0837, -4.0836, -4.0836, -4.0836, -4.0837,
           -4.0836, -4.0836, -4.0836, -4.0836, -4.0837, -4.0837, -4.0836,
           -4.0837],
          [-4.0836, -4.0837, -4.0837, -4.0836, -4.0836, -4.0836, -4.0837,
           -4.0836, -4.0836, -4.0836, -4.0836, -4.0837, -4.0837, -4.0836,
           -4.0837],
          [-4.0836, -4.0837, -4.0837, -4.0836, -4.0836, -4.0836, -4.0837,
           -4.0836, -4.0836, -4.0836, -4.0836, -4.0837, -4.0837, -4.0836,
           -4.0837],
          [-4.0836, -4.0837, -4.0837, -4.0836, -4.0836, -4.0836, -4.0837,
           -4.0836, -4.0836, -4.0836, -4.0836, -4.0837, -4.0837, -4.0836,
           -4.0837],
          [-4.0836, -4.0837, -4.0837, -4.0836, -4.0836, -4.0836, -4.0837,
           -4.0836, -4.0836, -4.0836, -4.0836, -4.0837, -4.0837, -4.0836,
           -4.0837]],

         [[-3.7062, -3.7062, -3.7061, -3.7061, -3.7062, -3.7061, -3.7061,
           -3.7061, -3.7062, -3.7061, -3.7062, -3.7062, -3.7061, -3.7061,
           -3.7062],
          [-3.7062, -3.7062, -3.7061, -3.7061, -3.7062, -3.7061, -3.7061,
           -3.7061, -3.7062, -3.7061, -3.7062, -3.7062, -3.7061, -3.7061,
           -3.7062],
          [-3.7062, -3.7062, -3.7061, -3.7061, -3.7062, -3.7061, -3.7061,
           -3.7061, -3.7062, -3.7061, -3.7062, -3.7062, -3.7061, -3.7061,
           -3.7062],
          [-3.7062, -3.7062, -3.7061, -3.7061, -3.7062, -3.7061, -3.7061,
           -3.7061, -3.7062, -3.7061, -3.7062, -3.7062, -3.7061, -3.7061,
           -3.7062],
          [-3.7062, -3.7062, -3.7061, -3.7061, -3.7062, -3.7061, -3.7061,
           -3.7061, -3.7062, -3.7061, -3.7062, -3.7062, -3.7061, -3.7061,
           -3.7062],
          [-3.7062, -3.7062, -3.7061, -3.7061, -3.7062, -3.7061, -3.7061,
           -3.7061, -3.7062, -3.7061, -3.7062, -3.7062, -3.7061, -3.7061,
           -3.7062],
          [-3.7062, -3.7062, -3.7061, -3.7061, -3.7062, -3.7061, -3.7061,
           -3.7061, -3.7062, -3.7061, -3.7062, -3.7062, -3.7061, -3.7061,
           -3.7062],
          [-3.7062, -3.7062, -3.7061, -3.7061, -3.7062, -3.7061, -3.7061,
           -3.7061, -3.7062, -3.7061, -3.7062, -3.7062, -3.7061, -3.7061,
           -3.7062],
          [-3.7062, -3.7062, -3.7061, -3.7061, -3.7062, -3.7061, -3.7061,
           -3.7061, -3.7062, -3.7061, -3.7062, -3.7062, -3.7061, -3.7061,
           -3.7062],
          [-3.7062, -3.7062, -3.7061, -3.7061, -3.7062, -3.7061, -3.7061,
           -3.7061, -3.7062, -3.7061, -3.7062, -3.7062, -3.7061, -3.7061,
           -3.7062],
          [-3.7062, -3.7062, -3.7061, -3.7061, -3.7062, -3.7061, -3.7061,
           -3.7061, -3.7062, -3.7061, -3.7062, -3.7062, -3.7061, -3.7061,
           -3.7062],
          [-3.7062, -3.7062, -3.7061, -3.7061, -3.7062, -3.7061, -3.7061,
           -3.7061, -3.7062, -3.7061, -3.7062, -3.7062, -3.7061, -3.7061,
           -3.7062],
          [-3.7062, -3.7062, -3.7061, -3.7061, -3.7062, -3.7061, -3.7061,
           -3.7061, -3.7062, -3.7061, -3.7062, -3.7062, -3.7061, -3.7061,
           -3.7062],
          [-3.7062, -3.7062, -3.7061, -3.7061, -3.7062, -3.7061, -3.7061,
           -3.7061, -3.7062, -3.7061, -3.7062, -3.7062, -3.7061, -3.7061,
           -3.7062],
          [-3.7062, -3.7062, -3.7061, -3.7061, -3.7062, -3.7061, -3.7061,
           -3.7061, -3.7062, -3.7061, -3.7062, -3.7062, -3.7061, -3.7061,
           -3.7062],
          [-3.7062, -3.7062, -3.7061, -3.7061, -3.7062, -3.7061, -3.7061,
           -3.7061, -3.7062, -3.7061, -3.7062, -3.7062, -3.7061, -3.7061,
           -3.7062]]],


        [[[-6.0048, -6.0049, -6.0049, -6.0048, -6.0049, -6.0048, -6.0049,
           -6.0048, -6.0048, -6.0048, -6.0048, -6.0049, -6.0049, -6.0049,
           -6.0049],
          [-6.0048, -6.0049, -6.0049, -6.0048, -6.0049, -6.0048, -6.0049,
           -6.0048, -6.0048, -6.0048, -6.0048, -6.0049, -6.0049, -6.0049,
           -6.0049],
          [-6.0048, -6.0049, -6.0049, -6.0048, -6.0049, -6.0048, -6.0049,
           -6.0048, -6.0048, -6.0048, -6.0048, -6.0049, -6.0049, -6.0049,
           -6.0049],
          [-6.0048, -6.0049, -6.0049, -6.0048, -6.0049, -6.0048, -6.0049,
           -6.0048, -6.0048, -6.0048, -6.0048, -6.0049, -6.0049, -6.0049,
           -6.0049],
          [-6.0048, -6.0049, -6.0049, -6.0048, -6.0049, -6.0048, -6.0049,
           -6.0048, -6.0048, -6.0048, -6.0048, -6.0049, -6.0049, -6.0049,
           -6.0049],
          [-6.0048, -6.0049, -6.0049, -6.0048, -6.0049, -6.0048, -6.0049,
           -6.0048, -6.0048, -6.0048, -6.0048, -6.0049, -6.0049, -6.0049,
           -6.0049],
          [-6.0048, -6.0049, -6.0049, -6.0048, -6.0049, -6.0048, -6.0049,
           -6.0048, -6.0048, -6.0048, -6.0048, -6.0049, -6.0049, -6.0049,
           -6.0049],
          [-6.0048, -6.0049, -6.0049, -6.0048, -6.0049, -6.0048, -6.0049,
           -6.0048, -6.0048, -6.0048, -6.0048, -6.0049, -6.0049, -6.0049,
           -6.0049],
          [-6.0048, -6.0049, -6.0049, -6.0048, -6.0049, -6.0048, -6.0049,
           -6.0048, -6.0048, -6.0048, -6.0048, -6.0049, -6.0049, -6.0049,
           -6.0049],
          [-6.0048, -6.0049, -6.0049, -6.0048, -6.0049, -6.0048, -6.0049,
           -6.0048, -6.0048, -6.0048, -6.0048, -6.0049, -6.0049, -6.0049,
           -6.0049],
          [-6.0048, -6.0049, -6.0049, -6.0048, -6.0049, -6.0048, -6.0049,
           -6.0048, -6.0048, -6.0048, -6.0048, -6.0049, -6.0049, -6.0049,
           -6.0049],
          [-6.0048, -6.0049, -6.0049, -6.0048, -6.0049, -6.0048, -6.0049,
           -6.0048, -6.0048, -6.0048, -6.0048, -6.0049, -6.0049, -6.0049,
           -6.0049],
          [-6.0048, -6.0049, -6.0049, -6.0048, -6.0049, -6.0048, -6.0049,
           -6.0048, -6.0048, -6.0048, -6.0048, -6.0049, -6.0049, -6.0049,
           -6.0049],
          [-6.0048, -6.0049, -6.0049, -6.0048, -6.0049, -6.0048, -6.0049,
           -6.0048, -6.0048, -6.0048, -6.0048, -6.0049, -6.0049, -6.0049,
           -6.0049],
          [-6.0048, -6.0049, -6.0049, -6.0048, -6.0049, -6.0048, -6.0049,
           -6.0048, -6.0048, -6.0048, -6.0048, -6.0049, -6.0049, -6.0049,
           -6.0049],
          [-6.0048, -6.0049, -6.0049, -6.0048, -6.0049, -6.0048, -6.0049,
           -6.0048, -6.0048, -6.0048, -6.0048, -6.0049, -6.0049, -6.0049,
           -6.0049]],

         [[-6.1630, -6.1630, -6.1630, -6.1630, -6.1630, -6.1630, -6.1630,
           -6.1630, -6.1630, -6.1630, -6.1630, -6.1630, -6.1630, -6.1629,
           -6.1631],
          [-6.1630, -6.1630, -6.1630, -6.1630, -6.1630, -6.1630, -6.1630,
           -6.1630, -6.1630, -6.1630, -6.1630, -6.1630, -6.1630, -6.1629,
           -6.1631],
          [-6.1630, -6.1630, -6.1630, -6.1630, -6.1630, -6.1630, -6.1630,
           -6.1630, -6.1630, -6.1630, -6.1630, -6.1630, -6.1630, -6.1629,
           -6.1631],
          [-6.1630, -6.1630, -6.1630, -6.1630, -6.1630, -6.1630, -6.1630,
           -6.1630, -6.1630, -6.1630, -6.1630, -6.1630, -6.1630, -6.1629,
           -6.1631],
          [-6.1630, -6.1630, -6.1630, -6.1630, -6.1630, -6.1630, -6.1630,
           -6.1630, -6.1630, -6.1630, -6.1630, -6.1630, -6.1630, -6.1629,
           -6.1631],
          [-6.1630, -6.1630, -6.1630, -6.1630, -6.1630, -6.1630, -6.1630,
           -6.1630, -6.1630, -6.1630, -6.1630, -6.1630, -6.1630, -6.1629,
           -6.1631],
          [-6.1630, -6.1630, -6.1630, -6.1630, -6.1630, -6.1630, -6.1630,
           -6.1630, -6.1630, -6.1630, -6.1630, -6.1630, -6.1630, -6.1629,
           -6.1631],
          [-6.1630, -6.1630, -6.1630, -6.1630, -6.1630, -6.1630, -6.1630,
           -6.1630, -6.1630, -6.1630, -6.1630, -6.1630, -6.1630, -6.1629,
           -6.1631],
          [-6.1630, -6.1630, -6.1630, -6.1630, -6.1630, -6.1630, -6.1630,
           -6.1630, -6.1630, -6.1630, -6.1630, -6.1630, -6.1630, -6.1629,
           -6.1631],
          [-6.1630, -6.1630, -6.1630, -6.1630, -6.1630, -6.1630, -6.1630,
           -6.1630, -6.1630, -6.1630, -6.1630, -6.1630, -6.1630, -6.1629,
           -6.1631],
          [-6.1630, -6.1630, -6.1630, -6.1630, -6.1630, -6.1630, -6.1630,
           -6.1630, -6.1630, -6.1630, -6.1630, -6.1630, -6.1630, -6.1629,
           -6.1631],
          [-6.1630, -6.1630, -6.1630, -6.1630, -6.1630, -6.1630, -6.1630,
           -6.1630, -6.1630, -6.1630, -6.1630, -6.1630, -6.1630, -6.1629,
           -6.1631],
          [-6.1630, -6.1630, -6.1630, -6.1630, -6.1630, -6.1630, -6.1630,
           -6.1630, -6.1630, -6.1630, -6.1630, -6.1630, -6.1630, -6.1629,
           -6.1631],
          [-6.1630, -6.1630, -6.1630, -6.1630, -6.1630, -6.1630, -6.1630,
           -6.1630, -6.1630, -6.1630, -6.1630, -6.1630, -6.1630, -6.1629,
           -6.1631],
          [-6.1630, -6.1630, -6.1630, -6.1630, -6.1630, -6.1630, -6.1630,
           -6.1630, -6.1630, -6.1630, -6.1630, -6.1630, -6.1630, -6.1629,
           -6.1631],
          [-6.1630, -6.1630, -6.1630, -6.1630, -6.1630, -6.1630, -6.1630,
           -6.1630, -6.1630, -6.1630, -6.1630, -6.1630, -6.1630, -6.1629,
           -6.1631]]]], grad_fn=<SliceBackward0>)
train_step: Return scale: 1.8043496746320078
train_step: Scaled advantages shape: torch.Size([16, 15, 16, 15])
train_step: Scaled advantages sample: tensor([[[[-2.2632, -2.2632, -2.2632, -2.2632, -2.2632, -2.2632, -2.2632,
           -2.2632, -2.2632, -2.2632, -2.2632, -2.2632, -2.2632, -2.2632,
           -2.2632],
          [-2.2632, -2.2632, -2.2632, -2.2632, -2.2632, -2.2632, -2.2632,
           -2.2632, -2.2632, -2.2632, -2.2632, -2.2632, -2.2632, -2.2632,
           -2.2632],
          [-2.2632, -2.2632, -2.2632, -2.2632, -2.2632, -2.2632, -2.2632,
           -2.2632, -2.2632, -2.2632, -2.2632, -2.2632, -2.2632, -2.2632,
           -2.2632],
          [-2.2632, -2.2632, -2.2632, -2.2632, -2.2632, -2.2632, -2.2632,
           -2.2632, -2.2632, -2.2632, -2.2632, -2.2632, -2.2632, -2.2632,
           -2.2632],
          [-2.2632, -2.2632, -2.2632, -2.2632, -2.2632, -2.2632, -2.2632,
           -2.2632, -2.2632, -2.2632, -2.2632, -2.2632, -2.2632, -2.2632,
           -2.2632],
          [-2.2632, -2.2632, -2.2632, -2.2632, -2.2632, -2.2632, -2.2632,
           -2.2632, -2.2632, -2.2632, -2.2632, -2.2632, -2.2632, -2.2632,
           -2.2632],
          [-2.2632, -2.2632, -2.2632, -2.2632, -2.2632, -2.2632, -2.2632,
           -2.2632, -2.2632, -2.2632, -2.2632, -2.2632, -2.2632, -2.2632,
           -2.2632],
          [-2.2632, -2.2632, -2.2632, -2.2632, -2.2632, -2.2632, -2.2632,
           -2.2632, -2.2632, -2.2632, -2.2632, -2.2632, -2.2632, -2.2632,
           -2.2632],
          [-2.2632, -2.2632, -2.2632, -2.2632, -2.2632, -2.2632, -2.2632,
           -2.2632, -2.2632, -2.2632, -2.2632, -2.2632, -2.2632, -2.2632,
           -2.2632],
          [-2.2632, -2.2632, -2.2632, -2.2632, -2.2632, -2.2632, -2.2632,
           -2.2632, -2.2632, -2.2632, -2.2632, -2.2632, -2.2632, -2.2632,
           -2.2632],
          [-2.2632, -2.2632, -2.2632, -2.2632, -2.2632, -2.2632, -2.2632,
           -2.2632, -2.2632, -2.2632, -2.2632, -2.2632, -2.2632, -2.2632,
           -2.2632],
          [-2.2632, -2.2632, -2.2632, -2.2632, -2.2632, -2.2632, -2.2632,
           -2.2632, -2.2632, -2.2632, -2.2632, -2.2632, -2.2632, -2.2632,
           -2.2632],
          [-2.2632, -2.2632, -2.2632, -2.2632, -2.2632, -2.2632, -2.2632,
           -2.2632, -2.2632, -2.2632, -2.2632, -2.2632, -2.2632, -2.2632,
           -2.2632],
          [-2.2632, -2.2632, -2.2632, -2.2632, -2.2632, -2.2632, -2.2632,
           -2.2632, -2.2632, -2.2632, -2.2632, -2.2632, -2.2632, -2.2632,
           -2.2632],
          [-2.2632, -2.2632, -2.2632, -2.2632, -2.2632, -2.2632, -2.2632,
           -2.2632, -2.2632, -2.2632, -2.2632, -2.2632, -2.2632, -2.2632,
           -2.2632],
          [-2.2632, -2.2632, -2.2632, -2.2632, -2.2632, -2.2632, -2.2632,
           -2.2632, -2.2632, -2.2632, -2.2632, -2.2632, -2.2632, -2.2632,
           -2.2632]],

         [[-2.0540, -2.0540, -2.0540, -2.0540, -2.0540, -2.0540, -2.0540,
           -2.0540, -2.0540, -2.0540, -2.0540, -2.0540, -2.0540, -2.0540,
           -2.0540],
          [-2.0540, -2.0540, -2.0540, -2.0540, -2.0540, -2.0540, -2.0540,
           -2.0540, -2.0540, -2.0540, -2.0540, -2.0540, -2.0540, -2.0540,
           -2.0540],
          [-2.0540, -2.0540, -2.0540, -2.0540, -2.0540, -2.0540, -2.0540,
           -2.0540, -2.0540, -2.0540, -2.0540, -2.0540, -2.0540, -2.0540,
           -2.0540],
          [-2.0540, -2.0540, -2.0540, -2.0540, -2.0540, -2.0540, -2.0540,
           -2.0540, -2.0540, -2.0540, -2.0540, -2.0540, -2.0540, -2.0540,
           -2.0540],
          [-2.0540, -2.0540, -2.0540, -2.0540, -2.0540, -2.0540, -2.0540,
           -2.0540, -2.0540, -2.0540, -2.0540, -2.0540, -2.0540, -2.0540,
           -2.0540],
          [-2.0540, -2.0540, -2.0540, -2.0540, -2.0540, -2.0540, -2.0540,
           -2.0540, -2.0540, -2.0540, -2.0540, -2.0540, -2.0540, -2.0540,
           -2.0540],
          [-2.0540, -2.0540, -2.0540, -2.0540, -2.0540, -2.0540, -2.0540,
           -2.0540, -2.0540, -2.0540, -2.0540, -2.0540, -2.0540, -2.0540,
           -2.0540],
          [-2.0540, -2.0540, -2.0540, -2.0540, -2.0540, -2.0540, -2.0540,
           -2.0540, -2.0540, -2.0540, -2.0540, -2.0540, -2.0540, -2.0540,
           -2.0540],
          [-2.0540, -2.0540, -2.0540, -2.0540, -2.0540, -2.0540, -2.0540,
           -2.0540, -2.0540, -2.0540, -2.0540, -2.0540, -2.0540, -2.0540,
           -2.0540],
          [-2.0540, -2.0540, -2.0540, -2.0540, -2.0540, -2.0540, -2.0540,
           -2.0540, -2.0540, -2.0540, -2.0540, -2.0540, -2.0540, -2.0540,
           -2.0540],
          [-2.0540, -2.0540, -2.0540, -2.0540, -2.0540, -2.0540, -2.0540,
           -2.0540, -2.0540, -2.0540, -2.0540, -2.0540, -2.0540, -2.0540,
           -2.0540],
          [-2.0540, -2.0540, -2.0540, -2.0540, -2.0540, -2.0540, -2.0540,
           -2.0540, -2.0540, -2.0540, -2.0540, -2.0540, -2.0540, -2.0540,
           -2.0540],
          [-2.0540, -2.0540, -2.0540, -2.0540, -2.0540, -2.0540, -2.0540,
           -2.0540, -2.0540, -2.0540, -2.0540, -2.0540, -2.0540, -2.0540,
           -2.0540],
          [-2.0540, -2.0540, -2.0540, -2.0540, -2.0540, -2.0540, -2.0540,
           -2.0540, -2.0540, -2.0540, -2.0540, -2.0540, -2.0540, -2.0540,
           -2.0540],
          [-2.0540, -2.0540, -2.0540, -2.0540, -2.0540, -2.0540, -2.0540,
           -2.0540, -2.0540, -2.0540, -2.0540, -2.0540, -2.0540, -2.0540,
           -2.0540],
          [-2.0540, -2.0540, -2.0540, -2.0540, -2.0540, -2.0540, -2.0540,
           -2.0540, -2.0540, -2.0540, -2.0540, -2.0540, -2.0540, -2.0540,
           -2.0540]]],


        [[[-3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280,
           -3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280,
           -3.3280],
          [-3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280,
           -3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280,
           -3.3280],
          [-3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280,
           -3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280,
           -3.3280],
          [-3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280,
           -3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280,
           -3.3280],
          [-3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280,
           -3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280,
           -3.3280],
          [-3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280,
           -3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280,
           -3.3280],
          [-3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280,
           -3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280,
           -3.3280],
          [-3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280,
           -3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280,
           -3.3280],
          [-3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280,
           -3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280,
           -3.3280],
          [-3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280,
           -3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280,
           -3.3280],
          [-3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280,
           -3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280,
           -3.3280],
          [-3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280,
           -3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280,
           -3.3280],
          [-3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280,
           -3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280,
           -3.3280],
          [-3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280,
           -3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280,
           -3.3280],
          [-3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280,
           -3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280,
           -3.3280],
          [-3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280,
           -3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280, -3.3280,
           -3.3280]],

         [[-3.4156, -3.4157, -3.4156, -3.4156, -3.4156, -3.4156, -3.4156,
           -3.4156, -3.4156, -3.4156, -3.4156, -3.4156, -3.4156, -3.4156,
           -3.4157],
          [-3.4156, -3.4157, -3.4156, -3.4156, -3.4156, -3.4156, -3.4156,
           -3.4156, -3.4156, -3.4156, -3.4156, -3.4156, -3.4156, -3.4156,
           -3.4157],
          [-3.4156, -3.4157, -3.4156, -3.4156, -3.4156, -3.4156, -3.4156,
           -3.4156, -3.4156, -3.4156, -3.4156, -3.4156, -3.4156, -3.4156,
           -3.4157],
          [-3.4156, -3.4157, -3.4156, -3.4156, -3.4156, -3.4156, -3.4156,
           -3.4156, -3.4156, -3.4156, -3.4156, -3.4156, -3.4156, -3.4156,
           -3.4157],
          [-3.4156, -3.4157, -3.4156, -3.4156, -3.4156, -3.4156, -3.4156,
           -3.4156, -3.4156, -3.4156, -3.4156, -3.4156, -3.4156, -3.4156,
           -3.4157],
          [-3.4156, -3.4157, -3.4156, -3.4156, -3.4156, -3.4156, -3.4156,
           -3.4156, -3.4156, -3.4156, -3.4156, -3.4156, -3.4156, -3.4156,
           -3.4157],
          [-3.4156, -3.4157, -3.4156, -3.4156, -3.4156, -3.4156, -3.4156,
           -3.4156, -3.4156, -3.4156, -3.4156, -3.4156, -3.4156, -3.4156,
           -3.4157],
          [-3.4156, -3.4157, -3.4156, -3.4156, -3.4156, -3.4156, -3.4156,
           -3.4156, -3.4156, -3.4156, -3.4156, -3.4156, -3.4156, -3.4156,
           -3.4157],
          [-3.4156, -3.4157, -3.4156, -3.4156, -3.4156, -3.4156, -3.4156,
           -3.4156, -3.4156, -3.4156, -3.4156, -3.4156, -3.4156, -3.4156,
           -3.4157],
          [-3.4156, -3.4157, -3.4156, -3.4156, -3.4156, -3.4156, -3.4156,
           -3.4156, -3.4156, -3.4156, -3.4156, -3.4156, -3.4156, -3.4156,
           -3.4157],
          [-3.4156, -3.4157, -3.4156, -3.4156, -3.4156, -3.4156, -3.4156,
           -3.4156, -3.4156, -3.4156, -3.4156, -3.4156, -3.4156, -3.4156,
           -3.4157],
          [-3.4156, -3.4157, -3.4156, -3.4156, -3.4156, -3.4156, -3.4156,
           -3.4156, -3.4156, -3.4156, -3.4156, -3.4156, -3.4156, -3.4156,
           -3.4157],
          [-3.4156, -3.4157, -3.4156, -3.4156, -3.4156, -3.4156, -3.4156,
           -3.4156, -3.4156, -3.4156, -3.4156, -3.4156, -3.4156, -3.4156,
           -3.4157],
          [-3.4156, -3.4157, -3.4156, -3.4156, -3.4156, -3.4156, -3.4156,
           -3.4156, -3.4156, -3.4156, -3.4156, -3.4156, -3.4156, -3.4156,
           -3.4157],
          [-3.4156, -3.4157, -3.4156, -3.4156, -3.4156, -3.4156, -3.4156,
           -3.4156, -3.4156, -3.4156, -3.4156, -3.4156, -3.4156, -3.4156,
           -3.4157],
          [-3.4156, -3.4157, -3.4156, -3.4156, -3.4156, -3.4156, -3.4156,
           -3.4156, -3.4156, -3.4156, -3.4156, -3.4156, -3.4156, -3.4156,
           -3.4157]]]], grad_fn=<SliceBackward0>)
train_step: Entropy shape: torch.Size([16, 15])
train_step: Entropy sample: tensor([[0.6640, 0.6672],
        [0.4144, 0.4864]], grad_fn=<SliceBackward0>)
train_step: Entropy coefficient: 0.01
train_step: Actor loss: -1.0467331409454346
train_step: returns shape after mean: torch.Size([16, 15])
train_step: target_indices shape: torch.Size([16, 15])
train_step: value_logits shape: torch.Size([16, 15, 255])
train_step: target_twohot shape: torch.Size([16, 15, 255])
--- Starting train_step at 2025-04-01 02:00:52 ---
Full starting_state: {'deter': tensor([[[-1.9107e-02, -4.6226e-02,  1.1742e-01,  ..., -2.6278e-02,
          -4.1729e-02, -7.2898e-02],
         [-1.2040e-01, -5.3884e-02,  4.4785e-02,  ...,  1.1616e-01,
           1.6936e-01,  7.3490e-03],
         [-1.3971e-01, -2.4909e-04,  2.6558e-02,  ..., -9.8025e-02,
          -1.4185e-01, -8.9354e-02],
         ...,
         [-6.8102e-03,  1.3878e-01, -7.6511e-02,  ...,  1.0299e-01,
           1.0560e-01,  1.7670e-01],
         [-1.5814e-01,  2.8932e-03, -2.1138e-02,  ...,  9.9884e-02,
          -1.2453e-02,  3.9327e-02],
         [ 1.4765e-01, -1.8151e-02, -4.4602e-02,  ...,  5.1193e-02,
          -3.0422e-02,  2.5983e-02]],

        [[-2.2505e-01, -1.4614e-01, -5.4082e-02,  ..., -7.7092e-02,
           6.5634e-02, -3.0132e-02],
         [-3.6947e-02, -8.4629e-02, -6.7409e-03,  ..., -1.2252e-01,
           5.2054e-02,  2.9556e-02],
         [ 2.7194e-02, -1.0567e-01, -1.8114e-01,  ...,  3.0348e-02,
           4.4100e-02, -2.5024e-01],
         ...,
         [-3.8581e-02, -2.7639e-02, -4.7807e-02,  ...,  2.0734e-01,
          -2.4588e-02, -4.8136e-02],
         [ 8.2808e-02,  1.0990e-02, -1.3178e-01,  ..., -8.1087e-03,
          -8.0986e-02, -1.1885e-01],
         [-1.1197e-01, -1.6791e-01, -9.4943e-02,  ..., -1.0211e-01,
           1.2124e-01, -7.2154e-02]],

        [[-1.2319e-01, -2.3423e-02, -1.7977e-02,  ...,  8.8870e-02,
           1.1525e-01, -1.3005e-01],
         [-4.2040e-02,  1.3244e-01, -7.5954e-02,  ..., -1.3359e-01,
          -1.0507e-01,  2.2691e-03],
         [-6.3900e-02,  2.5528e-02,  3.3649e-02,  ..., -1.4045e-01,
           1.8348e-01, -9.2773e-02],
         ...,
         [-1.0545e-02, -9.9873e-02,  1.2073e-01,  ...,  8.6451e-02,
          -9.3352e-03,  8.2541e-02],
         [ 8.1156e-02, -9.5993e-02,  6.5318e-02,  ..., -7.4027e-02,
           1.3986e-01, -6.0953e-02],
         [-7.2469e-02, -1.3213e-01,  6.0393e-02,  ..., -7.6299e-02,
          -5.5443e-02, -3.5069e-02]],

        ...,

        [[-5.2218e-02, -4.6901e-02, -1.1648e-02,  ...,  1.1820e-01,
          -1.9364e-01, -5.9870e-02],
         [-2.9035e-02,  1.7100e-02,  1.0245e-01,  ...,  9.5438e-03,
          -1.2093e-01, -2.7642e-02],
         [ 1.4072e-02,  2.8879e-02, -1.1897e-01,  ..., -2.1259e-01,
           6.7392e-02, -1.6834e-01],
         ...,
         [ 5.5824e-02,  6.2676e-02, -9.7869e-02,  ...,  7.2470e-03,
           2.2843e-02,  4.6740e-02],
         [-2.6173e-01, -2.0387e-02, -1.3663e-02,  ..., -6.1821e-02,
           1.4489e-01,  5.1699e-02],
         [-3.9072e-02, -1.0551e-01, -1.3073e-02,  ...,  1.1253e-01,
          -5.1878e-02, -9.2027e-02]],

        [[-3.3957e-03,  8.9548e-02,  8.9662e-03,  ...,  1.0278e-01,
          -3.3737e-02,  7.0651e-02],
         [-6.0904e-02, -7.5880e-02, -4.1782e-02,  ..., -1.1022e-01,
           3.5756e-02, -2.3964e-03],
         [-1.0494e-01, -1.8765e-01,  1.4748e-01,  ..., -1.7597e-01,
          -8.7838e-02, -5.0498e-02],
         ...,
         [-2.6364e-02, -2.2376e-01, -8.3636e-02,  ..., -4.5852e-02,
           3.4974e-02, -3.2396e-02],
         [-5.8594e-02, -1.1443e-01, -1.4887e-02,  ..., -3.4417e-02,
           2.2401e-02, -3.0141e-01],
         [-3.8286e-02,  6.4185e-03,  4.0513e-03,  ..., -2.4163e-02,
          -9.5552e-02, -6.9743e-02]],

        [[-1.4568e-01, -5.5136e-02, -1.2881e-01,  ..., -1.7925e-02,
           1.5129e-01, -1.6209e-02],
         [ 3.3415e-02, -9.8116e-02, -5.8517e-02,  ..., -3.5543e-02,
          -3.0526e-02, -2.9052e-02],
         [ 1.0982e-01, -1.6465e-02, -3.0891e-02,  ..., -8.6373e-02,
           1.3333e-01,  6.0936e-02],
         ...,
         [-1.1086e-02,  6.0040e-02, -2.2354e-02,  ..., -1.0500e-01,
           1.1842e-01,  1.8229e-01],
         [-2.8612e-02,  5.6795e-02, -1.1578e-01,  ..., -1.8675e-02,
          -8.1580e-03,  2.3988e-02],
         [-1.0733e-01,  1.6896e-02, -1.6582e-01,  ..., -5.7726e-03,
          -2.3254e-01,  1.8531e-02]]], grad_fn=<StackBackward0>), 'stoch': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [1., 0., 0.,  ..., 0., 0., 0.],
         [0., 1., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 1., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 1., 0.],
         [0., 1., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 1., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [1., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 1., 0., 0.]]])}
train_step: Starting state deter shape: torch.Size([16, 50, 128])
train_step: Starting state stoch shape: torch.Size([16, 50, 1024])
After ensuring logits/stoch: {'deter': tensor([[[-1.9107e-02, -4.6226e-02,  1.1742e-01,  ..., -2.6278e-02,
          -4.1729e-02, -7.2898e-02],
         [-1.2040e-01, -5.3884e-02,  4.4785e-02,  ...,  1.1616e-01,
           1.6936e-01,  7.3490e-03],
         [-1.3971e-01, -2.4909e-04,  2.6558e-02,  ..., -9.8025e-02,
          -1.4185e-01, -8.9354e-02],
         ...,
         [-6.8102e-03,  1.3878e-01, -7.6511e-02,  ...,  1.0299e-01,
           1.0560e-01,  1.7670e-01],
         [-1.5814e-01,  2.8932e-03, -2.1138e-02,  ...,  9.9884e-02,
          -1.2453e-02,  3.9327e-02],
         [ 1.4765e-01, -1.8151e-02, -4.4602e-02,  ...,  5.1193e-02,
          -3.0422e-02,  2.5983e-02]],

        [[-2.2505e-01, -1.4614e-01, -5.4082e-02,  ..., -7.7092e-02,
           6.5634e-02, -3.0132e-02],
         [-3.6947e-02, -8.4629e-02, -6.7409e-03,  ..., -1.2252e-01,
           5.2054e-02,  2.9556e-02],
         [ 2.7194e-02, -1.0567e-01, -1.8114e-01,  ...,  3.0348e-02,
           4.4100e-02, -2.5024e-01],
         ...,
         [-3.8581e-02, -2.7639e-02, -4.7807e-02,  ...,  2.0734e-01,
          -2.4588e-02, -4.8136e-02],
         [ 8.2808e-02,  1.0990e-02, -1.3178e-01,  ..., -8.1087e-03,
          -8.0986e-02, -1.1885e-01],
         [-1.1197e-01, -1.6791e-01, -9.4943e-02,  ..., -1.0211e-01,
           1.2124e-01, -7.2154e-02]],

        [[-1.2319e-01, -2.3423e-02, -1.7977e-02,  ...,  8.8870e-02,
           1.1525e-01, -1.3005e-01],
         [-4.2040e-02,  1.3244e-01, -7.5954e-02,  ..., -1.3359e-01,
          -1.0507e-01,  2.2691e-03],
         [-6.3900e-02,  2.5528e-02,  3.3649e-02,  ..., -1.4045e-01,
           1.8348e-01, -9.2773e-02],
         ...,
         [-1.0545e-02, -9.9873e-02,  1.2073e-01,  ...,  8.6451e-02,
          -9.3352e-03,  8.2541e-02],
         [ 8.1156e-02, -9.5993e-02,  6.5318e-02,  ..., -7.4027e-02,
           1.3986e-01, -6.0953e-02],
         [-7.2469e-02, -1.3213e-01,  6.0393e-02,  ..., -7.6299e-02,
          -5.5443e-02, -3.5069e-02]],

        ...,

        [[-5.2218e-02, -4.6901e-02, -1.1648e-02,  ...,  1.1820e-01,
          -1.9364e-01, -5.9870e-02],
         [-2.9035e-02,  1.7100e-02,  1.0245e-01,  ...,  9.5438e-03,
          -1.2093e-01, -2.7642e-02],
         [ 1.4072e-02,  2.8879e-02, -1.1897e-01,  ..., -2.1259e-01,
           6.7392e-02, -1.6834e-01],
         ...,
         [ 5.5824e-02,  6.2676e-02, -9.7869e-02,  ...,  7.2470e-03,
           2.2843e-02,  4.6740e-02],
         [-2.6173e-01, -2.0387e-02, -1.3663e-02,  ..., -6.1821e-02,
           1.4489e-01,  5.1699e-02],
         [-3.9072e-02, -1.0551e-01, -1.3073e-02,  ...,  1.1253e-01,
          -5.1878e-02, -9.2027e-02]],

        [[-3.3957e-03,  8.9548e-02,  8.9662e-03,  ...,  1.0278e-01,
          -3.3737e-02,  7.0651e-02],
         [-6.0904e-02, -7.5880e-02, -4.1782e-02,  ..., -1.1022e-01,
           3.5756e-02, -2.3964e-03],
         [-1.0494e-01, -1.8765e-01,  1.4748e-01,  ..., -1.7597e-01,
          -8.7838e-02, -5.0498e-02],
         ...,
         [-2.6364e-02, -2.2376e-01, -8.3636e-02,  ..., -4.5852e-02,
           3.4974e-02, -3.2396e-02],
         [-5.8594e-02, -1.1443e-01, -1.4887e-02,  ..., -3.4417e-02,
           2.2401e-02, -3.0141e-01],
         [-3.8286e-02,  6.4185e-03,  4.0513e-03,  ..., -2.4163e-02,
          -9.5552e-02, -6.9743e-02]],

        [[-1.4568e-01, -5.5136e-02, -1.2881e-01,  ..., -1.7925e-02,
           1.5129e-01, -1.6209e-02],
         [ 3.3415e-02, -9.8116e-02, -5.8517e-02,  ..., -3.5543e-02,
          -3.0526e-02, -2.9052e-02],
         [ 1.0982e-01, -1.6465e-02, -3.0891e-02,  ..., -8.6373e-02,
           1.3333e-01,  6.0936e-02],
         ...,
         [-1.1086e-02,  6.0040e-02, -2.2354e-02,  ..., -1.0500e-01,
           1.1842e-01,  1.8229e-01],
         [-2.8612e-02,  5.6795e-02, -1.1578e-01,  ..., -1.8675e-02,
          -8.1580e-03,  2.3988e-02],
         [-1.0733e-01,  1.6896e-02, -1.6582e-01,  ..., -5.7726e-03,
          -2.3254e-01,  1.8531e-02]]], grad_fn=<StackBackward0>), 'stoch': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [1., 0., 0.,  ..., 0., 0., 0.],
         [0., 1., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 1., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 1., 0.],
         [0., 1., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 1., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [1., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 1., 0., 0.]]]), 'logits': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]])}
train_step: Normalized hidden_state shape: torch.Size([1, 16, 128])
train_step: Normalized stoch shape: torch.Size([16, 1024])
train_step: Normalized deter shape: torch.Size([16, 128])
train_step: Post-imagine_trajectory: Imagined features shape: torch.Size([16, 15, 1152])
train_step: Post-imagine_trajectory: Imagined actions shape: torch.Size([16, 15, 2])
train_step: Post-imagine_trajectory: Imagined action indices shape: torch.Size([16, 15])
train_step: Post-imagine_trajectory: Imagined state deter shape: torch.Size([16, 15, 128])
train_step: Post-imagine_trajectory: Imagined state stoch shape: torch.Size([16, 15, 1024])
Reward shape: torch.Size([16, 15, 1]), Value shape: torch.Size([16, 15, 1]), Slow Value shape: torch.Size([16, 15, 1]), Discount shape: torch.Size([16, 15, 1, 1])
Return targets length: 15, First target shape: torch.Size([16, 16, 1])
train_step: Actor distribution shape: torch.Size([16, 15, 2])
train_step: Action log probabilities shape: torch.Size([16, 15])
train_step: Action log probabilities sample: tensor([[-1.1894, -0.9543],
        [-0.3321, -0.3879]], grad_fn=<SliceBackward0>)
train_step: Advantages shape: torch.Size([16, 15, 16, 15])
train_step: Advantages sample: tensor([[[[-4.0283, -4.0284, -4.0284, -4.0283, -4.0283, -4.0284, -4.0284,
           -4.0284, -4.0284, -4.0284, -4.0284, -4.0283, -4.0284, -4.0284,
           -4.0283],
          [-4.0283, -4.0284, -4.0284, -4.0283, -4.0283, -4.0284, -4.0284,
           -4.0284, -4.0284, -4.0284, -4.0284, -4.0283, -4.0284, -4.0284,
           -4.0283],
          [-4.0283, -4.0284, -4.0284, -4.0283, -4.0283, -4.0284, -4.0284,
           -4.0284, -4.0284, -4.0284, -4.0284, -4.0283, -4.0284, -4.0284,
           -4.0283],
          [-4.0283, -4.0284, -4.0284, -4.0283, -4.0283, -4.0284, -4.0284,
           -4.0284, -4.0284, -4.0284, -4.0284, -4.0283, -4.0284, -4.0284,
           -4.0283],
          [-4.0283, -4.0284, -4.0284, -4.0283, -4.0283, -4.0284, -4.0284,
           -4.0284, -4.0284, -4.0284, -4.0284, -4.0283, -4.0284, -4.0284,
           -4.0283],
          [-4.0283, -4.0284, -4.0284, -4.0283, -4.0283, -4.0284, -4.0284,
           -4.0284, -4.0284, -4.0284, -4.0284, -4.0283, -4.0284, -4.0284,
           -4.0283],
          [-4.0283, -4.0284, -4.0284, -4.0283, -4.0283, -4.0284, -4.0284,
           -4.0284, -4.0284, -4.0284, -4.0284, -4.0283, -4.0284, -4.0284,
           -4.0283],
          [-4.0283, -4.0284, -4.0284, -4.0283, -4.0283, -4.0284, -4.0284,
           -4.0284, -4.0284, -4.0284, -4.0284, -4.0283, -4.0284, -4.0284,
           -4.0283],
          [-4.0283, -4.0284, -4.0284, -4.0283, -4.0283, -4.0284, -4.0284,
           -4.0284, -4.0284, -4.0284, -4.0284, -4.0283, -4.0284, -4.0284,
           -4.0283],
          [-4.0283, -4.0284, -4.0284, -4.0283, -4.0283, -4.0284, -4.0284,
           -4.0284, -4.0284, -4.0284, -4.0284, -4.0283, -4.0284, -4.0284,
           -4.0283],
          [-4.0283, -4.0284, -4.0284, -4.0283, -4.0283, -4.0284, -4.0284,
           -4.0284, -4.0284, -4.0284, -4.0284, -4.0283, -4.0284, -4.0284,
           -4.0283],
          [-4.0283, -4.0284, -4.0284, -4.0283, -4.0283, -4.0284, -4.0284,
           -4.0284, -4.0284, -4.0284, -4.0284, -4.0283, -4.0284, -4.0284,
           -4.0283],
          [-4.0283, -4.0284, -4.0284, -4.0283, -4.0283, -4.0284, -4.0284,
           -4.0284, -4.0284, -4.0284, -4.0284, -4.0283, -4.0284, -4.0284,
           -4.0283],
          [-4.0283, -4.0284, -4.0284, -4.0283, -4.0283, -4.0284, -4.0284,
           -4.0284, -4.0284, -4.0284, -4.0284, -4.0283, -4.0284, -4.0284,
           -4.0283],
          [-4.0283, -4.0284, -4.0284, -4.0283, -4.0283, -4.0284, -4.0284,
           -4.0284, -4.0284, -4.0284, -4.0284, -4.0283, -4.0284, -4.0284,
           -4.0283],
          [-4.0283, -4.0284, -4.0284, -4.0283, -4.0283, -4.0284, -4.0284,
           -4.0284, -4.0284, -4.0284, -4.0284, -4.0283, -4.0284, -4.0284,
           -4.0283]],

         [[-3.9826, -3.9826, -3.9825, -3.9826, -3.9826, -3.9826, -3.9826,
           -3.9826, -3.9825, -3.9825, -3.9826, -3.9826, -3.9825, -3.9826,
           -3.9826],
          [-3.9826, -3.9826, -3.9825, -3.9826, -3.9826, -3.9826, -3.9826,
           -3.9826, -3.9825, -3.9825, -3.9826, -3.9826, -3.9825, -3.9826,
           -3.9826],
          [-3.9826, -3.9826, -3.9825, -3.9826, -3.9826, -3.9826, -3.9826,
           -3.9826, -3.9825, -3.9825, -3.9826, -3.9826, -3.9825, -3.9826,
           -3.9826],
          [-3.9826, -3.9826, -3.9825, -3.9826, -3.9826, -3.9826, -3.9826,
           -3.9826, -3.9825, -3.9825, -3.9826, -3.9826, -3.9825, -3.9826,
           -3.9826],
          [-3.9826, -3.9826, -3.9825, -3.9826, -3.9826, -3.9826, -3.9826,
           -3.9826, -3.9825, -3.9825, -3.9826, -3.9826, -3.9825, -3.9826,
           -3.9826],
          [-3.9826, -3.9826, -3.9825, -3.9826, -3.9826, -3.9826, -3.9826,
           -3.9826, -3.9825, -3.9825, -3.9826, -3.9826, -3.9825, -3.9826,
           -3.9826],
          [-3.9826, -3.9826, -3.9825, -3.9826, -3.9826, -3.9826, -3.9826,
           -3.9826, -3.9825, -3.9825, -3.9826, -3.9826, -3.9825, -3.9826,
           -3.9826],
          [-3.9826, -3.9826, -3.9825, -3.9826, -3.9826, -3.9826, -3.9826,
           -3.9826, -3.9825, -3.9825, -3.9826, -3.9826, -3.9825, -3.9826,
           -3.9826],
          [-3.9826, -3.9826, -3.9825, -3.9826, -3.9826, -3.9826, -3.9826,
           -3.9826, -3.9825, -3.9825, -3.9826, -3.9826, -3.9825, -3.9826,
           -3.9826],
          [-3.9826, -3.9826, -3.9825, -3.9826, -3.9826, -3.9826, -3.9826,
           -3.9826, -3.9825, -3.9825, -3.9826, -3.9826, -3.9825, -3.9826,
           -3.9826],
          [-3.9826, -3.9826, -3.9825, -3.9826, -3.9826, -3.9826, -3.9826,
           -3.9826, -3.9825, -3.9825, -3.9826, -3.9826, -3.9825, -3.9826,
           -3.9826],
          [-3.9826, -3.9826, -3.9825, -3.9826, -3.9826, -3.9826, -3.9826,
           -3.9826, -3.9825, -3.9825, -3.9826, -3.9826, -3.9825, -3.9826,
           -3.9826],
          [-3.9826, -3.9826, -3.9825, -3.9826, -3.9826, -3.9826, -3.9826,
           -3.9826, -3.9825, -3.9825, -3.9826, -3.9826, -3.9825, -3.9826,
           -3.9826],
          [-3.9826, -3.9826, -3.9825, -3.9826, -3.9826, -3.9826, -3.9826,
           -3.9826, -3.9825, -3.9825, -3.9826, -3.9826, -3.9825, -3.9826,
           -3.9826],
          [-3.9826, -3.9826, -3.9825, -3.9826, -3.9826, -3.9826, -3.9826,
           -3.9826, -3.9825, -3.9825, -3.9826, -3.9826, -3.9825, -3.9826,
           -3.9826],
          [-3.9826, -3.9826, -3.9825, -3.9826, -3.9826, -3.9826, -3.9826,
           -3.9826, -3.9825, -3.9825, -3.9826, -3.9826, -3.9825, -3.9826,
           -3.9826]]],


        [[[-8.1698, -8.1698, -8.1698, -8.1697, -8.1697, -8.1699, -8.1698,
           -8.1698, -8.1698, -8.1699, -8.1698, -8.1698, -8.1698, -8.1698,
           -8.1698],
          [-8.1698, -8.1698, -8.1698, -8.1697, -8.1697, -8.1699, -8.1698,
           -8.1698, -8.1698, -8.1699, -8.1698, -8.1698, -8.1698, -8.1698,
           -8.1698],
          [-8.1698, -8.1698, -8.1698, -8.1697, -8.1697, -8.1699, -8.1698,
           -8.1698, -8.1698, -8.1699, -8.1698, -8.1698, -8.1698, -8.1698,
           -8.1698],
          [-8.1698, -8.1698, -8.1698, -8.1697, -8.1697, -8.1699, -8.1698,
           -8.1698, -8.1698, -8.1699, -8.1698, -8.1698, -8.1698, -8.1698,
           -8.1698],
          [-8.1698, -8.1698, -8.1698, -8.1697, -8.1697, -8.1699, -8.1698,
           -8.1698, -8.1698, -8.1699, -8.1698, -8.1698, -8.1698, -8.1698,
           -8.1698],
          [-8.1698, -8.1698, -8.1698, -8.1697, -8.1697, -8.1699, -8.1698,
           -8.1698, -8.1698, -8.1699, -8.1698, -8.1698, -8.1698, -8.1698,
           -8.1698],
          [-8.1698, -8.1698, -8.1698, -8.1697, -8.1697, -8.1699, -8.1698,
           -8.1698, -8.1698, -8.1699, -8.1698, -8.1698, -8.1698, -8.1698,
           -8.1698],
          [-8.1698, -8.1698, -8.1698, -8.1697, -8.1697, -8.1699, -8.1698,
           -8.1698, -8.1698, -8.1699, -8.1698, -8.1698, -8.1698, -8.1698,
           -8.1698],
          [-8.1698, -8.1698, -8.1698, -8.1697, -8.1697, -8.1699, -8.1698,
           -8.1698, -8.1698, -8.1699, -8.1698, -8.1698, -8.1698, -8.1698,
           -8.1698],
          [-8.1698, -8.1698, -8.1698, -8.1697, -8.1697, -8.1699, -8.1698,
           -8.1698, -8.1698, -8.1699, -8.1698, -8.1698, -8.1698, -8.1698,
           -8.1698],
          [-8.1698, -8.1698, -8.1698, -8.1697, -8.1697, -8.1699, -8.1698,
           -8.1698, -8.1698, -8.1699, -8.1698, -8.1698, -8.1698, -8.1698,
           -8.1698],
          [-8.1698, -8.1698, -8.1698, -8.1697, -8.1697, -8.1699, -8.1698,
           -8.1698, -8.1698, -8.1699, -8.1698, -8.1698, -8.1698, -8.1698,
           -8.1698],
          [-8.1698, -8.1698, -8.1698, -8.1697, -8.1697, -8.1699, -8.1698,
           -8.1698, -8.1698, -8.1699, -8.1698, -8.1698, -8.1698, -8.1698,
           -8.1698],
          [-8.1698, -8.1698, -8.1698, -8.1697, -8.1697, -8.1699, -8.1698,
           -8.1698, -8.1698, -8.1699, -8.1698, -8.1698, -8.1698, -8.1698,
           -8.1698],
          [-8.1698, -8.1698, -8.1698, -8.1697, -8.1697, -8.1699, -8.1698,
           -8.1698, -8.1698, -8.1699, -8.1698, -8.1698, -8.1698, -8.1698,
           -8.1698],
          [-8.1698, -8.1698, -8.1698, -8.1697, -8.1697, -8.1699, -8.1698,
           -8.1698, -8.1698, -8.1699, -8.1698, -8.1698, -8.1698, -8.1698,
           -8.1698]],

         [[-7.6861, -7.6861, -7.6861, -7.6861, -7.6861, -7.6861, -7.6861,
           -7.6861, -7.6860, -7.6860, -7.6861, -7.6861, -7.6860, -7.6861,
           -7.6861],
          [-7.6861, -7.6861, -7.6861, -7.6861, -7.6861, -7.6861, -7.6861,
           -7.6861, -7.6860, -7.6860, -7.6861, -7.6861, -7.6860, -7.6861,
           -7.6861],
          [-7.6861, -7.6861, -7.6861, -7.6861, -7.6861, -7.6861, -7.6861,
           -7.6861, -7.6860, -7.6860, -7.6861, -7.6861, -7.6860, -7.6861,
           -7.6861],
          [-7.6861, -7.6861, -7.6861, -7.6861, -7.6861, -7.6861, -7.6861,
           -7.6861, -7.6860, -7.6860, -7.6861, -7.6861, -7.6860, -7.6861,
           -7.6861],
          [-7.6861, -7.6861, -7.6861, -7.6861, -7.6861, -7.6861, -7.6861,
           -7.6861, -7.6860, -7.6860, -7.6861, -7.6861, -7.6860, -7.6861,
           -7.6861],
          [-7.6861, -7.6861, -7.6861, -7.6861, -7.6861, -7.6861, -7.6861,
           -7.6861, -7.6860, -7.6860, -7.6861, -7.6861, -7.6860, -7.6861,
           -7.6861],
          [-7.6861, -7.6861, -7.6861, -7.6861, -7.6861, -7.6861, -7.6861,
           -7.6861, -7.6860, -7.6860, -7.6861, -7.6861, -7.6860, -7.6861,
           -7.6861],
          [-7.6861, -7.6861, -7.6861, -7.6861, -7.6861, -7.6861, -7.6861,
           -7.6861, -7.6860, -7.6860, -7.6861, -7.6861, -7.6860, -7.6861,
           -7.6861],
          [-7.6861, -7.6861, -7.6861, -7.6861, -7.6861, -7.6861, -7.6861,
           -7.6861, -7.6860, -7.6860, -7.6861, -7.6861, -7.6860, -7.6861,
           -7.6861],
          [-7.6861, -7.6861, -7.6861, -7.6861, -7.6861, -7.6861, -7.6861,
           -7.6861, -7.6860, -7.6860, -7.6861, -7.6861, -7.6860, -7.6861,
           -7.6861],
          [-7.6861, -7.6861, -7.6861, -7.6861, -7.6861, -7.6861, -7.6861,
           -7.6861, -7.6860, -7.6860, -7.6861, -7.6861, -7.6860, -7.6861,
           -7.6861],
          [-7.6861, -7.6861, -7.6861, -7.6861, -7.6861, -7.6861, -7.6861,
           -7.6861, -7.6860, -7.6860, -7.6861, -7.6861, -7.6860, -7.6861,
           -7.6861],
          [-7.6861, -7.6861, -7.6861, -7.6861, -7.6861, -7.6861, -7.6861,
           -7.6861, -7.6860, -7.6860, -7.6861, -7.6861, -7.6860, -7.6861,
           -7.6861],
          [-7.6861, -7.6861, -7.6861, -7.6861, -7.6861, -7.6861, -7.6861,
           -7.6861, -7.6860, -7.6860, -7.6861, -7.6861, -7.6860, -7.6861,
           -7.6861],
          [-7.6861, -7.6861, -7.6861, -7.6861, -7.6861, -7.6861, -7.6861,
           -7.6861, -7.6860, -7.6860, -7.6861, -7.6861, -7.6860, -7.6861,
           -7.6861],
          [-7.6861, -7.6861, -7.6861, -7.6861, -7.6861, -7.6861, -7.6861,
           -7.6861, -7.6860, -7.6860, -7.6861, -7.6861, -7.6860, -7.6861,
           -7.6861]]]], grad_fn=<SliceBackward0>)
train_step: Return scale: 1.847573610158122
train_step: Scaled advantages shape: torch.Size([16, 15, 16, 15])
train_step: Scaled advantages sample: tensor([[[[-2.1803, -2.1804, -2.1804, -2.1803, -2.1803, -2.1804, -2.1804,
           -2.1804, -2.1804, -2.1804, -2.1804, -2.1803, -2.1804, -2.1804,
           -2.1803],
          [-2.1803, -2.1804, -2.1804, -2.1803, -2.1803, -2.1804, -2.1804,
           -2.1804, -2.1804, -2.1804, -2.1804, -2.1803, -2.1804, -2.1804,
           -2.1803],
          [-2.1803, -2.1804, -2.1804, -2.1803, -2.1803, -2.1804, -2.1804,
           -2.1804, -2.1804, -2.1804, -2.1804, -2.1803, -2.1804, -2.1804,
           -2.1803],
          [-2.1803, -2.1804, -2.1804, -2.1803, -2.1803, -2.1804, -2.1804,
           -2.1804, -2.1804, -2.1804, -2.1804, -2.1803, -2.1804, -2.1804,
           -2.1803],
          [-2.1803, -2.1804, -2.1804, -2.1803, -2.1803, -2.1804, -2.1804,
           -2.1804, -2.1804, -2.1804, -2.1804, -2.1803, -2.1804, -2.1804,
           -2.1803],
          [-2.1803, -2.1804, -2.1804, -2.1803, -2.1803, -2.1804, -2.1804,
           -2.1804, -2.1804, -2.1804, -2.1804, -2.1803, -2.1804, -2.1804,
           -2.1803],
          [-2.1803, -2.1804, -2.1804, -2.1803, -2.1803, -2.1804, -2.1804,
           -2.1804, -2.1804, -2.1804, -2.1804, -2.1803, -2.1804, -2.1804,
           -2.1803],
          [-2.1803, -2.1804, -2.1804, -2.1803, -2.1803, -2.1804, -2.1804,
           -2.1804, -2.1804, -2.1804, -2.1804, -2.1803, -2.1804, -2.1804,
           -2.1803],
          [-2.1803, -2.1804, -2.1804, -2.1803, -2.1803, -2.1804, -2.1804,
           -2.1804, -2.1804, -2.1804, -2.1804, -2.1803, -2.1804, -2.1804,
           -2.1803],
          [-2.1803, -2.1804, -2.1804, -2.1803, -2.1803, -2.1804, -2.1804,
           -2.1804, -2.1804, -2.1804, -2.1804, -2.1803, -2.1804, -2.1804,
           -2.1803],
          [-2.1803, -2.1804, -2.1804, -2.1803, -2.1803, -2.1804, -2.1804,
           -2.1804, -2.1804, -2.1804, -2.1804, -2.1803, -2.1804, -2.1804,
           -2.1803],
          [-2.1803, -2.1804, -2.1804, -2.1803, -2.1803, -2.1804, -2.1804,
           -2.1804, -2.1804, -2.1804, -2.1804, -2.1803, -2.1804, -2.1804,
           -2.1803],
          [-2.1803, -2.1804, -2.1804, -2.1803, -2.1803, -2.1804, -2.1804,
           -2.1804, -2.1804, -2.1804, -2.1804, -2.1803, -2.1804, -2.1804,
           -2.1803],
          [-2.1803, -2.1804, -2.1804, -2.1803, -2.1803, -2.1804, -2.1804,
           -2.1804, -2.1804, -2.1804, -2.1804, -2.1803, -2.1804, -2.1804,
           -2.1803],
          [-2.1803, -2.1804, -2.1804, -2.1803, -2.1803, -2.1804, -2.1804,
           -2.1804, -2.1804, -2.1804, -2.1804, -2.1803, -2.1804, -2.1804,
           -2.1803],
          [-2.1803, -2.1804, -2.1804, -2.1803, -2.1803, -2.1804, -2.1804,
           -2.1804, -2.1804, -2.1804, -2.1804, -2.1803, -2.1804, -2.1804,
           -2.1803]],

         [[-2.1556, -2.1556, -2.1556, -2.1556, -2.1556, -2.1556, -2.1556,
           -2.1556, -2.1555, -2.1555, -2.1556, -2.1556, -2.1555, -2.1556,
           -2.1556],
          [-2.1556, -2.1556, -2.1556, -2.1556, -2.1556, -2.1556, -2.1556,
           -2.1556, -2.1555, -2.1555, -2.1556, -2.1556, -2.1555, -2.1556,
           -2.1556],
          [-2.1556, -2.1556, -2.1556, -2.1556, -2.1556, -2.1556, -2.1556,
           -2.1556, -2.1555, -2.1555, -2.1556, -2.1556, -2.1555, -2.1556,
           -2.1556],
          [-2.1556, -2.1556, -2.1556, -2.1556, -2.1556, -2.1556, -2.1556,
           -2.1556, -2.1555, -2.1555, -2.1556, -2.1556, -2.1555, -2.1556,
           -2.1556],
          [-2.1556, -2.1556, -2.1556, -2.1556, -2.1556, -2.1556, -2.1556,
           -2.1556, -2.1555, -2.1555, -2.1556, -2.1556, -2.1555, -2.1556,
           -2.1556],
          [-2.1556, -2.1556, -2.1556, -2.1556, -2.1556, -2.1556, -2.1556,
           -2.1556, -2.1555, -2.1555, -2.1556, -2.1556, -2.1555, -2.1556,
           -2.1556],
          [-2.1556, -2.1556, -2.1556, -2.1556, -2.1556, -2.1556, -2.1556,
           -2.1556, -2.1555, -2.1555, -2.1556, -2.1556, -2.1555, -2.1556,
           -2.1556],
          [-2.1556, -2.1556, -2.1556, -2.1556, -2.1556, -2.1556, -2.1556,
           -2.1556, -2.1555, -2.1555, -2.1556, -2.1556, -2.1555, -2.1556,
           -2.1556],
          [-2.1556, -2.1556, -2.1556, -2.1556, -2.1556, -2.1556, -2.1556,
           -2.1556, -2.1555, -2.1555, -2.1556, -2.1556, -2.1555, -2.1556,
           -2.1556],
          [-2.1556, -2.1556, -2.1556, -2.1556, -2.1556, -2.1556, -2.1556,
           -2.1556, -2.1555, -2.1555, -2.1556, -2.1556, -2.1555, -2.1556,
           -2.1556],
          [-2.1556, -2.1556, -2.1556, -2.1556, -2.1556, -2.1556, -2.1556,
           -2.1556, -2.1555, -2.1555, -2.1556, -2.1556, -2.1555, -2.1556,
           -2.1556],
          [-2.1556, -2.1556, -2.1556, -2.1556, -2.1556, -2.1556, -2.1556,
           -2.1556, -2.1555, -2.1555, -2.1556, -2.1556, -2.1555, -2.1556,
           -2.1556],
          [-2.1556, -2.1556, -2.1556, -2.1556, -2.1556, -2.1556, -2.1556,
           -2.1556, -2.1555, -2.1555, -2.1556, -2.1556, -2.1555, -2.1556,
           -2.1556],
          [-2.1556, -2.1556, -2.1556, -2.1556, -2.1556, -2.1556, -2.1556,
           -2.1556, -2.1555, -2.1555, -2.1556, -2.1556, -2.1555, -2.1556,
           -2.1556],
          [-2.1556, -2.1556, -2.1556, -2.1556, -2.1556, -2.1556, -2.1556,
           -2.1556, -2.1555, -2.1555, -2.1556, -2.1556, -2.1555, -2.1556,
           -2.1556],
          [-2.1556, -2.1556, -2.1556, -2.1556, -2.1556, -2.1556, -2.1556,
           -2.1556, -2.1555, -2.1555, -2.1556, -2.1556, -2.1555, -2.1556,
           -2.1556]]],


        [[[-4.4219, -4.4219, -4.4219, -4.4219, -4.4219, -4.4219, -4.4219,
           -4.4219, -4.4219, -4.4219, -4.4219, -4.4219, -4.4219, -4.4219,
           -4.4219],
          [-4.4219, -4.4219, -4.4219, -4.4219, -4.4219, -4.4219, -4.4219,
           -4.4219, -4.4219, -4.4219, -4.4219, -4.4219, -4.4219, -4.4219,
           -4.4219],
          [-4.4219, -4.4219, -4.4219, -4.4219, -4.4219, -4.4219, -4.4219,
           -4.4219, -4.4219, -4.4219, -4.4219, -4.4219, -4.4219, -4.4219,
           -4.4219],
          [-4.4219, -4.4219, -4.4219, -4.4219, -4.4219, -4.4219, -4.4219,
           -4.4219, -4.4219, -4.4219, -4.4219, -4.4219, -4.4219, -4.4219,
           -4.4219],
          [-4.4219, -4.4219, -4.4219, -4.4219, -4.4219, -4.4219, -4.4219,
           -4.4219, -4.4219, -4.4219, -4.4219, -4.4219, -4.4219, -4.4219,
           -4.4219],
          [-4.4219, -4.4219, -4.4219, -4.4219, -4.4219, -4.4219, -4.4219,
           -4.4219, -4.4219, -4.4219, -4.4219, -4.4219, -4.4219, -4.4219,
           -4.4219],
          [-4.4219, -4.4219, -4.4219, -4.4219, -4.4219, -4.4219, -4.4219,
           -4.4219, -4.4219, -4.4219, -4.4219, -4.4219, -4.4219, -4.4219,
           -4.4219],
          [-4.4219, -4.4219, -4.4219, -4.4219, -4.4219, -4.4219, -4.4219,
           -4.4219, -4.4219, -4.4219, -4.4219, -4.4219, -4.4219, -4.4219,
           -4.4219],
          [-4.4219, -4.4219, -4.4219, -4.4219, -4.4219, -4.4219, -4.4219,
           -4.4219, -4.4219, -4.4219, -4.4219, -4.4219, -4.4219, -4.4219,
           -4.4219],
          [-4.4219, -4.4219, -4.4219, -4.4219, -4.4219, -4.4219, -4.4219,
           -4.4219, -4.4219, -4.4219, -4.4219, -4.4219, -4.4219, -4.4219,
           -4.4219],
          [-4.4219, -4.4219, -4.4219, -4.4219, -4.4219, -4.4219, -4.4219,
           -4.4219, -4.4219, -4.4219, -4.4219, -4.4219, -4.4219, -4.4219,
           -4.4219],
          [-4.4219, -4.4219, -4.4219, -4.4219, -4.4219, -4.4219, -4.4219,
           -4.4219, -4.4219, -4.4219, -4.4219, -4.4219, -4.4219, -4.4219,
           -4.4219],
          [-4.4219, -4.4219, -4.4219, -4.4219, -4.4219, -4.4219, -4.4219,
           -4.4219, -4.4219, -4.4219, -4.4219, -4.4219, -4.4219, -4.4219,
           -4.4219],
          [-4.4219, -4.4219, -4.4219, -4.4219, -4.4219, -4.4219, -4.4219,
           -4.4219, -4.4219, -4.4219, -4.4219, -4.4219, -4.4219, -4.4219,
           -4.4219],
          [-4.4219, -4.4219, -4.4219, -4.4219, -4.4219, -4.4219, -4.4219,
           -4.4219, -4.4219, -4.4219, -4.4219, -4.4219, -4.4219, -4.4219,
           -4.4219],
          [-4.4219, -4.4219, -4.4219, -4.4219, -4.4219, -4.4219, -4.4219,
           -4.4219, -4.4219, -4.4219, -4.4219, -4.4219, -4.4219, -4.4219,
           -4.4219]],

         [[-4.1601, -4.1601, -4.1601, -4.1601, -4.1601, -4.1601, -4.1601,
           -4.1601, -4.1601, -4.1601, -4.1601, -4.1601, -4.1601, -4.1601,
           -4.1601],
          [-4.1601, -4.1601, -4.1601, -4.1601, -4.1601, -4.1601, -4.1601,
           -4.1601, -4.1601, -4.1601, -4.1601, -4.1601, -4.1601, -4.1601,
           -4.1601],
          [-4.1601, -4.1601, -4.1601, -4.1601, -4.1601, -4.1601, -4.1601,
           -4.1601, -4.1601, -4.1601, -4.1601, -4.1601, -4.1601, -4.1601,
           -4.1601],
          [-4.1601, -4.1601, -4.1601, -4.1601, -4.1601, -4.1601, -4.1601,
           -4.1601, -4.1601, -4.1601, -4.1601, -4.1601, -4.1601, -4.1601,
           -4.1601],
          [-4.1601, -4.1601, -4.1601, -4.1601, -4.1601, -4.1601, -4.1601,
           -4.1601, -4.1601, -4.1601, -4.1601, -4.1601, -4.1601, -4.1601,
           -4.1601],
          [-4.1601, -4.1601, -4.1601, -4.1601, -4.1601, -4.1601, -4.1601,
           -4.1601, -4.1601, -4.1601, -4.1601, -4.1601, -4.1601, -4.1601,
           -4.1601],
          [-4.1601, -4.1601, -4.1601, -4.1601, -4.1601, -4.1601, -4.1601,
           -4.1601, -4.1601, -4.1601, -4.1601, -4.1601, -4.1601, -4.1601,
           -4.1601],
          [-4.1601, -4.1601, -4.1601, -4.1601, -4.1601, -4.1601, -4.1601,
           -4.1601, -4.1601, -4.1601, -4.1601, -4.1601, -4.1601, -4.1601,
           -4.1601],
          [-4.1601, -4.1601, -4.1601, -4.1601, -4.1601, -4.1601, -4.1601,
           -4.1601, -4.1601, -4.1601, -4.1601, -4.1601, -4.1601, -4.1601,
           -4.1601],
          [-4.1601, -4.1601, -4.1601, -4.1601, -4.1601, -4.1601, -4.1601,
           -4.1601, -4.1601, -4.1601, -4.1601, -4.1601, -4.1601, -4.1601,
           -4.1601],
          [-4.1601, -4.1601, -4.1601, -4.1601, -4.1601, -4.1601, -4.1601,
           -4.1601, -4.1601, -4.1601, -4.1601, -4.1601, -4.1601, -4.1601,
           -4.1601],
          [-4.1601, -4.1601, -4.1601, -4.1601, -4.1601, -4.1601, -4.1601,
           -4.1601, -4.1601, -4.1601, -4.1601, -4.1601, -4.1601, -4.1601,
           -4.1601],
          [-4.1601, -4.1601, -4.1601, -4.1601, -4.1601, -4.1601, -4.1601,
           -4.1601, -4.1601, -4.1601, -4.1601, -4.1601, -4.1601, -4.1601,
           -4.1601],
          [-4.1601, -4.1601, -4.1601, -4.1601, -4.1601, -4.1601, -4.1601,
           -4.1601, -4.1601, -4.1601, -4.1601, -4.1601, -4.1601, -4.1601,
           -4.1601],
          [-4.1601, -4.1601, -4.1601, -4.1601, -4.1601, -4.1601, -4.1601,
           -4.1601, -4.1601, -4.1601, -4.1601, -4.1601, -4.1601, -4.1601,
           -4.1601],
          [-4.1601, -4.1601, -4.1601, -4.1601, -4.1601, -4.1601, -4.1601,
           -4.1601, -4.1601, -4.1601, -4.1601, -4.1601, -4.1601, -4.1601,
           -4.1601]]]], grad_fn=<SliceBackward0>)
train_step: Entropy shape: torch.Size([16, 15])
train_step: Entropy sample: tensor([[0.6145, 0.6665],
        [0.5953, 0.6280]], grad_fn=<SliceBackward0>)
train_step: Entropy coefficient: 0.01
train_step: Actor loss: -1.1601536273956299
train_step: returns shape after mean: torch.Size([16, 15])
train_step: target_indices shape: torch.Size([16, 15])
train_step: value_logits shape: torch.Size([16, 15, 255])
train_step: target_twohot shape: torch.Size([16, 15, 255])
