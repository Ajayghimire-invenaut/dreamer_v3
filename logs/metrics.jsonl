{"step": 1397, "model/total_parameters": 102063808.0, "model/parameters/world_model": 93932224.0, "model/parameters/task_behavior": 8131584.0, "frames_per_second": 0.0}
{"step": 0, "model/total_parameters": 102063808.0, "model/parameters/world_model": 93932224.0, "model/parameters/task_behavior": 8131584.0, "frames_per_second": 0.0}
{"step": 1, "evaluation/episode_1_reward": 18.0, "evaluation/episode_1_length": 18.0, "environment/episode_return": 8.0, "environment/mean_episode_return": 12.1, "environment/median_episode_return": 11.5, "evaluation/episode_2_reward": 8.0, "evaluation/episode_2_length": 8.0, "evaluation/episode_3_reward": 15.0, "evaluation/episode_3_length": 15.0, "evaluation/episode_4_reward": 9.0, "evaluation/episode_4_length": 9.0, "evaluation/episode_5_reward": 10.0, "evaluation/episode_5_length": 10.0, "evaluation/episode_6_reward": 11.0, "evaluation/episode_6_length": 11.0, "evaluation/episode_7_reward": 18.0, "evaluation/episode_7_length": 18.0, "evaluation/episode_8_reward": 12.0, "evaluation/episode_8_length": 12.0, "evaluation/episode_9_reward": 12.0, "evaluation/episode_9_length": 12.0, "evaluation/episode_10_reward": 8.0, "evaluation/episode_10_length": 8.0, "evaluation/average_reward": 12.1, "evaluation/average_length": 12.1, "evaluation/reward_std": 3.5623026261113755}
{"step": 590, "model/total_parameters": 102063808.0, "model/parameters/world_model": 93932224.0, "model/parameters/task_behavior": 8131584.0, "frames_per_second": 0.0}
{"step": 1068, "model/total_parameters": 102063808.0, "model/parameters/world_model": 93932224.0, "model/parameters/task_behavior": 8131584.0, "frames_per_second": 0.0}
{"step": 1326, "model/total_parameters": 62800768.0, "model/parameters/world_model": 61942528.0, "model/parameters/task_behavior": 858240.0, "evaluation/episode_1_reward": 10.0, "evaluation/episode_1_length": 10.0, "environment/episode_return": 16.0, "environment/mean_episode_return": 21.3, "environment/median_episode_return": 17.5, "evaluation/episode_2_reward": 15.0, "evaluation/episode_2_length": 15.0, "evaluation/episode_3_reward": 12.0, "evaluation/episode_3_length": 12.0, "evaluation/episode_4_reward": 42.0, "evaluation/episode_4_length": 42.0, "evaluation/episode_5_reward": 24.0, "evaluation/episode_5_length": 24.0, "evaluation/episode_6_reward": 19.0, "evaluation/episode_6_length": 19.0, "evaluation/episode_7_reward": 24.0, "evaluation/episode_7_length": 24.0, "evaluation/episode_8_reward": 39.0, "evaluation/episode_8_length": 39.0, "evaluation/episode_9_reward": 12.0, "evaluation/episode_9_length": 12.0, "evaluation/episode_10_reward": 16.0, "evaluation/episode_10_length": 16.0, "evaluation/average_reward": 21.3, "evaluation/average_length": 21.3, "evaluation/reward_standard_deviation": 10.630616162763097}
{"step": 1090, "model/total_parameters": 20604198.0, "model/parameters/world_model": 19943718.0, "model/parameters/task_behavior": 660480.0, "evaluation/episode_1_reward": 8.0, "evaluation/episode_1_length": 8.0, "environment/episode_return": 8.0, "environment/mean_episode_return": 8.0, "environment/median_episode_return": 8.0, "evaluation/episode_2_reward": 8.0, "evaluation/episode_2_length": 8.0, "evaluation/episode_3_reward": 8.0, "evaluation/episode_3_length": 8.0, "evaluation/episode_4_reward": 8.0, "evaluation/episode_4_length": 8.0, "evaluation/episode_5_reward": 8.0, "evaluation/episode_5_length": 8.0, "evaluation/episode_6_reward": 8.0, "evaluation/episode_6_length": 8.0, "evaluation/episode_7_reward": 8.0, "evaluation/episode_7_length": 8.0, "evaluation/episode_8_reward": 8.0, "evaluation/episode_8_length": 8.0, "evaluation/episode_9_reward": 8.0, "evaluation/episode_9_length": 8.0, "evaluation/episode_10_reward": 8.0, "evaluation/episode_10_length": 8.0, "evaluation/average_reward": 8.0, "evaluation/average_length": 8.0, "evaluation/reward_standard_deviation": 0.0}
{"step": 1090, "model/total_parameters": 20604198.0, "model/parameters/world_model": 19943718.0, "model/parameters/task_behavior": 660480.0, "evaluation/episode_1_reward": 8.0, "evaluation/episode_1_length": 8.0, "environment/episode_return": 8.0, "environment/mean_episode_return": 8.0, "environment/median_episode_return": 8.0, "evaluation/episode_2_reward": 8.0, "evaluation/episode_2_length": 8.0, "evaluation/episode_3_reward": 8.0, "evaluation/episode_3_length": 8.0, "evaluation/episode_4_reward": 8.0, "evaluation/episode_4_length": 8.0, "evaluation/episode_5_reward": 8.0, "evaluation/episode_5_length": 8.0, "evaluation/episode_6_reward": 8.0, "evaluation/episode_6_length": 8.0, "evaluation/episode_7_reward": 8.0, "evaluation/episode_7_length": 8.0, "evaluation/episode_8_reward": 8.0, "evaluation/episode_8_length": 8.0, "evaluation/episode_9_reward": 8.0, "evaluation/episode_9_length": 8.0, "evaluation/episode_10_reward": 8.0, "evaluation/episode_10_length": 8.0, "evaluation/average_reward": 8.0, "evaluation/average_length": 8.0, "evaluation/reward_standard_deviation": 0.0}
{"step": 1090, "model/total_parameters": 20604198.0, "model/parameters/world_model": 19943718.0, "model/parameters/task_behavior": 660480.0, "evaluation/episode_1_reward": 8.0, "evaluation/episode_1_length": 8.0, "environment/episode_return": 8.0, "environment/mean_episode_return": 8.0, "environment/median_episode_return": 8.0, "evaluation/episode_2_reward": 8.0, "evaluation/episode_2_length": 8.0, "evaluation/episode_3_reward": 8.0, "evaluation/episode_3_length": 8.0, "evaluation/episode_4_reward": 8.0, "evaluation/episode_4_length": 8.0, "evaluation/episode_5_reward": 8.0, "evaluation/episode_5_length": 8.0, "evaluation/episode_6_reward": 8.0, "evaluation/episode_6_length": 8.0, "evaluation/episode_7_reward": 8.0, "evaluation/episode_7_length": 8.0, "evaluation/episode_8_reward": 8.0, "evaluation/episode_8_length": 8.0, "evaluation/episode_9_reward": 8.0, "evaluation/episode_9_length": 8.0, "evaluation/episode_10_reward": 8.0, "evaluation/episode_10_length": 8.0, "evaluation/average_reward": 8.0, "evaluation/average_length": 8.0, "evaluation/reward_standard_deviation": 0.0}
{"step": 1090, "model/total_parameters": 20604198.0, "model/parameters/world_model": 19943718.0, "model/parameters/task_behavior": 660480.0, "evaluation/episode_1_reward": 8.0, "evaluation/episode_1_length": 8.0, "environment/episode_return": 8.0, "environment/mean_episode_return": 8.0, "environment/median_episode_return": 8.0, "evaluation/episode_2_reward": 8.0, "evaluation/episode_2_length": 8.0, "evaluation/episode_3_reward": 8.0, "evaluation/episode_3_length": 8.0, "evaluation/episode_4_reward": 8.0, "evaluation/episode_4_length": 8.0, "evaluation/episode_5_reward": 8.0, "evaluation/episode_5_length": 8.0, "evaluation/episode_6_reward": 8.0, "evaluation/episode_6_length": 8.0, "evaluation/episode_7_reward": 8.0, "evaluation/episode_7_length": 8.0, "evaluation/episode_8_reward": 8.0, "evaluation/episode_8_length": 8.0, "evaluation/episode_9_reward": 8.0, "evaluation/episode_9_length": 8.0, "evaluation/episode_10_reward": 8.0, "evaluation/episode_10_length": 8.0, "evaluation/average_reward": 8.0, "evaluation/average_length": 8.0, "evaluation/reward_standard_deviation": 0.0}
